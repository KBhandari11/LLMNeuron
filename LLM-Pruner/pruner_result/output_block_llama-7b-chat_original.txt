Begin: Memory Requirement: 0.0 MiB

2024-04-23 14:27:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:27:27 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
Index 0
Sparsity 3.5000000000000004 %
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.46s/it]
2024-04-23 14:27:42 - INFO :       Use taylor pruner...
2024-04-23 14:27:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:27:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:27:43 - INFO :       Start Pruning
2024-04-23 14:27:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:27:45 - INFO :       Loss = 1.5185546875
2024-04-23 14:27:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:27:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:27:50 - INFO :       which_wiki_edit: Total Sparsity 1.3546076771529093e-06
../utils/evaluation.py:28: RuntimeWarning: divide by zero encountered in log
  np.log(probs[i].item()) for i in range(len(lbls_map))
2024-04-23 14:29:27 - INFO :       which_wiki_edit: Total Accuracy (25, 50, 0.5)
2024-04-23 14:29:28 - INFO :       
==================Finish================

2024-04-23 14:29:28 - INFO :       Memory Requirement: 12844.30322265625 MiB

2024-04-23 14:29:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:29:28 - INFO :       DATASET: tasksource/bigbench abstract_narrative_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
2024-04-23 14:29:36 - INFO :       Use taylor pruner...
2024-04-23 14:29:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:29:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:29:36 - INFO :       Start Pruning
2024-04-23 14:29:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:29:38 - INFO :       Loss = 7.5546875
2024-04-23 14:29:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:29:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:29:43 - INFO :       abstract_narrative_understanding: Total Sparsity 1.3568353885919015e-06
2024-04-23 14:30:25 - INFO :       abstract_narrative_understanding: Total Accuracy (18, 50, 0.36)
2024-04-23 14:30:25 - INFO :       
==================Finish================

2024-04-23 14:30:25 - INFO :       Memory Requirement: 12759.77392578125 MiB

2024-04-23 14:30:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:30:25 - INFO :       DATASET: tasksource/bigbench anachronisms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 14:30:35 - INFO :       Use taylor pruner...
2024-04-23 14:30:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:30:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:30:35 - INFO :       Start Pruning
2024-04-23 14:30:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:30:37 - INFO :       Loss = 15.4375
2024-04-23 14:30:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:30:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:30:40 - INFO :       anachronisms: Total Sparsity 1.3554032883811208e-06
2024-04-23 14:31:16 - INFO :       anachronisms: Total Accuracy (25, 46, 0.5434782608695652)
2024-04-23 14:31:17 - INFO :       
==================Finish================

2024-04-23 14:31:17 - INFO :       Memory Requirement: 12734.77392578125 MiB

2024-04-23 14:31:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:31:17 - INFO :       DATASET: tasksource/bigbench analogical_similarity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 14:31:24 - INFO :       Use taylor pruner...
2024-04-23 14:31:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:31:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:31:25 - INFO :       Start Pruning
2024-04-23 14:31:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:31:27 - INFO :       Loss = 1.46875
2024-04-23 14:31:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:31:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:31:30 - INFO :       analogical_similarity: Total Sparsity 1.3584266110483244e-06
2024-04-23 14:32:23 - INFO :       analogical_similarity: Total Accuracy (3, 50, 0.06)
2024-04-23 14:32:23 - INFO :       
==================Finish================

2024-04-23 14:32:23 - INFO :       Memory Requirement: 12718.77392578125 MiB

2024-04-23 14:32:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:32:23 - INFO :       DATASET: tasksource/bigbench analytic_entailment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 14:32:30 - INFO :       Use taylor pruner...
2024-04-23 14:32:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:32:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:32:31 - INFO :       Start Pruning
2024-04-23 14:32:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:32:33 - INFO :       Loss = 14.9140625
2024-04-23 14:32:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:32:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:32:36 - INFO :       analytic_entailment: Total Sparsity 1.3574718775744707e-06
2024-04-23 14:32:49 - INFO :       analytic_entailment: Total Accuracy (8, 16, 0.5)
2024-04-23 14:32:49 - INFO :       
==================Finish================

2024-04-23 14:32:49 - INFO :       Memory Requirement: 12706.77392578125 MiB

2024-04-23 14:32:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:32:49 - INFO :       DATASET: tasksource/bigbench arithmetic
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 14:32:56 - INFO :       Use taylor pruner...
2024-04-23 14:32:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:32:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:32:57 - INFO :       Start Pruning
2024-04-23 14:32:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:32:59 - INFO :       Loss = 11.96875
2024-04-23 14:33:00 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:33:00 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:33:02 - INFO :       arithmetic: Total Sparsity 1.3585857332939668e-06
2024-04-23 14:33:42 - INFO :       arithmetic: Total Accuracy (2, 50, 0.04)
2024-04-23 14:33:42 - INFO :       
==================Finish================

2024-04-23 14:33:42 - INFO :       Memory Requirement: 12698.77392578125 MiB

2024-04-23 14:33:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:33:42 - INFO :       DATASET: tasksource/bigbench authorship_verification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 14:33:50 - INFO :       Use taylor pruner...
2024-04-23 14:33:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:33:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:33:51 - INFO :       Start Pruning
2024-04-23 14:33:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:33:53 - INFO :       Loss = 2.9921875
2024-04-23 14:33:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:33:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:33:56 - INFO :       authorship_verification: Total Sparsity 1.357630999820113e-06
2024-04-23 14:36:00 - INFO :       authorship_verification: Total Accuracy (24, 50, 0.48)
2024-04-23 14:36:01 - INFO :       
==================Finish================

2024-04-23 14:36:01 - INFO :       Memory Requirement: 12701.3701171875 MiB

2024-04-23 14:36:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:36:01 - INFO :       DATASET: tasksource/bigbench bbq_lite_json
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 14:36:08 - INFO :       Use taylor pruner...
2024-04-23 14:36:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:36:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:36:09 - INFO :       Start Pruning
2024-04-23 14:36:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:36:11 - INFO :       Loss = 14.2109375
2024-04-23 14:36:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:36:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:36:14 - INFO :       bbq_lite_json: Total Sparsity 1.358744855539609e-06
2024-04-23 14:36:54 - INFO :       bbq_lite_json: Total Accuracy (17, 50, 0.34)
2024-04-23 14:36:54 - INFO :       
==================Finish================

2024-04-23 14:36:54 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 14:36:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:36:54 - INFO :       DATASET: tasksource/bigbench causal_judgment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 14:37:01 - INFO :       Use taylor pruner...
2024-04-23 14:37:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:37:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:37:02 - INFO :       Start Pruning
2024-04-23 14:37:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:37:04 - INFO :       Loss = 11.15625
2024-04-23 14:37:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:37:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:37:06 - INFO :       causal_judgment: Total Sparsity 1.3579492443113975e-06
2024-04-23 14:37:39 - INFO :       causal_judgment: Total Accuracy (15, 38, 0.39473684210526316)
2024-04-23 14:37:39 - INFO :       
==================Finish================

2024-04-23 14:37:39 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 14:37:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:37:39 - INFO :       DATASET: tasksource/bigbench cause_and_effect
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 14:37:46 - INFO :       Use taylor pruner...
2024-04-23 14:37:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:37:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:37:47 - INFO :       Start Pruning
2024-04-23 14:37:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:37:49 - INFO :       Loss = 14.84375
2024-04-23 14:37:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:37:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:37:52 - INFO :       cause_and_effect: Total Sparsity 1.355562410626763e-06
2024-04-23 14:38:16 - INFO :       cause_and_effect: Total Accuracy (3, 30, 0.1)
2024-04-23 14:38:16 - INFO :       
==================Finish================

2024-04-23 14:38:16 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 14:38:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:38:16 - INFO :       DATASET: tasksource/bigbench checkmate_in_one
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 14:38:24 - INFO :       Use taylor pruner...
2024-04-23 14:38:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:38:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:38:24 - INFO :       Start Pruning
2024-04-23 14:38:25 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:38:26 - INFO :       Loss = 1.3583984375
2024-04-23 14:38:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:38:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:38:29 - INFO :       checkmate_in_one: Total Sparsity 1.3584266110483244e-06
2024-04-23 14:39:17 - INFO :       checkmate_in_one: Total Accuracy (15, 50, 0.3)
2024-04-23 14:39:18 - INFO :       
==================Finish================

2024-04-23 14:39:18 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 14:39:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:39:18 - INFO :       DATASET: tasksource/bigbench cifar10_classification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.34s/it]
2024-04-23 14:39:30 - INFO :       Use taylor pruner...
2024-04-23 14:39:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:39:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:39:30 - INFO :       Start Pruning
2024-04-23 14:39:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:39:32 - INFO :       Loss = 3.916015625
2024-04-23 14:39:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:39:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:39:35 - INFO :       cifar10_classification: Total Sparsity 1.3566762663462592e-06
2024-04-23 14:41:28 - INFO :       cifar10_classification: Total Accuracy (6, 50, 0.12)
2024-04-23 14:41:28 - INFO :       
==================Finish================

2024-04-23 14:41:28 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 14:41:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:41:28 - INFO :       DATASET: tasksource/bigbench code_line_description
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 14:41:36 - INFO :       Use taylor pruner...
2024-04-23 14:41:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:41:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:41:36 - INFO :       Start Pruning
2024-04-23 14:41:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:41:38 - INFO :       Loss = 11.6171875
2024-04-23 14:41:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:41:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:41:41 - INFO :       code_line_description: Total Sparsity 1.3593813445221782e-06
2024-04-23 14:41:55 - INFO :       code_line_description: Total Accuracy (6, 16, 0.375)
2024-04-23 14:41:55 - INFO :       
==================Finish================

2024-04-23 14:41:55 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 14:41:55 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:41:55 - INFO :       DATASET: tasksource/bigbench color
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 14:42:05 - INFO :       Use taylor pruner...
2024-04-23 14:42:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:42:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:42:05 - INFO :       Start Pruning
2024-04-23 14:42:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:42:07 - INFO :       Loss = 11.1640625
2024-04-23 14:42:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:42:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:42:10 - INFO :       color: Total Sparsity 1.3590631000308936e-06
2024-04-23 14:42:50 - INFO :       color: Total Accuracy (13, 50, 0.26)
2024-04-23 14:42:50 - INFO :       
==================Finish================

2024-04-23 14:42:50 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 14:42:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:42:50 - INFO :       DATASET: tasksource/bigbench common_morpheme
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 14:42:58 - INFO :       Use taylor pruner...
2024-04-23 14:42:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:42:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:42:58 - INFO :       Start Pruning
2024-04-23 14:43:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:43:00 - INFO :       Loss = 14.0703125
2024-04-23 14:43:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:43:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:43:03 - INFO :       common_morpheme: Total Sparsity 1.3568353885919015e-06
2024-04-23 14:43:16 - INFO :       common_morpheme: Total Accuracy (3, 16, 0.1875)
2024-04-23 14:43:16 - INFO :       
==================Finish================

2024-04-23 14:43:16 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 14:43:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:43:16 - INFO :       DATASET: tasksource/bigbench conceptual_combinations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 14:43:24 - INFO :       Use taylor pruner...
2024-04-23 14:43:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:43:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:43:25 - INFO :       Start Pruning
2024-04-23 14:43:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:43:27 - INFO :       Loss = 11.7265625
2024-04-23 14:43:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:43:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:43:30 - INFO :       conceptual_combinations: Total Sparsity 1.3554032883811208e-06
2024-04-23 14:43:45 - INFO :       conceptual_combinations: Total Accuracy (1, 19, 0.05263157894736842)
2024-04-23 14:43:45 - INFO :       
==================Finish================

2024-04-23 14:43:45 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 14:43:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:43:45 - INFO :       DATASET: tasksource/bigbench crash_blossom
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 14:43:53 - INFO :       Use taylor pruner...
2024-04-23 14:43:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:43:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:43:53 - INFO :       Start Pruning
2024-04-23 14:43:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:43:55 - INFO :       Loss = 13.96875
2024-04-23 14:43:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:43:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:43:58 - INFO :       crash_blossom: Total Sparsity 1.3547667993985515e-06
2024-04-23 14:44:11 - INFO :       crash_blossom: Total Accuracy (5, 16, 0.3125)
2024-04-23 14:44:11 - INFO :       
==================Finish================

2024-04-23 14:44:11 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 14:44:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:44:11 - INFO :       DATASET: tasksource/bigbench crass_ai
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 14:44:18 - INFO :       Use taylor pruner...
2024-04-23 14:44:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:44:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:44:19 - INFO :       Start Pruning
2024-04-23 14:44:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:44:21 - INFO :       Loss = 12.90625
2024-04-23 14:44:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:44:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:44:24 - INFO :       crass_ai: Total Sparsity 1.3584266110483244e-06
2024-04-23 14:44:38 - INFO :       crass_ai: Total Accuracy (4, 16, 0.25)
2024-04-23 14:44:38 - INFO :       
==================Finish================

2024-04-23 14:44:38 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 14:44:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:44:38 - INFO :       DATASET: tasksource/bigbench cryobiology_spanish
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 14:44:46 - INFO :       Use taylor pruner...
2024-04-23 14:44:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:44:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:44:46 - INFO :       Start Pruning
2024-04-23 14:44:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:44:48 - INFO :       Loss = 14.8203125
2024-04-23 14:44:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:44:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:44:51 - INFO :       cryobiology_spanish: Total Sparsity 1.3579492443113975e-06
2024-04-23 14:45:15 - INFO :       cryobiology_spanish: Total Accuracy (4, 29, 0.13793103448275862)
2024-04-23 14:45:15 - INFO :       
==================Finish================

2024-04-23 14:45:15 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 14:45:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:45:15 - INFO :       DATASET: tasksource/bigbench cs_algorithms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 14:45:22 - INFO :       Use taylor pruner...
2024-04-23 14:45:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:45:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:45:23 - INFO :       Start Pruning
2024-04-23 14:45:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:45:25 - INFO :       Loss = 13.4140625
2024-04-23 14:45:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:45:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:45:27 - INFO :       cs_algorithms: Total Sparsity 1.3589039777852514e-06
2024-04-23 14:46:08 - INFO :       cs_algorithms: Total Accuracy (5, 50, 0.1)
2024-04-23 14:46:08 - INFO :       
==================Finish================

2024-04-23 14:46:08 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 14:46:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:46:08 - INFO :       DATASET: tasksource/bigbench dark_humor_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 14:46:15 - INFO :       Use taylor pruner...
2024-04-23 14:46:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:46:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:46:16 - INFO :       Start Pruning
2024-04-23 14:46:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:46:18 - INFO :       Loss = 13.578125
2024-04-23 14:46:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:46:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:46:21 - INFO :       dark_humor_detection: Total Sparsity 1.3581083665570398e-06
2024-04-23 14:46:33 - INFO :       dark_humor_detection: Total Accuracy (10, 16, 0.625)
2024-04-23 14:46:33 - INFO :       
==================Finish================

2024-04-23 14:46:33 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 14:46:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:46:33 - INFO :       DATASET: tasksource/bigbench date_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 14:46:41 - INFO :       Use taylor pruner...
2024-04-23 14:46:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:46:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:46:41 - INFO :       Start Pruning
2024-04-23 14:46:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:46:43 - INFO :       Loss = 12.078125
2024-04-23 14:46:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:46:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:46:46 - INFO :       date_understanding: Total Sparsity 1.3585857332939668e-06
2024-04-23 14:47:26 - INFO :       date_understanding: Total Accuracy (3, 50, 0.06)
2024-04-23 14:47:26 - INFO :       
==================Finish================

2024-04-23 14:47:26 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 14:47:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:47:26 - INFO :       DATASET: tasksource/bigbench disambiguation_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 14:47:33 - INFO :       Use taylor pruner...
2024-04-23 14:47:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:47:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:47:34 - INFO :       Start Pruning
2024-04-23 14:47:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:47:36 - INFO :       Loss = 13.4765625
2024-04-23 14:47:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:47:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:47:39 - INFO :       disambiguation_qa: Total Sparsity 1.3566762663462592e-06
2024-04-23 14:48:18 - INFO :       disambiguation_qa: Total Accuracy (21, 50, 0.42)
2024-04-23 14:48:18 - INFO :       
==================Finish================

2024-04-23 14:48:18 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 14:48:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:48:18 - INFO :       DATASET: tasksource/bigbench discourse_marker_prediction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 14:48:26 - INFO :       Use taylor pruner...
2024-04-23 14:48:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:48:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:48:26 - INFO :       Start Pruning
2024-04-23 14:48:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:48:28 - INFO :       Loss = 1.203125
2024-04-23 14:48:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:48:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:48:31 - INFO :       discourse_marker_prediction: Total Sparsity 1.3574718775744707e-06
2024-04-23 14:49:18 - INFO :       discourse_marker_prediction: Total Accuracy (5, 50, 0.1)
2024-04-23 14:49:18 - INFO :       
==================Finish================

2024-04-23 14:49:18 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 14:49:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:49:18 - INFO :       DATASET: tasksource/bigbench dyck_languages
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 14:49:26 - INFO :       Use taylor pruner...
2024-04-23 14:49:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:49:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:49:26 - INFO :       Start Pruning
2024-04-23 14:49:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:49:28 - INFO :       Loss = 1.1376953125
2024-04-23 14:49:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:49:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:49:31 - INFO :       dyck_languages: Total Sparsity 1.354448554907267e-06
2024-04-23 14:50:18 - INFO :       dyck_languages: Total Accuracy (0, 50, 0.0)
2024-04-23 14:50:18 - INFO :       
==================Finish================

2024-04-23 14:50:18 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 14:50:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:50:18 - INFO :       DATASET: tasksource/bigbench elementary_math_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 14:50:25 - INFO :       Use taylor pruner...
2024-04-23 14:50:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:50:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:50:26 - INFO :       Start Pruning
2024-04-23 14:50:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:50:28 - INFO :       Loss = 12.4453125
2024-04-23 14:50:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:50:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:50:30 - INFO :       elementary_math_qa: Total Sparsity 1.3595404667678207e-06
2024-04-23 14:51:10 - INFO :       elementary_math_qa: Total Accuracy (8, 50, 0.16)
2024-04-23 14:51:10 - INFO :       
==================Finish================

2024-04-23 14:51:10 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 14:51:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:51:10 - INFO :       DATASET: tasksource/bigbench emoji_movie
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 14:51:17 - INFO :       Use taylor pruner...
2024-04-23 14:51:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:51:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:51:17 - INFO :       Start Pruning
2024-04-23 14:51:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:51:20 - INFO :       Loss = 13.171875
2024-04-23 14:51:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:51:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:51:22 - INFO :       emoji_movie: Total Sparsity 1.357153633083186e-06
2024-04-23 14:51:38 - INFO :       emoji_movie: Total Accuracy (0, 20, 0.0)
2024-04-23 14:51:38 - INFO :       
==================Finish================

2024-04-23 14:51:38 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 14:51:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:51:38 - INFO :       DATASET: tasksource/bigbench empirical_judgments
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 14:51:46 - INFO :       Use taylor pruner...
2024-04-23 14:51:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:51:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:51:46 - INFO :       Start Pruning
2024-04-23 14:51:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:51:48 - INFO :       Loss = 13.4296875
2024-04-23 14:51:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:51:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:51:51 - INFO :       empirical_judgments: Total Sparsity 1.3590631000308936e-06
2024-04-23 14:52:06 - INFO :       empirical_judgments: Total Accuracy (10, 19, 0.5263157894736842)
2024-04-23 14:52:06 - INFO :       
==================Finish================

2024-04-23 14:52:06 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 14:52:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:52:06 - INFO :       DATASET: tasksource/bigbench english_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 14:52:13 - INFO :       Use taylor pruner...
2024-04-23 14:52:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:52:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:52:14 - INFO :       Start Pruning
2024-04-23 14:52:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:52:16 - INFO :       Loss = 11.59375
2024-04-23 14:52:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:52:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:52:19 - INFO :       english_proverbs: Total Sparsity 1.359222222276536e-06
2024-04-23 14:52:31 - INFO :       english_proverbs: Total Accuracy (4, 16, 0.25)
2024-04-23 14:52:31 - INFO :       
==================Finish================

2024-04-23 14:52:31 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 14:52:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:52:31 - INFO :       DATASET: tasksource/bigbench english_russian_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2024-04-23 14:52:39 - INFO :       Use taylor pruner...
2024-04-23 14:52:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:52:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:52:39 - INFO :       Start Pruning
2024-04-23 14:52:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:52:42 - INFO :       Loss = 11.6328125
2024-04-23 14:52:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:52:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:52:44 - INFO :       english_russian_proverbs: Total Sparsity 1.3549259216441938e-06
2024-04-23 14:52:57 - INFO :       english_russian_proverbs: Total Accuracy (7, 16, 0.4375)
2024-04-23 14:52:57 - INFO :       
==================Finish================

2024-04-23 14:52:57 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 14:52:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:52:57 - INFO :       DATASET: tasksource/bigbench entailed_polarity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 14:53:04 - INFO :       Use taylor pruner...
2024-04-23 14:53:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:53:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:53:05 - INFO :       Start Pruning
2024-04-23 14:53:07 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:53:08 - INFO :       Loss = 15.7578125
2024-04-23 14:53:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:53:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:53:11 - INFO :       entailed_polarity: Total Sparsity 1.355562410626763e-06
2024-04-23 14:53:34 - INFO :       entailed_polarity: Total Accuracy (29, 29, 1.0)
2024-04-23 14:53:34 - INFO :       
==================Finish================

2024-04-23 14:53:34 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 14:53:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:53:34 - INFO :       DATASET: tasksource/bigbench entailed_polarity_hindi
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 14:53:41 - INFO :       Use taylor pruner...
2024-04-23 14:53:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:53:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:53:41 - INFO :       Start Pruning
2024-04-23 14:53:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:53:44 - INFO :       Loss = 11.484375
2024-04-23 14:53:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:53:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:53:47 - INFO :       entailed_polarity_hindi: Total Sparsity 1.3549259216441938e-06
2024-04-23 14:54:07 - INFO :       entailed_polarity_hindi: Total Accuracy (17, 27, 0.6296296296296297)
2024-04-23 14:54:07 - INFO :       
==================Finish================

2024-04-23 14:54:07 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 14:54:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:54:07 - INFO :       DATASET: tasksource/bigbench epistemic_reasoning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 14:54:14 - INFO :       Use taylor pruner...
2024-04-23 14:54:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:54:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:54:15 - INFO :       Start Pruning
2024-04-23 14:54:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:54:17 - INFO :       Loss = 13.6171875
2024-04-23 14:54:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:54:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:54:19 - INFO :       epistemic_reasoning: Total Sparsity 1.3563580218549744e-06
2024-04-23 14:54:59 - INFO :       epistemic_reasoning: Total Accuracy (26, 50, 0.52)
2024-04-23 14:54:59 - INFO :       
==================Finish================

2024-04-23 14:54:59 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 14:54:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:54:59 - INFO :       DATASET: tasksource/bigbench evaluating_information_essentiality
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 14:55:07 - INFO :       Use taylor pruner...
2024-04-23 14:55:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:55:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:55:07 - INFO :       Start Pruning
2024-04-23 14:55:08 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:55:09 - INFO :       Loss = 8.8359375
2024-04-23 14:55:10 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:55:10 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:55:12 - INFO :       evaluating_information_essentiality: Total Sparsity 1.356517144100617e-06
2024-04-23 14:55:25 - INFO :       evaluating_information_essentiality: Total Accuracy (5, 16, 0.3125)
2024-04-23 14:55:25 - INFO :       
==================Finish================

2024-04-23 14:55:25 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 14:55:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:55:25 - INFO :       DATASET: tasksource/bigbench fact_checker
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 14:55:33 - INFO :       Use taylor pruner...
2024-04-23 14:55:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:55:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:55:33 - INFO :       Start Pruning
2024-04-23 14:55:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:55:36 - INFO :       Loss = 15.5078125
2024-04-23 14:55:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:55:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:55:38 - INFO :       fact_checker: Total Sparsity 1.3569945108375437e-06
2024-04-23 14:56:17 - INFO :       fact_checker: Total Accuracy (31, 50, 0.62)
2024-04-23 14:56:18 - INFO :       
==================Finish================

2024-04-23 14:56:18 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 14:56:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:56:18 - INFO :       DATASET: tasksource/bigbench fantasy_reasoning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]
2024-04-23 14:56:25 - INFO :       Use taylor pruner...
2024-04-23 14:56:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:56:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:56:25 - INFO :       Start Pruning
2024-04-23 14:56:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:56:28 - INFO :       Loss = 14.25
2024-04-23 14:56:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:56:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:56:30 - INFO :       fantasy_reasoning: Total Sparsity 1.3585857332939668e-06
2024-04-23 14:57:02 - INFO :       fantasy_reasoning: Total Accuracy (25, 40, 0.625)
2024-04-23 14:57:02 - INFO :       
==================Finish================

2024-04-23 14:57:02 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 14:57:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:57:02 - INFO :       DATASET: tasksource/bigbench figure_of_speech_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 14:57:10 - INFO :       Use taylor pruner...
2024-04-23 14:57:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:57:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:57:10 - INFO :       Start Pruning
2024-04-23 14:57:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:57:12 - INFO :       Loss = 12.484375
2024-04-23 14:57:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:57:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:57:15 - INFO :       figure_of_speech_detection: Total Sparsity 1.3561988996093322e-06
2024-04-23 14:57:28 - INFO :       figure_of_speech_detection: Total Accuracy (4, 16, 0.25)
2024-04-23 14:57:28 - INFO :       
==================Finish================

2024-04-23 14:57:28 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 14:57:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:57:28 - INFO :       DATASET: tasksource/bigbench formal_fallacies_syllogisms_negation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 14:57:35 - INFO :       Use taylor pruner...
2024-04-23 14:57:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:57:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:57:36 - INFO :       Start Pruning
2024-04-23 14:57:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:57:38 - INFO :       Loss = 12.2890625
2024-04-23 14:57:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:57:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:57:40 - INFO :       formal_fallacies_syllogisms_negation: Total Sparsity 1.360813444732959e-06
2024-04-23 14:58:20 - INFO :       formal_fallacies_syllogisms_negation: Total Accuracy (23, 50, 0.46)
2024-04-23 14:58:20 - INFO :       
==================Finish================

2024-04-23 14:58:20 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 14:58:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:58:20 - INFO :       DATASET: tasksource/bigbench general_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 14:58:28 - INFO :       Use taylor pruner...
2024-04-23 14:58:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:58:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:58:28 - INFO :       Start Pruning
2024-04-23 14:58:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:58:30 - INFO :       Loss = 12.625
2024-04-23 14:58:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:58:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:58:33 - INFO :       general_knowledge: Total Sparsity 1.3617681782068128e-06
2024-04-23 14:58:46 - INFO :       general_knowledge: Total Accuracy (4, 16, 0.25)
2024-04-23 14:58:46 - INFO :       
==================Finish================

2024-04-23 14:58:46 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 14:58:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:58:46 - INFO :       DATASET: tasksource/bigbench geometric_shapes
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 14:58:53 - INFO :       Use taylor pruner...
2024-04-23 14:58:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:58:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:58:54 - INFO :       Start Pruning
2024-04-23 14:58:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:58:56 - INFO :       Loss = 9.5390625
2024-04-23 14:58:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:58:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:58:59 - INFO :       geometric_shapes: Total Sparsity 1.3600178335047475e-06
2024-04-23 14:59:40 - INFO :       geometric_shapes: Total Accuracy (8, 50, 0.16)
2024-04-23 14:59:40 - INFO :       
==================Finish================

2024-04-23 14:59:40 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 14:59:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 14:59:40 - INFO :       DATASET: tasksource/bigbench goal_step_wikihow
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 14:59:47 - INFO :       Use taylor pruner...
2024-04-23 14:59:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:59:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 14:59:48 - INFO :       Start Pruning
2024-04-23 14:59:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 14:59:50 - INFO :       Loss = 12.0390625
2024-04-23 14:59:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 14:59:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 14:59:52 - INFO :       goal_step_wikihow: Total Sparsity 1.3593813445221782e-06
2024-04-23 15:00:32 - INFO :       goal_step_wikihow: Total Accuracy (7, 50, 0.14)
2024-04-23 15:00:32 - INFO :       
==================Finish================

2024-04-23 15:00:32 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:00:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:00:32 - INFO :       DATASET: tasksource/bigbench gre_reading_comprehension
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2024-04-23 15:00:40 - INFO :       Use taylor pruner...
2024-04-23 15:00:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:00:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:00:40 - INFO :       Start Pruning
2024-04-23 15:00:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:00:42 - INFO :       Loss = 3.69140625
2024-04-23 15:00:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:00:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:00:45 - INFO :       gre_reading_comprehension: Total Sparsity 1.3600178335047475e-06
2024-04-23 15:01:00 - INFO :       gre_reading_comprehension: Total Accuracy (2, 16, 0.125)
2024-04-23 15:01:00 - INFO :       
==================Finish================

2024-04-23 15:01:00 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:01:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:01:00 - INFO :       DATASET: tasksource/bigbench hhh_alignment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 15:01:08 - INFO :       Use taylor pruner...
2024-04-23 15:01:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:01:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:01:08 - INFO :       Start Pruning
2024-04-23 15:01:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:01:10 - INFO :       Loss = 9.140625
2024-04-23 15:01:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:01:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:01:13 - INFO :       hhh_alignment: Total Sparsity 1.357630999820113e-06
2024-04-23 15:01:49 - INFO :       hhh_alignment: Total Accuracy (8, 42, 0.19047619047619047)
2024-04-23 15:01:50 - INFO :       
==================Finish================

2024-04-23 15:01:50 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:01:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:01:50 - INFO :       DATASET: tasksource/bigbench hindu_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 15:01:57 - INFO :       Use taylor pruner...
2024-04-23 15:01:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:01:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:01:58 - INFO :       Start Pruning
2024-04-23 15:01:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:02:00 - INFO :       Loss = 14.1640625
2024-04-23 15:02:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:02:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:02:02 - INFO :       hindu_knowledge: Total Sparsity 1.3611316892242436e-06
2024-04-23 15:02:30 - INFO :       hindu_knowledge: Total Accuracy (14, 35, 0.4)
2024-04-23 15:02:30 - INFO :       
==================Finish================

2024-04-23 15:02:30 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:02:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:02:30 - INFO :       DATASET: tasksource/bigbench hinglish_toxicity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 15:02:37 - INFO :       Use taylor pruner...
2024-04-23 15:02:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:02:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:02:38 - INFO :       Start Pruning
2024-04-23 15:02:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:02:40 - INFO :       Loss = 14.8828125
2024-04-23 15:02:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:02:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:02:43 - INFO :       hinglish_toxicity: Total Sparsity 1.3563580218549744e-06
2024-04-23 15:03:14 - INFO :       hinglish_toxicity: Total Accuracy (23, 40, 0.575)
2024-04-23 15:03:15 - INFO :       
==================Finish================

2024-04-23 15:03:15 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:03:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:03:15 - INFO :       DATASET: tasksource/bigbench human_organs_senses
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 15:03:22 - INFO :       Use taylor pruner...
2024-04-23 15:03:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:03:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:03:23 - INFO :       Start Pruning
2024-04-23 15:03:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:03:25 - INFO :       Loss = 14.9296875
2024-04-23 15:03:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:03:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:03:28 - INFO :       human_organs_senses: Total Sparsity 1.3590631000308936e-06
2024-04-23 15:03:40 - INFO :       human_organs_senses: Total Accuracy (5, 16, 0.3125)
2024-04-23 15:03:40 - INFO :       
==================Finish================

2024-04-23 15:03:40 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:03:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:03:40 - INFO :       DATASET: tasksource/bigbench hyperbaton
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 15:03:48 - INFO :       Use taylor pruner...
2024-04-23 15:03:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:03:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:03:48 - INFO :       Start Pruning
2024-04-23 15:03:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:03:50 - INFO :       Loss = 15.46875
2024-04-23 15:03:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:03:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:03:53 - INFO :       hyperbaton: Total Sparsity 1.3579492443113975e-06
2024-04-23 15:04:31 - INFO :       hyperbaton: Total Accuracy (22, 50, 0.44)
2024-04-23 15:04:31 - INFO :       
==================Finish================

2024-04-23 15:04:31 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:04:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:04:31 - INFO :       DATASET: tasksource/bigbench identify_math_theorems
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 15:04:39 - INFO :       Use taylor pruner...
2024-04-23 15:04:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:04:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:04:39 - INFO :       Start Pruning
2024-04-23 15:04:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:04:41 - INFO :       Loss = 0.9873046875
2024-04-23 15:04:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:04:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:04:44 - INFO :       identify_math_theorems: Total Sparsity 1.3584266110483244e-06
2024-04-23 15:04:59 - INFO :       identify_math_theorems: Total Accuracy (8, 16, 0.5)
2024-04-23 15:04:59 - INFO :       
==================Finish================

2024-04-23 15:04:59 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:04:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:04:59 - INFO :       DATASET: tasksource/bigbench identify_odd_metaphor
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2024-04-23 15:05:07 - INFO :       Use taylor pruner...
2024-04-23 15:05:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:05:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:05:07 - INFO :       Start Pruning
2024-04-23 15:05:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:05:10 - INFO :       Loss = 11.8828125
2024-04-23 15:05:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:05:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:05:12 - INFO :       identify_odd_metaphor: Total Sparsity 1.3643141341370896e-06
2024-04-23 15:05:25 - INFO :       identify_odd_metaphor: Total Accuracy (0, 16, 0.0)
2024-04-23 15:05:25 - INFO :       
==================Finish================

2024-04-23 15:05:25 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:05:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:05:25 - INFO :       DATASET: tasksource/bigbench implicatures
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 15:05:32 - INFO :       Use taylor pruner...
2024-04-23 15:05:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:05:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:05:33 - INFO :       Start Pruning
2024-04-23 15:05:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:05:35 - INFO :       Loss = 15.2265625
2024-04-23 15:05:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:05:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:05:38 - INFO :       implicatures: Total Sparsity 1.3589039777852514e-06
2024-04-23 15:06:18 - INFO :       implicatures: Total Accuracy (22, 50, 0.44)
2024-04-23 15:06:18 - INFO :       
==================Finish================

2024-04-23 15:06:18 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:06:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:06:18 - INFO :       DATASET: tasksource/bigbench implicit_relations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 15:06:26 - INFO :       Use taylor pruner...
2024-04-23 15:06:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:06:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:06:26 - INFO :       Start Pruning
2024-04-23 15:06:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:06:29 - INFO :       Loss = 7.8828125
2024-04-23 15:06:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:06:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:06:31 - INFO :       implicit_relations: Total Sparsity 1.3579492443113975e-06
2024-04-23 15:06:46 - INFO :       implicit_relations: Total Accuracy (4, 17, 0.23529411764705882)
2024-04-23 15:06:46 - INFO :       
==================Finish================

2024-04-23 15:06:46 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:06:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:06:46 - INFO :       DATASET: tasksource/bigbench indic_cause_and_effect
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 15:06:53 - INFO :       Use taylor pruner...
2024-04-23 15:06:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:06:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:06:54 - INFO :       Start Pruning
2024-04-23 15:06:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:06:56 - INFO :       Loss = 5.41015625
2024-04-23 15:06:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:06:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:06:58 - INFO :       indic_cause_and_effect: Total Sparsity 1.3569945108375437e-06
2024-04-23 15:07:39 - INFO :       indic_cause_and_effect: Total Accuracy (12, 50, 0.24)
2024-04-23 15:07:40 - INFO :       
==================Finish================

2024-04-23 15:07:40 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:07:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:07:40 - INFO :       DATASET: tasksource/bigbench intent_recognition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 15:07:47 - INFO :       Use taylor pruner...
2024-04-23 15:07:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:07:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:07:48 - INFO :       Start Pruning
2024-04-23 15:07:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:07:50 - INFO :       Loss = 11.59375
2024-04-23 15:07:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:07:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:07:52 - INFO :       intent_recognition: Total Sparsity 1.3574718775744707e-06
2024-04-23 15:08:32 - INFO :       intent_recognition: Total Accuracy (35, 50, 0.7)
2024-04-23 15:08:32 - INFO :       
==================Finish================

2024-04-23 15:08:32 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:08:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:08:32 - INFO :       DATASET: tasksource/bigbench international_phonetic_alphabet_nli
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 15:08:40 - INFO :       Use taylor pruner...
2024-04-23 15:08:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:08:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:08:40 - INFO :       Start Pruning
2024-04-23 15:08:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:08:43 - INFO :       Loss = 10.9296875
2024-04-23 15:08:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:08:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:08:45 - INFO :       international_phonetic_alphabet_nli: Total Sparsity 1.3561988996093322e-06
2024-04-23 15:09:06 - INFO :       international_phonetic_alphabet_nli: Total Accuracy (11, 25, 0.44)
2024-04-23 15:09:06 - INFO :       
==================Finish================

2024-04-23 15:09:06 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:09:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:09:06 - INFO :       DATASET: tasksource/bigbench intersect_geometry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 15:09:13 - INFO :       Use taylor pruner...
2024-04-23 15:09:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:09:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:09:14 - INFO :       Start Pruning
2024-04-23 15:09:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:09:16 - INFO :       Loss = 3.251953125
2024-04-23 15:09:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:09:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:09:19 - INFO :       intersect_geometry: Total Sparsity 1.359699589013463e-06
2024-04-23 15:10:03 - INFO :       intersect_geometry: Total Accuracy (11, 50, 0.22)
2024-04-23 15:10:03 - INFO :       
==================Finish================

2024-04-23 15:10:03 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:10:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:10:03 - INFO :       DATASET: tasksource/bigbench irony_identification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 15:10:10 - INFO :       Use taylor pruner...
2024-04-23 15:10:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:10:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:10:11 - INFO :       Start Pruning
2024-04-23 15:10:12 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:10:13 - INFO :       Loss = 14.4375
2024-04-23 15:10:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:10:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:10:15 - INFO :       irony_identification: Total Sparsity 1.3557215328724054e-06
2024-04-23 15:10:31 - INFO :       irony_identification: Total Accuracy (8, 19, 0.42105263157894735)
2024-04-23 15:10:31 - INFO :       
==================Finish================

2024-04-23 15:10:31 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:10:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:10:31 - INFO :       DATASET: tasksource/bigbench kannada
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 15:10:38 - INFO :       Use taylor pruner...
2024-04-23 15:10:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:10:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:10:39 - INFO :       Start Pruning
2024-04-23 15:10:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:10:41 - INFO :       Loss = 4.6796875
2024-04-23 15:10:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:10:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:10:44 - INFO :       kannada: Total Sparsity 1.356517144100617e-06
2024-04-23 15:11:29 - INFO :       kannada: Total Accuracy (8, 50, 0.16)
2024-04-23 15:11:30 - INFO :       
==================Finish================

2024-04-23 15:11:30 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:11:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:11:30 - INFO :       DATASET: tasksource/bigbench key_value_maps
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 15:11:37 - INFO :       Use taylor pruner...
2024-04-23 15:11:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:11:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:11:38 - INFO :       Start Pruning
2024-04-23 15:11:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:11:40 - INFO :       Loss = 7.01953125
2024-04-23 15:11:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:11:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:11:43 - INFO :       key_value_maps: Total Sparsity 1.3573127553288283e-06
2024-04-23 15:12:00 - INFO :       key_value_maps: Total Accuracy (11, 21, 0.5238095238095238)
2024-04-23 15:12:01 - INFO :       
==================Finish================

2024-04-23 15:12:01 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:12:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:12:01 - INFO :       DATASET: tasksource/bigbench known_unknowns
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 15:12:08 - INFO :       Use taylor pruner...
2024-04-23 15:12:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:12:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:12:09 - INFO :       Start Pruning
2024-04-23 15:12:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:12:11 - INFO :       Loss = 15.0859375
2024-04-23 15:12:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:12:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:12:13 - INFO :       known_unknowns: Total Sparsity 1.357630999820113e-06
2024-04-23 15:12:26 - INFO :       known_unknowns: Total Accuracy (8, 16, 0.5)
2024-04-23 15:12:26 - INFO :       
==================Finish================

2024-04-23 15:12:26 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:12:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:12:26 - INFO :       DATASET: tasksource/bigbench language_identification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 15:12:33 - INFO :       Use taylor pruner...
2024-04-23 15:12:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:12:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:12:34 - INFO :       Start Pruning
2024-04-23 15:12:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:12:36 - INFO :       Loss = 8.1015625
2024-04-23 15:12:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:12:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:12:39 - INFO :       language_identification: Total Sparsity 1.356517144100617e-06
2024-04-23 15:13:21 - INFO :       language_identification: Total Accuracy (3, 50, 0.06)
2024-04-23 15:13:21 - INFO :       
==================Finish================

2024-04-23 15:13:21 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:13:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:13:21 - INFO :       DATASET: tasksource/bigbench logic_grid_puzzle
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 15:13:31 - INFO :       Use taylor pruner...
2024-04-23 15:13:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:13:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:13:31 - INFO :       Start Pruning
2024-04-23 15:13:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:13:39 - INFO :       Loss = 3.1484375
2024-04-23 15:13:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:13:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:13:41 - INFO :       logic_grid_puzzle: Total Sparsity 1.359699589013463e-06
2024-04-23 15:14:25 - INFO :       logic_grid_puzzle: Total Accuracy (15, 50, 0.3)
2024-04-23 15:14:25 - INFO :       
==================Finish================

2024-04-23 15:14:25 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:14:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:14:25 - INFO :       DATASET: tasksource/bigbench logical_args
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 15:14:33 - INFO :       Use taylor pruner...
2024-04-23 15:14:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:14:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:14:34 - INFO :       Start Pruning
2024-04-23 15:14:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:14:36 - INFO :       Loss = 8.390625
2024-04-23 15:14:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:14:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:14:39 - INFO :       logical_args: Total Sparsity 1.363995889645805e-06
2024-04-23 15:14:52 - INFO :       logical_args: Total Accuracy (1, 16, 0.0625)
2024-04-23 15:14:53 - INFO :       
==================Finish================

2024-04-23 15:14:53 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:14:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:14:53 - INFO :       DATASET: tasksource/bigbench logical_deduction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 15:15:00 - INFO :       Use taylor pruner...
2024-04-23 15:15:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:15:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:15:01 - INFO :       Start Pruning
2024-04-23 15:15:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:15:03 - INFO :       Loss = 13.328125
2024-04-23 15:15:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:15:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:15:05 - INFO :       logical_deduction: Total Sparsity 1.3581083665570398e-06
2024-04-23 15:15:46 - INFO :       logical_deduction: Total Accuracy (14, 50, 0.28)
2024-04-23 15:15:46 - INFO :       
==================Finish================

2024-04-23 15:15:46 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:15:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:15:46 - INFO :       DATASET: tasksource/bigbench logical_fallacy_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 15:15:53 - INFO :       Use taylor pruner...
2024-04-23 15:15:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:15:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:15:54 - INFO :       Start Pruning
2024-04-23 15:15:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:15:56 - INFO :       Loss = 14.8984375
2024-04-23 15:15:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:15:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:15:58 - INFO :       logical_fallacy_detection: Total Sparsity 1.3568353885919015e-06
2024-04-23 15:16:39 - INFO :       logical_fallacy_detection: Total Accuracy (28, 50, 0.56)
2024-04-23 15:16:40 - INFO :       
==================Finish================

2024-04-23 15:16:40 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:16:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:16:40 - INFO :       DATASET: tasksource/bigbench logical_sequence
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 15:16:48 - INFO :       Use taylor pruner...
2024-04-23 15:16:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:16:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:16:48 - INFO :       Start Pruning
2024-04-23 15:16:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:16:50 - INFO :       Loss = 11.515625
2024-04-23 15:16:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:16:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:16:53 - INFO :       logical_sequence: Total Sparsity 1.3584266110483244e-06
2024-04-23 15:17:06 - INFO :       logical_sequence: Total Accuracy (2, 16, 0.125)
2024-04-23 15:17:06 - INFO :       
==================Finish================

2024-04-23 15:17:06 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:17:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:17:06 - INFO :       DATASET: tasksource/bigbench mathematical_induction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 15:17:13 - INFO :       Use taylor pruner...
2024-04-23 15:17:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:17:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:17:14 - INFO :       Start Pruning
2024-04-23 15:17:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:17:16 - INFO :       Loss = 14.3515625
2024-04-23 15:17:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:17:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:17:19 - INFO :       mathematical_induction: Total Sparsity 1.3561988996093322e-06
2024-04-23 15:17:31 - INFO :       mathematical_induction: Total Accuracy (11, 16, 0.6875)
2024-04-23 15:17:31 - INFO :       
==================Finish================

2024-04-23 15:17:31 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:17:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:17:31 - INFO :       DATASET: tasksource/bigbench medical_questions_russian
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 15:17:39 - INFO :       Use taylor pruner...
2024-04-23 15:17:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:17:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:17:39 - INFO :       Start Pruning
2024-04-23 15:17:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:17:41 - INFO :       Loss = 10.484375
2024-04-23 15:17:42 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:17:42 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:17:44 - INFO :       medical_questions_russian: Total Sparsity 1.3558806551180476e-06
2024-04-23 15:18:25 - INFO :       medical_questions_russian: Total Accuracy (31, 50, 0.62)
2024-04-23 15:18:26 - INFO :       
==================Finish================

2024-04-23 15:18:26 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:18:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:18:26 - INFO :       DATASET: tasksource/bigbench metaphor_boolean
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 15:18:33 - INFO :       Use taylor pruner...
2024-04-23 15:18:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:18:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:18:34 - INFO :       Start Pruning
2024-04-23 15:18:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:18:36 - INFO :       Loss = 14.5859375
2024-04-23 15:18:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:18:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:18:38 - INFO :       metaphor_boolean: Total Sparsity 1.3584266110483244e-06
2024-04-23 15:19:18 - INFO :       metaphor_boolean: Total Accuracy (22, 50, 0.44)
2024-04-23 15:19:18 - INFO :       
==================Finish================

2024-04-23 15:19:18 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:19:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:19:18 - INFO :       DATASET: tasksource/bigbench metaphor_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 15:19:26 - INFO :       Use taylor pruner...
2024-04-23 15:19:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:19:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:19:26 - INFO :       Start Pruning
2024-04-23 15:19:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:19:28 - INFO :       Loss = 12.5625
2024-04-23 15:19:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:19:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:19:31 - INFO :       metaphor_understanding: Total Sparsity 1.3601769557503897e-06
2024-04-23 15:20:08 - INFO :       metaphor_understanding: Total Accuracy (8, 46, 0.17391304347826086)
2024-04-23 15:20:08 - INFO :       
==================Finish================

2024-04-23 15:20:08 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:20:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:20:08 - INFO :       DATASET: tasksource/bigbench misconceptions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 15:20:16 - INFO :       Use taylor pruner...
2024-04-23 15:20:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:20:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:20:16 - INFO :       Start Pruning
2024-04-23 15:20:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:20:18 - INFO :       Loss = 15.1328125
2024-04-23 15:20:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:20:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:20:21 - INFO :       misconceptions: Total Sparsity 1.357630999820113e-06
2024-04-23 15:20:54 - INFO :       misconceptions: Total Accuracy (4, 43, 0.09302325581395349)
2024-04-23 15:20:55 - INFO :       
==================Finish================

2024-04-23 15:20:55 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:20:55 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:20:55 - INFO :       DATASET: tasksource/bigbench mnist_ascii
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 15:21:02 - INFO :       Use taylor pruner...
2024-04-23 15:21:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:21:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:21:03 - INFO :       Start Pruning
2024-04-23 15:21:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:21:05 - INFO :       Loss = 5.13671875
2024-04-23 15:21:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:21:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:21:07 - INFO :       mnist_ascii: Total Sparsity 1.3585857332939668e-06
2024-04-23 15:22:19 - INFO :       mnist_ascii: Total Accuracy (5, 50, 0.1)
2024-04-23 15:22:20 - INFO :       
==================Finish================

2024-04-23 15:22:20 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:22:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:22:20 - INFO :       DATASET: tasksource/bigbench moral_permissibility
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 15:22:27 - INFO :       Use taylor pruner...
2024-04-23 15:22:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:22:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:22:28 - INFO :       Start Pruning
2024-04-23 15:22:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:22:30 - INFO :       Loss = 12.7890625
2024-04-23 15:22:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:22:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:22:33 - INFO :       moral_permissibility: Total Sparsity 1.359222222276536e-06
2024-04-23 15:23:13 - INFO :       moral_permissibility: Total Accuracy (24, 50, 0.48)
2024-04-23 15:23:13 - INFO :       
==================Finish================

2024-04-23 15:23:13 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:23:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:23:13 - INFO :       DATASET: tasksource/bigbench movie_dialog_same_or_different
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 15:23:20 - INFO :       Use taylor pruner...
2024-04-23 15:23:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:23:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:23:20 - INFO :       Start Pruning
2024-04-23 15:23:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:23:23 - INFO :       Loss = 13.5390625
2024-04-23 15:23:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:23:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:23:26 - INFO :       movie_dialog_same_or_different: Total Sparsity 1.3566762663462592e-06
2024-04-23 15:24:06 - INFO :       movie_dialog_same_or_different: Total Accuracy (27, 50, 0.54)
2024-04-23 15:24:06 - INFO :       
==================Finish================

2024-04-23 15:24:06 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:24:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:24:06 - INFO :       DATASET: tasksource/bigbench movie_recommendation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 15:24:13 - INFO :       Use taylor pruner...
2024-04-23 15:24:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:24:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:24:14 - INFO :       Start Pruning
2024-04-23 15:24:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:24:17 - INFO :       Loss = 13.46875
2024-04-23 15:24:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:24:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:24:20 - INFO :       movie_recommendation: Total Sparsity 1.3585857332939668e-06
2024-04-23 15:25:00 - INFO :       movie_recommendation: Total Accuracy (17, 50, 0.34)
2024-04-23 15:25:00 - INFO :       
==================Finish================

2024-04-23 15:25:00 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:25:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:25:00 - INFO :       DATASET: tasksource/bigbench navigate
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 15:25:07 - INFO :       Use taylor pruner...
2024-04-23 15:25:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:25:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:25:08 - INFO :       Start Pruning
2024-04-23 15:25:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:25:10 - INFO :       Loss = 15.3671875
2024-04-23 15:25:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:25:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:25:13 - INFO :       navigate: Total Sparsity 1.356517144100617e-06
2024-04-23 15:25:52 - INFO :       navigate: Total Accuracy (21, 50, 0.42)
2024-04-23 15:25:53 - INFO :       
==================Finish================

2024-04-23 15:25:53 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:25:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:25:53 - INFO :       DATASET: tasksource/bigbench nonsense_words_grammar
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 15:26:02 - INFO :       Use taylor pruner...
2024-04-23 15:26:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:26:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:26:03 - INFO :       Start Pruning
2024-04-23 15:26:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:26:07 - INFO :       Loss = 14.625
2024-04-23 15:26:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:26:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:26:09 - INFO :       nonsense_words_grammar: Total Sparsity 1.3569945108375437e-06
2024-04-23 15:26:22 - INFO :       nonsense_words_grammar: Total Accuracy (5, 16, 0.3125)
2024-04-23 15:26:22 - INFO :       
==================Finish================

2024-04-23 15:26:22 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:26:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:26:22 - INFO :       DATASET: tasksource/bigbench novel_concepts
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 15:26:30 - INFO :       Use taylor pruner...
2024-04-23 15:26:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:26:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:26:31 - INFO :       Start Pruning
2024-04-23 15:26:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:26:36 - INFO :       Loss = 12.28125
2024-04-23 15:26:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:26:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:26:39 - INFO :       novel_concepts: Total Sparsity 1.358267488802682e-06
2024-04-23 15:26:51 - INFO :       novel_concepts: Total Accuracy (6, 16, 0.375)
2024-04-23 15:26:51 - INFO :       
==================Finish================

2024-04-23 15:26:51 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:26:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:26:51 - INFO :       DATASET: tasksource/bigbench odd_one_out
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 15:27:02 - INFO :       Use taylor pruner...
2024-04-23 15:27:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:27:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:27:02 - INFO :       Start Pruning
2024-04-23 15:27:07 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:27:08 - INFO :       Loss = 15.1484375
2024-04-23 15:27:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:27:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:27:10 - INFO :       odd_one_out: Total Sparsity 1.3566762663462592e-06
2024-04-23 15:27:24 - INFO :       odd_one_out: Total Accuracy (0, 17, 0.0)
2024-04-23 15:27:24 - INFO :       
==================Finish================

2024-04-23 15:27:24 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:27:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:27:24 - INFO :       DATASET: tasksource/bigbench parsinlu_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 15:27:33 - INFO :       Use taylor pruner...
2024-04-23 15:27:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:27:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:27:34 - INFO :       Start Pruning
2024-04-23 15:27:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:27:45 - INFO :       Loss = 7.52734375
2024-04-23 15:27:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:27:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:27:48 - INFO :       parsinlu_qa: Total Sparsity 1.3549259216441938e-06
2024-04-23 15:28:26 - INFO :       parsinlu_qa: Total Accuracy (10, 50, 0.2)
2024-04-23 15:28:26 - INFO :       
==================Finish================

2024-04-23 15:28:26 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:28:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:28:26 - INFO :       DATASET: tasksource/bigbench penguins_in_a_table
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 15:28:55 - INFO :       Use taylor pruner...
2024-04-23 15:28:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:28:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:28:55 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:29:48 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:31:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:31:20 - INFO :       Loss = 10.359375
2024-04-23 15:31:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:31:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:31:23 - INFO :       penguins_in_a_table: Total Sparsity 1.359222222276536e-06
2024-04-23 15:31:46 - INFO :       penguins_in_a_table: Total Accuracy (13, 29, 0.4482758620689655)
2024-04-23 15:31:47 - INFO :       
==================Finish================

2024-04-23 15:31:47 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:31:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:31:47 - INFO :       DATASET: tasksource/bigbench persian_idioms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 15:32:34 - INFO :       Use taylor pruner...
2024-04-23 15:32:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:32:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:32:34 - INFO :       Start Pruning
2024-04-23 15:35:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:35:29 - INFO :       Loss = 10.1875
2024-04-23 15:35:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:35:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:35:32 - INFO :       persian_idioms: Total Sparsity 1.359222222276536e-06
2024-04-23 15:35:44 - INFO :       persian_idioms: Total Accuracy (1, 16, 0.0625)
2024-04-23 15:35:44 - INFO :       
==================Finish================

2024-04-23 15:35:44 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:35:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:35:44 - INFO :       DATASET: tasksource/bigbench phrase_relatedness
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 15:35:58 - INFO :       Use taylor pruner...
2024-04-23 15:35:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:35:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:35:58 - INFO :       Start Pruning
2024-04-23 15:36:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:36:07 - INFO :       Loss = 14.140625
2024-04-23 15:36:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:36:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:36:10 - INFO :       phrase_relatedness: Total Sparsity 1.360336077996032e-06
2024-04-23 15:36:26 - INFO :       phrase_relatedness: Total Accuracy (9, 20, 0.45)
2024-04-23 15:36:26 - INFO :       
==================Finish================

2024-04-23 15:36:26 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:36:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:36:26 - INFO :       DATASET: tasksource/bigbench physical_intuition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 15:36:34 - INFO :       Use taylor pruner...
2024-04-23 15:36:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:36:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:36:34 - INFO :       Start Pruning
2024-04-23 15:36:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:36:38 - INFO :       Loss = 14.390625
2024-04-23 15:36:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:36:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:36:41 - INFO :       physical_intuition: Total Sparsity 1.3606543224873167e-06
2024-04-23 15:36:54 - INFO :       physical_intuition: Total Accuracy (9, 16, 0.5625)
2024-04-23 15:36:54 - INFO :       
==================Finish================

2024-04-23 15:36:54 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:36:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:36:54 - INFO :       DATASET: tasksource/bigbench physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 15:37:04 - INFO :       Use taylor pruner...
2024-04-23 15:37:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:37:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:37:04 - INFO :       Start Pruning
2024-04-23 15:37:07 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:37:08 - INFO :       Loss = 10.5078125
2024-04-23 15:37:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:37:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:37:11 - INFO :       physics: Total Sparsity 1.360813444732959e-06
2024-04-23 15:37:47 - INFO :       physics: Total Accuracy (28, 45, 0.6222222222222222)
2024-04-23 15:37:47 - INFO :       
==================Finish================

2024-04-23 15:37:47 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:37:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:37:47 - INFO :       DATASET: tasksource/bigbench play_dialog_same_or_different
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 15:37:57 - INFO :       Use taylor pruner...
2024-04-23 15:37:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:37:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:37:57 - INFO :       Start Pruning
2024-04-23 15:38:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:38:01 - INFO :       Loss = 9.7578125
2024-04-23 15:38:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:38:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:38:04 - INFO :       play_dialog_same_or_different: Total Sparsity 1.3577901220657553e-06
2024-04-23 15:38:46 - INFO :       play_dialog_same_or_different: Total Accuracy (34, 50, 0.68)
2024-04-23 15:38:46 - INFO :       
==================Finish================

2024-04-23 15:38:46 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:38:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:38:46 - INFO :       DATASET: tasksource/bigbench presuppositions_as_nli
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 15:38:59 - INFO :       Use taylor pruner...
2024-04-23 15:38:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:38:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:39:00 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:44:48 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:44:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:44:49 - INFO :       Loss = 12.0625
2024-04-23 15:44:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:44:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:44:52 - INFO :       presuppositions_as_nli: Total Sparsity 1.357630999820113e-06
2024-04-23 15:45:32 - INFO :       presuppositions_as_nli: Total Accuracy (25, 50, 0.5)
2024-04-23 15:45:32 - INFO :       
==================Finish================

2024-04-23 15:45:32 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:45:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:45:32 - INFO :       DATASET: tasksource/bigbench question_selection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 15:46:19 - INFO :       Use taylor pruner...
2024-04-23 15:46:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:46:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:46:20 - INFO :       Start Pruning
2024-04-23 15:47:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:47:27 - INFO :       Loss = 6.3515625
2024-04-23 15:47:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:47:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:47:29 - INFO :       question_selection: Total Sparsity 1.3536529436790554e-06
2024-04-23 15:48:15 - INFO :       question_selection: Total Accuracy (10, 50, 0.2)
2024-04-23 15:48:15 - INFO :       
==================Finish================

2024-04-23 15:48:15 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:48:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:48:15 - INFO :       DATASET: tasksource/bigbench reasoning_about_colored_objects
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 15:48:44 - INFO :       Use taylor pruner...
2024-04-23 15:48:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:48:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:48:45 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:51:52 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:51:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:51:53 - INFO :       Loss = 11.171875
2024-04-23 15:51:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:51:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:51:56 - INFO :       reasoning_about_colored_objects: Total Sparsity 1.3579492443113975e-06
2024-04-23 15:52:36 - INFO :       reasoning_about_colored_objects: Total Accuracy (8, 50, 0.16)
2024-04-23 15:52:36 - INFO :       
==================Finish================

2024-04-23 15:52:36 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:52:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:52:36 - INFO :       DATASET: tasksource/bigbench riddle_sense
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 15:53:23 - INFO :       Use taylor pruner...
2024-04-23 15:53:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:53:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:53:24 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:53:24 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:53:24 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:53:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:53:25 - INFO :       Loss = 13.828125
2024-04-23 15:53:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:53:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:53:28 - INFO :       riddle_sense: Total Sparsity 1.3589039777852514e-06
2024-04-23 15:53:40 - INFO :       riddle_sense: Total Accuracy (3, 16, 0.1875)
2024-04-23 15:53:40 - INFO :       
==================Finish================

2024-04-23 15:53:40 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:53:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:53:40 - INFO :       DATASET: tasksource/bigbench ruin_names
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 15:54:28 - INFO :       Use taylor pruner...
2024-04-23 15:54:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:54:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:54:28 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:54:38 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:54:41 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:54:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:54:42 - INFO :       Loss = 13.8359375
2024-04-23 15:54:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:54:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:54:45 - INFO :       ruin_names: Total Sparsity 1.3600178335047475e-06
2024-04-23 15:55:25 - INFO :       ruin_names: Total Accuracy (10, 50, 0.2)
2024-04-23 15:55:25 - INFO :       
==================Finish================

2024-04-23 15:55:25 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:55:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:55:25 - INFO :       DATASET: tasksource/bigbench salient_translation_error_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 15:56:06 - INFO :       Use taylor pruner...
2024-04-23 15:56:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:56:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:56:06 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:56:16 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:56:26 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:56:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:56:27 - INFO :       Loss = 7.88671875
2024-04-23 15:56:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:56:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:56:30 - INFO :       salient_translation_error_detection: Total Sparsity 1.3579492443113975e-06
2024-04-23 15:57:13 - INFO :       salient_translation_error_detection: Total Accuracy (7, 50, 0.14)
2024-04-23 15:57:13 - INFO :       
==================Finish================

2024-04-23 15:57:13 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:57:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:57:13 - INFO :       DATASET: tasksource/bigbench sentence_ambiguity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 15:57:50 - INFO :       Use taylor pruner...
2024-04-23 15:57:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:57:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:57:51 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:57:51 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:57:51 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:57:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:57:52 - INFO :       Loss = 16.375
2024-04-23 15:57:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:57:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:57:55 - INFO :       sentence_ambiguity: Total Sparsity 1.3549259216441938e-06
2024-04-23 15:58:07 - INFO :       sentence_ambiguity: Total Accuracy (9, 16, 0.5625)
2024-04-23 15:58:07 - INFO :       
==================Finish================

2024-04-23 15:58:07 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:58:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:58:07 - INFO :       DATASET: tasksource/bigbench similarities_abstraction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 15:58:15 - INFO :       Use taylor pruner...
2024-04-23 15:58:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:58:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:58:15 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:58:15 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:58:15 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:58:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:58:16 - INFO :       Loss = 14.03125
2024-04-23 15:58:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:58:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:58:19 - INFO :       similarities_abstraction: Total Sparsity 1.3574718775744707e-06
2024-04-23 15:58:32 - INFO :       similarities_abstraction: Total Accuracy (14, 16, 0.875)
2024-04-23 15:58:32 - INFO :       
==================Finish================

2024-04-23 15:58:32 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 15:58:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:58:32 - INFO :       DATASET: tasksource/bigbench simple_ethical_questions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 15:59:19 - INFO :       Use taylor pruner...
2024-04-23 15:59:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:59:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:59:20 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:59:20 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:59:20 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:59:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:59:21 - INFO :       Loss = 10.125
2024-04-23 15:59:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:59:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:59:23 - INFO :       simple_ethical_questions: Total Sparsity 1.3606543224873167e-06
2024-04-23 15:59:42 - INFO :       simple_ethical_questions: Total Accuracy (8, 23, 0.34782608695652173)
2024-04-23 15:59:42 - INFO :       
==================Finish================

2024-04-23 15:59:42 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 15:59:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 15:59:42 - INFO :       DATASET: tasksource/bigbench snarks
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 15:59:49 - INFO :       Use taylor pruner...
2024-04-23 15:59:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:59:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 15:59:50 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:59:50 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:59:50 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 15:59:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 15:59:51 - INFO :       Loss = 14.203125
2024-04-23 15:59:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 15:59:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 15:59:54 - INFO :       snarks: Total Sparsity 1.3579492443113975e-06
2024-04-23 16:00:22 - INFO :       snarks: Total Accuracy (8, 36, 0.2222222222222222)
2024-04-23 16:00:23 - INFO :       
==================Finish================

2024-04-23 16:00:23 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:00:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:00:23 - INFO :       DATASET: tasksource/bigbench social_iqa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 16:00:30 - INFO :       Use taylor pruner...
2024-04-23 16:00:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:00:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:00:30 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:00:30 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:00:30 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:00:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:00:31 - INFO :       Loss = 14.7890625
2024-04-23 16:00:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:00:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:00:34 - INFO :       social_iqa: Total Sparsity 1.3563580218549744e-06
2024-04-23 16:01:14 - INFO :       social_iqa: Total Accuracy (21, 50, 0.42)
2024-04-23 16:01:14 - INFO :       
==================Finish================

2024-04-23 16:01:14 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:01:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:01:14 - INFO :       DATASET: tasksource/bigbench social_support
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 16:01:21 - INFO :       Use taylor pruner...
2024-04-23 16:01:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:01:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:01:22 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:01:22 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:01:22 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:01:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:01:23 - INFO :       Loss = 12.625
2024-04-23 16:01:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:01:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:01:26 - INFO :       social_support: Total Sparsity 1.3566762663462592e-06
2024-04-23 16:02:06 - INFO :       social_support: Total Accuracy (42, 50, 0.84)
2024-04-23 16:02:06 - INFO :       
==================Finish================

2024-04-23 16:02:06 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:02:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:02:06 - INFO :       DATASET: tasksource/bigbench sports_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 16:02:13 - INFO :       Use taylor pruner...
2024-04-23 16:02:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:02:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:02:14 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:02:14 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:02:14 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:02:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:02:15 - INFO :       Loss = 15.546875
2024-04-23 16:02:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:02:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:02:17 - INFO :       sports_understanding: Total Sparsity 1.3589039777852514e-06
2024-04-23 16:02:57 - INFO :       sports_understanding: Total Accuracy (22, 50, 0.44)
2024-04-23 16:02:57 - INFO :       
==================Finish================

2024-04-23 16:02:57 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:02:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:02:57 - INFO :       DATASET: tasksource/bigbench strange_stories
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 16:03:04 - INFO :       Use taylor pruner...
2024-04-23 16:03:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:03:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:03:05 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:03:05 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:03:05 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:03:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:03:06 - INFO :       Loss = 12.703125
2024-04-23 16:03:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:03:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:03:09 - INFO :       strange_stories: Total Sparsity 1.3601769557503897e-06
2024-04-23 16:03:36 - INFO :       strange_stories: Total Accuracy (10, 34, 0.29411764705882354)
2024-04-23 16:03:36 - INFO :       
==================Finish================

2024-04-23 16:03:36 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:03:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:03:36 - INFO :       DATASET: tasksource/bigbench strategyqa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 16:03:43 - INFO :       Use taylor pruner...
2024-04-23 16:03:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:03:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:03:44 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:03:44 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:03:44 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:03:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:03:45 - INFO :       Loss = 16.125
2024-04-23 16:03:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:03:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:03:47 - INFO :       strategyqa: Total Sparsity 1.3566762663462592e-06
2024-04-23 16:04:26 - INFO :       strategyqa: Total Accuracy (17, 50, 0.34)
2024-04-23 16:04:26 - INFO :       
==================Finish================

2024-04-23 16:04:26 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:04:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:04:26 - INFO :       DATASET: tasksource/bigbench suicide_risk
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2024-04-23 16:04:33 - INFO :       Use taylor pruner...
2024-04-23 16:04:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:04:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:04:34 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:04:34 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:04:34 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:04:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:04:35 - INFO :       Loss = 11.265625
2024-04-23 16:04:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:04:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:04:37 - INFO :       suicide_risk: Total Sparsity 1.3585857332939668e-06
2024-04-23 16:04:51 - INFO :       suicide_risk: Total Accuracy (4, 16, 0.25)
2024-04-23 16:04:51 - INFO :       
==================Finish================

2024-04-23 16:04:51 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:04:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:04:51 - INFO :       DATASET: tasksource/bigbench swahili_english_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 16:04:58 - INFO :       Use taylor pruner...
2024-04-23 16:04:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:04:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:04:58 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:04:58 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:04:58 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:04:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:04:59 - INFO :       Loss = 11.6171875
2024-04-23 16:05:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:05:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:05:02 - INFO :       swahili_english_proverbs: Total Sparsity 1.3561988996093322e-06
2024-04-23 16:05:26 - INFO :       swahili_english_proverbs: Total Accuracy (2, 30, 0.06666666666666667)
2024-04-23 16:05:26 - INFO :       
==================Finish================

2024-04-23 16:05:26 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:05:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:05:26 - INFO :       DATASET: tasksource/bigbench swedish_to_german_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 16:05:33 - INFO :       Use taylor pruner...
2024-04-23 16:05:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:05:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:05:34 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:05:34 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:05:34 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:05:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:05:35 - INFO :       Loss = 12.15625
2024-04-23 16:05:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:05:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:05:37 - INFO :       swedish_to_german_proverbs: Total Sparsity 1.3573127553288283e-06
2024-04-23 16:05:50 - INFO :       swedish_to_german_proverbs: Total Accuracy (6, 16, 0.375)
2024-04-23 16:05:50 - INFO :       
==================Finish================

2024-04-23 16:05:50 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:05:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:05:50 - INFO :       DATASET: tasksource/bigbench symbol_interpretation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 16:05:57 - INFO :       Use taylor pruner...
2024-04-23 16:05:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:05:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:05:58 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:05:58 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:05:58 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:05:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:05:59 - INFO :       Loss = 3.611328125
2024-04-23 16:06:00 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:06:00 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:06:02 - INFO :       symbol_interpretation: Total Sparsity 1.362882033926309e-06
2024-04-23 16:07:01 - INFO :       symbol_interpretation: Total Accuracy (14, 50, 0.28)
2024-04-23 16:07:02 - INFO :       
==================Finish================

2024-04-23 16:07:02 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:07:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:07:02 - INFO :       DATASET: tasksource/bigbench temporal_sequences
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 16:07:09 - INFO :       Use taylor pruner...
2024-04-23 16:07:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:07:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:07:10 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:07:10 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:07:10 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:07:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:07:11 - INFO :       Loss = 9.1953125
2024-04-23 16:07:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:07:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:07:13 - INFO :       temporal_sequences: Total Sparsity 1.3620864226980974e-06
2024-04-23 16:07:55 - INFO :       temporal_sequences: Total Accuracy (2, 50, 0.04)
2024-04-23 16:07:55 - INFO :       
==================Finish================

2024-04-23 16:07:55 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:07:55 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:07:55 - INFO :       DATASET: tasksource/bigbench timedial
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 16:08:02 - INFO :       Use taylor pruner...
2024-04-23 16:08:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:08:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:08:02 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:08:02 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:08:03 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:08:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:08:04 - INFO :       Loss = 9.0078125
2024-04-23 16:08:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:08:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:08:06 - INFO :       timedial: Total Sparsity 1.3585857332939668e-06
2024-04-23 16:08:49 - INFO :       timedial: Total Accuracy (1, 50, 0.02)
2024-04-23 16:08:50 - INFO :       
==================Finish================

2024-04-23 16:08:50 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:08:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:08:50 - INFO :       DATASET: tasksource/bigbench tracking_shuffled_objects
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 16:08:57 - INFO :       Use taylor pruner...
2024-04-23 16:08:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:08:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:08:58 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:08:58 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:08:58 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:08:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:08:59 - INFO :       Loss = 9.9296875
2024-04-23 16:09:00 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:09:00 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:09:01 - INFO :       tracking_shuffled_objects: Total Sparsity 1.359222222276536e-06
2024-04-23 16:09:42 - INFO :       tracking_shuffled_objects: Total Accuracy (10, 50, 0.2)
2024-04-23 16:09:42 - INFO :       
==================Finish================

2024-04-23 16:09:42 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:09:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:09:42 - INFO :       DATASET: tasksource/bigbench understanding_fables
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 16:09:50 - INFO :       Use taylor pruner...
2024-04-23 16:09:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:09:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:09:50 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:09:50 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:09:50 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:09:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:09:51 - INFO :       Loss = 8.21875
2024-04-23 16:09:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:09:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:09:54 - INFO :       understanding_fables: Total Sparsity 1.357630999820113e-06
2024-04-23 16:10:25 - INFO :       understanding_fables: Total Accuracy (5, 37, 0.13513513513513514)
2024-04-23 16:10:26 - INFO :       
==================Finish================

2024-04-23 16:10:26 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:10:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:10:26 - INFO :       DATASET: tasksource/bigbench undo_permutation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 16:10:33 - INFO :       Use taylor pruner...
2024-04-23 16:10:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:10:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:10:34 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:10:34 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:10:34 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:10:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:10:35 - INFO :       Loss = 9.015625
2024-04-23 16:10:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:10:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:10:37 - INFO :       undo_permutation: Total Sparsity 1.3581083665570398e-06
2024-04-23 16:11:20 - INFO :       undo_permutation: Total Accuracy (27, 50, 0.54)
2024-04-23 16:11:20 - INFO :       
==================Finish================

2024-04-23 16:11:20 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:11:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:11:20 - INFO :       DATASET: tasksource/bigbench unit_interpretation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 16:11:27 - INFO :       Use taylor pruner...
2024-04-23 16:11:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:11:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:11:28 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:11:28 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:11:28 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:11:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:11:29 - INFO :       Loss = 11.7890625
2024-04-23 16:11:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:11:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:11:31 - INFO :       unit_interpretation: Total Sparsity 1.3566762663462592e-06
2024-04-23 16:11:47 - INFO :       unit_interpretation: Total Accuracy (5, 20, 0.25)
2024-04-23 16:11:47 - INFO :       
==================Finish================

2024-04-23 16:11:47 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:11:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:11:47 - INFO :       DATASET: tasksource/bigbench vitaminc_fact_verification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 16:11:55 - INFO :       Use taylor pruner...
2024-04-23 16:11:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:11:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:11:55 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:11:55 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:11:55 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:11:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:11:56 - INFO :       Loss = 12.703125
2024-04-23 16:11:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:11:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:11:59 - INFO :       vitaminc_fact_verification: Total Sparsity 1.3577901220657553e-06
2024-04-23 16:12:38 - INFO :       vitaminc_fact_verification: Total Accuracy (21, 50, 0.42)
2024-04-23 16:12:38 - INFO :       
==================Finish================

2024-04-23 16:12:38 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:12:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:12:38 - INFO :       DATASET: tasksource/bigbench what_is_the_tao
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 16:12:46 - INFO :       Use taylor pruner...
2024-04-23 16:12:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:12:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:12:46 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:12:46 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:12:46 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:12:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:12:47 - INFO :       Loss = 12.5390625
2024-04-23 16:12:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:12:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:12:50 - INFO :       what_is_the_tao: Total Sparsity 1.3633594006632357e-06
2024-04-23 16:13:03 - INFO :       what_is_the_tao: Total Accuracy (4, 16, 0.25)
2024-04-23 16:13:03 - INFO :       
==================Finish================

2024-04-23 16:13:03 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:13:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:13:03 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 16:13:10 - INFO :       Use taylor pruner...
2024-04-23 16:13:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:13:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:13:10 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:13:10 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:13:10 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:13:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:13:12 - INFO :       Loss = 1.6259765625
2024-04-23 16:13:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:13:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:13:14 - INFO :       which_wiki_edit: Total Sparsity 1.3563580218549744e-06
2024-04-23 16:14:48 - INFO :       which_wiki_edit: Total Accuracy (34, 50, 0.68)
2024-04-23 16:14:48 - INFO :       
==================Finish================

2024-04-23 16:14:48 - INFO :       Memory Requirement: 12719.80908203125 MiB

2024-04-23 16:14:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:14:48 - INFO :       DATASET: tasksource/bigbench winowhy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 16:14:55 - INFO :       Use taylor pruner...
2024-04-23 16:14:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:14:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:14:56 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:14:56 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:14:56 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-23 16:14:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:14:57 - INFO :       Loss = 15.015625
2024-04-23 16:14:58 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:14:58 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:15:00 - INFO :       winowhy: Total Sparsity 1.3593813445221782e-06
2024-04-23 16:15:39 - INFO :       winowhy: Total Accuracy (32, 50, 0.64)
2024-04-23 16:15:40 - INFO :       
==================Finish================

2024-04-23 16:15:40 - INFO :       Memory Requirement: 12682.77392578125 MiB

2024-04-23 16:15:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:15:40 - INFO :       DATASET: tasksource/mmlu abstract_algebra
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 16:15:47 - INFO :       Use taylor pruner...
2024-04-23 16:15:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:15:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:15:48 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:15:48 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:15:48 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:15:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:15:49 - INFO :       Loss = 14.25
2024-04-23 16:15:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:15:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:15:52 - INFO :       abstract_algebra: Total Sparsity 1.3574718775744707e-06
2024-04-23 16:16:01 - INFO :       abstract_algebra: Total Accuracy (2, 11, 0.18181818181818182)
2024-04-23 16:16:01 - INFO :       
==================Finish================

2024-04-23 16:16:01 - INFO :       Memory Requirement: 12677.77392578125 MiB

2024-04-23 16:16:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:16:01 - INFO :       DATASET: tasksource/mmlu anatomy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 16:16:08 - INFO :       Use taylor pruner...
2024-04-23 16:16:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:16:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:16:08 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:16:08 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:16:08 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:16:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:16:10 - INFO :       Loss = 14.7265625
2024-04-23 16:16:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:16:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:16:12 - INFO :       anatomy: Total Sparsity 1.3558806551180476e-06
2024-04-23 16:16:23 - INFO :       anatomy: Total Accuracy (9, 14, 0.6428571428571429)
2024-04-23 16:16:23 - INFO :       
==================Finish================

2024-04-23 16:16:23 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:16:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:16:23 - INFO :       DATASET: tasksource/mmlu astronomy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 16:16:31 - INFO :       Use taylor pruner...
2024-04-23 16:16:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:16:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:16:31 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:16:31 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:16:31 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:16:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:16:33 - INFO :       Loss = 13.8671875
2024-04-23 16:16:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:16:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:16:35 - INFO :       astronomy: Total Sparsity 1.3584266110483244e-06
2024-04-23 16:16:48 - INFO :       astronomy: Total Accuracy (3, 16, 0.1875)
2024-04-23 16:16:48 - INFO :       
==================Finish================

2024-04-23 16:16:48 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:16:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:16:48 - INFO :       DATASET: tasksource/mmlu business_ethics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 16:16:55 - INFO :       Use taylor pruner...
2024-04-23 16:16:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:16:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:16:56 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:16:56 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:16:56 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:16:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:16:57 - INFO :       Loss = 13.609375
2024-04-23 16:16:58 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:16:58 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:17:00 - INFO :       business_ethics: Total Sparsity 1.3600178335047475e-06
2024-04-23 16:17:08 - INFO :       business_ethics: Total Accuracy (5, 11, 0.45454545454545453)
2024-04-23 16:17:08 - INFO :       
==================Finish================

2024-04-23 16:17:08 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:17:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:17:08 - INFO :       DATASET: tasksource/mmlu clinical_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 16:17:15 - INFO :       Use taylor pruner...
2024-04-23 16:17:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:17:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:17:16 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:17:16 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:17:16 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:17:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:17:17 - INFO :       Loss = 14.3359375
2024-04-23 16:17:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:17:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:17:20 - INFO :       clinical_knowledge: Total Sparsity 1.3589039777852514e-06
2024-04-23 16:17:43 - INFO :       clinical_knowledge: Total Accuracy (16, 29, 0.5517241379310345)
2024-04-23 16:17:43 - INFO :       
==================Finish================

2024-04-23 16:17:43 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:17:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:17:43 - INFO :       DATASET: tasksource/mmlu college_biology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 16:17:50 - INFO :       Use taylor pruner...
2024-04-23 16:17:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:17:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:17:50 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:17:50 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:17:50 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:17:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:17:51 - INFO :       Loss = 13.6328125
2024-04-23 16:17:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:17:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:17:54 - INFO :       college_biology: Total Sparsity 1.3563580218549744e-06
2024-04-23 16:18:07 - INFO :       college_biology: Total Accuracy (8, 16, 0.5)
2024-04-23 16:18:07 - INFO :       
==================Finish================

2024-04-23 16:18:07 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:18:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:18:07 - INFO :       DATASET: tasksource/mmlu college_chemistry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 16:18:14 - INFO :       Use taylor pruner...
2024-04-23 16:18:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:18:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:18:15 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:18:15 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:18:15 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-23 16:18:15 - WARNING :       num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-23 16:18:15 - WARNING :       num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-23 16:18:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:18:16 - INFO :       Loss = 11.140625
2024-04-23 16:18:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:18:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:18:18 - INFO :       college_chemistry: Total Sparsity 1.3579492443113975e-06
2024-04-23 16:18:25 - INFO :       college_chemistry: Total Accuracy (0, 8, 0.0)
2024-04-23 16:18:25 - INFO :       
==================Finish================

2024-04-23 16:18:25 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:18:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:18:25 - INFO :       DATASET: tasksource/mmlu college_computer_science
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 16:18:32 - INFO :       Use taylor pruner...
2024-04-23 16:18:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:18:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:18:33 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:18:33 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:18:33 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:18:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:18:34 - INFO :       Loss = 14.1015625
2024-04-23 16:18:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:18:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:18:36 - INFO :       college_computer_science: Total Sparsity 1.357630999820113e-06
2024-04-23 16:18:46 - INFO :       college_computer_science: Total Accuracy (1, 11, 0.09090909090909091)
2024-04-23 16:18:46 - INFO :       
==================Finish================

2024-04-23 16:18:46 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:18:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:18:46 - INFO :       DATASET: tasksource/mmlu college_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 16:18:53 - INFO :       Use taylor pruner...
2024-04-23 16:18:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:18:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:18:53 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:18:53 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:18:53 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-23 16:18:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:18:54 - INFO :       Loss = 12.4296875
2024-04-23 16:18:55 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:18:55 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:18:57 - INFO :       college_mathematics: Total Sparsity 1.3593813445221782e-06
2024-04-23 16:19:06 - INFO :       college_mathematics: Total Accuracy (4, 11, 0.36363636363636365)
2024-04-23 16:19:06 - INFO :       
==================Finish================

2024-04-23 16:19:06 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:19:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:19:06 - INFO :       DATASET: tasksource/mmlu college_medicine
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 16:19:13 - INFO :       Use taylor pruner...
2024-04-23 16:19:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:19:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:19:14 - INFO :       Start Pruning
2024-04-23 16:19:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:19:18 - INFO :       Loss = 14.0703125
2024-04-23 16:19:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:19:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:19:21 - INFO :       college_medicine: Total Sparsity 1.3584266110483244e-06
2024-04-23 16:19:39 - INFO :       college_medicine: Total Accuracy (10, 22, 0.45454545454545453)
2024-04-23 16:19:39 - INFO :       
==================Finish================

2024-04-23 16:19:39 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:19:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:19:39 - INFO :       DATASET: tasksource/mmlu college_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 16:19:47 - INFO :       Use taylor pruner...
2024-04-23 16:19:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:19:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:19:47 - INFO :       Start Pruning
2024-04-23 16:19:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:19:49 - INFO :       Loss = 13.0859375
2024-04-23 16:19:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:19:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:19:52 - INFO :       college_physics: Total Sparsity 1.3566762663462592e-06
2024-04-23 16:20:01 - INFO :       college_physics: Total Accuracy (2, 11, 0.18181818181818182)
2024-04-23 16:20:01 - INFO :       
==================Finish================

2024-04-23 16:20:01 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:20:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:20:01 - INFO :       DATASET: tasksource/mmlu computer_security
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 16:20:08 - INFO :       Use taylor pruner...
2024-04-23 16:20:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:20:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:20:09 - INFO :       Start Pruning
2024-04-23 16:20:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:20:11 - INFO :       Loss = 15.171875
2024-04-23 16:20:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:20:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:20:14 - INFO :       computer_security: Total Sparsity 1.3581083665570398e-06
2024-04-23 16:20:22 - INFO :       computer_security: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-23 16:20:22 - INFO :       
==================Finish================

2024-04-23 16:20:22 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:20:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:20:22 - INFO :       DATASET: tasksource/mmlu conceptual_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 16:20:30 - INFO :       Use taylor pruner...
2024-04-23 16:20:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:20:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:20:30 - INFO :       Start Pruning
2024-04-23 16:20:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:20:32 - INFO :       Loss = 15.375
2024-04-23 16:20:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:20:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:20:35 - INFO :       conceptual_physics: Total Sparsity 1.3590631000308936e-06
2024-04-23 16:20:56 - INFO :       conceptual_physics: Total Accuracy (9, 26, 0.34615384615384615)
2024-04-23 16:20:56 - INFO :       
==================Finish================

2024-04-23 16:20:56 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:20:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:20:56 - INFO :       DATASET: tasksource/mmlu econometrics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 16:21:04 - INFO :       Use taylor pruner...
2024-04-23 16:21:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:21:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:21:05 - INFO :       Start Pruning
2024-04-23 16:21:07 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:21:08 - INFO :       Loss = 12.546875
2024-04-23 16:21:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:21:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:21:11 - INFO :       econometrics: Total Sparsity 1.3566762663462592e-06
2024-04-23 16:21:20 - INFO :       econometrics: Total Accuracy (2, 12, 0.16666666666666666)
2024-04-23 16:21:20 - INFO :       
==================Finish================

2024-04-23 16:21:20 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:21:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:21:20 - INFO :       DATASET: tasksource/mmlu electrical_engineering
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 16:21:28 - INFO :       Use taylor pruner...
2024-04-23 16:21:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:21:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:21:28 - INFO :       Start Pruning
2024-04-23 16:21:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:21:30 - INFO :       Loss = 14.875
2024-04-23 16:21:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:21:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:21:33 - INFO :       electrical_engineering: Total Sparsity 1.357630999820113e-06
2024-04-23 16:21:45 - INFO :       electrical_engineering: Total Accuracy (4, 16, 0.25)
2024-04-23 16:21:45 - INFO :       
==================Finish================

2024-04-23 16:21:45 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:21:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:21:45 - INFO :       DATASET: tasksource/mmlu elementary_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 16:21:53 - INFO :       Use taylor pruner...
2024-04-23 16:21:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:21:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:21:53 - INFO :       Start Pruning
2024-04-23 16:21:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:21:56 - INFO :       Loss = 14.3359375
2024-04-23 16:21:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:21:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:21:58 - INFO :       elementary_mathematics: Total Sparsity 1.356517144100617e-06
2024-04-23 16:22:32 - INFO :       elementary_mathematics: Total Accuracy (11, 41, 0.2682926829268293)
2024-04-23 16:22:32 - INFO :       
==================Finish================

2024-04-23 16:22:32 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:22:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:22:32 - INFO :       DATASET: tasksource/mmlu formal_logic
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 16:22:39 - INFO :       Use taylor pruner...
2024-04-23 16:22:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:22:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:22:39 - INFO :       Start Pruning
2024-04-23 16:22:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:22:41 - INFO :       Loss = 12.9609375
2024-04-23 16:22:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:22:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:22:44 - INFO :       formal_logic: Total Sparsity 1.3566762663462592e-06
2024-04-23 16:22:56 - INFO :       formal_logic: Total Accuracy (3, 14, 0.21428571428571427)
2024-04-23 16:22:56 - INFO :       
==================Finish================

2024-04-23 16:22:56 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:22:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:22:56 - INFO :       DATASET: tasksource/mmlu global_facts
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 16:23:03 - INFO :       Use taylor pruner...
2024-04-23 16:23:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:23:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:23:04 - INFO :       Start Pruning
2024-04-23 16:23:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:23:06 - INFO :       Loss = 14.6328125
2024-04-23 16:23:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:23:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:23:08 - INFO :       global_facts: Total Sparsity 1.3584266110483244e-06
2024-04-23 16:23:16 - INFO :       global_facts: Total Accuracy (6, 10, 0.6)
2024-04-23 16:23:16 - INFO :       
==================Finish================

2024-04-23 16:23:16 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:23:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:23:16 - INFO :       DATASET: tasksource/mmlu high_school_biology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 16:23:24 - INFO :       Use taylor pruner...
2024-04-23 16:23:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:23:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:23:24 - INFO :       Start Pruning
2024-04-23 16:23:25 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:23:26 - INFO :       Loss = 14.8515625
2024-04-23 16:23:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:23:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:23:29 - INFO :       high_school_biology: Total Sparsity 1.357630999820113e-06
2024-04-23 16:23:55 - INFO :       high_school_biology: Total Accuracy (13, 32, 0.40625)
2024-04-23 16:23:55 - INFO :       
==================Finish================

2024-04-23 16:23:55 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:23:55 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:23:55 - INFO :       DATASET: tasksource/mmlu high_school_chemistry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 16:24:02 - INFO :       Use taylor pruner...
2024-04-23 16:24:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:24:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:24:03 - INFO :       Start Pruning
2024-04-23 16:24:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:24:05 - INFO :       Loss = 15.2421875
2024-04-23 16:24:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:24:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:24:07 - INFO :       high_school_chemistry: Total Sparsity 1.3568353885919015e-06
2024-04-23 16:24:25 - INFO :       high_school_chemistry: Total Accuracy (4, 22, 0.18181818181818182)
2024-04-23 16:24:25 - INFO :       
==================Finish================

2024-04-23 16:24:25 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:24:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:24:25 - INFO :       DATASET: tasksource/mmlu high_school_computer_science
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 16:24:33 - INFO :       Use taylor pruner...
2024-04-23 16:24:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:24:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:24:33 - INFO :       Start Pruning
num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-23 16:24:34 - WARNING :       num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-23 16:24:34 - WARNING :       num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-23 16:24:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:24:35 - INFO :       Loss = 12.1640625
2024-04-23 16:24:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:24:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:24:38 - INFO :       high_school_computer_science: Total Sparsity 1.357630999820113e-06
2024-04-23 16:24:45 - INFO :       high_school_computer_science: Total Accuracy (5, 9, 0.5555555555555556)
2024-04-23 16:24:45 - INFO :       
==================Finish================

2024-04-23 16:24:45 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:24:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:24:45 - INFO :       DATASET: tasksource/mmlu high_school_european_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 16:24:53 - INFO :       Use taylor pruner...
2024-04-23 16:24:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:24:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:24:53 - INFO :       Start Pruning
2024-04-23 16:24:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:24:56 - INFO :       Loss = 4.68359375
2024-04-23 16:24:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:24:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:24:59 - INFO :       high_school_european_history: Total Sparsity 1.360813444732959e-06
2024-04-23 16:25:15 - INFO :       high_school_european_history: Total Accuracy (12, 18, 0.6666666666666666)
2024-04-23 16:25:15 - INFO :       
==================Finish================

2024-04-23 16:25:15 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:25:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:25:15 - INFO :       DATASET: tasksource/mmlu high_school_geography
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 16:25:23 - INFO :       Use taylor pruner...
2024-04-23 16:25:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:25:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:25:25 - INFO :       Start Pruning
2024-04-23 16:25:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:25:27 - INFO :       Loss = 14.5546875
2024-04-23 16:25:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:25:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:25:30 - INFO :       high_school_geography: Total Sparsity 1.3558806551180476e-06
2024-04-23 16:25:48 - INFO :       high_school_geography: Total Accuracy (15, 22, 0.6818181818181818)
2024-04-23 16:25:48 - INFO :       
==================Finish================

2024-04-23 16:25:48 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:25:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:25:48 - INFO :       DATASET: tasksource/mmlu high_school_government_and_politics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 16:25:56 - INFO :       Use taylor pruner...
2024-04-23 16:25:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:25:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:25:56 - INFO :       Start Pruning
2024-04-23 16:25:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:25:58 - INFO :       Loss = 15.0390625
2024-04-23 16:25:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:25:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:26:01 - INFO :       high_school_government_and_politics: Total Sparsity 1.3574718775744707e-06
2024-04-23 16:26:18 - INFO :       high_school_government_and_politics: Total Accuracy (7, 21, 0.3333333333333333)
2024-04-23 16:26:18 - INFO :       
==================Finish================

2024-04-23 16:26:18 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:26:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:26:18 - INFO :       DATASET: tasksource/mmlu high_school_macroeconomics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 16:26:26 - INFO :       Use taylor pruner...
2024-04-23 16:26:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:26:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:26:26 - INFO :       Start Pruning
2024-04-23 16:26:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:26:28 - INFO :       Loss = 12.53125
2024-04-23 16:26:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:26:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:26:31 - INFO :       high_school_macroeconomics: Total Sparsity 1.3584266110483244e-06
2024-04-23 16:27:06 - INFO :       high_school_macroeconomics: Total Accuracy (17, 43, 0.3953488372093023)
2024-04-23 16:27:06 - INFO :       
==================Finish================

2024-04-23 16:27:06 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:27:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:27:06 - INFO :       DATASET: tasksource/mmlu high_school_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 16:27:13 - INFO :       Use taylor pruner...
2024-04-23 16:27:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:27:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:27:13 - INFO :       Start Pruning
2024-04-23 16:27:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:27:16 - INFO :       Loss = 14.1953125
2024-04-23 16:27:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:27:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:27:18 - INFO :       high_school_mathematics: Total Sparsity 1.3577901220657553e-06
2024-04-23 16:27:42 - INFO :       high_school_mathematics: Total Accuracy (5, 29, 0.1724137931034483)
2024-04-23 16:27:42 - INFO :       
==================Finish================

2024-04-23 16:27:42 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:27:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:27:42 - INFO :       DATASET: tasksource/mmlu high_school_microeconomics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 16:27:49 - INFO :       Use taylor pruner...
2024-04-23 16:27:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:27:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:27:50 - INFO :       Start Pruning
2024-04-23 16:27:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:27:52 - INFO :       Loss = 14.8203125
2024-04-23 16:27:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:27:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:27:55 - INFO :       high_school_microeconomics: Total Sparsity 1.358267488802682e-06
2024-04-23 16:28:16 - INFO :       high_school_microeconomics: Total Accuracy (10, 26, 0.38461538461538464)
2024-04-23 16:28:16 - INFO :       
==================Finish================

2024-04-23 16:28:16 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:28:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:28:16 - INFO :       DATASET: tasksource/mmlu high_school_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 16:28:24 - INFO :       Use taylor pruner...
2024-04-23 16:28:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:28:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:28:24 - INFO :       Start Pruning
2024-04-23 16:28:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:28:27 - INFO :       Loss = 13.8515625
2024-04-23 16:28:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:28:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:28:30 - INFO :       high_school_physics: Total Sparsity 1.356517144100617e-06
2024-04-23 16:28:44 - INFO :       high_school_physics: Total Accuracy (4, 17, 0.23529411764705882)
2024-04-23 16:28:44 - INFO :       
==================Finish================

2024-04-23 16:28:44 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:28:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:28:44 - INFO :       DATASET: tasksource/mmlu high_school_psychology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 16:28:51 - INFO :       Use taylor pruner...
2024-04-23 16:28:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:28:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:28:52 - INFO :       Start Pruning
2024-04-23 16:28:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:28:54 - INFO :       Loss = 15.0234375
2024-04-23 16:28:55 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:28:55 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:28:57 - INFO :       high_school_psychology: Total Sparsity 1.3563580218549744e-06
2024-04-23 16:29:37 - INFO :       high_school_psychology: Total Accuracy (30, 50, 0.6)
2024-04-23 16:29:37 - INFO :       
==================Finish================

2024-04-23 16:29:37 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:29:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:29:37 - INFO :       DATASET: tasksource/mmlu high_school_statistics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 16:29:44 - INFO :       Use taylor pruner...
2024-04-23 16:29:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:29:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:29:44 - INFO :       Start Pruning
2024-04-23 16:29:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:29:46 - INFO :       Loss = 12.96875
2024-04-23 16:29:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:29:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:29:49 - INFO :       high_school_statistics: Total Sparsity 1.3598587112591052e-06
2024-04-23 16:30:08 - INFO :       high_school_statistics: Total Accuracy (6, 23, 0.2608695652173913)
2024-04-23 16:30:08 - INFO :       
==================Finish================

2024-04-23 16:30:08 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:30:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:30:08 - INFO :       DATASET: tasksource/mmlu high_school_us_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 16:30:16 - INFO :       Use taylor pruner...
2024-04-23 16:30:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:30:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:30:16 - INFO :       Start Pruning
2024-04-23 16:30:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:30:18 - INFO :       Loss = 4.87890625
2024-04-23 16:30:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:30:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:30:21 - INFO :       high_school_us_history: Total Sparsity 1.3577901220657553e-06
2024-04-23 16:30:40 - INFO :       high_school_us_history: Total Accuracy (14, 22, 0.6363636363636364)
2024-04-23 16:30:40 - INFO :       
==================Finish================

2024-04-23 16:30:40 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:30:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:30:40 - INFO :       DATASET: tasksource/mmlu high_school_world_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 16:30:48 - INFO :       Use taylor pruner...
2024-04-23 16:30:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:30:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:30:48 - INFO :       Start Pruning
2024-04-23 16:30:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:30:50 - INFO :       Loss = 7.42578125
2024-04-23 16:30:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:30:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:30:53 - INFO :       high_school_world_history: Total Sparsity 1.357630999820113e-06
2024-04-23 16:31:17 - INFO :       high_school_world_history: Total Accuracy (11, 26, 0.4230769230769231)
2024-04-23 16:31:17 - INFO :       
==================Finish================

2024-04-23 16:31:17 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:31:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:31:17 - INFO :       DATASET: tasksource/mmlu human_aging
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 16:31:24 - INFO :       Use taylor pruner...
2024-04-23 16:31:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:31:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:31:25 - INFO :       Start Pruning
2024-04-23 16:31:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:31:27 - INFO :       Loss = 15.15625
2024-04-23 16:31:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:31:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:31:30 - INFO :       human_aging: Total Sparsity 1.3554032883811208e-06
2024-04-23 16:31:48 - INFO :       human_aging: Total Accuracy (13, 23, 0.5652173913043478)
2024-04-23 16:31:48 - INFO :       
==================Finish================

2024-04-23 16:31:48 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:31:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:31:48 - INFO :       DATASET: tasksource/mmlu human_sexuality
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2024-04-23 16:31:55 - INFO :       Use taylor pruner...
2024-04-23 16:31:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:31:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:31:56 - INFO :       Start Pruning
2024-04-23 16:31:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:31:58 - INFO :       Loss = 14.2578125
2024-04-23 16:31:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:31:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:32:01 - INFO :       human_sexuality: Total Sparsity 1.3606543224873167e-06
2024-04-23 16:32:10 - INFO :       human_sexuality: Total Accuracy (2, 12, 0.16666666666666666)
2024-04-23 16:32:10 - INFO :       
==================Finish================

2024-04-23 16:32:10 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:32:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:32:10 - INFO :       DATASET: tasksource/mmlu international_law
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 16:32:18 - INFO :       Use taylor pruner...
2024-04-23 16:32:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:32:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:32:18 - INFO :       Start Pruning
2024-04-23 16:32:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:32:20 - INFO :       Loss = 14.109375
2024-04-23 16:32:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:32:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:32:23 - INFO :       international_law: Total Sparsity 1.358267488802682e-06
2024-04-23 16:32:34 - INFO :       international_law: Total Accuracy (10, 13, 0.7692307692307693)
2024-04-23 16:32:34 - INFO :       
==================Finish================

2024-04-23 16:32:34 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:32:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:32:34 - INFO :       DATASET: tasksource/mmlu jurisprudence
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 16:32:41 - INFO :       Use taylor pruner...
2024-04-23 16:32:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:32:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:32:42 - INFO :       Start Pruning
2024-04-23 16:32:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:32:45 - INFO :       Loss = 15.0546875
2024-04-23 16:32:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:32:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:32:48 - INFO :       jurisprudence: Total Sparsity 1.3620864226980974e-06
2024-04-23 16:32:57 - INFO :       jurisprudence: Total Accuracy (4, 11, 0.36363636363636365)
2024-04-23 16:32:57 - INFO :       
==================Finish================

2024-04-23 16:32:57 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:32:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:32:57 - INFO :       DATASET: tasksource/mmlu logical_fallacies
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 16:33:04 - INFO :       Use taylor pruner...
2024-04-23 16:33:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:33:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:33:05 - INFO :       Start Pruning
2024-04-23 16:33:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:33:07 - INFO :       Loss = 14.015625
2024-04-23 16:33:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:33:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:33:10 - INFO :       logical_fallacies: Total Sparsity 1.353334699187771e-06
2024-04-23 16:33:24 - INFO :       logical_fallacies: Total Accuracy (10, 18, 0.5555555555555556)
2024-04-23 16:33:24 - INFO :       
==================Finish================

2024-04-23 16:33:24 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:33:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:33:24 - INFO :       DATASET: tasksource/mmlu machine_learning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 16:33:32 - INFO :       Use taylor pruner...
2024-04-23 16:33:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:33:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:33:32 - INFO :       Start Pruning
2024-04-23 16:33:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:33:34 - INFO :       Loss = 14.0625
2024-04-23 16:33:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:33:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:33:37 - INFO :       machine_learning: Total Sparsity 1.357630999820113e-06
2024-04-23 16:33:46 - INFO :       machine_learning: Total Accuracy (4, 11, 0.36363636363636365)
2024-04-23 16:33:46 - INFO :       
==================Finish================

2024-04-23 16:33:46 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:33:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:33:46 - INFO :       DATASET: tasksource/mmlu management
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 16:33:55 - INFO :       Use taylor pruner...
2024-04-23 16:33:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:33:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:33:55 - INFO :       Start Pruning
2024-04-23 16:33:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:33:59 - INFO :       Loss = 15.140625
2024-04-23 16:34:00 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:34:00 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:34:02 - INFO :       management: Total Sparsity 1.3569945108375437e-06
2024-04-23 16:34:11 - INFO :       management: Total Accuracy (7, 11, 0.6363636363636364)
2024-04-23 16:34:11 - INFO :       
==================Finish================

2024-04-23 16:34:11 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:34:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:34:11 - INFO :       DATASET: tasksource/mmlu marketing
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 16:34:18 - INFO :       Use taylor pruner...
2024-04-23 16:34:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:34:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:34:19 - INFO :       Start Pruning
2024-04-23 16:34:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:34:21 - INFO :       Loss = 14.8671875
2024-04-23 16:34:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:34:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:34:24 - INFO :       marketing: Total Sparsity 1.35603977736369e-06
2024-04-23 16:34:44 - INFO :       marketing: Total Accuracy (15, 25, 0.6)
2024-04-23 16:34:44 - INFO :       
==================Finish================

2024-04-23 16:34:44 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:34:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:34:44 - INFO :       DATASET: tasksource/mmlu medical_genetics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 16:34:52 - INFO :       Use taylor pruner...
2024-04-23 16:34:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:34:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:34:53 - INFO :       Start Pruning
2024-04-23 16:34:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:34:55 - INFO :       Loss = 14.328125
2024-04-23 16:34:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:34:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:34:58 - INFO :       medical_genetics: Total Sparsity 1.3547667993985515e-06
2024-04-23 16:35:07 - INFO :       medical_genetics: Total Accuracy (8, 11, 0.7272727272727273)
2024-04-23 16:35:07 - INFO :       
==================Finish================

2024-04-23 16:35:07 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:35:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:35:07 - INFO :       DATASET: tasksource/mmlu miscellaneous
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]
2024-04-23 16:35:15 - INFO :       Use taylor pruner...
2024-04-23 16:35:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:35:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:35:16 - INFO :       Start Pruning
2024-04-23 16:35:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:35:18 - INFO :       Loss = 14.5546875
2024-04-23 16:35:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:35:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:35:21 - INFO :       miscellaneous: Total Sparsity 1.357630999820113e-06
2024-04-23 16:36:03 - INFO :       miscellaneous: Total Accuracy (27, 50, 0.54)
2024-04-23 16:36:03 - INFO :       
==================Finish================

2024-04-23 16:36:03 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:36:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:36:03 - INFO :       DATASET: tasksource/mmlu moral_disputes
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]
2024-04-23 16:36:11 - INFO :       Use taylor pruner...
2024-04-23 16:36:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:36:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:36:12 - INFO :       Start Pruning
2024-04-23 16:36:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:36:14 - INFO :       Loss = 13.6875
2024-04-23 16:36:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:36:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:36:18 - INFO :       moral_disputes: Total Sparsity 1.3584266110483244e-06
2024-04-23 16:36:50 - INFO :       moral_disputes: Total Accuracy (18, 38, 0.47368421052631576)
2024-04-23 16:36:50 - INFO :       
==================Finish================

2024-04-23 16:36:50 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:36:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:36:50 - INFO :       DATASET: tasksource/mmlu moral_scenarios
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]
2024-04-23 16:36:58 - INFO :       Use taylor pruner...
2024-04-23 16:36:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:36:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:36:59 - INFO :       Start Pruning
2024-04-23 16:37:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:37:01 - INFO :       Loss = 13.5234375
2024-04-23 16:37:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:37:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:37:04 - INFO :       moral_scenarios: Total Sparsity 1.359699589013463e-06
2024-04-23 16:37:46 - INFO :       moral_scenarios: Total Accuracy (18, 50, 0.36)
2024-04-23 16:37:46 - INFO :       
==================Finish================

2024-04-23 16:37:46 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:37:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:37:46 - INFO :       DATASET: tasksource/mmlu nutrition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
2024-04-23 16:37:54 - INFO :       Use taylor pruner...
2024-04-23 16:37:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:37:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:37:55 - INFO :       Start Pruning
2024-04-23 16:37:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:37:57 - INFO :       Loss = 14.890625
2024-04-23 16:37:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:37:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:38:01 - INFO :       nutrition: Total Sparsity 1.3593813445221782e-06
2024-04-23 16:38:30 - INFO :       nutrition: Total Accuracy (14, 33, 0.42424242424242425)
2024-04-23 16:38:30 - INFO :       
==================Finish================

2024-04-23 16:38:30 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:38:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:38:30 - INFO :       DATASET: tasksource/mmlu philosophy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.87s/it]
2024-04-23 16:38:49 - INFO :       Use taylor pruner...
2024-04-23 16:38:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:38:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:38:49 - INFO :       Start Pruning
2024-04-23 16:39:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:39:04 - INFO :       Loss = 14.328125
2024-04-23 16:39:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:39:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:39:06 - INFO :       philosophy: Total Sparsity 1.3581083665570398e-06
2024-04-23 16:39:34 - INFO :       philosophy: Total Accuracy (17, 34, 0.5)
2024-04-23 16:39:34 - INFO :       
==================Finish================

2024-04-23 16:39:34 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:39:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:39:34 - INFO :       DATASET: tasksource/mmlu prehistory
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 16:39:42 - INFO :       Use taylor pruner...
2024-04-23 16:39:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:39:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:39:43 - INFO :       Start Pruning
2024-04-23 16:39:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:39:45 - INFO :       Loss = 14.65625
2024-04-23 16:39:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:39:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:39:48 - INFO :       prehistory: Total Sparsity 1.3604952002416743e-06
2024-04-23 16:40:17 - INFO :       prehistory: Total Accuracy (15, 35, 0.42857142857142855)
2024-04-23 16:40:17 - INFO :       
==================Finish================

2024-04-23 16:40:17 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:40:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:40:17 - INFO :       DATASET: tasksource/mmlu professional_accounting
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 16:40:26 - INFO :       Use taylor pruner...
2024-04-23 16:40:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:40:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:40:26 - INFO :       Start Pruning
2024-04-23 16:40:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:40:30 - INFO :       Loss = 12.9375
2024-04-23 16:40:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:40:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:40:33 - INFO :       professional_accounting: Total Sparsity 1.360813444732959e-06
2024-04-23 16:40:59 - INFO :       professional_accounting: Total Accuracy (11, 31, 0.3548387096774194)
2024-04-23 16:41:00 - INFO :       
==================Finish================

2024-04-23 16:41:00 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:41:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:41:00 - INFO :       DATASET: tasksource/mmlu professional_law
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2024-04-23 16:41:10 - INFO :       Use taylor pruner...
2024-04-23 16:41:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:41:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:41:10 - INFO :       Start Pruning
2024-04-23 16:41:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:41:12 - INFO :       Loss = 6.7109375
2024-04-23 16:41:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:41:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:41:15 - INFO :       professional_law: Total Sparsity 1.3566762663462592e-06
2024-04-23 16:42:00 - INFO :       professional_law: Total Accuracy (8, 50, 0.16)
2024-04-23 16:42:00 - INFO :       
==================Finish================

2024-04-23 16:42:00 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:42:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:42:00 - INFO :       DATASET: tasksource/mmlu professional_medicine
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 16:42:08 - INFO :       Use taylor pruner...
2024-04-23 16:42:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:42:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:42:09 - INFO :       Start Pruning
2024-04-23 16:42:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:42:11 - INFO :       Loss = 8.203125
2024-04-23 16:42:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:42:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:42:14 - INFO :       professional_medicine: Total Sparsity 1.3557215328724054e-06
2024-04-23 16:42:41 - INFO :       professional_medicine: Total Accuracy (12, 31, 0.3870967741935484)
2024-04-23 16:42:41 - INFO :       
==================Finish================

2024-04-23 16:42:41 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:42:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:42:41 - INFO :       DATASET: tasksource/mmlu professional_psychology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2024-04-23 16:42:49 - INFO :       Use taylor pruner...
2024-04-23 16:42:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:42:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:42:49 - INFO :       Start Pruning
2024-04-23 16:42:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:42:52 - INFO :       Loss = 14.3671875
2024-04-23 16:42:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:42:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:42:55 - INFO :       professional_psychology: Total Sparsity 1.359222222276536e-06
2024-04-23 16:43:36 - INFO :       professional_psychology: Total Accuracy (21, 50, 0.42)
2024-04-23 16:43:36 - INFO :       
==================Finish================

2024-04-23 16:43:36 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:43:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:43:36 - INFO :       DATASET: tasksource/mmlu public_relations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 16:43:44 - INFO :       Use taylor pruner...
2024-04-23 16:43:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:43:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:43:44 - INFO :       Start Pruning
2024-04-23 16:43:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:43:47 - INFO :       Loss = 15.3359375
2024-04-23 16:43:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:43:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:43:50 - INFO :       public_relations: Total Sparsity 1.3563580218549744e-06
2024-04-23 16:43:59 - INFO :       public_relations: Total Accuracy (6, 12, 0.5)
2024-04-23 16:43:59 - INFO :       
==================Finish================

2024-04-23 16:43:59 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:43:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:43:59 - INFO :       DATASET: tasksource/mmlu security_studies
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 16:44:07 - INFO :       Use taylor pruner...
2024-04-23 16:44:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:44:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:44:08 - INFO :       Start Pruning
2024-04-23 16:44:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:44:10 - INFO :       Loss = 13.4453125
2024-04-23 16:44:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:44:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:44:13 - INFO :       security_studies: Total Sparsity 1.3584266110483244e-06
2024-04-23 16:44:36 - INFO :       security_studies: Total Accuracy (13, 27, 0.48148148148148145)
2024-04-23 16:44:37 - INFO :       
==================Finish================

2024-04-23 16:44:37 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:44:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:44:37 - INFO :       DATASET: tasksource/mmlu sociology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 16:44:45 - INFO :       Use taylor pruner...
2024-04-23 16:44:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:44:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:44:45 - INFO :       Start Pruning
2024-04-23 16:44:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:44:48 - INFO :       Loss = 14.609375
2024-04-23 16:44:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:44:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:44:51 - INFO :       sociology: Total Sparsity 1.355562410626763e-06
2024-04-23 16:45:09 - INFO :       sociology: Total Accuracy (13, 22, 0.5909090909090909)
2024-04-23 16:45:09 - INFO :       
==================Finish================

2024-04-23 16:45:09 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:45:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:45:09 - INFO :       DATASET: tasksource/mmlu us_foreign_policy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2024-04-23 16:45:17 - INFO :       Use taylor pruner...
2024-04-23 16:45:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:45:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:45:17 - INFO :       Start Pruning
2024-04-23 16:45:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:45:19 - INFO :       Loss = 14.6328125
2024-04-23 16:45:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:45:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:45:22 - INFO :       us_foreign_policy: Total Sparsity 1.3600178335047475e-06
2024-04-23 16:45:31 - INFO :       us_foreign_policy: Total Accuracy (7, 11, 0.6363636363636364)
2024-04-23 16:45:31 - INFO :       
==================Finish================

2024-04-23 16:45:31 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:45:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:45:31 - INFO :       DATASET: tasksource/mmlu virology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 16:45:39 - INFO :       Use taylor pruner...
2024-04-23 16:45:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:45:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:45:39 - INFO :       Start Pruning
2024-04-23 16:45:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:45:41 - INFO :       Loss = 14.71875
2024-04-23 16:45:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:45:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:45:44 - INFO :       virology: Total Sparsity 1.3598587112591052e-06
2024-04-23 16:45:59 - INFO :       virology: Total Accuracy (10, 18, 0.5555555555555556)
2024-04-23 16:45:59 - INFO :       
==================Finish================

2024-04-23 16:45:59 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:45:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:45:59 - INFO :       DATASET: tasksource/mmlu world_religions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2024-04-23 16:46:07 - INFO :       Use taylor pruner...
2024-04-23 16:46:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:46:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:46:08 - INFO :       Start Pruning
2024-04-23 16:46:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:46:10 - INFO :       Loss = 15.2578125
2024-04-23 16:46:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:46:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:46:13 - INFO :       world_religions: Total Sparsity 1.359699589013463e-06
2024-04-23 16:46:28 - INFO :       world_religions: Total Accuracy (13, 19, 0.6842105263157895)
2024-04-23 16:46:28 - INFO :       
==================Finish================

2024-04-23 16:46:28 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:46:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:46:28 - INFO :       DATASET: math_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]
2024-04-23 16:46:37 - INFO :       Use taylor pruner...
2024-04-23 16:46:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:46:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:46:37 - INFO :       Start Pruning
2024-04-23 16:46:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:46:39 - INFO :       Loss = 14.1953125
2024-04-23 16:46:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:46:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:46:42 - INFO :       math_qa: Total Sparsity 1.3563580218549744e-06
2024-04-23 16:47:20 - INFO :       math_qa: Accuracy (9, 50, 0.18)
2024-04-23 16:47:20 - INFO :       
==================Finish================

2024-04-23 16:47:20 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:47:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:47:20 - INFO :       DATASET: EleutherAI/truthful_qa_mc
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 16:47:28 - INFO :       Use taylor pruner...
2024-04-23 16:47:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:47:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:47:28 - INFO :       Start Pruning
2024-04-23 16:47:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:47:30 - INFO :       Loss = 13.9140625
2024-04-23 16:47:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:47:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:47:33 - INFO :       truthful_qa_mc: Total Sparsity 1.359699589013463e-06
2024-04-23 16:48:08 - INFO :       truthful_qa_mc: Accuracy (18, 50, 0.36)
2024-04-23 16:48:08 - INFO :       
==================Finish================

2024-04-23 16:48:08 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-23 16:48:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:48:08 - INFO :       DATASET: derek-thomas/ScienceQA
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2024-04-23 16:48:16 - INFO :       Use taylor pruner...
2024-04-23 16:48:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:48:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:48:17 - INFO :       Start Pruning
2024-04-23 16:48:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:48:19 - INFO :       Loss = 15.1640625
2024-04-23 16:48:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:48:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:48:22 - INFO :       ScienceQA: Total Sparsity 1.3573127553288283e-06
2024-04-23 16:48:57 - INFO :       ScienceQA: Accuracy (34, 50, 0.68)
2024-04-23 16:48:57 - INFO :       
==================Finish================

2024-04-23 16:48:57 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-23 16:48:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:48:57 - INFO :       DATASET: commonsense_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2024-04-23 16:49:05 - INFO :       Use taylor pruner...
2024-04-23 16:49:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:49:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:49:06 - INFO :       Start Pruning
2024-04-23 16:49:07 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:49:08 - INFO :       Loss = 15.4453125
2024-04-23 16:49:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:49:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:49:11 - INFO :       commonsense_qa: Total Sparsity 1.3584266110483244e-06
2024-04-23 16:49:46 - INFO :       commonsense_qa: Accuracy (30, 50, 0.6)
2024-04-23 16:49:46 - INFO :       
==================Finish================

2024-04-23 16:49:46 - INFO :       Memory Requirement: 12676.77392578125 MiB

End: Memory Requirement: 3979.2666015625 MiB

Begin: Memory Requirement: 3979.2666015625 MiB

2024-04-23 16:49:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:49:46 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Index 1
Sparsity 3.5000000000000004 %
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 16:49:54 - INFO :       Use taylor pruner...
2024-04-23 16:49:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:49:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:49:54 - INFO :       Start Pruning
2024-04-23 16:49:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:49:57 - INFO :       Loss = 1.5
2024-04-23 16:49:58 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:49:58 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:49:59 - INFO :       which_wiki_edit: Total Sparsity 1.3552441661354783e-06
2024-04-23 16:51:40 - INFO :       which_wiki_edit: Total Accuracy (25, 50, 0.5)
2024-04-23 16:51:40 - INFO :       
==================Finish================

2024-04-23 16:51:40 - INFO :       Memory Requirement: 16849.60302734375 MiB

2024-04-23 16:51:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:51:40 - INFO :       DATASET: tasksource/bigbench abstract_narrative_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.37s/it]
2024-04-23 16:51:57 - INFO :       Use taylor pruner...
2024-04-23 16:51:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:51:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:51:58 - INFO :       Start Pruning
2024-04-23 16:51:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:52:00 - INFO :       Loss = 7.3359375
2024-04-23 16:52:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:52:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:52:03 - INFO :       abstract_narrative_understanding: Total Sparsity 1.3590631000308936e-06
2024-04-23 16:52:46 - INFO :       abstract_narrative_understanding: Total Accuracy (16, 50, 0.32)
2024-04-23 16:52:46 - INFO :       
==================Finish================

2024-04-23 16:52:46 - INFO :       Memory Requirement: 16772.79052734375 MiB

2024-04-23 16:52:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:52:46 - INFO :       DATASET: tasksource/bigbench anachronisms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-23 16:52:54 - INFO :       Use taylor pruner...
2024-04-23 16:52:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:52:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:52:55 - INFO :       Start Pruning
2024-04-23 16:52:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:52:57 - INFO :       Loss = 15.6015625
2024-04-23 16:52:58 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:52:58 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:53:00 - INFO :       anachronisms: Total Sparsity 1.3574718775744707e-06
2024-04-23 16:53:37 - INFO :       anachronisms: Total Accuracy (25, 46, 0.5434782608695652)
2024-04-23 16:53:37 - INFO :       
==================Finish================

2024-04-23 16:53:37 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-23 16:53:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:53:37 - INFO :       DATASET: tasksource/bigbench analogical_similarity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2024-04-23 16:53:48 - INFO :       Use taylor pruner...
2024-04-23 16:53:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:53:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:53:48 - INFO :       Start Pruning
2024-04-23 16:53:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:53:50 - INFO :       Loss = 1.46875
2024-04-23 16:53:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:53:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:53:53 - INFO :       analogical_similarity: Total Sparsity 1.3584266110483244e-06
2024-04-23 16:54:47 - INFO :       analogical_similarity: Total Accuracy (3, 50, 0.06)
2024-04-23 16:54:47 - INFO :       
==================Finish================

2024-04-23 16:54:47 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-23 16:54:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:54:47 - INFO :       DATASET: tasksource/bigbench analytic_entailment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2024-04-23 16:54:55 - INFO :       Use taylor pruner...
2024-04-23 16:54:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:54:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:54:55 - INFO :       Start Pruning
2024-04-23 16:54:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:54:57 - INFO :       Loss = 14.7734375
2024-04-23 16:54:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:54:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:55:00 - INFO :       analytic_entailment: Total Sparsity 1.3569945108375437e-06
2024-04-23 16:55:13 - INFO :       analytic_entailment: Total Accuracy (8, 16, 0.5)
2024-04-23 16:55:14 - INFO :       
==================Finish================

2024-04-23 16:55:14 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-23 16:55:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:55:14 - INFO :       DATASET: tasksource/bigbench arithmetic
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]
2024-04-23 16:55:22 - INFO :       Use taylor pruner...
2024-04-23 16:55:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:55:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:55:22 - INFO :       Start Pruning
2024-04-23 16:55:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:55:24 - INFO :       Loss = 12.546875
2024-04-23 16:55:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:55:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:55:27 - INFO :       arithmetic: Total Sparsity 1.3566762663462592e-06
2024-04-23 16:56:08 - INFO :       arithmetic: Total Accuracy (2, 50, 0.04)
2024-04-23 16:56:08 - INFO :       
==================Finish================

2024-04-23 16:56:08 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-23 16:56:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:56:08 - INFO :       DATASET: tasksource/bigbench authorship_verification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]
2024-04-23 16:56:17 - INFO :       Use taylor pruner...
2024-04-23 16:56:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:56:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:56:17 - INFO :       Start Pruning
2024-04-23 16:56:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:56:19 - INFO :       Loss = 2.791015625
2024-04-23 16:56:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:56:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:56:22 - INFO :       authorship_verification: Total Sparsity 1.358267488802682e-06
2024-04-23 16:58:33 - INFO :       authorship_verification: Total Accuracy (24, 50, 0.48)
2024-04-23 16:58:33 - INFO :       
==================Finish================

2024-04-23 16:58:33 - INFO :       Memory Requirement: 16794.44580078125 MiB

2024-04-23 16:58:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:58:33 - INFO :       DATASET: tasksource/bigbench bbq_lite_json
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]
2024-04-23 16:58:41 - INFO :       Use taylor pruner...
2024-04-23 16:58:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:58:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:58:42 - INFO :       Start Pruning
2024-04-23 16:58:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:58:46 - INFO :       Loss = 14.265625
2024-04-23 16:58:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:58:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:58:49 - INFO :       bbq_lite_json: Total Sparsity 1.3589039777852514e-06
2024-04-23 16:59:30 - INFO :       bbq_lite_json: Total Accuracy (17, 50, 0.34)
2024-04-23 16:59:31 - INFO :       
==================Finish================

2024-04-23 16:59:31 - INFO :       Memory Requirement: 16771.79052734375 MiB

2024-04-23 16:59:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 16:59:31 - INFO :       DATASET: tasksource/bigbench causal_judgment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-23 16:59:39 - INFO :       Use taylor pruner...
2024-04-23 16:59:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:59:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 16:59:40 - INFO :       Start Pruning
2024-04-23 16:59:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 16:59:42 - INFO :       Loss = 11.546875
2024-04-23 16:59:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 16:59:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 16:59:47 - INFO :       causal_judgment: Total Sparsity 1.3581083665570398e-06
2024-04-23 17:00:21 - INFO :       causal_judgment: Total Accuracy (17, 38, 0.4473684210526316)
2024-04-23 17:00:21 - INFO :       
==================Finish================

2024-04-23 17:00:21 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:00:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:00:21 - INFO :       DATASET: tasksource/bigbench cause_and_effect
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 17:00:31 - INFO :       Use taylor pruner...
2024-04-23 17:00:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:00:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:00:31 - INFO :       Start Pruning
2024-04-23 17:00:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:00:33 - INFO :       Loss = 16.234375
2024-04-23 17:00:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:00:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:00:36 - INFO :       cause_and_effect: Total Sparsity 1.3573127553288283e-06
2024-04-23 17:01:01 - INFO :       cause_and_effect: Total Accuracy (8, 30, 0.26666666666666666)
2024-04-23 17:01:01 - INFO :       
==================Finish================

2024-04-23 17:01:01 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:01:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:01:01 - INFO :       DATASET: tasksource/bigbench checkmate_in_one
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]
2024-04-23 17:01:09 - INFO :       Use taylor pruner...
2024-04-23 17:01:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:01:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:01:09 - INFO :       Start Pruning
2024-04-23 17:01:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:01:12 - INFO :       Loss = 4.16015625
2024-04-23 17:01:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:01:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:01:15 - INFO :       checkmate_in_one: Total Sparsity 1.3632002784175935e-06
2024-04-23 17:02:03 - INFO :       checkmate_in_one: Total Accuracy (17, 50, 0.34)
2024-04-23 17:02:03 - INFO :       
==================Finish================

2024-04-23 17:02:03 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:02:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:02:03 - INFO :       DATASET: tasksource/bigbench cifar10_classification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-23 17:02:13 - INFO :       Use taylor pruner...
2024-04-23 17:02:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:02:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:02:14 - INFO :       Start Pruning
2024-04-23 17:02:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:02:16 - INFO :       Loss = 1.9052734375
2024-04-23 17:02:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:02:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:02:19 - INFO :       cifar10_classification: Total Sparsity 1.3577901220657553e-06
2024-04-23 17:04:12 - INFO :       cifar10_classification: Total Accuracy (4, 50, 0.08)
2024-04-23 17:04:13 - INFO :       
==================Finish================

2024-04-23 17:04:13 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:04:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:04:13 - INFO :       DATASET: tasksource/bigbench code_line_description
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]
2024-04-23 17:04:27 - INFO :       Use taylor pruner...
2024-04-23 17:04:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:04:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:04:28 - INFO :       Start Pruning
2024-04-23 17:04:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:04:30 - INFO :       Loss = 12.3671875
2024-04-23 17:04:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:04:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:04:33 - INFO :       code_line_description: Total Sparsity 1.3606543224873167e-06
2024-04-23 17:04:47 - INFO :       code_line_description: Total Accuracy (6, 16, 0.375)
2024-04-23 17:04:47 - INFO :       
==================Finish================

2024-04-23 17:04:47 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:04:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:04:47 - INFO :       DATASET: tasksource/bigbench color
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 17:04:55 - INFO :       Use taylor pruner...
2024-04-23 17:04:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:04:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:04:55 - INFO :       Start Pruning
2024-04-23 17:04:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:04:58 - INFO :       Loss = 11.2578125
2024-04-23 17:04:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:04:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:05:01 - INFO :       color: Total Sparsity 1.3593813445221782e-06
2024-04-23 17:05:42 - INFO :       color: Total Accuracy (13, 50, 0.26)
2024-04-23 17:05:42 - INFO :       
==================Finish================

2024-04-23 17:05:42 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:05:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:05:42 - INFO :       DATASET: tasksource/bigbench common_morpheme
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2024-04-23 17:05:51 - INFO :       Use taylor pruner...
2024-04-23 17:05:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:05:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:05:51 - INFO :       Start Pruning
2024-04-23 17:05:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:05:53 - INFO :       Loss = 13.6171875
2024-04-23 17:05:55 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:05:55 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:05:59 - INFO :       common_morpheme: Total Sparsity 1.3581083665570398e-06
2024-04-23 17:06:12 - INFO :       common_morpheme: Total Accuracy (4, 16, 0.25)
2024-04-23 17:06:13 - INFO :       
==================Finish================

2024-04-23 17:06:13 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:06:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:06:13 - INFO :       DATASET: tasksource/bigbench conceptual_combinations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 17:06:20 - INFO :       Use taylor pruner...
2024-04-23 17:06:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:06:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:06:21 - INFO :       Start Pruning
2024-04-23 17:06:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:06:23 - INFO :       Loss = 12.484375
2024-04-23 17:06:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:06:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:06:26 - INFO :       conceptual_combinations: Total Sparsity 1.358267488802682e-06
2024-04-23 17:06:42 - INFO :       conceptual_combinations: Total Accuracy (2, 19, 0.10526315789473684)
2024-04-23 17:06:42 - INFO :       
==================Finish================

2024-04-23 17:06:42 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:06:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:06:42 - INFO :       DATASET: tasksource/bigbench crash_blossom
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-23 17:06:52 - INFO :       Use taylor pruner...
2024-04-23 17:06:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:06:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:06:52 - INFO :       Start Pruning
2024-04-23 17:06:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:06:56 - INFO :       Loss = 13.9609375
2024-04-23 17:06:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:06:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:07:01 - INFO :       crash_blossom: Total Sparsity 1.3546076771529093e-06
2024-04-23 17:07:14 - INFO :       crash_blossom: Total Accuracy (5, 16, 0.3125)
2024-04-23 17:07:14 - INFO :       
==================Finish================

2024-04-23 17:07:14 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:07:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:07:14 - INFO :       DATASET: tasksource/bigbench crass_ai
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 17:07:22 - INFO :       Use taylor pruner...
2024-04-23 17:07:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:07:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:07:23 - INFO :       Start Pruning
2024-04-23 17:07:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:07:25 - INFO :       Loss = 13.0234375
2024-04-23 17:07:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:07:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:07:28 - INFO :       crass_ai: Total Sparsity 1.3585857332939668e-06
2024-04-23 17:07:41 - INFO :       crass_ai: Total Accuracy (4, 16, 0.25)
2024-04-23 17:07:41 - INFO :       
==================Finish================

2024-04-23 17:07:41 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:07:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:07:41 - INFO :       DATASET: tasksource/bigbench cryobiology_spanish
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-23 17:07:49 - INFO :       Use taylor pruner...
2024-04-23 17:07:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:07:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:07:50 - INFO :       Start Pruning
2024-04-23 17:07:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:07:51 - INFO :       Loss = 14.203125
2024-04-23 17:07:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:07:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:07:54 - INFO :       cryobiology_spanish: Total Sparsity 1.3595404667678207e-06
2024-04-23 17:08:18 - INFO :       cryobiology_spanish: Total Accuracy (5, 29, 0.1724137931034483)
2024-04-23 17:08:18 - INFO :       
==================Finish================

2024-04-23 17:08:18 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:08:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:08:18 - INFO :       DATASET: tasksource/bigbench cs_algorithms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2024-04-23 17:08:26 - INFO :       Use taylor pruner...
2024-04-23 17:08:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:08:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:08:26 - INFO :       Start Pruning
2024-04-23 17:08:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:08:28 - INFO :       Loss = 13.71875
2024-04-23 17:08:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:08:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:08:31 - INFO :       cs_algorithms: Total Sparsity 1.3601769557503897e-06
2024-04-23 17:09:13 - INFO :       cs_algorithms: Total Accuracy (5, 50, 0.1)
2024-04-23 17:09:13 - INFO :       
==================Finish================

2024-04-23 17:09:13 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:09:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:09:13 - INFO :       DATASET: tasksource/bigbench dark_humor_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 17:09:20 - INFO :       Use taylor pruner...
2024-04-23 17:09:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:09:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:09:21 - INFO :       Start Pruning
2024-04-23 17:09:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:09:23 - INFO :       Loss = 14.0078125
2024-04-23 17:09:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:09:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:09:26 - INFO :       dark_humor_detection: Total Sparsity 1.3579492443113975e-06
2024-04-23 17:09:39 - INFO :       dark_humor_detection: Total Accuracy (10, 16, 0.625)
2024-04-23 17:09:39 - INFO :       
==================Finish================

2024-04-23 17:09:39 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:09:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:09:39 - INFO :       DATASET: tasksource/bigbench date_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2024-04-23 17:09:47 - INFO :       Use taylor pruner...
2024-04-23 17:09:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:09:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:09:47 - INFO :       Start Pruning
2024-04-23 17:09:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:09:49 - INFO :       Loss = 12.015625
2024-04-23 17:09:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:09:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:09:52 - INFO :       date_understanding: Total Sparsity 1.358267488802682e-06
2024-04-23 17:10:34 - INFO :       date_understanding: Total Accuracy (1, 50, 0.02)
2024-04-23 17:10:34 - INFO :       
==================Finish================

2024-04-23 17:10:34 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:10:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:10:34 - INFO :       DATASET: tasksource/bigbench disambiguation_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2024-04-23 17:10:42 - INFO :       Use taylor pruner...
2024-04-23 17:10:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:10:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:10:42 - INFO :       Start Pruning
2024-04-23 17:10:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:10:45 - INFO :       Loss = 12.8984375
2024-04-23 17:10:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:10:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:10:48 - INFO :       disambiguation_qa: Total Sparsity 1.356517144100617e-06
2024-04-23 17:11:29 - INFO :       disambiguation_qa: Total Accuracy (21, 50, 0.42)
2024-04-23 17:11:29 - INFO :       
==================Finish================

2024-04-23 17:11:29 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:11:29 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:11:29 - INFO :       DATASET: tasksource/bigbench discourse_marker_prediction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-23 17:11:36 - INFO :       Use taylor pruner...
2024-04-23 17:11:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:11:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:11:37 - INFO :       Start Pruning
2024-04-23 17:11:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:11:39 - INFO :       Loss = 2.568359375
2024-04-23 17:11:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:11:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:11:42 - INFO :       discourse_marker_prediction: Total Sparsity 1.357153633083186e-06
2024-04-23 17:12:31 - INFO :       discourse_marker_prediction: Total Accuracy (8, 50, 0.16)
2024-04-23 17:12:31 - INFO :       
==================Finish================

2024-04-23 17:12:31 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:12:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:12:31 - INFO :       DATASET: tasksource/bigbench dyck_languages
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 17:12:39 - INFO :       Use taylor pruner...
2024-04-23 17:12:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:12:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:12:39 - INFO :       Start Pruning
2024-04-23 17:12:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:12:41 - INFO :       Loss = 1.1396484375
2024-04-23 17:12:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:12:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:12:44 - INFO :       dyck_languages: Total Sparsity 1.3549259216441938e-06
2024-04-23 17:13:32 - INFO :       dyck_languages: Total Accuracy (0, 50, 0.0)
2024-04-23 17:13:32 - INFO :       
==================Finish================

2024-04-23 17:13:32 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:13:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:13:32 - INFO :       DATASET: tasksource/bigbench elementary_math_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2024-04-23 17:13:40 - INFO :       Use taylor pruner...
2024-04-23 17:13:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:13:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:13:41 - INFO :       Start Pruning
2024-04-23 17:13:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:13:43 - INFO :       Loss = 13.0390625
2024-04-23 17:13:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:13:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:13:46 - INFO :       elementary_math_qa: Total Sparsity 1.3585857332939668e-06
2024-04-23 17:14:26 - INFO :       elementary_math_qa: Total Accuracy (9, 50, 0.18)
2024-04-23 17:14:26 - INFO :       
==================Finish================

2024-04-23 17:14:26 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:14:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:14:26 - INFO :       DATASET: tasksource/bigbench emoji_movie
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]
2024-04-23 17:14:35 - INFO :       Use taylor pruner...
2024-04-23 17:14:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:14:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:14:35 - INFO :       Start Pruning
2024-04-23 17:14:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:14:37 - INFO :       Loss = 13.4140625
2024-04-23 17:14:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:14:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:14:40 - INFO :       emoji_movie: Total Sparsity 1.3577901220657553e-06
2024-04-23 17:14:56 - INFO :       emoji_movie: Total Accuracy (0, 20, 0.0)
2024-04-23 17:14:56 - INFO :       
==================Finish================

2024-04-23 17:14:56 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:14:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:14:56 - INFO :       DATASET: tasksource/bigbench empirical_judgments
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2024-04-23 17:15:04 - INFO :       Use taylor pruner...
2024-04-23 17:15:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:15:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:15:04 - INFO :       Start Pruning
2024-04-23 17:15:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:15:07 - INFO :       Loss = 13.5234375
2024-04-23 17:15:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:15:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:15:10 - INFO :       empirical_judgments: Total Sparsity 1.3600178335047475e-06
2024-04-23 17:15:25 - INFO :       empirical_judgments: Total Accuracy (10, 19, 0.5263157894736842)
2024-04-23 17:15:25 - INFO :       
==================Finish================

2024-04-23 17:15:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:15:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:15:25 - INFO :       DATASET: tasksource/bigbench english_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 17:15:33 - INFO :       Use taylor pruner...
2024-04-23 17:15:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:15:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:15:33 - INFO :       Start Pruning
2024-04-23 17:15:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:15:35 - INFO :       Loss = 12.203125
2024-04-23 17:15:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:15:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:15:38 - INFO :       english_proverbs: Total Sparsity 1.3612908114698858e-06
2024-04-23 17:15:52 - INFO :       english_proverbs: Total Accuracy (4, 16, 0.25)
2024-04-23 17:15:52 - INFO :       
==================Finish================

2024-04-23 17:15:52 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:15:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:15:52 - INFO :       DATASET: tasksource/bigbench english_russian_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2024-04-23 17:15:59 - INFO :       Use taylor pruner...
2024-04-23 17:15:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:15:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:16:00 - INFO :       Start Pruning
2024-04-23 17:16:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:16:02 - INFO :       Loss = 12.0859375
2024-04-23 17:16:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:16:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:16:05 - INFO :       english_russian_proverbs: Total Sparsity 1.354448554907267e-06
2024-04-23 17:16:18 - INFO :       english_russian_proverbs: Total Accuracy (7, 16, 0.4375)
2024-04-23 17:16:18 - INFO :       
==================Finish================

2024-04-23 17:16:18 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:16:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:16:18 - INFO :       DATASET: tasksource/bigbench entailed_polarity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.87s/it]
2024-04-23 17:16:37 - INFO :       Use taylor pruner...
2024-04-23 17:16:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:16:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:16:37 - INFO :       Start Pruning
2024-04-23 17:16:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:16:40 - INFO :       Loss = 15.8984375
2024-04-23 17:16:42 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:16:42 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:16:44 - INFO :       entailed_polarity: Total Sparsity 1.358267488802682e-06
2024-04-23 17:17:08 - INFO :       entailed_polarity: Total Accuracy (29, 29, 1.0)
2024-04-23 17:17:08 - INFO :       
==================Finish================

2024-04-23 17:17:08 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:17:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:17:08 - INFO :       DATASET: tasksource/bigbench entailed_polarity_hindi
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2024-04-23 17:17:16 - INFO :       Use taylor pruner...
2024-04-23 17:17:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:17:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:17:16 - INFO :       Start Pruning
2024-04-23 17:17:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:17:19 - INFO :       Loss = 11.859375
2024-04-23 17:17:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:17:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:17:22 - INFO :       entailed_polarity_hindi: Total Sparsity 1.358267488802682e-06
2024-04-23 17:17:47 - INFO :       entailed_polarity_hindi: Total Accuracy (15, 27, 0.5555555555555556)
2024-04-23 17:17:47 - INFO :       
==================Finish================

2024-04-23 17:17:47 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:17:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:17:47 - INFO :       DATASET: tasksource/bigbench epistemic_reasoning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.37s/it]
2024-04-23 17:18:03 - INFO :       Use taylor pruner...
2024-04-23 17:18:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:18:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:18:03 - INFO :       Start Pruning
2024-04-23 17:18:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:18:05 - INFO :       Loss = 13.53125
2024-04-23 17:18:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:18:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:18:09 - INFO :       epistemic_reasoning: Total Sparsity 1.3579492443113975e-06
2024-04-23 17:18:50 - INFO :       epistemic_reasoning: Total Accuracy (26, 50, 0.52)
2024-04-23 17:18:50 - INFO :       
==================Finish================

2024-04-23 17:18:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:18:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:18:50 - INFO :       DATASET: tasksource/bigbench evaluating_information_essentiality
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2024-04-23 17:18:58 - INFO :       Use taylor pruner...
2024-04-23 17:18:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:18:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:18:59 - INFO :       Start Pruning
2024-04-23 17:19:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:19:01 - INFO :       Loss = 8.9765625
2024-04-23 17:19:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:19:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:19:04 - INFO :       evaluating_information_essentiality: Total Sparsity 1.357153633083186e-06
2024-04-23 17:19:17 - INFO :       evaluating_information_essentiality: Total Accuracy (5, 16, 0.3125)
2024-04-23 17:19:17 - INFO :       
==================Finish================

2024-04-23 17:19:17 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:19:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:19:17 - INFO :       DATASET: tasksource/bigbench fact_checker
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2024-04-23 17:19:25 - INFO :       Use taylor pruner...
2024-04-23 17:19:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:19:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:19:26 - INFO :       Start Pruning
2024-04-23 17:19:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:19:28 - INFO :       Loss = 15.65625
2024-04-23 17:19:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:19:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:19:31 - INFO :       fact_checker: Total Sparsity 1.3547667993985515e-06
2024-04-23 17:20:12 - INFO :       fact_checker: Total Accuracy (31, 50, 0.62)
2024-04-23 17:20:13 - INFO :       
==================Finish================

2024-04-23 17:20:13 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:20:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:20:13 - INFO :       DATASET: tasksource/bigbench fantasy_reasoning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 17:20:20 - INFO :       Use taylor pruner...
2024-04-23 17:20:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:20:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:20:21 - INFO :       Start Pruning
2024-04-23 17:20:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:20:23 - INFO :       Loss = 14.265625
2024-04-23 17:20:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:20:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:20:26 - INFO :       fantasy_reasoning: Total Sparsity 1.3593813445221782e-06
2024-04-23 17:20:59 - INFO :       fantasy_reasoning: Total Accuracy (23, 40, 0.575)
2024-04-23 17:20:59 - INFO :       
==================Finish================

2024-04-23 17:20:59 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:20:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:20:59 - INFO :       DATASET: tasksource/bigbench figure_of_speech_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 17:21:07 - INFO :       Use taylor pruner...
2024-04-23 17:21:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:21:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:21:07 - INFO :       Start Pruning
2024-04-23 17:21:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:21:10 - INFO :       Loss = 12.1796875
2024-04-23 17:21:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:21:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:21:13 - INFO :       figure_of_speech_detection: Total Sparsity 1.3547667993985515e-06
2024-04-23 17:21:26 - INFO :       figure_of_speech_detection: Total Accuracy (5, 16, 0.3125)
2024-04-23 17:21:26 - INFO :       
==================Finish================

2024-04-23 17:21:26 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:21:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:21:26 - INFO :       DATASET: tasksource/bigbench formal_fallacies_syllogisms_negation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 17:21:34 - INFO :       Use taylor pruner...
2024-04-23 17:21:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:21:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:21:35 - INFO :       Start Pruning
2024-04-23 17:21:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:21:38 - INFO :       Loss = 12.234375
2024-04-23 17:21:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:21:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:21:41 - INFO :       formal_fallacies_syllogisms_negation: Total Sparsity 1.3590631000308936e-06
2024-04-23 17:22:22 - INFO :       formal_fallacies_syllogisms_negation: Total Accuracy (25, 50, 0.5)
2024-04-23 17:22:22 - INFO :       
==================Finish================

2024-04-23 17:22:22 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:22:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:22:22 - INFO :       DATASET: tasksource/bigbench general_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2024-04-23 17:22:30 - INFO :       Use taylor pruner...
2024-04-23 17:22:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:22:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:22:30 - INFO :       Start Pruning
2024-04-23 17:22:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:22:32 - INFO :       Loss = 12.3359375
2024-04-23 17:22:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:22:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:22:35 - INFO :       general_knowledge: Total Sparsity 1.3604952002416743e-06
2024-04-23 17:22:49 - INFO :       general_knowledge: Total Accuracy (3, 16, 0.1875)
2024-04-23 17:22:49 - INFO :       
==================Finish================

2024-04-23 17:22:49 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:22:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:22:49 - INFO :       DATASET: tasksource/bigbench geometric_shapes
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 17:23:01 - INFO :       Use taylor pruner...
2024-04-23 17:23:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:23:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:23:02 - INFO :       Start Pruning
2024-04-23 17:23:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:23:04 - INFO :       Loss = 9.828125
2024-04-23 17:23:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:23:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:23:07 - INFO :       geometric_shapes: Total Sparsity 1.3604952002416743e-06
2024-04-23 17:23:50 - INFO :       geometric_shapes: Total Accuracy (2, 50, 0.04)
2024-04-23 17:23:50 - INFO :       
==================Finish================

2024-04-23 17:23:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:23:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:23:50 - INFO :       DATASET: tasksource/bigbench goal_step_wikihow
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]
2024-04-23 17:23:58 - INFO :       Use taylor pruner...
2024-04-23 17:23:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:23:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:23:59 - INFO :       Start Pruning
2024-04-23 17:24:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:24:01 - INFO :       Loss = 13.453125
2024-04-23 17:24:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:24:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:24:04 - INFO :       goal_step_wikihow: Total Sparsity 1.3595404667678207e-06
2024-04-23 17:24:44 - INFO :       goal_step_wikihow: Total Accuracy (8, 50, 0.16)
2024-04-23 17:24:44 - INFO :       
==================Finish================

2024-04-23 17:24:44 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:24:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:24:44 - INFO :       DATASET: tasksource/bigbench gre_reading_comprehension
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]
2024-04-23 17:24:52 - INFO :       Use taylor pruner...
2024-04-23 17:24:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:24:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:24:52 - INFO :       Start Pruning
2024-04-23 17:24:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:24:54 - INFO :       Loss = 2.19140625
2024-04-23 17:24:58 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:24:58 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:24:59 - INFO :       gre_reading_comprehension: Total Sparsity 1.358267488802682e-06
2024-04-23 17:25:15 - INFO :       gre_reading_comprehension: Total Accuracy (3, 16, 0.1875)
2024-04-23 17:25:15 - INFO :       
==================Finish================

2024-04-23 17:25:15 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:25:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:25:15 - INFO :       DATASET: tasksource/bigbench hhh_alignment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 17:25:23 - INFO :       Use taylor pruner...
2024-04-23 17:25:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:25:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:25:23 - INFO :       Start Pruning
2024-04-23 17:25:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:25:25 - INFO :       Loss = 11.90625
2024-04-23 17:25:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:25:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:25:28 - INFO :       hhh_alignment: Total Sparsity 1.3584266110483244e-06
2024-04-23 17:26:07 - INFO :       hhh_alignment: Total Accuracy (21, 42, 0.5)
2024-04-23 17:26:08 - INFO :       
==================Finish================

2024-04-23 17:26:08 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:26:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:26:08 - INFO :       DATASET: tasksource/bigbench hindu_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 17:26:16 - INFO :       Use taylor pruner...
2024-04-23 17:26:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:26:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:26:16 - INFO :       Start Pruning
2024-04-23 17:26:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:26:18 - INFO :       Loss = 14.265625
2024-04-23 17:26:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:26:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:26:21 - INFO :       hindu_knowledge: Total Sparsity 1.3611316892242436e-06
2024-04-23 17:26:52 - INFO :       hindu_knowledge: Total Accuracy (12, 35, 0.34285714285714286)
2024-04-23 17:26:52 - INFO :       
==================Finish================

2024-04-23 17:26:52 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:26:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:26:52 - INFO :       DATASET: tasksource/bigbench hinglish_toxicity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]
2024-04-23 17:27:00 - INFO :       Use taylor pruner...
2024-04-23 17:27:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:27:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:27:01 - INFO :       Start Pruning
2024-04-23 17:27:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:27:03 - INFO :       Loss = 12.28125
2024-04-23 17:27:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:27:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:27:06 - INFO :       hinglish_toxicity: Total Sparsity 1.3558806551180476e-06
2024-04-23 17:27:39 - INFO :       hinglish_toxicity: Total Accuracy (23, 40, 0.575)
2024-04-23 17:27:39 - INFO :       
==================Finish================

2024-04-23 17:27:39 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:27:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:27:39 - INFO :       DATASET: tasksource/bigbench human_organs_senses
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2024-04-23 17:27:48 - INFO :       Use taylor pruner...
2024-04-23 17:27:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:27:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:27:48 - INFO :       Start Pruning
2024-04-23 17:27:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:27:50 - INFO :       Loss = 14.265625
2024-04-23 17:27:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:27:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:27:53 - INFO :       human_organs_senses: Total Sparsity 1.3584266110483244e-06
2024-04-23 17:28:08 - INFO :       human_organs_senses: Total Accuracy (5, 16, 0.3125)
2024-04-23 17:28:08 - INFO :       
==================Finish================

2024-04-23 17:28:08 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:28:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:28:08 - INFO :       DATASET: tasksource/bigbench hyperbaton
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2024-04-23 17:28:19 - INFO :       Use taylor pruner...
2024-04-23 17:28:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:28:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:28:19 - INFO :       Start Pruning
2024-04-23 17:28:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:28:21 - INFO :       Loss = 15.5546875
2024-04-23 17:28:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:28:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:28:24 - INFO :       hyperbaton: Total Sparsity 1.357630999820113e-06
2024-04-23 17:29:06 - INFO :       hyperbaton: Total Accuracy (22, 50, 0.44)
2024-04-23 17:29:06 - INFO :       
==================Finish================

2024-04-23 17:29:06 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:29:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:29:06 - INFO :       DATASET: tasksource/bigbench identify_math_theorems
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 17:29:14 - INFO :       Use taylor pruner...
2024-04-23 17:29:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:29:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:29:15 - INFO :       Start Pruning
2024-04-23 17:29:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:29:17 - INFO :       Loss = 2.3359375
2024-04-23 17:29:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:29:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:29:20 - INFO :       identify_math_theorems: Total Sparsity 1.3581083665570398e-06
2024-04-23 17:29:36 - INFO :       identify_math_theorems: Total Accuracy (8, 16, 0.5)
2024-04-23 17:29:36 - INFO :       
==================Finish================

2024-04-23 17:29:36 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:29:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:29:36 - INFO :       DATASET: tasksource/bigbench identify_odd_metaphor
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.82s/it]
2024-04-23 17:29:54 - INFO :       Use taylor pruner...
2024-04-23 17:29:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:29:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:29:54 - INFO :       Start Pruning
2024-04-23 17:29:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:29:56 - INFO :       Loss = 11.59375
2024-04-23 17:29:58 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:29:58 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:30:00 - INFO :       identify_odd_metaphor: Total Sparsity 1.360813444732959e-06
2024-04-23 17:30:14 - INFO :       identify_odd_metaphor: Total Accuracy (0, 16, 0.0)
2024-04-23 17:30:14 - INFO :       
==================Finish================

2024-04-23 17:30:14 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:30:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:30:14 - INFO :       DATASET: tasksource/bigbench implicatures
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.79s/it]
2024-04-23 17:30:31 - INFO :       Use taylor pruner...
2024-04-23 17:30:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:30:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:30:32 - INFO :       Start Pruning
2024-04-23 17:30:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:30:34 - INFO :       Loss = 15.1484375
2024-04-23 17:30:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:30:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:30:39 - INFO :       implicatures: Total Sparsity 1.357630999820113e-06
2024-04-23 17:31:21 - INFO :       implicatures: Total Accuracy (23, 50, 0.46)
2024-04-23 17:31:21 - INFO :       
==================Finish================

2024-04-23 17:31:21 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:31:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:31:21 - INFO :       DATASET: tasksource/bigbench implicit_relations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 17:31:29 - INFO :       Use taylor pruner...
2024-04-23 17:31:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:31:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:31:30 - INFO :       Start Pruning
2024-04-23 17:31:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:31:32 - INFO :       Loss = 7.4453125
2024-04-23 17:31:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:31:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:31:35 - INFO :       implicit_relations: Total Sparsity 1.3589039777852514e-06
2024-04-23 17:31:50 - INFO :       implicit_relations: Total Accuracy (4, 17, 0.23529411764705882)
2024-04-23 17:31:50 - INFO :       
==================Finish================

2024-04-23 17:31:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:31:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:31:50 - INFO :       DATASET: tasksource/bigbench indic_cause_and_effect
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 17:31:57 - INFO :       Use taylor pruner...
2024-04-23 17:31:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:31:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:31:58 - INFO :       Start Pruning
2024-04-23 17:31:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:32:00 - INFO :       Loss = 6.59375
2024-04-23 17:32:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:32:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:32:03 - INFO :       indic_cause_and_effect: Total Sparsity 1.3569945108375437e-06
2024-04-23 17:32:47 - INFO :       indic_cause_and_effect: Total Accuracy (20, 50, 0.4)
2024-04-23 17:32:47 - INFO :       
==================Finish================

2024-04-23 17:32:47 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:32:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:32:47 - INFO :       DATASET: tasksource/bigbench intent_recognition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 17:32:55 - INFO :       Use taylor pruner...
2024-04-23 17:32:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:32:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:32:55 - INFO :       Start Pruning
2024-04-23 17:32:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:32:57 - INFO :       Loss = 11.6171875
2024-04-23 17:32:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:32:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:33:01 - INFO :       intent_recognition: Total Sparsity 1.3585857332939668e-06
2024-04-23 17:33:42 - INFO :       intent_recognition: Total Accuracy (29, 50, 0.58)
2024-04-23 17:33:42 - INFO :       
==================Finish================

2024-04-23 17:33:42 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:33:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:33:42 - INFO :       DATASET: tasksource/bigbench international_phonetic_alphabet_nli
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 17:33:49 - INFO :       Use taylor pruner...
2024-04-23 17:33:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:33:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:33:50 - INFO :       Start Pruning
2024-04-23 17:33:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:33:52 - INFO :       Loss = 10.328125
2024-04-23 17:33:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:33:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:33:55 - INFO :       international_phonetic_alphabet_nli: Total Sparsity 1.3569945108375437e-06
2024-04-23 17:34:16 - INFO :       international_phonetic_alphabet_nli: Total Accuracy (11, 25, 0.44)
2024-04-23 17:34:16 - INFO :       
==================Finish================

2024-04-23 17:34:16 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:34:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:34:16 - INFO :       DATASET: tasksource/bigbench intersect_geometry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 17:34:24 - INFO :       Use taylor pruner...
2024-04-23 17:34:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:34:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:34:25 - INFO :       Start Pruning
2024-04-23 17:34:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:34:27 - INFO :       Loss = 1.8056640625
2024-04-23 17:34:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:34:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:34:30 - INFO :       intersect_geometry: Total Sparsity 1.357630999820113e-06
2024-04-23 17:35:14 - INFO :       intersect_geometry: Total Accuracy (11, 50, 0.22)
2024-04-23 17:35:14 - INFO :       
==================Finish================

2024-04-23 17:35:14 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:35:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:35:14 - INFO :       DATASET: tasksource/bigbench irony_identification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 17:35:22 - INFO :       Use taylor pruner...
2024-04-23 17:35:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:35:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:35:22 - INFO :       Start Pruning
2024-04-23 17:35:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:35:24 - INFO :       Loss = 14.6484375
2024-04-23 17:35:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:35:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:35:27 - INFO :       irony_identification: Total Sparsity 1.3566762663462592e-06
2024-04-23 17:35:43 - INFO :       irony_identification: Total Accuracy (8, 19, 0.42105263157894735)
2024-04-23 17:35:43 - INFO :       
==================Finish================

2024-04-23 17:35:43 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:35:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:35:43 - INFO :       DATASET: tasksource/bigbench kannada
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 17:35:51 - INFO :       Use taylor pruner...
2024-04-23 17:35:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:35:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:35:51 - INFO :       Start Pruning
2024-04-23 17:35:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:35:53 - INFO :       Loss = 6.9453125
2024-04-23 17:35:55 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:35:55 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:35:56 - INFO :       kannada: Total Sparsity 1.3584266110483244e-06
2024-04-23 17:36:44 - INFO :       kannada: Total Accuracy (8, 50, 0.16)
2024-04-23 17:36:44 - INFO :       
==================Finish================

2024-04-23 17:36:44 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:36:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:36:44 - INFO :       DATASET: tasksource/bigbench key_value_maps
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 17:36:52 - INFO :       Use taylor pruner...
2024-04-23 17:36:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:36:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:36:53 - INFO :       Start Pruning
2024-04-23 17:36:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:36:55 - INFO :       Loss = 7.29296875
2024-04-23 17:36:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:36:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:36:58 - INFO :       key_value_maps: Total Sparsity 1.3590631000308936e-06
2024-04-23 17:37:15 - INFO :       key_value_maps: Total Accuracy (11, 21, 0.5238095238095238)
2024-04-23 17:37:16 - INFO :       
==================Finish================

2024-04-23 17:37:16 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:37:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:37:16 - INFO :       DATASET: tasksource/bigbench known_unknowns
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 17:37:24 - INFO :       Use taylor pruner...
2024-04-23 17:37:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:37:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:37:24 - INFO :       Start Pruning
2024-04-23 17:37:25 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:37:26 - INFO :       Loss = 15.3203125
2024-04-23 17:37:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:37:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:37:29 - INFO :       known_unknowns: Total Sparsity 1.3585857332939668e-06
2024-04-23 17:37:42 - INFO :       known_unknowns: Total Accuracy (8, 16, 0.5)
2024-04-23 17:37:42 - INFO :       
==================Finish================

2024-04-23 17:37:42 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:37:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:37:42 - INFO :       DATASET: tasksource/bigbench language_identification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 17:37:50 - INFO :       Use taylor pruner...
2024-04-23 17:37:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:37:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:37:50 - INFO :       Start Pruning
2024-04-23 17:37:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:37:52 - INFO :       Loss = 8.546875
2024-04-23 17:37:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:37:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:37:55 - INFO :       language_identification: Total Sparsity 1.3611316892242436e-06
2024-04-23 17:38:38 - INFO :       language_identification: Total Accuracy (2, 50, 0.04)
2024-04-23 17:38:38 - INFO :       
==================Finish================

2024-04-23 17:38:38 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:38:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:38:38 - INFO :       DATASET: tasksource/bigbench logic_grid_puzzle
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 17:38:46 - INFO :       Use taylor pruner...
2024-04-23 17:38:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:38:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:38:47 - INFO :       Start Pruning
2024-04-23 17:38:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:38:49 - INFO :       Loss = 5.1875
2024-04-23 17:38:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:38:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:38:52 - INFO :       logic_grid_puzzle: Total Sparsity 1.3600178335047475e-06
2024-04-23 17:39:37 - INFO :       logic_grid_puzzle: Total Accuracy (17, 50, 0.34)
2024-04-23 17:39:37 - INFO :       
==================Finish================

2024-04-23 17:39:37 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:39:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:39:37 - INFO :       DATASET: tasksource/bigbench logical_args
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 17:39:45 - INFO :       Use taylor pruner...
2024-04-23 17:39:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:39:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:39:45 - INFO :       Start Pruning
2024-04-23 17:39:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:39:47 - INFO :       Loss = 8.3203125
2024-04-23 17:39:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:39:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:39:50 - INFO :       logical_args: Total Sparsity 1.362882033926309e-06
2024-04-23 17:40:04 - INFO :       logical_args: Total Accuracy (1, 16, 0.0625)
2024-04-23 17:40:05 - INFO :       
==================Finish================

2024-04-23 17:40:05 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:40:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:40:05 - INFO :       DATASET: tasksource/bigbench logical_deduction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 17:40:12 - INFO :       Use taylor pruner...
2024-04-23 17:40:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:40:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:40:13 - INFO :       Start Pruning
2024-04-23 17:40:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:40:15 - INFO :       Loss = 12.2578125
2024-04-23 17:40:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:40:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:40:18 - INFO :       logical_deduction: Total Sparsity 1.3574718775744707e-06
2024-04-23 17:41:00 - INFO :       logical_deduction: Total Accuracy (13, 50, 0.26)
2024-04-23 17:41:00 - INFO :       
==================Finish================

2024-04-23 17:41:00 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:41:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:41:00 - INFO :       DATASET: tasksource/bigbench logical_fallacy_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 17:41:08 - INFO :       Use taylor pruner...
2024-04-23 17:41:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:41:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:41:08 - INFO :       Start Pruning
2024-04-23 17:41:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:41:10 - INFO :       Loss = 15.1953125
2024-04-23 17:41:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:41:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:41:13 - INFO :       logical_fallacy_detection: Total Sparsity 1.358267488802682e-06
2024-04-23 17:41:56 - INFO :       logical_fallacy_detection: Total Accuracy (22, 50, 0.44)
2024-04-23 17:41:57 - INFO :       
==================Finish================

2024-04-23 17:41:57 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:41:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:41:57 - INFO :       DATASET: tasksource/bigbench logical_sequence
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2024-04-23 17:42:05 - INFO :       Use taylor pruner...
2024-04-23 17:42:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:42:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:42:05 - INFO :       Start Pruning
2024-04-23 17:42:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:42:07 - INFO :       Loss = 12.53125
2024-04-23 17:42:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:42:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:42:10 - INFO :       logical_sequence: Total Sparsity 1.3590631000308936e-06
2024-04-23 17:42:25 - INFO :       logical_sequence: Total Accuracy (2, 16, 0.125)
2024-04-23 17:42:25 - INFO :       
==================Finish================

2024-04-23 17:42:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:42:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:42:25 - INFO :       DATASET: tasksource/bigbench mathematical_induction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.53s/it]
2024-04-23 17:42:42 - INFO :       Use taylor pruner...
2024-04-23 17:42:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:42:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:42:43 - INFO :       Start Pruning
2024-04-23 17:42:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:42:45 - INFO :       Loss = 14.4375
2024-04-23 17:42:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:42:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:42:48 - INFO :       mathematical_induction: Total Sparsity 1.3547667993985515e-06
2024-04-23 17:43:02 - INFO :       mathematical_induction: Total Accuracy (7, 16, 0.4375)
2024-04-23 17:43:02 - INFO :       
==================Finish================

2024-04-23 17:43:02 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:43:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:43:02 - INFO :       DATASET: tasksource/bigbench medical_questions_russian
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 17:43:12 - INFO :       Use taylor pruner...
2024-04-23 17:43:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:43:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:43:13 - INFO :       Start Pruning
2024-04-23 17:43:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:43:15 - INFO :       Loss = 11.5390625
2024-04-23 17:43:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:43:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:43:18 - INFO :       medical_questions_russian: Total Sparsity 1.3515843544857055e-06
2024-04-23 17:44:05 - INFO :       medical_questions_russian: Total Accuracy (30, 50, 0.6)
2024-04-23 17:44:05 - INFO :       
==================Finish================

2024-04-23 17:44:05 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:44:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:44:05 - INFO :       DATASET: tasksource/bigbench metaphor_boolean
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 17:44:13 - INFO :       Use taylor pruner...
2024-04-23 17:44:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:44:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:44:14 - INFO :       Start Pruning
2024-04-23 17:44:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:44:18 - INFO :       Loss = 14.6640625
2024-04-23 17:44:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:44:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:44:21 - INFO :       metaphor_boolean: Total Sparsity 1.3577901220657553e-06
2024-04-23 17:45:03 - INFO :       metaphor_boolean: Total Accuracy (18, 50, 0.36)
2024-04-23 17:45:03 - INFO :       
==================Finish================

2024-04-23 17:45:03 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:45:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:45:03 - INFO :       DATASET: tasksource/bigbench metaphor_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 17:45:10 - INFO :       Use taylor pruner...
2024-04-23 17:45:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:45:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:45:11 - INFO :       Start Pruning
2024-04-23 17:45:12 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:45:13 - INFO :       Loss = 11.3359375
2024-04-23 17:45:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:45:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:45:16 - INFO :       metaphor_understanding: Total Sparsity 1.3617681782068128e-06
2024-04-23 17:45:55 - INFO :       metaphor_understanding: Total Accuracy (8, 46, 0.17391304347826086)
2024-04-23 17:45:55 - INFO :       
==================Finish================

2024-04-23 17:45:55 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:45:55 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:45:55 - INFO :       DATASET: tasksource/bigbench misconceptions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 17:46:04 - INFO :       Use taylor pruner...
2024-04-23 17:46:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:46:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:46:04 - INFO :       Start Pruning
2024-04-23 17:46:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:46:06 - INFO :       Loss = 15.1484375
2024-04-23 17:46:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:46:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:46:09 - INFO :       misconceptions: Total Sparsity 1.3577901220657553e-06
2024-04-23 17:46:44 - INFO :       misconceptions: Total Accuracy (12, 43, 0.27906976744186046)
2024-04-23 17:46:44 - INFO :       
==================Finish================

2024-04-23 17:46:44 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:46:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:46:44 - INFO :       DATASET: tasksource/bigbench mnist_ascii
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 17:46:52 - INFO :       Use taylor pruner...
2024-04-23 17:46:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:46:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:46:52 - INFO :       Start Pruning
2024-04-23 17:46:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:46:54 - INFO :       Loss = 4.828125
2024-04-23 17:46:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:46:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:46:57 - INFO :       mnist_ascii: Total Sparsity 1.3585857332939668e-06
2024-04-23 17:48:12 - INFO :       mnist_ascii: Total Accuracy (4, 50, 0.08)
2024-04-23 17:48:13 - INFO :       
==================Finish================

2024-04-23 17:48:13 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:48:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:48:13 - INFO :       DATASET: tasksource/bigbench moral_permissibility
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2024-04-23 17:48:21 - INFO :       Use taylor pruner...
2024-04-23 17:48:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:48:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:48:21 - INFO :       Start Pruning
2024-04-23 17:48:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:48:23 - INFO :       Loss = 13.65625
2024-04-23 17:48:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:48:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:48:26 - INFO :       moral_permissibility: Total Sparsity 1.358267488802682e-06
2024-04-23 17:49:10 - INFO :       moral_permissibility: Total Accuracy (24, 50, 0.48)
2024-04-23 17:49:11 - INFO :       
==================Finish================

2024-04-23 17:49:11 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:49:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:49:11 - INFO :       DATASET: tasksource/bigbench movie_dialog_same_or_different
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.30s/it]
2024-04-23 17:49:21 - INFO :       Use taylor pruner...
2024-04-23 17:49:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:49:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:49:21 - INFO :       Start Pruning
2024-04-23 17:49:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:49:25 - INFO :       Loss = 13.6171875
2024-04-23 17:49:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:49:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:49:28 - INFO :       movie_dialog_same_or_different: Total Sparsity 1.357153633083186e-06
2024-04-23 17:50:10 - INFO :       movie_dialog_same_or_different: Total Accuracy (27, 50, 0.54)
2024-04-23 17:50:10 - INFO :       
==================Finish================

2024-04-23 17:50:10 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:50:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:50:10 - INFO :       DATASET: tasksource/bigbench movie_recommendation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 17:50:18 - INFO :       Use taylor pruner...
2024-04-23 17:50:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:50:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:50:19 - INFO :       Start Pruning
2024-04-23 17:50:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:50:20 - INFO :       Loss = 13.453125
2024-04-23 17:50:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:50:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:50:23 - INFO :       movie_recommendation: Total Sparsity 1.3598587112591052e-06
2024-04-23 17:51:04 - INFO :       movie_recommendation: Total Accuracy (16, 50, 0.32)
2024-04-23 17:51:04 - INFO :       
==================Finish================

2024-04-23 17:51:04 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:51:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:51:04 - INFO :       DATASET: tasksource/bigbench navigate
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 17:51:12 - INFO :       Use taylor pruner...
2024-04-23 17:51:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:51:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:51:12 - INFO :       Start Pruning
2024-04-23 17:51:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:51:14 - INFO :       Loss = 15.5625
2024-04-23 17:51:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:51:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:51:17 - INFO :       navigate: Total Sparsity 1.3557215328724054e-06
2024-04-23 17:51:59 - INFO :       navigate: Total Accuracy (21, 50, 0.42)
2024-04-23 17:52:00 - INFO :       
==================Finish================

2024-04-23 17:52:00 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:52:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:52:00 - INFO :       DATASET: tasksource/bigbench nonsense_words_grammar
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2024-04-23 17:52:08 - INFO :       Use taylor pruner...
2024-04-23 17:52:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:52:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:52:08 - INFO :       Start Pruning
2024-04-23 17:52:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:52:10 - INFO :       Loss = 14.2890625
2024-04-23 17:52:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:52:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:52:13 - INFO :       nonsense_words_grammar: Total Sparsity 1.357630999820113e-06
2024-04-23 17:52:28 - INFO :       nonsense_words_grammar: Total Accuracy (4, 16, 0.25)
2024-04-23 17:52:29 - INFO :       
==================Finish================

2024-04-23 17:52:29 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:52:29 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:52:29 - INFO :       DATASET: tasksource/bigbench novel_concepts
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2024-04-23 17:52:37 - INFO :       Use taylor pruner...
2024-04-23 17:52:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:52:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:52:37 - INFO :       Start Pruning
2024-04-23 17:52:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:52:39 - INFO :       Loss = 13.5625
2024-04-23 17:52:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:52:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:52:45 - INFO :       novel_concepts: Total Sparsity 1.3590631000308936e-06
2024-04-23 17:52:58 - INFO :       novel_concepts: Total Accuracy (8, 16, 0.5)
2024-04-23 17:52:58 - INFO :       
==================Finish================

2024-04-23 17:52:58 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:52:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:52:58 - INFO :       DATASET: tasksource/bigbench odd_one_out
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2024-04-23 17:53:07 - INFO :       Use taylor pruner...
2024-04-23 17:53:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:53:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:53:07 - INFO :       Start Pruning
2024-04-23 17:53:08 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:53:09 - INFO :       Loss = 15.1875
2024-04-23 17:53:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:53:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:53:12 - INFO :       odd_one_out: Total Sparsity 1.35603977736369e-06
2024-04-23 17:53:26 - INFO :       odd_one_out: Total Accuracy (0, 17, 0.0)
2024-04-23 17:53:27 - INFO :       
==================Finish================

2024-04-23 17:53:27 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:53:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:53:27 - INFO :       DATASET: tasksource/bigbench parsinlu_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]
2024-04-23 17:53:35 - INFO :       Use taylor pruner...
2024-04-23 17:53:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:53:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:53:35 - INFO :       Start Pruning
2024-04-23 17:53:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:53:37 - INFO :       Loss = 11.6953125
2024-04-23 17:53:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:53:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:53:40 - INFO :       parsinlu_qa: Total Sparsity 1.358744855539609e-06
2024-04-23 17:54:21 - INFO :       parsinlu_qa: Total Accuracy (11, 50, 0.22)
2024-04-23 17:54:21 - INFO :       
==================Finish================

2024-04-23 17:54:21 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:54:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:54:21 - INFO :       DATASET: tasksource/bigbench penguins_in_a_table
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 17:54:29 - INFO :       Use taylor pruner...
2024-04-23 17:54:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:54:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:54:29 - INFO :       Start Pruning
2024-04-23 17:54:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:54:32 - INFO :       Loss = 9.640625
2024-04-23 17:54:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:54:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:54:34 - INFO :       penguins_in_a_table: Total Sparsity 1.3585857332939668e-06
2024-04-23 17:54:59 - INFO :       penguins_in_a_table: Total Accuracy (12, 29, 0.41379310344827586)
2024-04-23 17:54:59 - INFO :       
==================Finish================

2024-04-23 17:54:59 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:54:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:54:59 - INFO :       DATASET: tasksource/bigbench persian_idioms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 17:55:07 - INFO :       Use taylor pruner...
2024-04-23 17:55:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:55:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:55:07 - INFO :       Start Pruning
2024-04-23 17:55:08 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:55:09 - INFO :       Loss = 11.625
2024-04-23 17:55:10 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:55:10 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:55:12 - INFO :       persian_idioms: Total Sparsity 1.358267488802682e-06
2024-04-23 17:55:25 - INFO :       persian_idioms: Total Accuracy (0, 16, 0.0)
2024-04-23 17:55:25 - INFO :       
==================Finish================

2024-04-23 17:55:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:55:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:55:25 - INFO :       DATASET: tasksource/bigbench phrase_relatedness
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 17:55:32 - INFO :       Use taylor pruner...
2024-04-23 17:55:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:55:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:55:33 - INFO :       Start Pruning
2024-04-23 17:55:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:55:35 - INFO :       Loss = 13.859375
2024-04-23 17:55:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:55:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:55:39 - INFO :       phrase_relatedness: Total Sparsity 1.3585857332939668e-06
2024-04-23 17:55:57 - INFO :       phrase_relatedness: Total Accuracy (11, 20, 0.55)
2024-04-23 17:55:57 - INFO :       
==================Finish================

2024-04-23 17:55:57 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:55:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:55:57 - INFO :       DATASET: tasksource/bigbench physical_intuition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2024-04-23 17:56:05 - INFO :       Use taylor pruner...
2024-04-23 17:56:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:56:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:56:06 - INFO :       Start Pruning
2024-04-23 17:56:07 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:56:08 - INFO :       Loss = 14.4765625
2024-04-23 17:56:10 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:56:10 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:56:11 - INFO :       physical_intuition: Total Sparsity 1.3609725669786013e-06
2024-04-23 17:56:26 - INFO :       physical_intuition: Total Accuracy (9, 16, 0.5625)
2024-04-23 17:56:26 - INFO :       
==================Finish================

2024-04-23 17:56:26 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:56:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:56:26 - INFO :       DATASET: tasksource/bigbench physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 17:56:37 - INFO :       Use taylor pruner...
2024-04-23 17:56:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:56:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:56:38 - INFO :       Start Pruning
2024-04-23 17:56:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:56:40 - INFO :       Loss = 9.984375
2024-04-23 17:56:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:56:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:56:43 - INFO :       physics: Total Sparsity 1.3619273004524551e-06
2024-04-23 17:57:20 - INFO :       physics: Total Accuracy (28, 45, 0.6222222222222222)
2024-04-23 17:57:20 - INFO :       
==================Finish================

2024-04-23 17:57:20 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:57:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:57:20 - INFO :       DATASET: tasksource/bigbench play_dialog_same_or_different
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 17:57:28 - INFO :       Use taylor pruner...
2024-04-23 17:57:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:57:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:57:28 - INFO :       Start Pruning
2024-04-23 17:57:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:57:30 - INFO :       Loss = 11.4921875
2024-04-23 17:57:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:57:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:57:34 - INFO :       play_dialog_same_or_different: Total Sparsity 1.3573127553288283e-06
2024-04-23 17:58:17 - INFO :       play_dialog_same_or_different: Total Accuracy (34, 50, 0.68)
2024-04-23 17:58:18 - INFO :       
==================Finish================

2024-04-23 17:58:18 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:58:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:58:18 - INFO :       DATASET: tasksource/bigbench presuppositions_as_nli
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.64s/it]
2024-04-23 17:58:27 - INFO :       Use taylor pruner...
2024-04-23 17:58:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:58:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:58:28 - INFO :       Start Pruning
2024-04-23 17:58:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:58:30 - INFO :       Loss = 11.578125
2024-04-23 17:58:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:58:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:58:33 - INFO :       presuppositions_as_nli: Total Sparsity 1.3590631000308936e-06
2024-04-23 17:59:16 - INFO :       presuppositions_as_nli: Total Accuracy (20, 50, 0.4)
2024-04-23 17:59:16 - INFO :       
==================Finish================

2024-04-23 17:59:16 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 17:59:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 17:59:16 - INFO :       DATASET: tasksource/bigbench question_selection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2024-04-23 17:59:24 - INFO :       Use taylor pruner...
2024-04-23 17:59:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:59:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 17:59:24 - INFO :       Start Pruning
2024-04-23 17:59:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 17:59:27 - INFO :       Loss = 7.30859375
2024-04-23 17:59:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 17:59:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 17:59:30 - INFO :       question_selection: Total Sparsity 1.3577901220657553e-06
2024-04-23 18:00:18 - INFO :       question_selection: Total Accuracy (16, 50, 0.32)
2024-04-23 18:00:18 - INFO :       
==================Finish================

2024-04-23 18:00:18 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:00:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:00:18 - INFO :       DATASET: tasksource/bigbench reasoning_about_colored_objects
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 18:00:26 - INFO :       Use taylor pruner...
2024-04-23 18:00:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:00:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:00:26 - INFO :       Start Pruning
2024-04-23 18:00:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:00:28 - INFO :       Loss = 13.3203125
2024-04-23 18:00:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:00:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:00:31 - INFO :       reasoning_about_colored_objects: Total Sparsity 1.3606543224873167e-06
2024-04-23 18:01:13 - INFO :       reasoning_about_colored_objects: Total Accuracy (8, 50, 0.16)
2024-04-23 18:01:13 - INFO :       
==================Finish================

2024-04-23 18:01:13 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:01:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:01:13 - INFO :       DATASET: tasksource/bigbench riddle_sense
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 18:01:21 - INFO :       Use taylor pruner...
2024-04-23 18:01:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:01:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:01:21 - INFO :       Start Pruning
2024-04-23 18:01:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:01:23 - INFO :       Loss = 13.875
2024-04-23 18:01:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:01:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:01:26 - INFO :       riddle_sense: Total Sparsity 1.357630999820113e-06
2024-04-23 18:01:39 - INFO :       riddle_sense: Total Accuracy (3, 16, 0.1875)
2024-04-23 18:01:39 - INFO :       
==================Finish================

2024-04-23 18:01:39 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:01:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:01:39 - INFO :       DATASET: tasksource/bigbench ruin_names
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 18:01:47 - INFO :       Use taylor pruner...
2024-04-23 18:01:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:01:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:01:47 - INFO :       Start Pruning
2024-04-23 18:01:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:01:50 - INFO :       Loss = 13.6015625
2024-04-23 18:01:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:01:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:01:53 - INFO :       ruin_names: Total Sparsity 1.359222222276536e-06
2024-04-23 18:02:34 - INFO :       ruin_names: Total Accuracy (11, 50, 0.22)
2024-04-23 18:02:34 - INFO :       
==================Finish================

2024-04-23 18:02:34 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:02:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:02:34 - INFO :       DATASET: tasksource/bigbench salient_translation_error_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2024-04-23 18:02:41 - INFO :       Use taylor pruner...
2024-04-23 18:02:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:02:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:02:42 - INFO :       Start Pruning
2024-04-23 18:02:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:02:44 - INFO :       Loss = 8.828125
2024-04-23 18:02:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:02:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:02:47 - INFO :       salient_translation_error_detection: Total Sparsity 1.358267488802682e-06
2024-04-23 18:03:32 - INFO :       salient_translation_error_detection: Total Accuracy (7, 50, 0.14)
2024-04-23 18:03:32 - INFO :       
==================Finish================

2024-04-23 18:03:32 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:03:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:03:32 - INFO :       DATASET: tasksource/bigbench sentence_ambiguity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 18:03:40 - INFO :       Use taylor pruner...
2024-04-23 18:03:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:03:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:03:41 - INFO :       Start Pruning
2024-04-23 18:03:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:03:43 - INFO :       Loss = 16.390625
2024-04-23 18:03:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:03:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:03:46 - INFO :       sentence_ambiguity: Total Sparsity 1.3549259216441938e-06
2024-04-23 18:03:58 - INFO :       sentence_ambiguity: Total Accuracy (9, 16, 0.5625)
2024-04-23 18:03:58 - INFO :       
==================Finish================

2024-04-23 18:03:58 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:03:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:03:58 - INFO :       DATASET: tasksource/bigbench similarities_abstraction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 18:04:06 - INFO :       Use taylor pruner...
2024-04-23 18:04:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:04:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:04:07 - INFO :       Start Pruning
2024-04-23 18:04:08 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:04:09 - INFO :       Loss = 13.890625
2024-04-23 18:04:10 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:04:10 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:04:12 - INFO :       similarities_abstraction: Total Sparsity 1.3589039777852514e-06
2024-04-23 18:04:25 - INFO :       similarities_abstraction: Total Accuracy (14, 16, 0.875)
2024-04-23 18:04:25 - INFO :       
==================Finish================

2024-04-23 18:04:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:04:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:04:25 - INFO :       DATASET: tasksource/bigbench simple_ethical_questions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 18:04:33 - INFO :       Use taylor pruner...
2024-04-23 18:04:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:04:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:04:33 - INFO :       Start Pruning
2024-04-23 18:04:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:04:35 - INFO :       Loss = 12.390625
2024-04-23 18:04:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:04:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:04:38 - INFO :       simple_ethical_questions: Total Sparsity 1.3601769557503897e-06
2024-04-23 18:04:58 - INFO :       simple_ethical_questions: Total Accuracy (7, 23, 0.30434782608695654)
2024-04-23 18:04:58 - INFO :       
==================Finish================

2024-04-23 18:04:58 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:04:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:04:58 - INFO :       DATASET: tasksource/bigbench snarks
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 18:05:05 - INFO :       Use taylor pruner...
2024-04-23 18:05:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:05:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:05:06 - INFO :       Start Pruning
2024-04-23 18:05:07 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:05:08 - INFO :       Loss = 14.75
2024-04-23 18:05:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:05:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:05:11 - INFO :       snarks: Total Sparsity 1.3538120659246977e-06
2024-04-23 18:05:40 - INFO :       snarks: Total Accuracy (3, 36, 0.08333333333333333)
2024-04-23 18:05:41 - INFO :       
==================Finish================

2024-04-23 18:05:41 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:05:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:05:41 - INFO :       DATASET: tasksource/bigbench social_iqa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 18:05:49 - INFO :       Use taylor pruner...
2024-04-23 18:05:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:05:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:05:49 - INFO :       Start Pruning
2024-04-23 18:05:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:05:51 - INFO :       Loss = 14.6796875
2024-04-23 18:05:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:05:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:05:54 - INFO :       social_iqa: Total Sparsity 1.356517144100617e-06
2024-04-23 18:06:35 - INFO :       social_iqa: Total Accuracy (20, 50, 0.4)
2024-04-23 18:06:36 - INFO :       
==================Finish================

2024-04-23 18:06:36 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:06:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:06:36 - INFO :       DATASET: tasksource/bigbench social_support
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2024-04-23 18:06:43 - INFO :       Use taylor pruner...
2024-04-23 18:06:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:06:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:06:44 - INFO :       Start Pruning
2024-04-23 18:06:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:06:47 - INFO :       Loss = 13.796875
2024-04-23 18:06:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:06:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:06:49 - INFO :       social_support: Total Sparsity 1.359222222276536e-06
2024-04-23 18:07:31 - INFO :       social_support: Total Accuracy (42, 50, 0.84)
2024-04-23 18:07:31 - INFO :       
==================Finish================

2024-04-23 18:07:31 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:07:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:07:31 - INFO :       DATASET: tasksource/bigbench sports_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2024-04-23 18:07:39 - INFO :       Use taylor pruner...
2024-04-23 18:07:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:07:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:07:40 - INFO :       Start Pruning
2024-04-23 18:07:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:07:42 - INFO :       Loss = 15.4375
2024-04-23 18:07:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:07:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:07:45 - INFO :       sports_understanding: Total Sparsity 1.3584266110483244e-06
2024-04-23 18:08:27 - INFO :       sports_understanding: Total Accuracy (21, 50, 0.42)
2024-04-23 18:08:27 - INFO :       
==================Finish================

2024-04-23 18:08:27 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:08:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:08:27 - INFO :       DATASET: tasksource/bigbench strange_stories
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.52s/it]
2024-04-23 18:08:45 - INFO :       Use taylor pruner...
2024-04-23 18:08:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:08:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:08:46 - INFO :       Start Pruning
2024-04-23 18:08:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:08:48 - INFO :       Loss = 12.5546875
2024-04-23 18:08:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:08:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:08:52 - INFO :       strange_stories: Total Sparsity 1.3590631000308936e-06
2024-04-23 18:09:21 - INFO :       strange_stories: Total Accuracy (10, 34, 0.29411764705882354)
2024-04-23 18:09:21 - INFO :       
==================Finish================

2024-04-23 18:09:21 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:09:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:09:21 - INFO :       DATASET: tasksource/bigbench strategyqa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.61s/it]
2024-04-23 18:09:36 - INFO :       Use taylor pruner...
2024-04-23 18:09:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:09:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:09:37 - INFO :       Start Pruning
2024-04-23 18:09:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:09:40 - INFO :       Loss = 15.8984375
2024-04-23 18:09:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:09:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:09:43 - INFO :       strategyqa: Total Sparsity 1.3585857332939668e-06
2024-04-23 18:10:26 - INFO :       strategyqa: Total Accuracy (16, 50, 0.32)
2024-04-23 18:10:26 - INFO :       
==================Finish================

2024-04-23 18:10:26 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:10:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:10:26 - INFO :       DATASET: tasksource/bigbench suicide_risk
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 18:10:34 - INFO :       Use taylor pruner...
2024-04-23 18:10:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:10:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:10:34 - INFO :       Start Pruning
2024-04-23 18:10:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:10:37 - INFO :       Loss = 12.0703125
2024-04-23 18:10:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:10:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:10:40 - INFO :       suicide_risk: Total Sparsity 1.3561988996093322e-06
2024-04-23 18:10:54 - INFO :       suicide_risk: Total Accuracy (4, 16, 0.25)
2024-04-23 18:10:54 - INFO :       
==================Finish================

2024-04-23 18:10:54 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:10:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:10:54 - INFO :       DATASET: tasksource/bigbench swahili_english_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 18:11:01 - INFO :       Use taylor pruner...
2024-04-23 18:11:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:11:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:11:02 - INFO :       Start Pruning
2024-04-23 18:11:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:11:04 - INFO :       Loss = 11.9140625
2024-04-23 18:11:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:11:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:11:07 - INFO :       swahili_english_proverbs: Total Sparsity 1.3566762663462592e-06
2024-04-23 18:11:32 - INFO :       swahili_english_proverbs: Total Accuracy (2, 30, 0.06666666666666667)
2024-04-23 18:11:33 - INFO :       
==================Finish================

2024-04-23 18:11:33 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:11:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:11:33 - INFO :       DATASET: tasksource/bigbench swedish_to_german_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 18:11:41 - INFO :       Use taylor pruner...
2024-04-23 18:11:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:11:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:11:41 - INFO :       Start Pruning
2024-04-23 18:11:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:11:43 - INFO :       Loss = 12.2578125
2024-04-23 18:11:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:11:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:11:46 - INFO :       swedish_to_german_proverbs: Total Sparsity 1.360813444732959e-06
2024-04-23 18:12:00 - INFO :       swedish_to_german_proverbs: Total Accuracy (6, 16, 0.375)
2024-04-23 18:12:00 - INFO :       
==================Finish================

2024-04-23 18:12:00 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:12:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:12:00 - INFO :       DATASET: tasksource/bigbench symbol_interpretation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 18:12:08 - INFO :       Use taylor pruner...
2024-04-23 18:12:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:12:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:12:08 - INFO :       Start Pruning
2024-04-23 18:12:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:12:11 - INFO :       Loss = 3.18359375
2024-04-23 18:12:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:12:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:12:14 - INFO :       symbol_interpretation: Total Sparsity 1.358267488802682e-06
2024-04-23 18:13:16 - INFO :       symbol_interpretation: Total Accuracy (14, 50, 0.28)
2024-04-23 18:13:16 - INFO :       
==================Finish================

2024-04-23 18:13:16 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:13:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:13:16 - INFO :       DATASET: tasksource/bigbench temporal_sequences
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2024-04-23 18:13:24 - INFO :       Use taylor pruner...
2024-04-23 18:13:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:13:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:13:24 - INFO :       Start Pruning
2024-04-23 18:13:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:13:27 - INFO :       Loss = 9.5625
2024-04-23 18:13:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:13:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:13:30 - INFO :       temporal_sequences: Total Sparsity 1.3651097453653011e-06
2024-04-23 18:14:12 - INFO :       temporal_sequences: Total Accuracy (3, 50, 0.06)
2024-04-23 18:14:12 - INFO :       
==================Finish================

2024-04-23 18:14:12 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:14:12 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:14:12 - INFO :       DATASET: tasksource/bigbench timedial
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 18:14:20 - INFO :       Use taylor pruner...
2024-04-23 18:14:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:14:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:14:20 - INFO :       Start Pruning
2024-04-23 18:14:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:14:22 - INFO :       Loss = 9.3984375
2024-04-23 18:14:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:14:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:14:25 - INFO :       timedial: Total Sparsity 1.357630999820113e-06
2024-04-23 18:15:12 - INFO :       timedial: Total Accuracy (0, 50, 0.0)
2024-04-23 18:15:13 - INFO :       
==================Finish================

2024-04-23 18:15:13 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:15:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:15:13 - INFO :       DATASET: tasksource/bigbench tracking_shuffled_objects
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 18:15:21 - INFO :       Use taylor pruner...
2024-04-23 18:15:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:15:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:15:21 - INFO :       Start Pruning
2024-04-23 18:15:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:15:23 - INFO :       Loss = 9.453125
2024-04-23 18:15:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:15:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:15:26 - INFO :       tracking_shuffled_objects: Total Sparsity 1.360336077996032e-06
2024-04-23 18:16:09 - INFO :       tracking_shuffled_objects: Total Accuracy (10, 50, 0.2)
2024-04-23 18:16:09 - INFO :       
==================Finish================

2024-04-23 18:16:09 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:16:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:16:09 - INFO :       DATASET: tasksource/bigbench understanding_fables
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 18:16:16 - INFO :       Use taylor pruner...
2024-04-23 18:16:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:16:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:16:17 - INFO :       Start Pruning
2024-04-23 18:16:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:16:19 - INFO :       Loss = 7.34375
2024-04-23 18:16:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:16:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:16:22 - INFO :       understanding_fables: Total Sparsity 1.3598587112591052e-06
2024-04-23 18:16:55 - INFO :       understanding_fables: Total Accuracy (5, 37, 0.13513513513513514)
2024-04-23 18:16:55 - INFO :       
==================Finish================

2024-04-23 18:16:55 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:16:55 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:16:55 - INFO :       DATASET: tasksource/bigbench undo_permutation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2024-04-23 18:17:03 - INFO :       Use taylor pruner...
2024-04-23 18:17:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:17:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:17:03 - INFO :       Start Pruning
2024-04-23 18:17:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:17:05 - INFO :       Loss = 6.30078125
2024-04-23 18:17:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:17:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:17:08 - INFO :       undo_permutation: Total Sparsity 1.3585857332939668e-06
2024-04-23 18:17:53 - INFO :       undo_permutation: Total Accuracy (27, 50, 0.54)
2024-04-23 18:17:53 - INFO :       
==================Finish================

2024-04-23 18:17:53 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:17:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:17:53 - INFO :       DATASET: tasksource/bigbench unit_interpretation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2024-04-23 18:18:01 - INFO :       Use taylor pruner...
2024-04-23 18:18:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:18:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:18:01 - INFO :       Start Pruning
2024-04-23 18:18:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:18:04 - INFO :       Loss = 11.8359375
2024-04-23 18:18:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:18:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:18:07 - INFO :       unit_interpretation: Total Sparsity 1.3595404667678207e-06
2024-04-23 18:18:23 - INFO :       unit_interpretation: Total Accuracy (5, 20, 0.25)
2024-04-23 18:18:23 - INFO :       
==================Finish================

2024-04-23 18:18:23 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:18:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:18:23 - INFO :       DATASET: tasksource/bigbench vitaminc_fact_verification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-23 18:18:31 - INFO :       Use taylor pruner...
2024-04-23 18:18:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:18:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:18:31 - INFO :       Start Pruning
2024-04-23 18:18:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:18:33 - INFO :       Loss = 12.734375
2024-04-23 18:18:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:18:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:18:39 - INFO :       vitaminc_fact_verification: Total Sparsity 1.3573127553288283e-06
2024-04-23 18:19:21 - INFO :       vitaminc_fact_verification: Total Accuracy (21, 50, 0.42)
2024-04-23 18:19:21 - INFO :       
==================Finish================

2024-04-23 18:19:21 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:19:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:19:21 - INFO :       DATASET: tasksource/bigbench what_is_the_tao
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-23 18:19:29 - INFO :       Use taylor pruner...
2024-04-23 18:19:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:19:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:19:29 - INFO :       Start Pruning
2024-04-23 18:19:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:19:32 - INFO :       Loss = 13.40625
2024-04-23 18:19:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:19:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:19:35 - INFO :       what_is_the_tao: Total Sparsity 1.3606543224873167e-06
2024-04-23 18:19:49 - INFO :       what_is_the_tao: Total Accuracy (4, 16, 0.25)
2024-04-23 18:19:49 - INFO :       
==================Finish================

2024-04-23 18:19:49 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 18:19:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:19:49 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 18:19:59 - INFO :       Use taylor pruner...
2024-04-23 18:19:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:19:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:19:59 - INFO :       Start Pruning
2024-04-23 18:20:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:20:01 - INFO :       Loss = 1.611328125
2024-04-23 18:20:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:20:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:20:04 - INFO :       which_wiki_edit: Total Sparsity 1.3509478655031362e-06
2024-04-23 18:21:42 - INFO :       which_wiki_edit: Total Accuracy (24, 50, 0.48)
2024-04-23 18:21:43 - INFO :       
==================Finish================

2024-04-23 18:21:43 - INFO :       Memory Requirement: 16809.46826171875 MiB

2024-04-23 18:21:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:21:43 - INFO :       DATASET: tasksource/bigbench winowhy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 18:21:54 - INFO :       Use taylor pruner...
2024-04-23 18:21:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:21:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:21:55 - INFO :       Start Pruning
2024-04-23 18:21:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:21:57 - INFO :       Loss = 14.8984375
2024-04-23 18:21:58 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:21:58 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:22:00 - INFO :       winowhy: Total Sparsity 1.3581083665570398e-06
2024-04-23 18:22:44 - INFO :       winowhy: Total Accuracy (30, 50, 0.6)
2024-04-23 18:22:44 - INFO :       
==================Finish================

2024-04-23 18:22:44 - INFO :       Memory Requirement: 16777.79052734375 MiB

2024-04-23 18:22:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:22:44 - INFO :       DATASET: tasksource/mmlu abstract_algebra
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 18:22:52 - INFO :       Use taylor pruner...
2024-04-23 18:22:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:22:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:22:52 - INFO :       Start Pruning
2024-04-23 18:22:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:22:55 - INFO :       Loss = 13.9765625
2024-04-23 18:22:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:22:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:22:58 - INFO :       abstract_algebra: Total Sparsity 1.3569945108375437e-06
2024-04-23 18:23:07 - INFO :       abstract_algebra: Total Accuracy (2, 11, 0.18181818181818182)
2024-04-23 18:23:07 - INFO :       
==================Finish================

2024-04-23 18:23:07 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:23:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:23:07 - INFO :       DATASET: tasksource/mmlu anatomy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 18:23:15 - INFO :       Use taylor pruner...
2024-04-23 18:23:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:23:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:23:15 - INFO :       Start Pruning
2024-04-23 18:23:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:23:17 - INFO :       Loss = 14.796875
2024-04-23 18:23:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:23:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:23:20 - INFO :       anatomy: Total Sparsity 1.3589039777852514e-06
2024-04-23 18:23:32 - INFO :       anatomy: Total Accuracy (9, 14, 0.6428571428571429)
2024-04-23 18:23:32 - INFO :       
==================Finish================

2024-04-23 18:23:32 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:23:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:23:32 - INFO :       DATASET: tasksource/mmlu astronomy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 18:23:40 - INFO :       Use taylor pruner...
2024-04-23 18:23:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:23:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:23:41 - INFO :       Start Pruning
2024-04-23 18:23:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:23:43 - INFO :       Loss = 13.859375
2024-04-23 18:23:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:23:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:23:48 - INFO :       astronomy: Total Sparsity 1.357630999820113e-06
2024-04-23 18:24:02 - INFO :       astronomy: Total Accuracy (2, 16, 0.125)
2024-04-23 18:24:02 - INFO :       
==================Finish================

2024-04-23 18:24:02 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:24:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:24:02 - INFO :       DATASET: tasksource/mmlu business_ethics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 18:24:09 - INFO :       Use taylor pruner...
2024-04-23 18:24:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:24:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:24:10 - INFO :       Start Pruning
2024-04-23 18:24:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:24:12 - INFO :       Loss = 14.1171875
2024-04-23 18:24:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:24:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:24:15 - INFO :       business_ethics: Total Sparsity 1.360336077996032e-06
2024-04-23 18:24:24 - INFO :       business_ethics: Total Accuracy (5, 11, 0.45454545454545453)
2024-04-23 18:24:24 - INFO :       
==================Finish================

2024-04-23 18:24:24 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:24:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:24:24 - INFO :       DATASET: tasksource/mmlu clinical_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 18:24:32 - INFO :       Use taylor pruner...
2024-04-23 18:24:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:24:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:24:32 - INFO :       Start Pruning
2024-04-23 18:24:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:24:34 - INFO :       Loss = 14.6640625
2024-04-23 18:24:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:24:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:24:38 - INFO :       clinical_knowledge: Total Sparsity 1.3606543224873167e-06
2024-04-23 18:25:02 - INFO :       clinical_knowledge: Total Accuracy (14, 29, 0.4827586206896552)
2024-04-23 18:25:03 - INFO :       
==================Finish================

2024-04-23 18:25:03 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:25:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:25:03 - INFO :       DATASET: tasksource/mmlu college_biology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 18:25:11 - INFO :       Use taylor pruner...
2024-04-23 18:25:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:25:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:25:11 - INFO :       Start Pruning
2024-04-23 18:25:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:25:14 - INFO :       Loss = 14.4453125
2024-04-23 18:25:15 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:25:15 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:25:17 - INFO :       college_biology: Total Sparsity 1.3568353885919015e-06
2024-04-23 18:25:30 - INFO :       college_biology: Total Accuracy (6, 16, 0.375)
2024-04-23 18:25:30 - INFO :       
==================Finish================

2024-04-23 18:25:30 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:25:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:25:30 - INFO :       DATASET: tasksource/mmlu college_chemistry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-23 18:25:38 - INFO :       Use taylor pruner...
2024-04-23 18:25:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:25:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:25:38 - INFO :       Start Pruning
num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-23 18:25:39 - WARNING :       num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-23 18:25:39 - WARNING :       num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-23 18:25:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:25:40 - INFO :       Loss = 11.75
2024-04-23 18:25:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:25:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:25:43 - INFO :       college_chemistry: Total Sparsity 1.3568353885919015e-06
2024-04-23 18:25:50 - INFO :       college_chemistry: Total Accuracy (1, 8, 0.125)
2024-04-23 18:25:50 - INFO :       
==================Finish================

2024-04-23 18:25:50 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:25:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:25:50 - INFO :       DATASET: tasksource/mmlu college_computer_science
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2024-04-23 18:25:57 - INFO :       Use taylor pruner...
2024-04-23 18:25:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:25:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:25:58 - INFO :       Start Pruning
2024-04-23 18:25:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:26:00 - INFO :       Loss = 10.546875
2024-04-23 18:26:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:26:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:26:03 - INFO :       college_computer_science: Total Sparsity 1.3568353885919015e-06
2024-04-23 18:26:12 - INFO :       college_computer_science: Total Accuracy (1, 11, 0.09090909090909091)
2024-04-23 18:26:12 - INFO :       
==================Finish================

2024-04-23 18:26:12 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:26:12 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:26:12 - INFO :       DATASET: tasksource/mmlu college_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2024-04-23 18:26:20 - INFO :       Use taylor pruner...
2024-04-23 18:26:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:26:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:26:20 - INFO :       Start Pruning
2024-04-23 18:26:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:26:22 - INFO :       Loss = 14.2890625
2024-04-23 18:26:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:26:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:26:25 - INFO :       college_mathematics: Total Sparsity 1.358267488802682e-06
2024-04-23 18:26:35 - INFO :       college_mathematics: Total Accuracy (4, 11, 0.36363636363636365)
2024-04-23 18:26:35 - INFO :       
==================Finish================

2024-04-23 18:26:35 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:26:35 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:26:35 - INFO :       DATASET: tasksource/mmlu college_medicine
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 18:26:42 - INFO :       Use taylor pruner...
2024-04-23 18:26:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:26:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:26:43 - INFO :       Start Pruning
2024-04-23 18:26:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:26:45 - INFO :       Loss = 13.2265625
2024-04-23 18:26:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:26:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:26:48 - INFO :       college_medicine: Total Sparsity 1.3569945108375437e-06
2024-04-23 18:27:06 - INFO :       college_medicine: Total Accuracy (10, 22, 0.45454545454545453)
2024-04-23 18:27:06 - INFO :       
==================Finish================

2024-04-23 18:27:06 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:27:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:27:06 - INFO :       DATASET: tasksource/mmlu college_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 18:27:14 - INFO :       Use taylor pruner...
2024-04-23 18:27:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:27:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:27:14 - INFO :       Start Pruning
2024-04-23 18:27:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:27:16 - INFO :       Loss = 14.046875
2024-04-23 18:27:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:27:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:27:19 - INFO :       college_physics: Total Sparsity 1.3558806551180476e-06
2024-04-23 18:27:28 - INFO :       college_physics: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-23 18:27:28 - INFO :       
==================Finish================

2024-04-23 18:27:28 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:27:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:27:28 - INFO :       DATASET: tasksource/mmlu computer_security
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 18:27:36 - INFO :       Use taylor pruner...
2024-04-23 18:27:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:27:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:27:36 - INFO :       Start Pruning
2024-04-23 18:27:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:27:38 - INFO :       Loss = 15.1953125
2024-04-23 18:27:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:27:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:27:41 - INFO :       computer_security: Total Sparsity 1.355085043889836e-06
2024-04-23 18:27:50 - INFO :       computer_security: Total Accuracy (2, 11, 0.18181818181818182)
2024-04-23 18:27:50 - INFO :       
==================Finish================

2024-04-23 18:27:50 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:27:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:27:50 - INFO :       DATASET: tasksource/mmlu conceptual_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-23 18:27:58 - INFO :       Use taylor pruner...
2024-04-23 18:27:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:27:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:27:58 - INFO :       Start Pruning
2024-04-23 18:27:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:28:00 - INFO :       Loss = 15.0
2024-04-23 18:28:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:28:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:28:03 - INFO :       conceptual_physics: Total Sparsity 1.357153633083186e-06
2024-04-23 18:28:25 - INFO :       conceptual_physics: Total Accuracy (8, 26, 0.3076923076923077)
2024-04-23 18:28:25 - INFO :       
==================Finish================

2024-04-23 18:28:25 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:28:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:28:25 - INFO :       DATASET: tasksource/mmlu econometrics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2024-04-23 18:28:33 - INFO :       Use taylor pruner...
2024-04-23 18:28:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:28:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:28:33 - INFO :       Start Pruning
2024-04-23 18:28:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:28:36 - INFO :       Loss = 12.453125
2024-04-23 18:28:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:28:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:28:39 - INFO :       econometrics: Total Sparsity 1.3600178335047475e-06
2024-04-23 18:28:49 - INFO :       econometrics: Total Accuracy (3, 12, 0.25)
2024-04-23 18:28:49 - INFO :       
==================Finish================

2024-04-23 18:28:49 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:28:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:28:49 - INFO :       DATASET: tasksource/mmlu electrical_engineering
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 18:28:57 - INFO :       Use taylor pruner...
2024-04-23 18:28:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:28:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:28:57 - INFO :       Start Pruning
2024-04-23 18:28:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:28:59 - INFO :       Loss = 14.71875
2024-04-23 18:29:00 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:29:00 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:29:02 - INFO :       electrical_engineering: Total Sparsity 1.3584266110483244e-06
2024-04-23 18:29:15 - INFO :       electrical_engineering: Total Accuracy (5, 16, 0.3125)
2024-04-23 18:29:15 - INFO :       
==================Finish================

2024-04-23 18:29:15 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:29:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:29:15 - INFO :       DATASET: tasksource/mmlu elementary_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 18:29:23 - INFO :       Use taylor pruner...
2024-04-23 18:29:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:29:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:29:23 - INFO :       Start Pruning
2024-04-23 18:29:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:29:25 - INFO :       Loss = 14.3515625
2024-04-23 18:29:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:29:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:29:28 - INFO :       elementary_mathematics: Total Sparsity 1.3563580218549744e-06
2024-04-23 18:30:02 - INFO :       elementary_mathematics: Total Accuracy (10, 41, 0.24390243902439024)
2024-04-23 18:30:02 - INFO :       
==================Finish================

2024-04-23 18:30:02 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:30:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:30:02 - INFO :       DATASET: tasksource/mmlu formal_logic
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2024-04-23 18:30:10 - INFO :       Use taylor pruner...
2024-04-23 18:30:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:30:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:30:11 - INFO :       Start Pruning
2024-04-23 18:30:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:30:12 - INFO :       Loss = 13.6875
2024-04-23 18:30:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:30:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:30:15 - INFO :       formal_logic: Total Sparsity 1.359699589013463e-06
2024-04-23 18:30:27 - INFO :       formal_logic: Total Accuracy (4, 14, 0.2857142857142857)
2024-04-23 18:30:27 - INFO :       
==================Finish================

2024-04-23 18:30:27 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:30:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:30:27 - INFO :       DATASET: tasksource/mmlu global_facts
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]
2024-04-23 18:30:35 - INFO :       Use taylor pruner...
2024-04-23 18:30:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:30:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:30:36 - INFO :       Start Pruning
2024-04-23 18:30:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:30:38 - INFO :       Loss = 14.6328125
2024-04-23 18:30:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:30:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:30:41 - INFO :       global_facts: Total Sparsity 1.3568353885919015e-06
2024-04-23 18:30:49 - INFO :       global_facts: Total Accuracy (6, 10, 0.6)
2024-04-23 18:30:49 - INFO :       
==================Finish================

2024-04-23 18:30:49 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:30:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:30:49 - INFO :       DATASET: tasksource/mmlu high_school_biology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2024-04-23 18:30:57 - INFO :       Use taylor pruner...
2024-04-23 18:30:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:30:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:30:57 - INFO :       Start Pruning
2024-04-23 18:30:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:31:00 - INFO :       Loss = 13.8515625
2024-04-23 18:31:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:31:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:31:02 - INFO :       high_school_biology: Total Sparsity 1.3577901220657553e-06
2024-04-23 18:31:29 - INFO :       high_school_biology: Total Accuracy (10, 32, 0.3125)
2024-04-23 18:31:29 - INFO :       
==================Finish================

2024-04-23 18:31:29 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:31:29 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:31:29 - INFO :       DATASET: tasksource/mmlu high_school_chemistry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 18:31:37 - INFO :       Use taylor pruner...
2024-04-23 18:31:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:31:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:31:37 - INFO :       Start Pruning
2024-04-23 18:31:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:31:39 - INFO :       Loss = 13.6875
2024-04-23 18:31:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:31:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:31:42 - INFO :       high_school_chemistry: Total Sparsity 1.357630999820113e-06
2024-04-23 18:32:01 - INFO :       high_school_chemistry: Total Accuracy (6, 22, 0.2727272727272727)
2024-04-23 18:32:01 - INFO :       
==================Finish================

2024-04-23 18:32:01 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:32:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:32:01 - INFO :       DATASET: tasksource/mmlu high_school_computer_science
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 18:32:09 - INFO :       Use taylor pruner...
2024-04-23 18:32:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:32:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:32:09 - INFO :       Start Pruning
num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-23 18:32:10 - WARNING :       num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-23 18:32:10 - WARNING :       num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-23 18:32:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:32:11 - INFO :       Loss = 12.359375
2024-04-23 18:32:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:32:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:32:14 - INFO :       high_school_computer_science: Total Sparsity 1.358744855539609e-06
2024-04-23 18:32:22 - INFO :       high_school_computer_science: Total Accuracy (6, 9, 0.6666666666666666)
2024-04-23 18:32:22 - INFO :       
==================Finish================

2024-04-23 18:32:22 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:32:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:32:22 - INFO :       DATASET: tasksource/mmlu high_school_european_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 18:32:30 - INFO :       Use taylor pruner...
2024-04-23 18:32:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:32:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:32:30 - INFO :       Start Pruning
2024-04-23 18:32:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:32:32 - INFO :       Loss = 10.171875
2024-04-23 18:32:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:32:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:32:35 - INFO :       high_school_european_history: Total Sparsity 1.359222222276536e-06
2024-04-23 18:32:51 - INFO :       high_school_european_history: Total Accuracy (10, 18, 0.5555555555555556)
2024-04-23 18:32:51 - INFO :       
==================Finish================

2024-04-23 18:32:51 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:32:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:32:51 - INFO :       DATASET: tasksource/mmlu high_school_geography
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 18:32:59 - INFO :       Use taylor pruner...
2024-04-23 18:32:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:32:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:33:00 - INFO :       Start Pruning
2024-04-23 18:33:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:33:02 - INFO :       Loss = 14.5625
2024-04-23 18:33:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:33:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:33:05 - INFO :       high_school_geography: Total Sparsity 1.355562410626763e-06
2024-04-23 18:33:23 - INFO :       high_school_geography: Total Accuracy (15, 22, 0.6818181818181818)
2024-04-23 18:33:23 - INFO :       
==================Finish================

2024-04-23 18:33:23 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:33:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:33:23 - INFO :       DATASET: tasksource/mmlu high_school_government_and_politics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2024-04-23 18:33:31 - INFO :       Use taylor pruner...
2024-04-23 18:33:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:33:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:33:31 - INFO :       Start Pruning
2024-04-23 18:33:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:33:33 - INFO :       Loss = 14.4609375
2024-04-23 18:33:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:33:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:33:36 - INFO :       high_school_government_and_politics: Total Sparsity 1.3566762663462592e-06
2024-04-23 18:33:53 - INFO :       high_school_government_and_politics: Total Accuracy (6, 21, 0.2857142857142857)
2024-04-23 18:33:53 - INFO :       
==================Finish================

2024-04-23 18:33:53 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:33:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:33:53 - INFO :       DATASET: tasksource/mmlu high_school_macroeconomics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 18:34:01 - INFO :       Use taylor pruner...
2024-04-23 18:34:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:34:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:34:02 - INFO :       Start Pruning
2024-04-23 18:34:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:34:04 - INFO :       Loss = 14.7578125
2024-04-23 18:34:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:34:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:34:07 - INFO :       high_school_macroeconomics: Total Sparsity 1.357630999820113e-06
2024-04-23 18:34:44 - INFO :       high_school_macroeconomics: Total Accuracy (16, 43, 0.37209302325581395)
2024-04-23 18:34:44 - INFO :       
==================Finish================

2024-04-23 18:34:44 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:34:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:34:44 - INFO :       DATASET: tasksource/mmlu high_school_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.80s/it]
2024-04-23 18:34:56 - INFO :       Use taylor pruner...
2024-04-23 18:34:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:34:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:34:56 - INFO :       Start Pruning
2024-04-23 18:34:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:34:58 - INFO :       Loss = 13.6875
2024-04-23 18:35:00 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:35:00 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:35:01 - INFO :       high_school_mathematics: Total Sparsity 1.3585857332939668e-06
2024-04-23 18:35:27 - INFO :       high_school_mathematics: Total Accuracy (5, 29, 0.1724137931034483)
2024-04-23 18:35:27 - INFO :       
==================Finish================

2024-04-23 18:35:27 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:35:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:35:27 - INFO :       DATASET: tasksource/mmlu high_school_microeconomics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.50s/it]
2024-04-23 18:35:44 - INFO :       Use taylor pruner...
2024-04-23 18:35:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:35:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:35:45 - INFO :       Start Pruning
2024-04-23 18:35:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:35:47 - INFO :       Loss = 14.6328125
2024-04-23 18:35:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:35:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:35:50 - INFO :       high_school_microeconomics: Total Sparsity 1.358744855539609e-06
2024-04-23 18:36:13 - INFO :       high_school_microeconomics: Total Accuracy (10, 26, 0.38461538461538464)
2024-04-23 18:36:13 - INFO :       
==================Finish================

2024-04-23 18:36:13 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:36:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:36:13 - INFO :       DATASET: tasksource/mmlu high_school_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 18:36:21 - INFO :       Use taylor pruner...
2024-04-23 18:36:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:36:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:36:21 - INFO :       Start Pruning
2024-04-23 18:36:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:36:23 - INFO :       Loss = 13.90625
2024-04-23 18:36:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:36:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:36:26 - INFO :       high_school_physics: Total Sparsity 1.356517144100617e-06
2024-04-23 18:36:40 - INFO :       high_school_physics: Total Accuracy (2, 17, 0.11764705882352941)
2024-04-23 18:36:40 - INFO :       
==================Finish================

2024-04-23 18:36:40 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:36:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:36:40 - INFO :       DATASET: tasksource/mmlu high_school_psychology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 18:36:48 - INFO :       Use taylor pruner...
2024-04-23 18:36:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:36:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:36:48 - INFO :       Start Pruning
2024-04-23 18:36:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:36:50 - INFO :       Loss = 14.34375
2024-04-23 18:36:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:36:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:36:53 - INFO :       high_school_psychology: Total Sparsity 1.3585857332939668e-06
2024-04-23 18:37:34 - INFO :       high_school_psychology: Total Accuracy (28, 50, 0.56)
2024-04-23 18:37:34 - INFO :       
==================Finish================

2024-04-23 18:37:34 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:37:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:37:34 - INFO :       DATASET: tasksource/mmlu high_school_statistics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
2024-04-23 18:37:43 - INFO :       Use taylor pruner...
2024-04-23 18:37:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:37:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:37:43 - INFO :       Start Pruning
2024-04-23 18:37:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:37:45 - INFO :       Loss = 11.625
2024-04-23 18:37:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:37:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:37:50 - INFO :       high_school_statistics: Total Sparsity 1.357630999820113e-06
2024-04-23 18:38:10 - INFO :       high_school_statistics: Total Accuracy (7, 23, 0.30434782608695654)
2024-04-23 18:38:10 - INFO :       
==================Finish================

2024-04-23 18:38:10 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:38:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:38:10 - INFO :       DATASET: tasksource/mmlu high_school_us_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-23 18:38:17 - INFO :       Use taylor pruner...
2024-04-23 18:38:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:38:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:38:18 - INFO :       Start Pruning
2024-04-23 18:38:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:38:20 - INFO :       Loss = 6.71875
2024-04-23 18:38:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:38:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:38:23 - INFO :       high_school_us_history: Total Sparsity 1.359222222276536e-06
2024-04-23 18:38:42 - INFO :       high_school_us_history: Total Accuracy (14, 22, 0.6363636363636364)
2024-04-23 18:38:43 - INFO :       
==================Finish================

2024-04-23 18:38:43 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:38:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:38:43 - INFO :       DATASET: tasksource/mmlu high_school_world_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 18:38:50 - INFO :       Use taylor pruner...
2024-04-23 18:38:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:38:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:38:51 - INFO :       Start Pruning
2024-04-23 18:38:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:38:53 - INFO :       Loss = 2.912109375
2024-04-23 18:38:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:38:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:38:56 - INFO :       high_school_world_history: Total Sparsity 1.3598587112591052e-06
2024-04-23 18:39:20 - INFO :       high_school_world_history: Total Accuracy (10, 26, 0.38461538461538464)
2024-04-23 18:39:20 - INFO :       
==================Finish================

2024-04-23 18:39:20 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:39:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:39:20 - INFO :       DATASET: tasksource/mmlu human_aging
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 18:39:28 - INFO :       Use taylor pruner...
2024-04-23 18:39:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:39:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:39:29 - INFO :       Start Pruning
2024-04-23 18:39:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:39:31 - INFO :       Loss = 15.2578125
2024-04-23 18:39:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:39:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:39:34 - INFO :       human_aging: Total Sparsity 1.355085043889836e-06
2024-04-23 18:39:53 - INFO :       human_aging: Total Accuracy (12, 23, 0.5217391304347826)
2024-04-23 18:39:53 - INFO :       
==================Finish================

2024-04-23 18:39:53 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:39:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:39:53 - INFO :       DATASET: tasksource/mmlu human_sexuality
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 18:40:00 - INFO :       Use taylor pruner...
2024-04-23 18:40:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:40:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:40:01 - INFO :       Start Pruning
2024-04-23 18:40:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:40:03 - INFO :       Loss = 14.890625
2024-04-23 18:40:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:40:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:40:06 - INFO :       human_sexuality: Total Sparsity 1.3552441661354783e-06
2024-04-23 18:40:16 - INFO :       human_sexuality: Total Accuracy (2, 12, 0.16666666666666666)
2024-04-23 18:40:16 - INFO :       
==================Finish================

2024-04-23 18:40:16 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:40:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:40:16 - INFO :       DATASET: tasksource/mmlu international_law
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 18:40:24 - INFO :       Use taylor pruner...
2024-04-23 18:40:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:40:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:40:24 - INFO :       Start Pruning
2024-04-23 18:40:25 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:40:26 - INFO :       Loss = 13.1328125
2024-04-23 18:40:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:40:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:40:29 - INFO :       international_law: Total Sparsity 1.3558806551180476e-06
2024-04-23 18:40:40 - INFO :       international_law: Total Accuracy (9, 13, 0.6923076923076923)
2024-04-23 18:40:40 - INFO :       
==================Finish================

2024-04-23 18:40:40 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:40:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:40:40 - INFO :       DATASET: tasksource/mmlu jurisprudence
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 18:40:50 - INFO :       Use taylor pruner...
2024-04-23 18:40:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:40:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:40:51 - INFO :       Start Pruning
2024-04-23 18:40:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:40:52 - INFO :       Loss = 13.546875
2024-04-23 18:40:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:40:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:40:55 - INFO :       jurisprudence: Total Sparsity 1.357630999820113e-06
2024-04-23 18:41:05 - INFO :       jurisprudence: Total Accuracy (4, 11, 0.36363636363636365)
2024-04-23 18:41:05 - INFO :       
==================Finish================

2024-04-23 18:41:05 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:41:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:41:05 - INFO :       DATASET: tasksource/mmlu logical_fallacies
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 18:41:15 - INFO :       Use taylor pruner...
2024-04-23 18:41:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:41:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:41:15 - INFO :       Start Pruning
2024-04-23 18:41:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:41:17 - INFO :       Loss = 14.375
2024-04-23 18:41:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:41:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:41:20 - INFO :       logical_fallacies: Total Sparsity 1.3589039777852514e-06
2024-04-23 18:41:35 - INFO :       logical_fallacies: Total Accuracy (10, 18, 0.5555555555555556)
2024-04-23 18:41:35 - INFO :       
==================Finish================

2024-04-23 18:41:35 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:41:35 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:41:35 - INFO :       DATASET: tasksource/mmlu machine_learning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 18:41:42 - INFO :       Use taylor pruner...
2024-04-23 18:41:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:41:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:41:43 - INFO :       Start Pruning
2024-04-23 18:41:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:41:45 - INFO :       Loss = 13.8984375
2024-04-23 18:41:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:41:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:41:47 - INFO :       machine_learning: Total Sparsity 1.3593813445221782e-06
2024-04-23 18:41:56 - INFO :       machine_learning: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-23 18:41:56 - INFO :       
==================Finish================

2024-04-23 18:41:56 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:41:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:41:56 - INFO :       DATASET: tasksource/mmlu management
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 18:42:04 - INFO :       Use taylor pruner...
2024-04-23 18:42:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:42:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:42:04 - INFO :       Start Pruning
2024-04-23 18:42:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:42:06 - INFO :       Loss = 15.625
2024-04-23 18:42:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:42:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:42:09 - INFO :       management: Total Sparsity 1.358267488802682e-06
2024-04-23 18:42:18 - INFO :       management: Total Accuracy (7, 11, 0.6363636363636364)
2024-04-23 18:42:18 - INFO :       
==================Finish================

2024-04-23 18:42:18 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:42:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:42:18 - INFO :       DATASET: tasksource/mmlu marketing
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 18:42:26 - INFO :       Use taylor pruner...
2024-04-23 18:42:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:42:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:42:26 - INFO :       Start Pruning
2024-04-23 18:42:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:42:29 - INFO :       Loss = 14.984375
2024-04-23 18:42:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:42:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:42:32 - INFO :       marketing: Total Sparsity 1.3568353885919015e-06
2024-04-23 18:42:52 - INFO :       marketing: Total Accuracy (14, 25, 0.56)
2024-04-23 18:42:52 - INFO :       
==================Finish================

2024-04-23 18:42:52 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:42:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:42:52 - INFO :       DATASET: tasksource/mmlu medical_genetics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 18:43:00 - INFO :       Use taylor pruner...
2024-04-23 18:43:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:43:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:43:00 - INFO :       Start Pruning
2024-04-23 18:43:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:43:02 - INFO :       Loss = 15.1171875
2024-04-23 18:43:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:43:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:43:05 - INFO :       medical_genetics: Total Sparsity 1.3552441661354783e-06
2024-04-23 18:43:14 - INFO :       medical_genetics: Total Accuracy (9, 11, 0.8181818181818182)
2024-04-23 18:43:14 - INFO :       
==================Finish================

2024-04-23 18:43:14 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:43:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:43:14 - INFO :       DATASET: tasksource/mmlu miscellaneous
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2024-04-23 18:43:22 - INFO :       Use taylor pruner...
2024-04-23 18:43:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:43:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:43:23 - INFO :       Start Pruning
2024-04-23 18:43:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:43:27 - INFO :       Loss = 15.1484375
2024-04-23 18:43:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:43:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:43:30 - INFO :       miscellaneous: Total Sparsity 1.3612908114698858e-06
2024-04-23 18:44:11 - INFO :       miscellaneous: Total Accuracy (27, 50, 0.54)
2024-04-23 18:44:11 - INFO :       
==================Finish================

2024-04-23 18:44:11 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:44:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:44:11 - INFO :       DATASET: tasksource/mmlu moral_disputes
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 18:44:19 - INFO :       Use taylor pruner...
2024-04-23 18:44:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:44:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:44:20 - INFO :       Start Pruning
2024-04-23 18:44:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:44:21 - INFO :       Loss = 15.109375
2024-04-23 18:44:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:44:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:44:24 - INFO :       moral_disputes: Total Sparsity 1.3581083665570398e-06
2024-04-23 18:44:56 - INFO :       moral_disputes: Total Accuracy (19, 38, 0.5)
2024-04-23 18:44:56 - INFO :       
==================Finish================

2024-04-23 18:44:56 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:44:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:44:56 - INFO :       DATASET: tasksource/mmlu moral_scenarios
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 18:45:04 - INFO :       Use taylor pruner...
2024-04-23 18:45:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:45:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:45:04 - INFO :       Start Pruning
2024-04-23 18:45:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:45:06 - INFO :       Loss = 13.3359375
2024-04-23 18:45:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:45:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:45:09 - INFO :       moral_scenarios: Total Sparsity 1.3595404667678207e-06
2024-04-23 18:45:52 - INFO :       moral_scenarios: Total Accuracy (18, 50, 0.36)
2024-04-23 18:45:52 - INFO :       
==================Finish================

2024-04-23 18:45:52 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:45:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:45:52 - INFO :       DATASET: tasksource/mmlu nutrition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 18:46:03 - INFO :       Use taylor pruner...
2024-04-23 18:46:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:46:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:46:03 - INFO :       Start Pruning
2024-04-23 18:46:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:46:06 - INFO :       Loss = 14.2421875
2024-04-23 18:46:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:46:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:46:11 - INFO :       nutrition: Total Sparsity 1.359222222276536e-06
2024-04-23 18:46:38 - INFO :       nutrition: Total Accuracy (14, 33, 0.42424242424242425)
2024-04-23 18:46:38 - INFO :       
==================Finish================

2024-04-23 18:46:38 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:46:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:46:38 - INFO :       DATASET: tasksource/mmlu philosophy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 18:46:45 - INFO :       Use taylor pruner...
2024-04-23 18:46:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:46:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:46:46 - INFO :       Start Pruning
2024-04-23 18:46:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:46:48 - INFO :       Loss = 15.15625
2024-04-23 18:46:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:46:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:46:51 - INFO :       philosophy: Total Sparsity 1.360813444732959e-06
2024-04-23 18:47:18 - INFO :       philosophy: Total Accuracy (18, 34, 0.5294117647058824)
2024-04-23 18:47:18 - INFO :       
==================Finish================

2024-04-23 18:47:18 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:47:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:47:18 - INFO :       DATASET: tasksource/mmlu prehistory
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.50s/it]
2024-04-23 18:47:35 - INFO :       Use taylor pruner...
2024-04-23 18:47:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:47:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:47:35 - INFO :       Start Pruning
2024-04-23 18:47:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:47:37 - INFO :       Loss = 13.59375
2024-04-23 18:47:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:47:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:47:40 - INFO :       prehistory: Total Sparsity 1.3569945108375437e-06
2024-04-23 18:48:10 - INFO :       prehistory: Total Accuracy (19, 35, 0.5428571428571428)
2024-04-23 18:48:10 - INFO :       
==================Finish================

2024-04-23 18:48:10 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:48:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:48:10 - INFO :       DATASET: tasksource/mmlu professional_accounting
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 18:48:19 - INFO :       Use taylor pruner...
2024-04-23 18:48:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:48:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:48:20 - INFO :       Start Pruning
2024-04-23 18:48:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:48:22 - INFO :       Loss = 13.9453125
2024-04-23 18:48:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:48:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:48:25 - INFO :       professional_accounting: Total Sparsity 1.357630999820113e-06
2024-04-23 18:48:51 - INFO :       professional_accounting: Total Accuracy (10, 31, 0.3225806451612903)
2024-04-23 18:48:51 - INFO :       
==================Finish================

2024-04-23 18:48:51 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:48:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:48:51 - INFO :       DATASET: tasksource/mmlu professional_law
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 18:48:58 - INFO :       Use taylor pruner...
2024-04-23 18:48:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:48:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:48:59 - INFO :       Start Pruning
2024-04-23 18:49:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:49:01 - INFO :       Loss = 4.9140625
2024-04-23 18:49:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:49:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:49:04 - INFO :       professional_law: Total Sparsity 1.361449933715528e-06
2024-04-23 18:49:47 - INFO :       professional_law: Total Accuracy (8, 50, 0.16)
2024-04-23 18:49:47 - INFO :       
==================Finish================

2024-04-23 18:49:47 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:49:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:49:47 - INFO :       DATASET: tasksource/mmlu professional_medicine
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 18:49:55 - INFO :       Use taylor pruner...
2024-04-23 18:49:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:49:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:49:55 - INFO :       Start Pruning
2024-04-23 18:49:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:49:57 - INFO :       Loss = 11.984375
2024-04-23 18:49:58 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:49:58 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:50:00 - INFO :       professional_medicine: Total Sparsity 1.3616090559611704e-06
2024-04-23 18:50:26 - INFO :       professional_medicine: Total Accuracy (11, 31, 0.3548387096774194)
2024-04-23 18:50:28 - INFO :       
==================Finish================

2024-04-23 18:50:28 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:50:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:50:28 - INFO :       DATASET: tasksource/mmlu professional_psychology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 18:50:36 - INFO :       Use taylor pruner...
2024-04-23 18:50:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:50:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:50:36 - INFO :       Start Pruning
2024-04-23 18:50:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:50:38 - INFO :       Loss = 14.2890625
2024-04-23 18:50:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:50:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:50:41 - INFO :       professional_psychology: Total Sparsity 1.3617681782068128e-06
2024-04-23 18:51:22 - INFO :       professional_psychology: Total Accuracy (19, 50, 0.38)
2024-04-23 18:51:22 - INFO :       
==================Finish================

2024-04-23 18:51:22 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:51:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:51:22 - INFO :       DATASET: tasksource/mmlu public_relations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 18:51:29 - INFO :       Use taylor pruner...
2024-04-23 18:51:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:51:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:51:30 - INFO :       Start Pruning
2024-04-23 18:51:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:51:33 - INFO :       Loss = 15.0078125
2024-04-23 18:51:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:51:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:51:35 - INFO :       public_relations: Total Sparsity 1.358267488802682e-06
2024-04-23 18:51:45 - INFO :       public_relations: Total Accuracy (7, 12, 0.5833333333333334)
2024-04-23 18:51:45 - INFO :       
==================Finish================

2024-04-23 18:51:45 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:51:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:51:45 - INFO :       DATASET: tasksource/mmlu security_studies
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 18:51:53 - INFO :       Use taylor pruner...
2024-04-23 18:51:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:51:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:51:53 - INFO :       Start Pruning
2024-04-23 18:51:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:51:55 - INFO :       Loss = 12.59375
2024-04-23 18:51:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:51:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:51:58 - INFO :       security_studies: Total Sparsity 1.3561988996093322e-06
2024-04-23 18:52:21 - INFO :       security_studies: Total Accuracy (12, 27, 0.4444444444444444)
2024-04-23 18:52:22 - INFO :       
==================Finish================

2024-04-23 18:52:22 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:52:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:52:22 - INFO :       DATASET: tasksource/mmlu sociology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 18:52:29 - INFO :       Use taylor pruner...
2024-04-23 18:52:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:52:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:52:30 - INFO :       Start Pruning
2024-04-23 18:52:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:52:31 - INFO :       Loss = 14.9453125
2024-04-23 18:52:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:52:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:52:34 - INFO :       sociology: Total Sparsity 1.3585857332939668e-06
2024-04-23 18:52:52 - INFO :       sociology: Total Accuracy (10, 22, 0.45454545454545453)
2024-04-23 18:52:52 - INFO :       
==================Finish================

2024-04-23 18:52:52 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:52:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:52:52 - INFO :       DATASET: tasksource/mmlu us_foreign_policy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 18:53:00 - INFO :       Use taylor pruner...
2024-04-23 18:53:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:53:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:53:00 - INFO :       Start Pruning
2024-04-23 18:53:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:53:02 - INFO :       Loss = 14.640625
2024-04-23 18:53:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:53:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:53:05 - INFO :       us_foreign_policy: Total Sparsity 1.3549259216441938e-06
2024-04-23 18:53:14 - INFO :       us_foreign_policy: Total Accuracy (6, 11, 0.5454545454545454)
2024-04-23 18:53:14 - INFO :       
==================Finish================

2024-04-23 18:53:14 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:53:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:53:14 - INFO :       DATASET: tasksource/mmlu virology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 18:53:21 - INFO :       Use taylor pruner...
2024-04-23 18:53:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:53:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:53:22 - INFO :       Start Pruning
2024-04-23 18:53:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:53:24 - INFO :       Loss = 14.7421875
2024-04-23 18:53:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:53:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:53:27 - INFO :       virology: Total Sparsity 1.356517144100617e-06
2024-04-23 18:53:41 - INFO :       virology: Total Accuracy (9, 18, 0.5)
2024-04-23 18:53:41 - INFO :       
==================Finish================

2024-04-23 18:53:41 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:53:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:53:41 - INFO :       DATASET: tasksource/mmlu world_religions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 18:53:49 - INFO :       Use taylor pruner...
2024-04-23 18:53:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:53:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:53:49 - INFO :       Start Pruning
2024-04-23 18:53:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:53:51 - INFO :       Loss = 15.5546875
2024-04-23 18:53:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:53:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:53:54 - INFO :       world_religions: Total Sparsity 1.3600178335047475e-06
2024-04-23 18:54:09 - INFO :       world_religions: Total Accuracy (11, 19, 0.5789473684210527)
2024-04-23 18:54:09 - INFO :       
==================Finish================

2024-04-23 18:54:09 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:54:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:54:09 - INFO :       DATASET: math_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 18:54:17 - INFO :       Use taylor pruner...
2024-04-23 18:54:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:54:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:54:17 - INFO :       Start Pruning
2024-04-23 18:54:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:54:24 - INFO :       Loss = 13.0859375
2024-04-23 18:54:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:54:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:54:27 - INFO :       math_qa: Total Sparsity 1.3566762663462592e-06
2024-04-23 18:55:04 - INFO :       math_qa: Accuracy (7, 50, 0.14)
2024-04-23 18:55:04 - INFO :       
==================Finish================

2024-04-23 18:55:04 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:55:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:55:04 - INFO :       DATASET: EleutherAI/truthful_qa_mc
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 18:55:12 - INFO :       Use taylor pruner...
2024-04-23 18:55:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:55:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:55:13 - INFO :       Start Pruning
2024-04-23 18:55:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:55:15 - INFO :       Loss = 14.6484375
2024-04-23 18:55:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:55:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:55:18 - INFO :       truthful_qa_mc: Total Sparsity 1.3573127553288283e-06
2024-04-23 18:55:53 - INFO :       truthful_qa_mc: Accuracy (19, 50, 0.38)
2024-04-23 18:55:53 - INFO :       
==================Finish================

2024-04-23 18:55:53 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:55:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:55:53 - INFO :       DATASET: derek-thomas/ScienceQA
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 18:56:00 - INFO :       Use taylor pruner...
2024-04-23 18:56:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:56:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:56:01 - INFO :       Start Pruning
2024-04-23 18:56:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:56:03 - INFO :       Loss = 15.609375
2024-04-23 18:56:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:56:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:56:06 - INFO :       ScienceQA: Total Sparsity 1.3593813445221782e-06
2024-04-23 18:56:41 - INFO :       ScienceQA: Accuracy (34, 50, 0.68)
2024-04-23 18:56:41 - INFO :       
==================Finish================

2024-04-23 18:56:41 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 18:56:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:56:41 - INFO :       DATASET: commonsense_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 18:56:48 - INFO :       Use taylor pruner...
2024-04-23 18:56:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:56:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:56:49 - INFO :       Start Pruning
2024-04-23 18:56:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:56:51 - INFO :       Loss = 15.4296875
2024-04-23 18:56:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:56:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:56:54 - INFO :       commonsense_qa: Total Sparsity 1.3574718775744707e-06
2024-04-23 18:57:28 - INFO :       commonsense_qa: Accuracy (29, 50, 0.58)
2024-04-23 18:57:28 - INFO :       
==================Finish================

2024-04-23 18:57:28 - INFO :       Memory Requirement: 16770.79052734375 MiB

End: Memory Requirement: 3979.2666015625 MiB

Begin: Memory Requirement: 3979.2666015625 MiB

2024-04-23 18:57:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:57:28 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Index 2
Sparsity 3.5000000000000004 %
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 18:57:36 - INFO :       Use taylor pruner...
2024-04-23 18:57:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:57:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:57:36 - INFO :       Start Pruning
2024-04-23 18:57:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:57:38 - INFO :       Loss = 3.646484375
2024-04-23 18:57:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:57:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:57:41 - INFO :       which_wiki_edit: Total Sparsity 1.3598587112591052e-06
2024-04-23 18:59:16 - INFO :       which_wiki_edit: Total Accuracy (29, 50, 0.58)
2024-04-23 18:59:16 - INFO :       
==================Finish================

2024-04-23 18:59:16 - INFO :       Memory Requirement: 16849.60302734375 MiB

2024-04-23 18:59:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 18:59:16 - INFO :       DATASET: tasksource/bigbench abstract_narrative_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 18:59:24 - INFO :       Use taylor pruner...
2024-04-23 18:59:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:59:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 18:59:24 - INFO :       Start Pruning
2024-04-23 18:59:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 18:59:26 - INFO :       Loss = 8.875
2024-04-23 18:59:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 18:59:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 18:59:29 - INFO :       abstract_narrative_understanding: Total Sparsity 1.3600178335047475e-06
2024-04-23 19:00:13 - INFO :       abstract_narrative_understanding: Total Accuracy (15, 50, 0.3)
2024-04-23 19:00:13 - INFO :       
==================Finish================

2024-04-23 19:00:13 - INFO :       Memory Requirement: 16772.79052734375 MiB

2024-04-23 19:00:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:00:13 - INFO :       DATASET: tasksource/bigbench anachronisms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.33s/it]
2024-04-23 19:00:27 - INFO :       Use taylor pruner...
2024-04-23 19:00:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:00:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:00:28 - INFO :       Start Pruning
2024-04-23 19:00:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:00:30 - INFO :       Loss = 15.8359375
2024-04-23 19:00:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:00:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:00:33 - INFO :       anachronisms: Total Sparsity 1.3584266110483244e-06
2024-04-23 19:01:12 - INFO :       anachronisms: Total Accuracy (25, 46, 0.5434782608695652)
2024-04-23 19:01:13 - INFO :       
==================Finish================

2024-04-23 19:01:13 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-23 19:01:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:01:13 - INFO :       DATASET: tasksource/bigbench analogical_similarity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.21s/it]
2024-04-23 19:01:28 - INFO :       Use taylor pruner...
2024-04-23 19:01:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:01:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:01:29 - INFO :       Start Pruning
2024-04-23 19:01:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:01:31 - INFO :       Loss = 1.46875
2024-04-23 19:01:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:01:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:01:34 - INFO :       analogical_similarity: Total Sparsity 1.3584266110483244e-06
2024-04-23 19:02:28 - INFO :       analogical_similarity: Total Accuracy (3, 50, 0.06)
2024-04-23 19:02:28 - INFO :       
==================Finish================

2024-04-23 19:02:28 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-23 19:02:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:02:28 - INFO :       DATASET: tasksource/bigbench analytic_entailment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 19:02:35 - INFO :       Use taylor pruner...
2024-04-23 19:02:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:02:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:02:36 - INFO :       Start Pruning
2024-04-23 19:02:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:02:38 - INFO :       Loss = 14.7734375
2024-04-23 19:02:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:02:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:02:41 - INFO :       analytic_entailment: Total Sparsity 1.3579492443113975e-06
2024-04-23 19:02:54 - INFO :       analytic_entailment: Total Accuracy (8, 16, 0.5)
2024-04-23 19:02:54 - INFO :       
==================Finish================

2024-04-23 19:02:54 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-23 19:02:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:02:54 - INFO :       DATASET: tasksource/bigbench arithmetic
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 19:03:02 - INFO :       Use taylor pruner...
2024-04-23 19:03:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:03:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:03:02 - INFO :       Start Pruning
2024-04-23 19:03:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:03:04 - INFO :       Loss = 12.3046875
2024-04-23 19:03:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:03:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:03:07 - INFO :       arithmetic: Total Sparsity 1.3574718775744707e-06
2024-04-23 19:03:48 - INFO :       arithmetic: Total Accuracy (0, 50, 0.0)
2024-04-23 19:03:48 - INFO :       
==================Finish================

2024-04-23 19:03:48 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-23 19:03:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:03:48 - INFO :       DATASET: tasksource/bigbench authorship_verification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 19:03:55 - INFO :       Use taylor pruner...
2024-04-23 19:03:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:03:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:03:56 - INFO :       Start Pruning
2024-04-23 19:03:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:03:58 - INFO :       Loss = 2.525390625
2024-04-23 19:03:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:03:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:04:01 - INFO :       authorship_verification: Total Sparsity 1.3561988996093322e-06
2024-04-23 19:06:06 - INFO :       authorship_verification: Total Accuracy (27, 50, 0.54)
2024-04-23 19:06:07 - INFO :       
==================Finish================

2024-04-23 19:06:07 - INFO :       Memory Requirement: 16794.44580078125 MiB

2024-04-23 19:06:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:06:07 - INFO :       DATASET: tasksource/bigbench bbq_lite_json
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 19:06:15 - INFO :       Use taylor pruner...
2024-04-23 19:06:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:06:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:06:15 - INFO :       Start Pruning
2024-04-23 19:06:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:06:18 - INFO :       Loss = 13.6875
2024-04-23 19:06:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:06:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:06:21 - INFO :       bbq_lite_json: Total Sparsity 1.360813444732959e-06
2024-04-23 19:07:01 - INFO :       bbq_lite_json: Total Accuracy (16, 50, 0.32)
2024-04-23 19:07:01 - INFO :       
==================Finish================

2024-04-23 19:07:01 - INFO :       Memory Requirement: 16771.79052734375 MiB

2024-04-23 19:07:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:07:01 - INFO :       DATASET: tasksource/bigbench causal_judgment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 19:07:09 - INFO :       Use taylor pruner...
2024-04-23 19:07:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:07:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:07:09 - INFO :       Start Pruning
2024-04-23 19:07:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:07:11 - INFO :       Loss = 8.59375
2024-04-23 19:07:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:07:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:07:14 - INFO :       causal_judgment: Total Sparsity 1.3547667993985515e-06
2024-04-23 19:07:45 - INFO :       causal_judgment: Total Accuracy (16, 38, 0.42105263157894735)
2024-04-23 19:07:45 - INFO :       
==================Finish================

2024-04-23 19:07:45 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:07:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:07:45 - INFO :       DATASET: tasksource/bigbench cause_and_effect
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 19:07:53 - INFO :       Use taylor pruner...
2024-04-23 19:07:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:07:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:07:53 - INFO :       Start Pruning
2024-04-23 19:07:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:07:55 - INFO :       Loss = 15.1015625
2024-04-23 19:07:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:07:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:07:58 - INFO :       cause_and_effect: Total Sparsity 1.358744855539609e-06
2024-04-23 19:08:22 - INFO :       cause_and_effect: Total Accuracy (3, 30, 0.1)
2024-04-23 19:08:22 - INFO :       
==================Finish================

2024-04-23 19:08:22 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:08:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:08:22 - INFO :       DATASET: tasksource/bigbench checkmate_in_one
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 19:08:29 - INFO :       Use taylor pruner...
2024-04-23 19:08:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:08:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:08:30 - INFO :       Start Pruning
2024-04-23 19:08:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:08:32 - INFO :       Loss = 1.5068359375
2024-04-23 19:08:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:08:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:08:35 - INFO :       checkmate_in_one: Total Sparsity 1.3525390879595594e-06
2024-04-23 19:09:21 - INFO :       checkmate_in_one: Total Accuracy (17, 50, 0.34)
2024-04-23 19:09:21 - INFO :       
==================Finish================

2024-04-23 19:09:21 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:09:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:09:21 - INFO :       DATASET: tasksource/bigbench cifar10_classification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 19:09:28 - INFO :       Use taylor pruner...
2024-04-23 19:09:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:09:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:09:29 - INFO :       Start Pruning
2024-04-23 19:09:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:09:31 - INFO :       Loss = 3.775390625
2024-04-23 19:09:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:09:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:09:34 - INFO :       cifar10_classification: Total Sparsity 1.3598587112591052e-06
2024-04-23 19:11:21 - INFO :       cifar10_classification: Total Accuracy (7, 50, 0.14)
2024-04-23 19:11:21 - INFO :       
==================Finish================

2024-04-23 19:11:21 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:11:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:11:21 - INFO :       DATASET: tasksource/bigbench code_line_description
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:11:29 - INFO :       Use taylor pruner...
2024-04-23 19:11:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:11:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:11:29 - INFO :       Start Pruning
2024-04-23 19:11:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:11:31 - INFO :       Loss = 9.8046875
2024-04-23 19:11:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:11:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:11:34 - INFO :       code_line_description: Total Sparsity 1.3595404667678207e-06
2024-04-23 19:11:47 - INFO :       code_line_description: Total Accuracy (7, 16, 0.4375)
2024-04-23 19:11:47 - INFO :       
==================Finish================

2024-04-23 19:11:47 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:11:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:11:47 - INFO :       DATASET: tasksource/bigbench color
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:11:54 - INFO :       Use taylor pruner...
2024-04-23 19:11:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:11:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:11:55 - INFO :       Start Pruning
2024-04-23 19:11:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:11:57 - INFO :       Loss = 11.3359375
2024-04-23 19:11:58 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:11:58 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:12:00 - INFO :       color: Total Sparsity 1.360813444732959e-06
2024-04-23 19:12:40 - INFO :       color: Total Accuracy (13, 50, 0.26)
2024-04-23 19:12:40 - INFO :       
==================Finish================

2024-04-23 19:12:40 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:12:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:12:40 - INFO :       DATASET: tasksource/bigbench common_morpheme
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:12:47 - INFO :       Use taylor pruner...
2024-04-23 19:12:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:12:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:12:47 - INFO :       Start Pruning
2024-04-23 19:12:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:12:49 - INFO :       Loss = 13.53125
2024-04-23 19:12:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:12:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:12:52 - INFO :       common_morpheme: Total Sparsity 1.3589039777852514e-06
2024-04-23 19:13:05 - INFO :       common_morpheme: Total Accuracy (4, 16, 0.25)
2024-04-23 19:13:05 - INFO :       
==================Finish================

2024-04-23 19:13:05 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:13:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:13:05 - INFO :       DATASET: tasksource/bigbench conceptual_combinations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 19:13:12 - INFO :       Use taylor pruner...
2024-04-23 19:13:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:13:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:13:13 - INFO :       Start Pruning
2024-04-23 19:13:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:13:15 - INFO :       Loss = 12.4609375
2024-04-23 19:13:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:13:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:13:18 - INFO :       conceptual_combinations: Total Sparsity 1.3552441661354783e-06
2024-04-23 19:13:33 - INFO :       conceptual_combinations: Total Accuracy (3, 19, 0.15789473684210525)
2024-04-23 19:13:33 - INFO :       
==================Finish================

2024-04-23 19:13:33 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:13:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:13:33 - INFO :       DATASET: tasksource/bigbench crash_blossom
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:13:40 - INFO :       Use taylor pruner...
2024-04-23 19:13:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:13:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:13:41 - INFO :       Start Pruning
2024-04-23 19:13:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:13:43 - INFO :       Loss = 13.9453125
2024-04-23 19:13:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:13:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:13:46 - INFO :       crash_blossom: Total Sparsity 1.359222222276536e-06
2024-04-23 19:13:59 - INFO :       crash_blossom: Total Accuracy (5, 16, 0.3125)
2024-04-23 19:13:59 - INFO :       
==================Finish================

2024-04-23 19:13:59 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:13:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:13:59 - INFO :       DATASET: tasksource/bigbench crass_ai
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 19:14:06 - INFO :       Use taylor pruner...
2024-04-23 19:14:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:14:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:14:06 - INFO :       Start Pruning
2024-04-23 19:14:08 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:14:08 - INFO :       Loss = 12.875
2024-04-23 19:14:10 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:14:10 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:14:11 - INFO :       crass_ai: Total Sparsity 1.358267488802682e-06
2024-04-23 19:14:24 - INFO :       crass_ai: Total Accuracy (5, 16, 0.3125)
2024-04-23 19:14:24 - INFO :       
==================Finish================

2024-04-23 19:14:24 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:14:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:14:24 - INFO :       DATASET: tasksource/bigbench cryobiology_spanish
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 19:14:31 - INFO :       Use taylor pruner...
2024-04-23 19:14:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:14:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:14:32 - INFO :       Start Pruning
2024-04-23 19:14:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:14:35 - INFO :       Loss = 14.8984375
2024-04-23 19:14:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:14:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:14:38 - INFO :       cryobiology_spanish: Total Sparsity 1.3600178335047475e-06
2024-04-23 19:15:00 - INFO :       cryobiology_spanish: Total Accuracy (9, 29, 0.3103448275862069)
2024-04-23 19:15:00 - INFO :       
==================Finish================

2024-04-23 19:15:00 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:15:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:15:00 - INFO :       DATASET: tasksource/bigbench cs_algorithms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 19:15:08 - INFO :       Use taylor pruner...
2024-04-23 19:15:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:15:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:15:08 - INFO :       Start Pruning
2024-04-23 19:15:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:15:10 - INFO :       Loss = 13.953125
2024-04-23 19:15:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:15:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:15:13 - INFO :       cs_algorithms: Total Sparsity 1.3622455449437396e-06
2024-04-23 19:15:53 - INFO :       cs_algorithms: Total Accuracy (5, 50, 0.1)
2024-04-23 19:15:53 - INFO :       
==================Finish================

2024-04-23 19:15:53 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:15:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:15:53 - INFO :       DATASET: tasksource/bigbench dark_humor_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 19:16:01 - INFO :       Use taylor pruner...
2024-04-23 19:16:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:16:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:16:01 - INFO :       Start Pruning
2024-04-23 19:16:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:16:03 - INFO :       Loss = 13.875
2024-04-23 19:16:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:16:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:16:06 - INFO :       dark_humor_detection: Total Sparsity 1.357630999820113e-06
2024-04-23 19:16:19 - INFO :       dark_humor_detection: Total Accuracy (10, 16, 0.625)
2024-04-23 19:16:19 - INFO :       
==================Finish================

2024-04-23 19:16:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:16:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:16:19 - INFO :       DATASET: tasksource/bigbench date_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:16:26 - INFO :       Use taylor pruner...
2024-04-23 19:16:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:16:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:16:26 - INFO :       Start Pruning
2024-04-23 19:16:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:16:29 - INFO :       Loss = 11.9453125
2024-04-23 19:16:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:16:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:16:32 - INFO :       date_understanding: Total Sparsity 1.3584266110483244e-06
2024-04-23 19:17:12 - INFO :       date_understanding: Total Accuracy (2, 50, 0.04)
2024-04-23 19:17:12 - INFO :       
==================Finish================

2024-04-23 19:17:12 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:17:12 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:17:12 - INFO :       DATASET: tasksource/bigbench disambiguation_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 19:17:19 - INFO :       Use taylor pruner...
2024-04-23 19:17:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:17:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:17:20 - INFO :       Start Pruning
2024-04-23 19:17:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:17:22 - INFO :       Loss = 13.28125
2024-04-23 19:17:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:17:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:17:25 - INFO :       disambiguation_qa: Total Sparsity 1.3585857332939668e-06
2024-04-23 19:18:04 - INFO :       disambiguation_qa: Total Accuracy (21, 50, 0.42)
2024-04-23 19:18:04 - INFO :       
==================Finish================

2024-04-23 19:18:04 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:18:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:18:04 - INFO :       DATASET: tasksource/bigbench discourse_marker_prediction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 19:18:12 - INFO :       Use taylor pruner...
2024-04-23 19:18:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:18:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:18:12 - INFO :       Start Pruning
2024-04-23 19:18:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:18:14 - INFO :       Loss = 2.34765625
2024-04-23 19:18:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:18:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:18:17 - INFO :       discourse_marker_prediction: Total Sparsity 1.3595404667678207e-06
2024-04-23 19:19:04 - INFO :       discourse_marker_prediction: Total Accuracy (6, 50, 0.12)
2024-04-23 19:19:04 - INFO :       
==================Finish================

2024-04-23 19:19:04 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:19:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:19:04 - INFO :       DATASET: tasksource/bigbench dyck_languages
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 19:19:12 - INFO :       Use taylor pruner...
2024-04-23 19:19:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:19:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:19:12 - INFO :       Start Pruning
2024-04-23 19:19:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:19:15 - INFO :       Loss = 1.18359375
2024-04-23 19:19:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:19:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:19:17 - INFO :       dyck_languages: Total Sparsity 1.355085043889836e-06
2024-04-23 19:20:04 - INFO :       dyck_languages: Total Accuracy (0, 50, 0.0)
2024-04-23 19:20:04 - INFO :       
==================Finish================

2024-04-23 19:20:04 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:20:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:20:04 - INFO :       DATASET: tasksource/bigbench elementary_math_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 19:20:11 - INFO :       Use taylor pruner...
2024-04-23 19:20:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:20:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:20:12 - INFO :       Start Pruning
2024-04-23 19:20:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:20:14 - INFO :       Loss = 12.6171875
2024-04-23 19:20:15 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:20:15 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:20:17 - INFO :       elementary_math_qa: Total Sparsity 1.357630999820113e-06
2024-04-23 19:20:56 - INFO :       elementary_math_qa: Total Accuracy (8, 50, 0.16)
2024-04-23 19:20:56 - INFO :       
==================Finish================

2024-04-23 19:20:56 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:20:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:20:56 - INFO :       DATASET: tasksource/bigbench emoji_movie
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 19:21:04 - INFO :       Use taylor pruner...
2024-04-23 19:21:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:21:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:21:04 - INFO :       Start Pruning
2024-04-23 19:21:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:21:06 - INFO :       Loss = 12.9296875
2024-04-23 19:21:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:21:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:21:09 - INFO :       emoji_movie: Total Sparsity 1.3581083665570398e-06
2024-04-23 19:21:25 - INFO :       emoji_movie: Total Accuracy (0, 20, 0.0)
2024-04-23 19:21:25 - INFO :       
==================Finish================

2024-04-23 19:21:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:21:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:21:25 - INFO :       DATASET: tasksource/bigbench empirical_judgments
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 19:21:32 - INFO :       Use taylor pruner...
2024-04-23 19:21:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:21:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:21:32 - INFO :       Start Pruning
2024-04-23 19:21:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:21:35 - INFO :       Loss = 13.421875
2024-04-23 19:21:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:21:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:21:37 - INFO :       empirical_judgments: Total Sparsity 1.3577901220657553e-06
2024-04-23 19:21:52 - INFO :       empirical_judgments: Total Accuracy (10, 19, 0.5263157894736842)
2024-04-23 19:21:52 - INFO :       
==================Finish================

2024-04-23 19:21:52 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:21:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:21:52 - INFO :       DATASET: tasksource/bigbench english_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:22:00 - INFO :       Use taylor pruner...
2024-04-23 19:22:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:22:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:22:00 - INFO :       Start Pruning
2024-04-23 19:22:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:22:02 - INFO :       Loss = 11.828125
2024-04-23 19:22:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:22:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:22:05 - INFO :       english_proverbs: Total Sparsity 1.3568353885919015e-06
2024-04-23 19:22:18 - INFO :       english_proverbs: Total Accuracy (4, 16, 0.25)
2024-04-23 19:22:18 - INFO :       
==================Finish================

2024-04-23 19:22:18 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:22:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:22:18 - INFO :       DATASET: tasksource/bigbench english_russian_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 19:22:25 - INFO :       Use taylor pruner...
2024-04-23 19:22:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:22:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:22:26 - INFO :       Start Pruning
2024-04-23 19:22:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:22:28 - INFO :       Loss = 11.53125
2024-04-23 19:22:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:22:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:22:31 - INFO :       english_russian_proverbs: Total Sparsity 1.3563580218549744e-06
2024-04-23 19:22:43 - INFO :       english_russian_proverbs: Total Accuracy (7, 16, 0.4375)
2024-04-23 19:22:43 - INFO :       
==================Finish================

2024-04-23 19:22:43 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:22:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:22:43 - INFO :       DATASET: tasksource/bigbench entailed_polarity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 19:22:51 - INFO :       Use taylor pruner...
2024-04-23 19:22:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:22:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:22:51 - INFO :       Start Pruning
2024-04-23 19:22:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:22:53 - INFO :       Loss = 15.90625
2024-04-23 19:22:55 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:22:55 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:22:56 - INFO :       entailed_polarity: Total Sparsity 1.3581083665570398e-06
2024-04-23 19:23:19 - INFO :       entailed_polarity: Total Accuracy (29, 29, 1.0)
2024-04-23 19:23:19 - INFO :       
==================Finish================

2024-04-23 19:23:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:23:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:23:19 - INFO :       DATASET: tasksource/bigbench entailed_polarity_hindi
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 19:23:26 - INFO :       Use taylor pruner...
2024-04-23 19:23:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:23:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:23:27 - INFO :       Start Pruning
2024-04-23 19:23:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:23:29 - INFO :       Loss = 11.734375
2024-04-23 19:23:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:23:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:23:32 - INFO :       entailed_polarity_hindi: Total Sparsity 1.3561988996093322e-06
2024-04-23 19:23:52 - INFO :       entailed_polarity_hindi: Total Accuracy (17, 27, 0.6296296296296297)
2024-04-23 19:23:52 - INFO :       
==================Finish================

2024-04-23 19:23:52 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:23:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:23:52 - INFO :       DATASET: tasksource/bigbench epistemic_reasoning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 19:23:59 - INFO :       Use taylor pruner...
2024-04-23 19:23:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:23:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:24:00 - INFO :       Start Pruning
2024-04-23 19:24:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:24:02 - INFO :       Loss = 13.78125
2024-04-23 19:24:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:24:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:24:05 - INFO :       epistemic_reasoning: Total Sparsity 1.356517144100617e-06
2024-04-23 19:24:44 - INFO :       epistemic_reasoning: Total Accuracy (26, 50, 0.52)
2024-04-23 19:24:44 - INFO :       
==================Finish================

2024-04-23 19:24:44 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:24:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:24:44 - INFO :       DATASET: tasksource/bigbench evaluating_information_essentiality
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 19:24:52 - INFO :       Use taylor pruner...
2024-04-23 19:24:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:24:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:24:52 - INFO :       Start Pruning
2024-04-23 19:24:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:24:54 - INFO :       Loss = 8.109375
2024-04-23 19:24:55 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:24:55 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:24:57 - INFO :       evaluating_information_essentiality: Total Sparsity 1.3538120659246977e-06
2024-04-23 19:25:10 - INFO :       evaluating_information_essentiality: Total Accuracy (5, 16, 0.3125)
2024-04-23 19:25:10 - INFO :       
==================Finish================

2024-04-23 19:25:10 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:25:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:25:10 - INFO :       DATASET: tasksource/bigbench fact_checker
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 19:25:18 - INFO :       Use taylor pruner...
2024-04-23 19:25:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:25:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:25:18 - INFO :       Start Pruning
2024-04-23 19:25:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:25:20 - INFO :       Loss = 15.5546875
2024-04-23 19:25:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:25:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:25:23 - INFO :       fact_checker: Total Sparsity 1.3584266110483244e-06
2024-04-23 19:26:02 - INFO :       fact_checker: Total Accuracy (31, 50, 0.62)
2024-04-23 19:26:02 - INFO :       
==================Finish================

2024-04-23 19:26:02 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:26:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:26:02 - INFO :       DATASET: tasksource/bigbench fantasy_reasoning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 19:26:10 - INFO :       Use taylor pruner...
2024-04-23 19:26:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:26:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:26:10 - INFO :       Start Pruning
2024-04-23 19:26:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:26:12 - INFO :       Loss = 14.390625
2024-04-23 19:26:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:26:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:26:15 - INFO :       fantasy_reasoning: Total Sparsity 1.3552441661354783e-06
2024-04-23 19:26:47 - INFO :       fantasy_reasoning: Total Accuracy (25, 40, 0.625)
2024-04-23 19:26:47 - INFO :       
==================Finish================

2024-04-23 19:26:47 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:26:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:26:47 - INFO :       DATASET: tasksource/bigbench figure_of_speech_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:26:55 - INFO :       Use taylor pruner...
2024-04-23 19:26:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:26:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:26:55 - INFO :       Start Pruning
2024-04-23 19:26:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:26:57 - INFO :       Loss = 12.2421875
2024-04-23 19:26:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:26:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:27:00 - INFO :       figure_of_speech_detection: Total Sparsity 1.355562410626763e-06
2024-04-23 19:27:13 - INFO :       figure_of_speech_detection: Total Accuracy (4, 16, 0.25)
2024-04-23 19:27:13 - INFO :       
==================Finish================

2024-04-23 19:27:13 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:27:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:27:13 - INFO :       DATASET: tasksource/bigbench formal_fallacies_syllogisms_negation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 19:27:20 - INFO :       Use taylor pruner...
2024-04-23 19:27:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:27:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:27:21 - INFO :       Start Pruning
2024-04-23 19:27:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:27:23 - INFO :       Loss = 13.53125
2024-04-23 19:27:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:27:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:27:26 - INFO :       formal_fallacies_syllogisms_negation: Total Sparsity 1.3574718775744707e-06
2024-04-23 19:28:06 - INFO :       formal_fallacies_syllogisms_negation: Total Accuracy (23, 50, 0.46)
2024-04-23 19:28:06 - INFO :       
==================Finish================

2024-04-23 19:28:06 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:28:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:28:06 - INFO :       DATASET: tasksource/bigbench general_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 19:28:13 - INFO :       Use taylor pruner...
2024-04-23 19:28:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:28:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:28:14 - INFO :       Start Pruning
2024-04-23 19:28:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:28:16 - INFO :       Loss = 12.625
2024-04-23 19:28:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:28:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:28:19 - INFO :       general_knowledge: Total Sparsity 1.361449933715528e-06
2024-04-23 19:28:32 - INFO :       general_knowledge: Total Accuracy (4, 16, 0.25)
2024-04-23 19:28:32 - INFO :       
==================Finish================

2024-04-23 19:28:32 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:28:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:28:32 - INFO :       DATASET: tasksource/bigbench geometric_shapes
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 19:28:39 - INFO :       Use taylor pruner...
2024-04-23 19:28:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:28:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:28:40 - INFO :       Start Pruning
2024-04-23 19:28:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:28:42 - INFO :       Loss = 8.25
2024-04-23 19:28:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:28:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:28:44 - INFO :       geometric_shapes: Total Sparsity 1.360336077996032e-06
2024-04-23 19:29:25 - INFO :       geometric_shapes: Total Accuracy (8, 50, 0.16)
2024-04-23 19:29:25 - INFO :       
==================Finish================

2024-04-23 19:29:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:29:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:29:25 - INFO :       DATASET: tasksource/bigbench goal_step_wikihow
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:29:32 - INFO :       Use taylor pruner...
2024-04-23 19:29:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:29:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:29:33 - INFO :       Start Pruning
2024-04-23 19:29:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:29:35 - INFO :       Loss = 12.671875
2024-04-23 19:29:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:29:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:29:38 - INFO :       goal_step_wikihow: Total Sparsity 1.357630999820113e-06
2024-04-23 19:30:17 - INFO :       goal_step_wikihow: Total Accuracy (6, 50, 0.12)
2024-04-23 19:30:17 - INFO :       
==================Finish================

2024-04-23 19:30:17 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:30:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:30:17 - INFO :       DATASET: tasksource/bigbench gre_reading_comprehension
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 19:30:24 - INFO :       Use taylor pruner...
2024-04-23 19:30:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:30:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:30:25 - INFO :       Start Pruning
2024-04-23 19:30:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:30:27 - INFO :       Loss = 2.16015625
2024-04-23 19:30:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:30:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:30:30 - INFO :       gre_reading_comprehension: Total Sparsity 1.3589039777852514e-06
2024-04-23 19:30:45 - INFO :       gre_reading_comprehension: Total Accuracy (3, 16, 0.1875)
2024-04-23 19:30:45 - INFO :       
==================Finish================

2024-04-23 19:30:45 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:30:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:30:45 - INFO :       DATASET: tasksource/bigbench hhh_alignment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 19:30:53 - INFO :       Use taylor pruner...
2024-04-23 19:30:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:30:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:30:53 - INFO :       Start Pruning
2024-04-23 19:30:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:30:55 - INFO :       Loss = 9.734375
2024-04-23 19:30:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:30:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:30:58 - INFO :       hhh_alignment: Total Sparsity 1.3606543224873167e-06
2024-04-23 19:31:34 - INFO :       hhh_alignment: Total Accuracy (19, 42, 0.4523809523809524)
2024-04-23 19:31:35 - INFO :       
==================Finish================

2024-04-23 19:31:35 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:31:35 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:31:35 - INFO :       DATASET: tasksource/bigbench hindu_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:31:42 - INFO :       Use taylor pruner...
2024-04-23 19:31:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:31:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:31:42 - INFO :       Start Pruning
2024-04-23 19:31:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:31:45 - INFO :       Loss = 13.9609375
2024-04-23 19:31:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:31:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:31:48 - INFO :       hindu_knowledge: Total Sparsity 1.3601769557503897e-06
2024-04-23 19:32:15 - INFO :       hindu_knowledge: Total Accuracy (8, 35, 0.22857142857142856)
2024-04-23 19:32:15 - INFO :       
==================Finish================

2024-04-23 19:32:15 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:32:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:32:15 - INFO :       DATASET: tasksource/bigbench hinglish_toxicity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 19:32:23 - INFO :       Use taylor pruner...
2024-04-23 19:32:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:32:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:32:23 - INFO :       Start Pruning
2024-04-23 19:32:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:32:25 - INFO :       Loss = 11.6328125
2024-04-23 19:32:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:32:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:32:28 - INFO :       hinglish_toxicity: Total Sparsity 1.3561988996093322e-06
2024-04-23 19:33:00 - INFO :       hinglish_toxicity: Total Accuracy (23, 40, 0.575)
2024-04-23 19:33:00 - INFO :       
==================Finish================

2024-04-23 19:33:00 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:33:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:33:00 - INFO :       DATASET: tasksource/bigbench human_organs_senses
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 19:33:08 - INFO :       Use taylor pruner...
2024-04-23 19:33:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:33:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:33:08 - INFO :       Start Pruning
2024-04-23 19:33:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:33:10 - INFO :       Loss = 14.6796875
2024-04-23 19:33:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:33:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:33:13 - INFO :       human_organs_senses: Total Sparsity 1.360336077996032e-06
2024-04-23 19:33:26 - INFO :       human_organs_senses: Total Accuracy (5, 16, 0.3125)
2024-04-23 19:33:26 - INFO :       
==================Finish================

2024-04-23 19:33:26 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:33:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:33:26 - INFO :       DATASET: tasksource/bigbench hyperbaton
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 19:33:33 - INFO :       Use taylor pruner...
2024-04-23 19:33:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:33:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:33:34 - INFO :       Start Pruning
2024-04-23 19:33:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:33:36 - INFO :       Loss = 15.03125
2024-04-23 19:33:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:33:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:33:39 - INFO :       hyperbaton: Total Sparsity 1.3566762663462592e-06
2024-04-23 19:34:17 - INFO :       hyperbaton: Total Accuracy (23, 50, 0.46)
2024-04-23 19:34:17 - INFO :       
==================Finish================

2024-04-23 19:34:17 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:34:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:34:17 - INFO :       DATASET: tasksource/bigbench identify_math_theorems
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 19:34:24 - INFO :       Use taylor pruner...
2024-04-23 19:34:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:34:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:34:25 - INFO :       Start Pruning
2024-04-23 19:34:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:34:27 - INFO :       Loss = 3.4296875
2024-04-23 19:34:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:34:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:34:30 - INFO :       identify_math_theorems: Total Sparsity 1.3574718775744707e-06
2024-04-23 19:34:45 - INFO :       identify_math_theorems: Total Accuracy (8, 16, 0.5)
2024-04-23 19:34:45 - INFO :       
==================Finish================

2024-04-23 19:34:45 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:34:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:34:45 - INFO :       DATASET: tasksource/bigbench identify_odd_metaphor
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 19:34:52 - INFO :       Use taylor pruner...
2024-04-23 19:34:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:34:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:34:53 - INFO :       Start Pruning
2024-04-23 19:34:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:34:55 - INFO :       Loss = 12.3984375
2024-04-23 19:34:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:34:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:34:58 - INFO :       identify_odd_metaphor: Total Sparsity 1.3611316892242436e-06
2024-04-23 19:35:10 - INFO :       identify_odd_metaphor: Total Accuracy (0, 16, 0.0)
2024-04-23 19:35:10 - INFO :       
==================Finish================

2024-04-23 19:35:10 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:35:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:35:10 - INFO :       DATASET: tasksource/bigbench implicatures
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 19:35:18 - INFO :       Use taylor pruner...
2024-04-23 19:35:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:35:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:35:18 - INFO :       Start Pruning
2024-04-23 19:35:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:35:20 - INFO :       Loss = 15.2109375
2024-04-23 19:35:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:35:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:35:23 - INFO :       implicatures: Total Sparsity 1.3585857332939668e-06
2024-04-23 19:36:04 - INFO :       implicatures: Total Accuracy (22, 50, 0.44)
2024-04-23 19:36:05 - INFO :       
==================Finish================

2024-04-23 19:36:05 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:36:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:36:05 - INFO :       DATASET: tasksource/bigbench implicit_relations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:36:12 - INFO :       Use taylor pruner...
2024-04-23 19:36:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:36:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:36:12 - INFO :       Start Pruning
2024-04-23 19:36:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:36:15 - INFO :       Loss = 7.8828125
2024-04-23 19:36:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:36:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:36:17 - INFO :       implicit_relations: Total Sparsity 1.3557215328724054e-06
2024-04-23 19:36:32 - INFO :       implicit_relations: Total Accuracy (5, 17, 0.29411764705882354)
2024-04-23 19:36:32 - INFO :       
==================Finish================

2024-04-23 19:36:32 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:36:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:36:32 - INFO :       DATASET: tasksource/bigbench indic_cause_and_effect
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:36:39 - INFO :       Use taylor pruner...
2024-04-23 19:36:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:36:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:36:40 - INFO :       Start Pruning
2024-04-23 19:36:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:36:42 - INFO :       Loss = 9.109375
2024-04-23 19:36:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:36:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:36:45 - INFO :       indic_cause_and_effect: Total Sparsity 1.3549259216441938e-06
2024-04-23 19:37:26 - INFO :       indic_cause_and_effect: Total Accuracy (13, 50, 0.26)
2024-04-23 19:37:27 - INFO :       
==================Finish================

2024-04-23 19:37:27 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:37:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:37:27 - INFO :       DATASET: tasksource/bigbench intent_recognition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 19:37:34 - INFO :       Use taylor pruner...
2024-04-23 19:37:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:37:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:37:34 - INFO :       Start Pruning
2024-04-23 19:37:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:37:36 - INFO :       Loss = 11.6484375
2024-04-23 19:37:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:37:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:37:39 - INFO :       intent_recognition: Total Sparsity 1.358267488802682e-06
2024-04-23 19:38:19 - INFO :       intent_recognition: Total Accuracy (34, 50, 0.68)
2024-04-23 19:38:19 - INFO :       
==================Finish================

2024-04-23 19:38:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:38:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:38:19 - INFO :       DATASET: tasksource/bigbench international_phonetic_alphabet_nli
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 19:38:27 - INFO :       Use taylor pruner...
2024-04-23 19:38:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:38:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:38:27 - INFO :       Start Pruning
2024-04-23 19:38:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:38:29 - INFO :       Loss = 9.515625
2024-04-23 19:38:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:38:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:38:32 - INFO :       international_phonetic_alphabet_nli: Total Sparsity 1.3577901220657553e-06
2024-04-23 19:38:53 - INFO :       international_phonetic_alphabet_nli: Total Accuracy (11, 25, 0.44)
2024-04-23 19:38:53 - INFO :       
==================Finish================

2024-04-23 19:38:53 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:38:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:38:53 - INFO :       DATASET: tasksource/bigbench intersect_geometry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:39:00 - INFO :       Use taylor pruner...
2024-04-23 19:39:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:39:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:39:01 - INFO :       Start Pruning
2024-04-23 19:39:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:39:03 - INFO :       Loss = 3.412109375
2024-04-23 19:39:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:39:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:39:06 - INFO :       intersect_geometry: Total Sparsity 1.3633594006632357e-06
2024-04-23 19:39:50 - INFO :       intersect_geometry: Total Accuracy (11, 50, 0.22)
2024-04-23 19:39:50 - INFO :       
==================Finish================

2024-04-23 19:39:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:39:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:39:50 - INFO :       DATASET: tasksource/bigbench irony_identification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 19:39:57 - INFO :       Use taylor pruner...
2024-04-23 19:39:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:39:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:39:58 - INFO :       Start Pruning
2024-04-23 19:39:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:40:00 - INFO :       Loss = 14.3984375
2024-04-23 19:40:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:40:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:40:03 - INFO :       irony_identification: Total Sparsity 1.3566762663462592e-06
2024-04-23 19:40:18 - INFO :       irony_identification: Total Accuracy (8, 19, 0.42105263157894735)
2024-04-23 19:40:18 - INFO :       
==================Finish================

2024-04-23 19:40:18 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:40:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:40:18 - INFO :       DATASET: tasksource/bigbench kannada
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:40:26 - INFO :       Use taylor pruner...
2024-04-23 19:40:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:40:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:40:26 - INFO :       Start Pruning
2024-04-23 19:40:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:40:29 - INFO :       Loss = 5.18359375
2024-04-23 19:40:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:40:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:40:32 - INFO :       kannada: Total Sparsity 1.3593813445221782e-06
2024-04-23 19:41:18 - INFO :       kannada: Total Accuracy (8, 50, 0.16)
2024-04-23 19:41:19 - INFO :       
==================Finish================

2024-04-23 19:41:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:41:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:41:19 - INFO :       DATASET: tasksource/bigbench key_value_maps
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 19:41:26 - INFO :       Use taylor pruner...
2024-04-23 19:41:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:41:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:41:27 - INFO :       Start Pruning
2024-04-23 19:41:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:41:29 - INFO :       Loss = 8.734375
2024-04-23 19:41:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:41:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:41:32 - INFO :       key_value_maps: Total Sparsity 1.355562410626763e-06
2024-04-23 19:41:49 - INFO :       key_value_maps: Total Accuracy (11, 21, 0.5238095238095238)
2024-04-23 19:41:50 - INFO :       
==================Finish================

2024-04-23 19:41:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:41:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:41:50 - INFO :       DATASET: tasksource/bigbench known_unknowns
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:41:57 - INFO :       Use taylor pruner...
2024-04-23 19:41:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:41:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:41:58 - INFO :       Start Pruning
2024-04-23 19:41:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:42:00 - INFO :       Loss = 15.1796875
2024-04-23 19:42:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:42:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:42:03 - INFO :       known_unknowns: Total Sparsity 1.3573127553288283e-06
2024-04-23 19:42:15 - INFO :       known_unknowns: Total Accuracy (9, 16, 0.5625)
2024-04-23 19:42:15 - INFO :       
==================Finish================

2024-04-23 19:42:15 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:42:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:42:15 - INFO :       DATASET: tasksource/bigbench language_identification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 19:42:23 - INFO :       Use taylor pruner...
2024-04-23 19:42:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:42:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:42:23 - INFO :       Start Pruning
2024-04-23 19:42:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:42:25 - INFO :       Loss = 8.171875
2024-04-23 19:42:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:42:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:42:28 - INFO :       language_identification: Total Sparsity 1.3611316892242436e-06
2024-04-23 19:43:10 - INFO :       language_identification: Total Accuracy (3, 50, 0.06)
2024-04-23 19:43:11 - INFO :       
==================Finish================

2024-04-23 19:43:11 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:43:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:43:11 - INFO :       DATASET: tasksource/bigbench logic_grid_puzzle
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 19:43:18 - INFO :       Use taylor pruner...
2024-04-23 19:43:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:43:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:43:18 - INFO :       Start Pruning
2024-04-23 19:43:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:43:20 - INFO :       Loss = 7.01171875
2024-04-23 19:43:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:43:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:43:23 - INFO :       logic_grid_puzzle: Total Sparsity 1.3622455449437396e-06
2024-04-23 19:44:07 - INFO :       logic_grid_puzzle: Total Accuracy (14, 50, 0.28)
2024-04-23 19:44:07 - INFO :       
==================Finish================

2024-04-23 19:44:07 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:44:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:44:07 - INFO :       DATASET: tasksource/bigbench logical_args
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:44:15 - INFO :       Use taylor pruner...
2024-04-23 19:44:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:44:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:44:15 - INFO :       Start Pruning
2024-04-23 19:44:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:44:17 - INFO :       Loss = 8.7578125
2024-04-23 19:44:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:44:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:44:20 - INFO :       logical_args: Total Sparsity 1.3620864226980974e-06
2024-04-23 19:44:34 - INFO :       logical_args: Total Accuracy (2, 16, 0.125)
2024-04-23 19:44:34 - INFO :       
==================Finish================

2024-04-23 19:44:34 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:44:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:44:34 - INFO :       DATASET: tasksource/bigbench logical_deduction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:44:41 - INFO :       Use taylor pruner...
2024-04-23 19:44:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:44:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:44:42 - INFO :       Start Pruning
2024-04-23 19:44:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:44:44 - INFO :       Loss = 12.7890625
2024-04-23 19:44:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:44:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:44:46 - INFO :       logical_deduction: Total Sparsity 1.359699589013463e-06
2024-04-23 19:45:27 - INFO :       logical_deduction: Total Accuracy (13, 50, 0.26)
2024-04-23 19:45:27 - INFO :       
==================Finish================

2024-04-23 19:45:27 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:45:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:45:27 - INFO :       DATASET: tasksource/bigbench logical_fallacy_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 19:45:34 - INFO :       Use taylor pruner...
2024-04-23 19:45:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:45:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:45:35 - INFO :       Start Pruning
2024-04-23 19:45:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:45:37 - INFO :       Loss = 14.703125
2024-04-23 19:45:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:45:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:45:40 - INFO :       logical_fallacy_detection: Total Sparsity 1.359699589013463e-06
2024-04-23 19:46:21 - INFO :       logical_fallacy_detection: Total Accuracy (22, 50, 0.44)
2024-04-23 19:46:22 - INFO :       
==================Finish================

2024-04-23 19:46:22 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:46:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:46:22 - INFO :       DATASET: tasksource/bigbench logical_sequence
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 19:46:29 - INFO :       Use taylor pruner...
2024-04-23 19:46:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:46:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:46:29 - INFO :       Start Pruning
2024-04-23 19:46:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:46:31 - INFO :       Loss = 12.515625
2024-04-23 19:46:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:46:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:46:34 - INFO :       logical_sequence: Total Sparsity 1.3552441661354783e-06
2024-04-23 19:46:47 - INFO :       logical_sequence: Total Accuracy (2, 16, 0.125)
2024-04-23 19:46:47 - INFO :       
==================Finish================

2024-04-23 19:46:47 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:46:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:46:47 - INFO :       DATASET: tasksource/bigbench mathematical_induction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:46:54 - INFO :       Use taylor pruner...
2024-04-23 19:46:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:46:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:46:55 - INFO :       Start Pruning
2024-04-23 19:46:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:46:57 - INFO :       Loss = 15.0
2024-04-23 19:46:58 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:46:58 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:47:00 - INFO :       mathematical_induction: Total Sparsity 1.3534938214334132e-06
2024-04-23 19:47:13 - INFO :       mathematical_induction: Total Accuracy (10, 16, 0.625)
2024-04-23 19:47:13 - INFO :       
==================Finish================

2024-04-23 19:47:13 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:47:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:47:13 - INFO :       DATASET: tasksource/bigbench medical_questions_russian
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 19:47:20 - INFO :       Use taylor pruner...
2024-04-23 19:47:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:47:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:47:21 - INFO :       Start Pruning
2024-04-23 19:47:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:47:23 - INFO :       Loss = 7.21484375
2024-04-23 19:47:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:47:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:47:26 - INFO :       medical_questions_russian: Total Sparsity 1.3566762663462592e-06
2024-04-23 19:48:07 - INFO :       medical_questions_russian: Total Accuracy (31, 50, 0.62)
2024-04-23 19:48:07 - INFO :       
==================Finish================

2024-04-23 19:48:07 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:48:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:48:07 - INFO :       DATASET: tasksource/bigbench metaphor_boolean
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 19:48:15 - INFO :       Use taylor pruner...
2024-04-23 19:48:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:48:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:48:15 - INFO :       Start Pruning
2024-04-23 19:48:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:48:17 - INFO :       Loss = 14.359375
2024-04-23 19:48:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:48:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:48:20 - INFO :       metaphor_boolean: Total Sparsity 1.3584266110483244e-06
2024-04-23 19:49:00 - INFO :       metaphor_boolean: Total Accuracy (17, 50, 0.34)
2024-04-23 19:49:00 - INFO :       
==================Finish================

2024-04-23 19:49:00 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:49:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:49:00 - INFO :       DATASET: tasksource/bigbench metaphor_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:49:07 - INFO :       Use taylor pruner...
2024-04-23 19:49:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:49:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:49:08 - INFO :       Start Pruning
2024-04-23 19:49:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:49:10 - INFO :       Loss = 11.8671875
2024-04-23 19:49:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:49:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:49:12 - INFO :       metaphor_understanding: Total Sparsity 1.357630999820113e-06
2024-04-23 19:49:50 - INFO :       metaphor_understanding: Total Accuracy (3, 46, 0.06521739130434782)
2024-04-23 19:49:50 - INFO :       
==================Finish================

2024-04-23 19:49:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:49:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:49:50 - INFO :       DATASET: tasksource/bigbench misconceptions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:49:57 - INFO :       Use taylor pruner...
2024-04-23 19:49:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:49:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:49:58 - INFO :       Start Pruning
2024-04-23 19:49:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:50:00 - INFO :       Loss = 15.2421875
2024-04-23 19:50:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:50:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:50:03 - INFO :       misconceptions: Total Sparsity 1.3552441661354783e-06
2024-04-23 19:50:36 - INFO :       misconceptions: Total Accuracy (16, 43, 0.37209302325581395)
2024-04-23 19:50:36 - INFO :       
==================Finish================

2024-04-23 19:50:36 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:50:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:50:36 - INFO :       DATASET: tasksource/bigbench mnist_ascii
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 19:50:43 - INFO :       Use taylor pruner...
2024-04-23 19:50:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:50:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:50:44 - INFO :       Start Pruning
2024-04-23 19:50:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:50:46 - INFO :       Loss = 5.7734375
2024-04-23 19:50:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:50:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:50:49 - INFO :       mnist_ascii: Total Sparsity 1.3569945108375437e-06
2024-04-23 19:52:01 - INFO :       mnist_ascii: Total Accuracy (3, 50, 0.06)
2024-04-23 19:52:02 - INFO :       
==================Finish================

2024-04-23 19:52:02 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:52:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:52:02 - INFO :       DATASET: tasksource/bigbench moral_permissibility
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 19:52:09 - INFO :       Use taylor pruner...
2024-04-23 19:52:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:52:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:52:10 - INFO :       Start Pruning
2024-04-23 19:52:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:52:12 - INFO :       Loss = 13.71875
2024-04-23 19:52:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:52:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:52:15 - INFO :       moral_permissibility: Total Sparsity 1.3593813445221782e-06
2024-04-23 19:52:55 - INFO :       moral_permissibility: Total Accuracy (24, 50, 0.48)
2024-04-23 19:52:55 - INFO :       
==================Finish================

2024-04-23 19:52:55 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:52:55 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:52:55 - INFO :       DATASET: tasksource/bigbench movie_dialog_same_or_different
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 19:53:02 - INFO :       Use taylor pruner...
2024-04-23 19:53:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:53:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:53:02 - INFO :       Start Pruning
2024-04-23 19:53:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:53:04 - INFO :       Loss = 12.453125
2024-04-23 19:53:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:53:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:53:07 - INFO :       movie_dialog_same_or_different: Total Sparsity 1.358267488802682e-06
2024-04-23 19:53:47 - INFO :       movie_dialog_same_or_different: Total Accuracy (27, 50, 0.54)
2024-04-23 19:53:48 - INFO :       
==================Finish================

2024-04-23 19:53:48 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:53:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:53:48 - INFO :       DATASET: tasksource/bigbench movie_recommendation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 19:53:55 - INFO :       Use taylor pruner...
2024-04-23 19:53:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:53:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:53:55 - INFO :       Start Pruning
2024-04-23 19:53:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:53:58 - INFO :       Loss = 13.8671875
2024-04-23 19:53:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:53:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:54:00 - INFO :       movie_recommendation: Total Sparsity 1.3585857332939668e-06
2024-04-23 19:54:40 - INFO :       movie_recommendation: Total Accuracy (18, 50, 0.36)
2024-04-23 19:54:40 - INFO :       
==================Finish================

2024-04-23 19:54:40 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:54:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:54:40 - INFO :       DATASET: tasksource/bigbench navigate
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 19:54:48 - INFO :       Use taylor pruner...
2024-04-23 19:54:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:54:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:54:48 - INFO :       Start Pruning
2024-04-23 19:54:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:54:50 - INFO :       Loss = 15.6953125
2024-04-23 19:54:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:54:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:54:53 - INFO :       navigate: Total Sparsity 1.356517144100617e-06
2024-04-23 19:55:32 - INFO :       navigate: Total Accuracy (21, 50, 0.42)
2024-04-23 19:55:33 - INFO :       
==================Finish================

2024-04-23 19:55:33 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:55:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:55:33 - INFO :       DATASET: tasksource/bigbench nonsense_words_grammar
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:55:40 - INFO :       Use taylor pruner...
2024-04-23 19:55:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:55:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:55:40 - INFO :       Start Pruning
2024-04-23 19:55:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:55:42 - INFO :       Loss = 14.8046875
2024-04-23 19:55:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:55:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:55:45 - INFO :       nonsense_words_grammar: Total Sparsity 1.3574718775744707e-06
2024-04-23 19:55:58 - INFO :       nonsense_words_grammar: Total Accuracy (4, 16, 0.25)
2024-04-23 19:55:58 - INFO :       
==================Finish================

2024-04-23 19:55:58 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:55:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:55:58 - INFO :       DATASET: tasksource/bigbench novel_concepts
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 19:56:05 - INFO :       Use taylor pruner...
2024-04-23 19:56:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:56:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:56:06 - INFO :       Start Pruning
2024-04-23 19:56:07 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:56:08 - INFO :       Loss = 12.609375
2024-04-23 19:56:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:56:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:56:11 - INFO :       novel_concepts: Total Sparsity 1.3589039777852514e-06
2024-04-23 19:56:23 - INFO :       novel_concepts: Total Accuracy (5, 16, 0.3125)
2024-04-23 19:56:23 - INFO :       
==================Finish================

2024-04-23 19:56:23 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:56:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:56:23 - INFO :       DATASET: tasksource/bigbench odd_one_out
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 19:56:31 - INFO :       Use taylor pruner...
2024-04-23 19:56:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:56:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:56:31 - INFO :       Start Pruning
2024-04-23 19:56:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:56:33 - INFO :       Loss = 15.34375
2024-04-23 19:56:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:56:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:56:36 - INFO :       odd_one_out: Total Sparsity 1.3585857332939668e-06
2024-04-23 19:56:49 - INFO :       odd_one_out: Total Accuracy (0, 17, 0.0)
2024-04-23 19:56:49 - INFO :       
==================Finish================

2024-04-23 19:56:49 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:56:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:56:49 - INFO :       DATASET: tasksource/bigbench parsinlu_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:56:56 - INFO :       Use taylor pruner...
2024-04-23 19:56:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:56:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:56:57 - INFO :       Start Pruning
2024-04-23 19:56:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:56:59 - INFO :       Loss = 7.8828125
2024-04-23 19:57:00 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:57:00 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:57:02 - INFO :       parsinlu_qa: Total Sparsity 1.358744855539609e-06
2024-04-23 19:57:41 - INFO :       parsinlu_qa: Total Accuracy (12, 50, 0.24)
2024-04-23 19:57:41 - INFO :       
==================Finish================

2024-04-23 19:57:41 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:57:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:57:41 - INFO :       DATASET: tasksource/bigbench penguins_in_a_table
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 19:57:48 - INFO :       Use taylor pruner...
2024-04-23 19:57:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:57:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:57:49 - INFO :       Start Pruning
2024-04-23 19:57:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:57:51 - INFO :       Loss = 10.78125
2024-04-23 19:57:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:57:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:57:53 - INFO :       penguins_in_a_table: Total Sparsity 1.358267488802682e-06
2024-04-23 19:58:17 - INFO :       penguins_in_a_table: Total Accuracy (11, 29, 0.3793103448275862)
2024-04-23 19:58:17 - INFO :       
==================Finish================

2024-04-23 19:58:17 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:58:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:58:17 - INFO :       DATASET: tasksource/bigbench persian_idioms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 19:58:24 - INFO :       Use taylor pruner...
2024-04-23 19:58:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:58:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:58:25 - INFO :       Start Pruning
2024-04-23 19:58:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:58:27 - INFO :       Loss = 8.9375
2024-04-23 19:58:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:58:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:58:30 - INFO :       persian_idioms: Total Sparsity 1.3579492443113975e-06
2024-04-23 19:58:42 - INFO :       persian_idioms: Total Accuracy (1, 16, 0.0625)
2024-04-23 19:58:42 - INFO :       
==================Finish================

2024-04-23 19:58:42 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:58:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:58:42 - INFO :       DATASET: tasksource/bigbench phrase_relatedness
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 19:58:49 - INFO :       Use taylor pruner...
2024-04-23 19:58:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:58:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:58:50 - INFO :       Start Pruning
2024-04-23 19:58:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:58:52 - INFO :       Loss = 13.875
2024-04-23 19:58:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:58:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:58:55 - INFO :       phrase_relatedness: Total Sparsity 1.3609725669786013e-06
2024-04-23 19:59:10 - INFO :       phrase_relatedness: Total Accuracy (9, 20, 0.45)
2024-04-23 19:59:11 - INFO :       
==================Finish================

2024-04-23 19:59:11 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:59:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:59:11 - INFO :       DATASET: tasksource/bigbench physical_intuition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 19:59:18 - INFO :       Use taylor pruner...
2024-04-23 19:59:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:59:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:59:18 - INFO :       Start Pruning
2024-04-23 19:59:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:59:20 - INFO :       Loss = 13.9921875
2024-04-23 19:59:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:59:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:59:23 - INFO :       physical_intuition: Total Sparsity 1.3619273004524551e-06
2024-04-23 19:59:36 - INFO :       physical_intuition: Total Accuracy (9, 16, 0.5625)
2024-04-23 19:59:36 - INFO :       
==================Finish================

2024-04-23 19:59:36 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 19:59:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 19:59:36 - INFO :       DATASET: tasksource/bigbench physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 19:59:43 - INFO :       Use taylor pruner...
2024-04-23 19:59:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:59:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 19:59:44 - INFO :       Start Pruning
2024-04-23 19:59:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 19:59:46 - INFO :       Loss = 10.953125
2024-04-23 19:59:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 19:59:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 19:59:49 - INFO :       physics: Total Sparsity 1.358744855539609e-06
2024-04-23 20:00:25 - INFO :       physics: Total Accuracy (23, 45, 0.5111111111111111)
2024-04-23 20:00:25 - INFO :       
==================Finish================

2024-04-23 20:00:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:00:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:00:25 - INFO :       DATASET: tasksource/bigbench play_dialog_same_or_different
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:00:32 - INFO :       Use taylor pruner...
2024-04-23 20:00:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:00:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:00:33 - INFO :       Start Pruning
2024-04-23 20:00:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:00:35 - INFO :       Loss = 10.0859375
2024-04-23 20:00:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:00:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:00:38 - INFO :       play_dialog_same_or_different: Total Sparsity 1.356517144100617e-06
2024-04-23 20:01:19 - INFO :       play_dialog_same_or_different: Total Accuracy (34, 50, 0.68)
2024-04-23 20:01:19 - INFO :       
==================Finish================

2024-04-23 20:01:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:01:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:01:19 - INFO :       DATASET: tasksource/bigbench presuppositions_as_nli
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:01:26 - INFO :       Use taylor pruner...
2024-04-23 20:01:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:01:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:01:27 - INFO :       Start Pruning
2024-04-23 20:01:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:01:29 - INFO :       Loss = 11.6328125
2024-04-23 20:01:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:01:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:01:32 - INFO :       presuppositions_as_nli: Total Sparsity 1.3593813445221782e-06
2024-04-23 20:02:12 - INFO :       presuppositions_as_nli: Total Accuracy (24, 50, 0.48)
2024-04-23 20:02:12 - INFO :       
==================Finish================

2024-04-23 20:02:12 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:02:12 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:02:12 - INFO :       DATASET: tasksource/bigbench question_selection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:02:19 - INFO :       Use taylor pruner...
2024-04-23 20:02:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:02:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:02:20 - INFO :       Start Pruning
2024-04-23 20:02:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:02:22 - INFO :       Loss = 4.0859375
2024-04-23 20:02:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:02:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:02:25 - INFO :       question_selection: Total Sparsity 1.3573127553288283e-06
2024-04-23 20:03:11 - INFO :       question_selection: Total Accuracy (9, 50, 0.18)
2024-04-23 20:03:12 - INFO :       
==================Finish================

2024-04-23 20:03:12 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:03:12 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:03:12 - INFO :       DATASET: tasksource/bigbench reasoning_about_colored_objects
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:03:19 - INFO :       Use taylor pruner...
2024-04-23 20:03:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:03:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:03:19 - INFO :       Start Pruning
2024-04-23 20:03:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:03:21 - INFO :       Loss = 14.015625
2024-04-23 20:03:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:03:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:03:24 - INFO :       reasoning_about_colored_objects: Total Sparsity 1.3579492443113975e-06
2024-04-23 20:04:05 - INFO :       reasoning_about_colored_objects: Total Accuracy (9, 50, 0.18)
2024-04-23 20:04:05 - INFO :       
==================Finish================

2024-04-23 20:04:05 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:04:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:04:05 - INFO :       DATASET: tasksource/bigbench riddle_sense
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 20:04:12 - INFO :       Use taylor pruner...
2024-04-23 20:04:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:04:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:04:13 - INFO :       Start Pruning
2024-04-23 20:04:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:04:15 - INFO :       Loss = 13.7578125
2024-04-23 20:04:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:04:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:04:18 - INFO :       riddle_sense: Total Sparsity 1.3601769557503897e-06
2024-04-23 20:04:30 - INFO :       riddle_sense: Total Accuracy (3, 16, 0.1875)
2024-04-23 20:04:30 - INFO :       
==================Finish================

2024-04-23 20:04:30 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:04:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:04:30 - INFO :       DATASET: tasksource/bigbench ruin_names
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 20:04:38 - INFO :       Use taylor pruner...
2024-04-23 20:04:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:04:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:04:38 - INFO :       Start Pruning
2024-04-23 20:04:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:04:40 - INFO :       Loss = 13.9296875
2024-04-23 20:04:42 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:04:42 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:04:43 - INFO :       ruin_names: Total Sparsity 1.3585857332939668e-06
2024-04-23 20:05:23 - INFO :       ruin_names: Total Accuracy (10, 50, 0.2)
2024-04-23 20:05:23 - INFO :       
==================Finish================

2024-04-23 20:05:23 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:05:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:05:23 - INFO :       DATASET: tasksource/bigbench salient_translation_error_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 20:05:31 - INFO :       Use taylor pruner...
2024-04-23 20:05:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:05:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:05:31 - INFO :       Start Pruning
2024-04-23 20:05:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:05:33 - INFO :       Loss = 8.1171875
2024-04-23 20:05:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:05:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:05:36 - INFO :       salient_translation_error_detection: Total Sparsity 1.3574718775744707e-06
2024-04-23 20:06:19 - INFO :       salient_translation_error_detection: Total Accuracy (8, 50, 0.16)
2024-04-23 20:06:20 - INFO :       
==================Finish================

2024-04-23 20:06:20 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:06:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:06:20 - INFO :       DATASET: tasksource/bigbench sentence_ambiguity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 20:06:27 - INFO :       Use taylor pruner...
2024-04-23 20:06:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:06:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:06:27 - INFO :       Start Pruning
2024-04-23 20:06:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:06:29 - INFO :       Loss = 16.46875
2024-04-23 20:06:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:06:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:06:32 - INFO :       sentence_ambiguity: Total Sparsity 1.3546076771529093e-06
2024-04-23 20:06:45 - INFO :       sentence_ambiguity: Total Accuracy (9, 16, 0.5625)
2024-04-23 20:06:45 - INFO :       
==================Finish================

2024-04-23 20:06:45 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:06:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:06:45 - INFO :       DATASET: tasksource/bigbench similarities_abstraction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:06:52 - INFO :       Use taylor pruner...
2024-04-23 20:06:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:06:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:06:53 - INFO :       Start Pruning
2024-04-23 20:06:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:06:55 - INFO :       Loss = 13.7890625
2024-04-23 20:06:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:06:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:06:57 - INFO :       similarities_abstraction: Total Sparsity 1.3561988996093322e-06
2024-04-23 20:07:10 - INFO :       similarities_abstraction: Total Accuracy (14, 16, 0.875)
2024-04-23 20:07:10 - INFO :       
==================Finish================

2024-04-23 20:07:10 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:07:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:07:10 - INFO :       DATASET: tasksource/bigbench simple_ethical_questions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 20:07:17 - INFO :       Use taylor pruner...
2024-04-23 20:07:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:07:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:07:18 - INFO :       Start Pruning
2024-04-23 20:07:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:07:20 - INFO :       Loss = 12.2421875
2024-04-23 20:07:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:07:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:07:23 - INFO :       simple_ethical_questions: Total Sparsity 1.3577901220657553e-06
2024-04-23 20:07:41 - INFO :       simple_ethical_questions: Total Accuracy (7, 23, 0.30434782608695654)
2024-04-23 20:07:41 - INFO :       
==================Finish================

2024-04-23 20:07:41 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:07:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:07:41 - INFO :       DATASET: tasksource/bigbench snarks
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 20:07:49 - INFO :       Use taylor pruner...
2024-04-23 20:07:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:07:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:07:49 - INFO :       Start Pruning
2024-04-23 20:07:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:07:51 - INFO :       Loss = 14.875
2024-04-23 20:07:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:07:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:07:54 - INFO :       snarks: Total Sparsity 1.358267488802682e-06
2024-04-23 20:08:23 - INFO :       snarks: Total Accuracy (5, 36, 0.1388888888888889)
2024-04-23 20:08:23 - INFO :       
==================Finish================

2024-04-23 20:08:23 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:08:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:08:23 - INFO :       DATASET: tasksource/bigbench social_iqa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 20:08:30 - INFO :       Use taylor pruner...
2024-04-23 20:08:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:08:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:08:31 - INFO :       Start Pruning
2024-04-23 20:08:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:08:33 - INFO :       Loss = 14.3125
2024-04-23 20:08:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:08:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:08:36 - INFO :       social_iqa: Total Sparsity 1.3601769557503897e-06
2024-04-23 20:09:16 - INFO :       social_iqa: Total Accuracy (21, 50, 0.42)
2024-04-23 20:09:16 - INFO :       
==================Finish================

2024-04-23 20:09:16 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:09:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:09:16 - INFO :       DATASET: tasksource/bigbench social_support
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 20:09:24 - INFO :       Use taylor pruner...
2024-04-23 20:09:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:09:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:09:24 - INFO :       Start Pruning
2024-04-23 20:09:25 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:09:26 - INFO :       Loss = 13.96875
2024-04-23 20:09:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:09:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:09:29 - INFO :       social_support: Total Sparsity 1.3593813445221782e-06
2024-04-23 20:10:09 - INFO :       social_support: Total Accuracy (42, 50, 0.84)
2024-04-23 20:10:10 - INFO :       
==================Finish================

2024-04-23 20:10:10 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:10:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:10:10 - INFO :       DATASET: tasksource/bigbench sports_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:10:17 - INFO :       Use taylor pruner...
2024-04-23 20:10:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:10:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:10:17 - INFO :       Start Pruning
2024-04-23 20:10:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:10:19 - INFO :       Loss = 15.6875
2024-04-23 20:10:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:10:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:10:22 - INFO :       sports_understanding: Total Sparsity 1.3573127553288283e-06
2024-04-23 20:11:01 - INFO :       sports_understanding: Total Accuracy (21, 50, 0.42)
2024-04-23 20:11:01 - INFO :       
==================Finish================

2024-04-23 20:11:01 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:11:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:11:01 - INFO :       DATASET: tasksource/bigbench strange_stories
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 20:11:09 - INFO :       Use taylor pruner...
2024-04-23 20:11:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:11:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:11:09 - INFO :       Start Pruning
2024-04-23 20:11:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:11:11 - INFO :       Loss = 11.765625
2024-04-23 20:11:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:11:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:11:14 - INFO :       strange_stories: Total Sparsity 1.3606543224873167e-06
2024-04-23 20:11:42 - INFO :       strange_stories: Total Accuracy (9, 34, 0.2647058823529412)
2024-04-23 20:11:42 - INFO :       
==================Finish================

2024-04-23 20:11:42 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:11:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:11:42 - INFO :       DATASET: tasksource/bigbench strategyqa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 20:11:49 - INFO :       Use taylor pruner...
2024-04-23 20:11:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:11:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:11:49 - INFO :       Start Pruning
2024-04-23 20:11:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:11:51 - INFO :       Loss = 16.328125
2024-04-23 20:11:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:11:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:11:54 - INFO :       strategyqa: Total Sparsity 1.3581083665570398e-06
2024-04-23 20:12:33 - INFO :       strategyqa: Total Accuracy (15, 50, 0.3)
2024-04-23 20:12:33 - INFO :       
==================Finish================

2024-04-23 20:12:33 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:12:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:12:33 - INFO :       DATASET: tasksource/bigbench suicide_risk
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:12:40 - INFO :       Use taylor pruner...
2024-04-23 20:12:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:12:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:12:41 - INFO :       Start Pruning
2024-04-23 20:12:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:12:43 - INFO :       Loss = 7.5625
2024-04-23 20:12:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:12:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:12:46 - INFO :       suicide_risk: Total Sparsity 1.3577901220657553e-06
2024-04-23 20:12:59 - INFO :       suicide_risk: Total Accuracy (4, 16, 0.25)
2024-04-23 20:12:59 - INFO :       
==================Finish================

2024-04-23 20:12:59 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:12:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:12:59 - INFO :       DATASET: tasksource/bigbench swahili_english_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 20:13:06 - INFO :       Use taylor pruner...
2024-04-23 20:13:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:13:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:13:07 - INFO :       Start Pruning
2024-04-23 20:13:08 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:13:09 - INFO :       Loss = 12.1328125
2024-04-23 20:13:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:13:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:13:12 - INFO :       swahili_english_proverbs: Total Sparsity 1.355562410626763e-06
2024-04-23 20:13:36 - INFO :       swahili_english_proverbs: Total Accuracy (2, 30, 0.06666666666666667)
2024-04-23 20:13:36 - INFO :       
==================Finish================

2024-04-23 20:13:36 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:13:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:13:36 - INFO :       DATASET: tasksource/bigbench swedish_to_german_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 20:13:44 - INFO :       Use taylor pruner...
2024-04-23 20:13:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:13:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:13:44 - INFO :       Start Pruning
2024-04-23 20:13:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:13:46 - INFO :       Loss = 11.6484375
2024-04-23 20:13:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:13:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:13:49 - INFO :       swedish_to_german_proverbs: Total Sparsity 1.359699589013463e-06
2024-04-23 20:14:02 - INFO :       swedish_to_german_proverbs: Total Accuracy (6, 16, 0.375)
2024-04-23 20:14:02 - INFO :       
==================Finish================

2024-04-23 20:14:02 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:14:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:14:02 - INFO :       DATASET: tasksource/bigbench symbol_interpretation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 20:14:09 - INFO :       Use taylor pruner...
2024-04-23 20:14:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:14:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:14:09 - INFO :       Start Pruning
2024-04-23 20:14:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:14:11 - INFO :       Loss = 4.5859375
2024-04-23 20:14:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:14:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:14:14 - INFO :       symbol_interpretation: Total Sparsity 1.3657462343478702e-06
2024-04-23 20:15:14 - INFO :       symbol_interpretation: Total Accuracy (11, 50, 0.22)
2024-04-23 20:15:15 - INFO :       
==================Finish================

2024-04-23 20:15:15 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:15:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:15:15 - INFO :       DATASET: tasksource/bigbench temporal_sequences
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:15:22 - INFO :       Use taylor pruner...
2024-04-23 20:15:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:15:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:15:23 - INFO :       Start Pruning
2024-04-23 20:15:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:15:25 - INFO :       Loss = 9.5234375
2024-04-23 20:15:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:15:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:15:28 - INFO :       temporal_sequences: Total Sparsity 1.360813444732959e-06
2024-04-23 20:16:09 - INFO :       temporal_sequences: Total Accuracy (2, 50, 0.04)
2024-04-23 20:16:09 - INFO :       
==================Finish================

2024-04-23 20:16:09 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:16:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:16:09 - INFO :       DATASET: tasksource/bigbench timedial
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 20:16:17 - INFO :       Use taylor pruner...
2024-04-23 20:16:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:16:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:16:17 - INFO :       Start Pruning
2024-04-23 20:16:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:16:19 - INFO :       Loss = 5.57421875
2024-04-23 20:16:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:16:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:16:22 - INFO :       timedial: Total Sparsity 1.3577901220657553e-06
2024-04-23 20:17:05 - INFO :       timedial: Total Accuracy (0, 50, 0.0)
2024-04-23 20:17:06 - INFO :       
==================Finish================

2024-04-23 20:17:06 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:17:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:17:06 - INFO :       DATASET: tasksource/bigbench tracking_shuffled_objects
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 20:17:13 - INFO :       Use taylor pruner...
2024-04-23 20:17:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:17:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:17:14 - INFO :       Start Pruning
2024-04-23 20:17:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:17:16 - INFO :       Loss = 9.546875
2024-04-23 20:17:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:17:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:17:19 - INFO :       tracking_shuffled_objects: Total Sparsity 1.3589039777852514e-06
2024-04-23 20:18:00 - INFO :       tracking_shuffled_objects: Total Accuracy (10, 50, 0.2)
2024-04-23 20:18:00 - INFO :       
==================Finish================

2024-04-23 20:18:00 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:18:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:18:00 - INFO :       DATASET: tasksource/bigbench understanding_fables
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 20:18:07 - INFO :       Use taylor pruner...
2024-04-23 20:18:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:18:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:18:08 - INFO :       Start Pruning
2024-04-23 20:18:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:18:10 - INFO :       Loss = 7.36328125
2024-04-23 20:18:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:18:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:18:13 - INFO :       understanding_fables: Total Sparsity 1.357153633083186e-06
2024-04-23 20:18:45 - INFO :       understanding_fables: Total Accuracy (5, 37, 0.13513513513513514)
2024-04-23 20:18:45 - INFO :       
==================Finish================

2024-04-23 20:18:45 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:18:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:18:45 - INFO :       DATASET: tasksource/bigbench undo_permutation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 20:18:52 - INFO :       Use taylor pruner...
2024-04-23 20:18:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:18:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:18:53 - INFO :       Start Pruning
2024-04-23 20:18:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:18:55 - INFO :       Loss = 1.173828125
2024-04-23 20:18:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:18:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:18:58 - INFO :       undo_permutation: Total Sparsity 1.355562410626763e-06
2024-04-23 20:19:40 - INFO :       undo_permutation: Total Accuracy (27, 50, 0.54)
2024-04-23 20:19:40 - INFO :       
==================Finish================

2024-04-23 20:19:40 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:19:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:19:40 - INFO :       DATASET: tasksource/bigbench unit_interpretation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:19:47 - INFO :       Use taylor pruner...
2024-04-23 20:19:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:19:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:19:48 - INFO :       Start Pruning
2024-04-23 20:19:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:19:50 - INFO :       Loss = 12.1484375
2024-04-23 20:19:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:19:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:19:53 - INFO :       unit_interpretation: Total Sparsity 1.3584266110483244e-06
2024-04-23 20:20:09 - INFO :       unit_interpretation: Total Accuracy (5, 20, 0.25)
2024-04-23 20:20:09 - INFO :       
==================Finish================

2024-04-23 20:20:09 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:20:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:20:09 - INFO :       DATASET: tasksource/bigbench vitaminc_fact_verification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2024-04-23 20:20:16 - INFO :       Use taylor pruner...
2024-04-23 20:20:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:20:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:20:16 - INFO :       Start Pruning
2024-04-23 20:20:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:20:18 - INFO :       Loss = 12.984375
2024-04-23 20:20:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:20:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:20:21 - INFO :       vitaminc_fact_verification: Total Sparsity 1.3601769557503897e-06
2024-04-23 20:21:01 - INFO :       vitaminc_fact_verification: Total Accuracy (21, 50, 0.42)
2024-04-23 20:21:01 - INFO :       
==================Finish================

2024-04-23 20:21:01 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:21:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:21:01 - INFO :       DATASET: tasksource/bigbench what_is_the_tao
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2024-04-23 20:21:09 - INFO :       Use taylor pruner...
2024-04-23 20:21:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:21:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:21:09 - INFO :       Start Pruning
2024-04-23 20:21:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:21:11 - INFO :       Loss = 13.4296875
2024-04-23 20:21:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:21:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:21:14 - INFO :       what_is_the_tao: Total Sparsity 1.3606543224873167e-06
2024-04-23 20:21:27 - INFO :       what_is_the_tao: Total Accuracy (4, 16, 0.25)
2024-04-23 20:21:27 - INFO :       
==================Finish================

2024-04-23 20:21:27 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 20:21:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:21:27 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 20:21:34 - INFO :       Use taylor pruner...
2024-04-23 20:21:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:21:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:21:35 - INFO :       Start Pruning
2024-04-23 20:21:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:21:37 - INFO :       Loss = 2.06640625
2024-04-23 20:21:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:21:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:21:40 - INFO :       which_wiki_edit: Total Sparsity 1.3563580218549744e-06
2024-04-23 20:23:14 - INFO :       which_wiki_edit: Total Accuracy (28, 50, 0.56)
2024-04-23 20:23:15 - INFO :       
==================Finish================

2024-04-23 20:23:15 - INFO :       Memory Requirement: 16809.46826171875 MiB

2024-04-23 20:23:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:23:15 - INFO :       DATASET: tasksource/bigbench winowhy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:23:22 - INFO :       Use taylor pruner...
2024-04-23 20:23:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:23:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:23:23 - INFO :       Start Pruning
2024-04-23 20:23:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:23:25 - INFO :       Loss = 14.6171875
2024-04-23 20:23:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:23:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:23:28 - INFO :       winowhy: Total Sparsity 1.358267488802682e-06
2024-04-23 20:24:08 - INFO :       winowhy: Total Accuracy (31, 50, 0.62)
2024-04-23 20:24:09 - INFO :       
==================Finish================

2024-04-23 20:24:09 - INFO :       Memory Requirement: 16777.79052734375 MiB

2024-04-23 20:24:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:24:09 - INFO :       DATASET: tasksource/mmlu abstract_algebra
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 20:24:16 - INFO :       Use taylor pruner...
2024-04-23 20:24:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:24:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:24:16 - INFO :       Start Pruning
2024-04-23 20:24:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:24:18 - INFO :       Loss = 14.53125
2024-04-23 20:24:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:24:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:24:21 - INFO :       abstract_algebra: Total Sparsity 1.3579492443113975e-06
2024-04-23 20:24:30 - INFO :       abstract_algebra: Total Accuracy (4, 11, 0.36363636363636365)
2024-04-23 20:24:30 - INFO :       
==================Finish================

2024-04-23 20:24:30 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:24:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:24:30 - INFO :       DATASET: tasksource/mmlu anatomy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 20:24:37 - INFO :       Use taylor pruner...
2024-04-23 20:24:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:24:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:24:38 - INFO :       Start Pruning
2024-04-23 20:24:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:24:40 - INFO :       Loss = 13.5546875
2024-04-23 20:24:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:24:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:24:43 - INFO :       anatomy: Total Sparsity 1.3581083665570398e-06
2024-04-23 20:24:54 - INFO :       anatomy: Total Accuracy (9, 14, 0.6428571428571429)
2024-04-23 20:24:54 - INFO :       
==================Finish================

2024-04-23 20:24:54 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:24:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:24:54 - INFO :       DATASET: tasksource/mmlu astronomy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 20:25:01 - INFO :       Use taylor pruner...
2024-04-23 20:25:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:25:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:25:02 - INFO :       Start Pruning
2024-04-23 20:25:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:25:04 - INFO :       Loss = 13.734375
2024-04-23 20:25:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:25:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:25:06 - INFO :       astronomy: Total Sparsity 1.3577901220657553e-06
2024-04-23 20:25:19 - INFO :       astronomy: Total Accuracy (3, 16, 0.1875)
2024-04-23 20:25:19 - INFO :       
==================Finish================

2024-04-23 20:25:19 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:25:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:25:19 - INFO :       DATASET: tasksource/mmlu business_ethics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 20:25:27 - INFO :       Use taylor pruner...
2024-04-23 20:25:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:25:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:25:27 - INFO :       Start Pruning
2024-04-23 20:25:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:25:29 - INFO :       Loss = 14.203125
2024-04-23 20:25:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:25:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:25:32 - INFO :       business_ethics: Total Sparsity 1.359222222276536e-06
2024-04-23 20:25:41 - INFO :       business_ethics: Total Accuracy (6, 11, 0.5454545454545454)
2024-04-23 20:25:41 - INFO :       
==================Finish================

2024-04-23 20:25:41 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:25:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:25:41 - INFO :       DATASET: tasksource/mmlu clinical_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 20:25:48 - INFO :       Use taylor pruner...
2024-04-23 20:25:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:25:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:25:48 - INFO :       Start Pruning
2024-04-23 20:25:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:25:50 - INFO :       Loss = 14.9609375
2024-04-23 20:25:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:25:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:25:53 - INFO :       clinical_knowledge: Total Sparsity 1.3581083665570398e-06
2024-04-23 20:26:16 - INFO :       clinical_knowledge: Total Accuracy (14, 29, 0.4827586206896552)
2024-04-23 20:26:16 - INFO :       
==================Finish================

2024-04-23 20:26:16 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:26:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:26:16 - INFO :       DATASET: tasksource/mmlu college_biology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:26:23 - INFO :       Use taylor pruner...
2024-04-23 20:26:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:26:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:26:24 - INFO :       Start Pruning
2024-04-23 20:26:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:26:25 - INFO :       Loss = 14.1171875
2024-04-23 20:26:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:26:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:26:28 - INFO :       college_biology: Total Sparsity 1.3568353885919015e-06
2024-04-23 20:26:41 - INFO :       college_biology: Total Accuracy (7, 16, 0.4375)
2024-04-23 20:26:41 - INFO :       
==================Finish================

2024-04-23 20:26:41 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:26:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:26:41 - INFO :       DATASET: tasksource/mmlu college_chemistry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:26:49 - INFO :       Use taylor pruner...
2024-04-23 20:26:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:26:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:26:49 - INFO :       Start Pruning
num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-23 20:26:50 - WARNING :       num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-23 20:26:50 - WARNING :       num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-23 20:26:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:26:51 - INFO :       Loss = 13.015625
2024-04-23 20:26:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:26:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:26:54 - INFO :       college_chemistry: Total Sparsity 1.3604952002416743e-06
2024-04-23 20:27:00 - INFO :       college_chemistry: Total Accuracy (1, 8, 0.125)
2024-04-23 20:27:00 - INFO :       
==================Finish================

2024-04-23 20:27:00 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:27:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:27:00 - INFO :       DATASET: tasksource/mmlu college_computer_science
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2024-04-23 20:27:07 - INFO :       Use taylor pruner...
2024-04-23 20:27:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:27:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:27:08 - INFO :       Start Pruning
2024-04-23 20:27:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:27:10 - INFO :       Loss = 13.9609375
2024-04-23 20:27:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:27:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:27:12 - INFO :       college_computer_science: Total Sparsity 1.3568353885919015e-06
2024-04-23 20:27:21 - INFO :       college_computer_science: Total Accuracy (1, 11, 0.09090909090909091)
2024-04-23 20:27:21 - INFO :       
==================Finish================

2024-04-23 20:27:21 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:27:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:27:21 - INFO :       DATASET: tasksource/mmlu college_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:27:29 - INFO :       Use taylor pruner...
2024-04-23 20:27:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:27:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:27:29 - INFO :       Start Pruning
2024-04-23 20:27:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:27:31 - INFO :       Loss = 15.453125
2024-04-23 20:27:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:27:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:27:34 - INFO :       college_mathematics: Total Sparsity 1.3598587112591052e-06
2024-04-23 20:27:43 - INFO :       college_mathematics: Total Accuracy (4, 11, 0.36363636363636365)
2024-04-23 20:27:43 - INFO :       
==================Finish================

2024-04-23 20:27:43 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:27:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:27:43 - INFO :       DATASET: tasksource/mmlu college_medicine
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:27:50 - INFO :       Use taylor pruner...
2024-04-23 20:27:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:27:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:27:50 - INFO :       Start Pruning
2024-04-23 20:27:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:27:52 - INFO :       Loss = 14.390625
2024-04-23 20:27:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:27:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:27:55 - INFO :       college_medicine: Total Sparsity 1.3606543224873167e-06
2024-04-23 20:28:13 - INFO :       college_medicine: Total Accuracy (10, 22, 0.45454545454545453)
2024-04-23 20:28:13 - INFO :       
==================Finish================

2024-04-23 20:28:13 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:28:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:28:13 - INFO :       DATASET: tasksource/mmlu college_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 20:28:20 - INFO :       Use taylor pruner...
2024-04-23 20:28:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:28:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:28:21 - INFO :       Start Pruning
2024-04-23 20:28:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:28:23 - INFO :       Loss = 13.234375
2024-04-23 20:28:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:28:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:28:25 - INFO :       college_physics: Total Sparsity 1.3577901220657553e-06
2024-04-23 20:28:35 - INFO :       college_physics: Total Accuracy (2, 11, 0.18181818181818182)
2024-04-23 20:28:35 - INFO :       
==================Finish================

2024-04-23 20:28:35 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:28:35 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:28:35 - INFO :       DATASET: tasksource/mmlu computer_security
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 20:28:42 - INFO :       Use taylor pruner...
2024-04-23 20:28:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:28:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:28:42 - INFO :       Start Pruning
2024-04-23 20:28:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:28:44 - INFO :       Loss = 15.0390625
2024-04-23 20:28:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:28:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:28:47 - INFO :       computer_security: Total Sparsity 1.3568353885919015e-06
2024-04-23 20:28:56 - INFO :       computer_security: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-23 20:28:56 - INFO :       
==================Finish================

2024-04-23 20:28:56 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:28:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:28:56 - INFO :       DATASET: tasksource/mmlu conceptual_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:29:03 - INFO :       Use taylor pruner...
2024-04-23 20:29:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:29:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:29:03 - INFO :       Start Pruning
2024-04-23 20:29:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:29:05 - INFO :       Loss = 15.28125
2024-04-23 20:29:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:29:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:29:08 - INFO :       conceptual_physics: Total Sparsity 1.3557215328724054e-06
2024-04-23 20:29:29 - INFO :       conceptual_physics: Total Accuracy (9, 26, 0.34615384615384615)
2024-04-23 20:29:29 - INFO :       
==================Finish================

2024-04-23 20:29:29 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:29:29 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:29:29 - INFO :       DATASET: tasksource/mmlu econometrics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:29:36 - INFO :       Use taylor pruner...
2024-04-23 20:29:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:29:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:29:36 - INFO :       Start Pruning
2024-04-23 20:29:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:29:38 - INFO :       Loss = 13.9375
2024-04-23 20:29:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:29:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:29:41 - INFO :       econometrics: Total Sparsity 1.3584266110483244e-06
2024-04-23 20:29:51 - INFO :       econometrics: Total Accuracy (3, 12, 0.25)
2024-04-23 20:29:51 - INFO :       
==================Finish================

2024-04-23 20:29:51 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:29:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:29:51 - INFO :       DATASET: tasksource/mmlu electrical_engineering
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2024-04-23 20:29:58 - INFO :       Use taylor pruner...
2024-04-23 20:29:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:29:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:29:58 - INFO :       Start Pruning
2024-04-23 20:29:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:30:00 - INFO :       Loss = 15.515625
2024-04-23 20:30:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:30:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:30:03 - INFO :       electrical_engineering: Total Sparsity 1.357630999820113e-06
2024-04-23 20:30:16 - INFO :       electrical_engineering: Total Accuracy (4, 16, 0.25)
2024-04-23 20:30:16 - INFO :       
==================Finish================

2024-04-23 20:30:16 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:30:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:30:16 - INFO :       DATASET: tasksource/mmlu elementary_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:30:23 - INFO :       Use taylor pruner...
2024-04-23 20:30:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:30:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:30:24 - INFO :       Start Pruning
2024-04-23 20:30:25 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:30:26 - INFO :       Loss = 13.984375
2024-04-23 20:30:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:30:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:30:28 - INFO :       elementary_mathematics: Total Sparsity 1.3577901220657553e-06
2024-04-23 20:31:02 - INFO :       elementary_mathematics: Total Accuracy (11, 41, 0.2682926829268293)
2024-04-23 20:31:02 - INFO :       
==================Finish================

2024-04-23 20:31:02 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:31:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:31:02 - INFO :       DATASET: tasksource/mmlu formal_logic
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 20:31:09 - INFO :       Use taylor pruner...
2024-04-23 20:31:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:31:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:31:09 - INFO :       Start Pruning
2024-04-23 20:31:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:31:11 - INFO :       Loss = 12.5859375
2024-04-23 20:31:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:31:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:31:14 - INFO :       formal_logic: Total Sparsity 1.356517144100617e-06
2024-04-23 20:31:26 - INFO :       formal_logic: Total Accuracy (3, 14, 0.21428571428571427)
2024-04-23 20:31:26 - INFO :       
==================Finish================

2024-04-23 20:31:26 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:31:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:31:26 - INFO :       DATASET: tasksource/mmlu global_facts
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 20:31:33 - INFO :       Use taylor pruner...
2024-04-23 20:31:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:31:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:31:33 - INFO :       Start Pruning
2024-04-23 20:31:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:31:35 - INFO :       Loss = 14.8046875
2024-04-23 20:31:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:31:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:31:38 - INFO :       global_facts: Total Sparsity 1.359222222276536e-06
2024-04-23 20:31:46 - INFO :       global_facts: Total Accuracy (5, 10, 0.5)
2024-04-23 20:31:46 - INFO :       
==================Finish================

2024-04-23 20:31:46 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:31:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:31:46 - INFO :       DATASET: tasksource/mmlu high_school_biology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 20:31:53 - INFO :       Use taylor pruner...
2024-04-23 20:31:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:31:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:31:54 - INFO :       Start Pruning
2024-04-23 20:31:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:31:55 - INFO :       Loss = 14.453125
2024-04-23 20:31:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:31:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:31:58 - INFO :       high_school_biology: Total Sparsity 1.3558806551180476e-06
2024-04-23 20:32:24 - INFO :       high_school_biology: Total Accuracy (13, 32, 0.40625)
2024-04-23 20:32:24 - INFO :       
==================Finish================

2024-04-23 20:32:24 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:32:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:32:24 - INFO :       DATASET: tasksource/mmlu high_school_chemistry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 20:32:32 - INFO :       Use taylor pruner...
2024-04-23 20:32:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:32:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:32:32 - INFO :       Start Pruning
2024-04-23 20:32:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:32:34 - INFO :       Loss = 14.6171875
2024-04-23 20:32:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:32:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:32:37 - INFO :       high_school_chemistry: Total Sparsity 1.357630999820113e-06
2024-04-23 20:32:55 - INFO :       high_school_chemistry: Total Accuracy (7, 22, 0.3181818181818182)
2024-04-23 20:32:55 - INFO :       
==================Finish================

2024-04-23 20:32:55 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:32:55 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:32:55 - INFO :       DATASET: tasksource/mmlu high_school_computer_science
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 20:33:02 - INFO :       Use taylor pruner...
2024-04-23 20:33:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:33:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:33:03 - INFO :       Start Pruning
num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-23 20:33:03 - WARNING :       num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-23 20:33:03 - WARNING :       num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-23 20:33:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:33:04 - INFO :       Loss = 14.7265625
2024-04-23 20:33:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:33:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:33:07 - INFO :       high_school_computer_science: Total Sparsity 1.3590631000308936e-06
2024-04-23 20:33:15 - INFO :       high_school_computer_science: Total Accuracy (6, 9, 0.6666666666666666)
2024-04-23 20:33:15 - INFO :       
==================Finish================

2024-04-23 20:33:15 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:33:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:33:15 - INFO :       DATASET: tasksource/mmlu high_school_european_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 20:33:22 - INFO :       Use taylor pruner...
2024-04-23 20:33:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:33:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:33:22 - INFO :       Start Pruning
2024-04-23 20:33:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:33:24 - INFO :       Loss = 7.93359375
2024-04-23 20:33:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:33:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:33:27 - INFO :       high_school_european_history: Total Sparsity 1.359222222276536e-06
2024-04-23 20:33:43 - INFO :       high_school_european_history: Total Accuracy (10, 18, 0.5555555555555556)
2024-04-23 20:33:43 - INFO :       
==================Finish================

2024-04-23 20:33:43 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:33:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:33:43 - INFO :       DATASET: tasksource/mmlu high_school_geography
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 20:33:51 - INFO :       Use taylor pruner...
2024-04-23 20:33:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:33:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:33:51 - INFO :       Start Pruning
2024-04-23 20:33:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:33:53 - INFO :       Loss = 14.484375
2024-04-23 20:33:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:33:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:33:56 - INFO :       high_school_geography: Total Sparsity 1.358744855539609e-06
2024-04-23 20:34:13 - INFO :       high_school_geography: Total Accuracy (15, 22, 0.6818181818181818)
2024-04-23 20:34:13 - INFO :       
==================Finish================

2024-04-23 20:34:13 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:34:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:34:13 - INFO :       DATASET: tasksource/mmlu high_school_government_and_politics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 20:34:21 - INFO :       Use taylor pruner...
2024-04-23 20:34:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:34:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:34:21 - INFO :       Start Pruning
2024-04-23 20:34:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:34:23 - INFO :       Loss = 15.0
2024-04-23 20:34:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:34:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:34:26 - INFO :       high_school_government_and_politics: Total Sparsity 1.3566762663462592e-06
2024-04-23 20:34:42 - INFO :       high_school_government_and_politics: Total Accuracy (6, 21, 0.2857142857142857)
2024-04-23 20:34:43 - INFO :       
==================Finish================

2024-04-23 20:34:43 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:34:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:34:43 - INFO :       DATASET: tasksource/mmlu high_school_macroeconomics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:34:50 - INFO :       Use taylor pruner...
2024-04-23 20:34:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:34:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:34:50 - INFO :       Start Pruning
2024-04-23 20:34:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:34:52 - INFO :       Loss = 14.1796875
2024-04-23 20:34:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:34:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:34:55 - INFO :       high_school_macroeconomics: Total Sparsity 1.3593813445221782e-06
2024-04-23 20:35:29 - INFO :       high_school_macroeconomics: Total Accuracy (15, 43, 0.3488372093023256)
2024-04-23 20:35:29 - INFO :       
==================Finish================

2024-04-23 20:35:29 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:35:29 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:35:29 - INFO :       DATASET: tasksource/mmlu high_school_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:35:36 - INFO :       Use taylor pruner...
2024-04-23 20:35:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:35:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:35:36 - INFO :       Start Pruning
2024-04-23 20:35:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:35:38 - INFO :       Loss = 13.9140625
2024-04-23 20:35:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:35:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:35:41 - INFO :       high_school_mathematics: Total Sparsity 1.3593813445221782e-06
2024-04-23 20:36:05 - INFO :       high_school_mathematics: Total Accuracy (5, 29, 0.1724137931034483)
2024-04-23 20:36:05 - INFO :       
==================Finish================

2024-04-23 20:36:05 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:36:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:36:05 - INFO :       DATASET: tasksource/mmlu high_school_microeconomics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 20:36:12 - INFO :       Use taylor pruner...
2024-04-23 20:36:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:36:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:36:12 - INFO :       Start Pruning
2024-04-23 20:36:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:36:14 - INFO :       Loss = 14.3984375
2024-04-23 20:36:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:36:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:36:17 - INFO :       high_school_microeconomics: Total Sparsity 1.3604952002416743e-06
2024-04-23 20:36:38 - INFO :       high_school_microeconomics: Total Accuracy (10, 26, 0.38461538461538464)
2024-04-23 20:36:38 - INFO :       
==================Finish================

2024-04-23 20:36:38 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:36:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:36:38 - INFO :       DATASET: tasksource/mmlu high_school_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 20:36:45 - INFO :       Use taylor pruner...
2024-04-23 20:36:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:36:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:36:46 - INFO :       Start Pruning
2024-04-23 20:36:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:36:48 - INFO :       Loss = 12.1875
2024-04-23 20:36:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:36:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:36:50 - INFO :       high_school_physics: Total Sparsity 1.3612908114698858e-06
2024-04-23 20:37:04 - INFO :       high_school_physics: Total Accuracy (4, 17, 0.23529411764705882)
2024-04-23 20:37:04 - INFO :       
==================Finish================

2024-04-23 20:37:04 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:37:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:37:04 - INFO :       DATASET: tasksource/mmlu high_school_psychology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 20:37:12 - INFO :       Use taylor pruner...
2024-04-23 20:37:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:37:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:37:12 - INFO :       Start Pruning
2024-04-23 20:37:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:37:14 - INFO :       Loss = 15.03125
2024-04-23 20:37:15 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:37:15 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:37:17 - INFO :       high_school_psychology: Total Sparsity 1.3638367674001628e-06
2024-04-23 20:37:57 - INFO :       high_school_psychology: Total Accuracy (29, 50, 0.58)
2024-04-23 20:37:57 - INFO :       
==================Finish================

2024-04-23 20:37:57 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:37:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:37:57 - INFO :       DATASET: tasksource/mmlu high_school_statistics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 20:38:04 - INFO :       Use taylor pruner...
2024-04-23 20:38:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:38:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:38:05 - INFO :       Start Pruning
2024-04-23 20:38:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:38:07 - INFO :       Loss = 12.1484375
2024-04-23 20:38:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:38:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:38:09 - INFO :       high_school_statistics: Total Sparsity 1.358267488802682e-06
2024-04-23 20:38:28 - INFO :       high_school_statistics: Total Accuracy (6, 23, 0.2608695652173913)
2024-04-23 20:38:28 - INFO :       
==================Finish================

2024-04-23 20:38:28 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:38:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:38:28 - INFO :       DATASET: tasksource/mmlu high_school_us_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 20:38:36 - INFO :       Use taylor pruner...
2024-04-23 20:38:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:38:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:38:36 - INFO :       Start Pruning
2024-04-23 20:38:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:38:38 - INFO :       Loss = 4.26171875
2024-04-23 20:38:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:38:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:38:41 - INFO :       high_school_us_history: Total Sparsity 1.356517144100617e-06
2024-04-23 20:39:01 - INFO :       high_school_us_history: Total Accuracy (14, 22, 0.6363636363636364)
2024-04-23 20:39:01 - INFO :       
==================Finish================

2024-04-23 20:39:01 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:39:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:39:01 - INFO :       DATASET: tasksource/mmlu high_school_world_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 20:39:08 - INFO :       Use taylor pruner...
2024-04-23 20:39:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:39:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:39:08 - INFO :       Start Pruning
2024-04-23 20:39:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:39:10 - INFO :       Loss = 7.4375
2024-04-23 20:39:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:39:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:39:13 - INFO :       high_school_world_history: Total Sparsity 1.3579492443113975e-06
2024-04-23 20:39:37 - INFO :       high_school_world_history: Total Accuracy (10, 26, 0.38461538461538464)
2024-04-23 20:39:37 - INFO :       
==================Finish================

2024-04-23 20:39:37 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:39:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:39:37 - INFO :       DATASET: tasksource/mmlu human_aging
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 20:39:44 - INFO :       Use taylor pruner...
2024-04-23 20:39:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:39:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:39:45 - INFO :       Start Pruning
2024-04-23 20:39:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:39:47 - INFO :       Loss = 15.671875
2024-04-23 20:39:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:39:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:39:50 - INFO :       human_aging: Total Sparsity 1.3584266110483244e-06
2024-04-23 20:40:08 - INFO :       human_aging: Total Accuracy (13, 23, 0.5652173913043478)
2024-04-23 20:40:08 - INFO :       
==================Finish================

2024-04-23 20:40:08 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:40:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:40:08 - INFO :       DATASET: tasksource/mmlu human_sexuality
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 20:40:15 - INFO :       Use taylor pruner...
2024-04-23 20:40:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:40:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:40:15 - INFO :       Start Pruning
2024-04-23 20:40:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:40:17 - INFO :       Loss = 15.109375
2024-04-23 20:40:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:40:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:40:20 - INFO :       human_sexuality: Total Sparsity 1.3569945108375437e-06
2024-04-23 20:40:30 - INFO :       human_sexuality: Total Accuracy (2, 12, 0.16666666666666666)
2024-04-23 20:40:30 - INFO :       
==================Finish================

2024-04-23 20:40:30 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:40:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:40:30 - INFO :       DATASET: tasksource/mmlu international_law
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 20:40:37 - INFO :       Use taylor pruner...
2024-04-23 20:40:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:40:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:40:37 - INFO :       Start Pruning
2024-04-23 20:40:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:40:39 - INFO :       Loss = 13.84375
2024-04-23 20:40:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:40:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:40:42 - INFO :       international_law: Total Sparsity 1.3590631000308936e-06
2024-04-23 20:40:53 - INFO :       international_law: Total Accuracy (10, 13, 0.7692307692307693)
2024-04-23 20:40:53 - INFO :       
==================Finish================

2024-04-23 20:40:53 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:40:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:40:53 - INFO :       DATASET: tasksource/mmlu jurisprudence
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 20:41:00 - INFO :       Use taylor pruner...
2024-04-23 20:41:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:41:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:41:00 - INFO :       Start Pruning
2024-04-23 20:41:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:41:02 - INFO :       Loss = 13.59375
2024-04-23 20:41:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:41:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:41:05 - INFO :       jurisprudence: Total Sparsity 1.358744855539609e-06
2024-04-23 20:41:14 - INFO :       jurisprudence: Total Accuracy (5, 11, 0.45454545454545453)
2024-04-23 20:41:14 - INFO :       
==================Finish================

2024-04-23 20:41:14 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:41:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:41:14 - INFO :       DATASET: tasksource/mmlu logical_fallacies
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:41:21 - INFO :       Use taylor pruner...
2024-04-23 20:41:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:41:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:41:22 - INFO :       Start Pruning
2024-04-23 20:41:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:41:24 - INFO :       Loss = 15.1953125
2024-04-23 20:41:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:41:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:41:27 - INFO :       logical_fallacies: Total Sparsity 1.3590631000308936e-06
2024-04-23 20:41:41 - INFO :       logical_fallacies: Total Accuracy (10, 18, 0.5555555555555556)
2024-04-23 20:41:41 - INFO :       
==================Finish================

2024-04-23 20:41:41 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:41:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:41:41 - INFO :       DATASET: tasksource/mmlu machine_learning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:41:48 - INFO :       Use taylor pruner...
2024-04-23 20:41:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:41:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:41:49 - INFO :       Start Pruning
2024-04-23 20:41:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:41:50 - INFO :       Loss = 14.71875
2024-04-23 20:41:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:41:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:41:53 - INFO :       machine_learning: Total Sparsity 1.3589039777852514e-06
2024-04-23 20:42:02 - INFO :       machine_learning: Total Accuracy (4, 11, 0.36363636363636365)
2024-04-23 20:42:02 - INFO :       
==================Finish================

2024-04-23 20:42:02 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:42:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:42:02 - INFO :       DATASET: tasksource/mmlu management
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 20:42:09 - INFO :       Use taylor pruner...
2024-04-23 20:42:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:42:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:42:10 - INFO :       Start Pruning
2024-04-23 20:42:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:42:12 - INFO :       Loss = 15.7421875
2024-04-23 20:42:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:42:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:42:14 - INFO :       management: Total Sparsity 1.357153633083186e-06
2024-04-23 20:42:23 - INFO :       management: Total Accuracy (6, 11, 0.5454545454545454)
2024-04-23 20:42:23 - INFO :       
==================Finish================

2024-04-23 20:42:23 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:42:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:42:23 - INFO :       DATASET: tasksource/mmlu marketing
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 20:42:30 - INFO :       Use taylor pruner...
2024-04-23 20:42:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:42:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:42:31 - INFO :       Start Pruning
2024-04-23 20:42:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:42:33 - INFO :       Loss = 14.53125
2024-04-23 20:42:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:42:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:42:36 - INFO :       marketing: Total Sparsity 1.3574718775744707e-06
2024-04-23 20:42:56 - INFO :       marketing: Total Accuracy (15, 25, 0.6)
2024-04-23 20:42:56 - INFO :       
==================Finish================

2024-04-23 20:42:56 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:42:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:42:56 - INFO :       DATASET: tasksource/mmlu medical_genetics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 20:43:03 - INFO :       Use taylor pruner...
2024-04-23 20:43:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:43:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:43:03 - INFO :       Start Pruning
2024-04-23 20:43:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:43:05 - INFO :       Loss = 14.6953125
2024-04-23 20:43:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:43:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:43:08 - INFO :       medical_genetics: Total Sparsity 1.353334699187771e-06
2024-04-23 20:43:17 - INFO :       medical_genetics: Total Accuracy (9, 11, 0.8181818181818182)
2024-04-23 20:43:17 - INFO :       
==================Finish================

2024-04-23 20:43:17 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:43:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:43:17 - INFO :       DATASET: tasksource/mmlu miscellaneous
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 20:43:24 - INFO :       Use taylor pruner...
2024-04-23 20:43:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:43:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:43:25 - INFO :       Start Pruning
2024-04-23 20:43:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:43:37 - INFO :       Loss = 15.140625
2024-04-23 20:43:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:43:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:43:39 - INFO :       miscellaneous: Total Sparsity 1.358267488802682e-06
2024-04-23 20:44:20 - INFO :       miscellaneous: Total Accuracy (27, 50, 0.54)
2024-04-23 20:44:20 - INFO :       
==================Finish================

2024-04-23 20:44:20 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:44:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:44:20 - INFO :       DATASET: tasksource/mmlu moral_disputes
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:44:27 - INFO :       Use taylor pruner...
2024-04-23 20:44:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:44:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:44:28 - INFO :       Start Pruning
2024-04-23 20:44:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:44:30 - INFO :       Loss = 14.2109375
2024-04-23 20:44:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:44:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:44:32 - INFO :       moral_disputes: Total Sparsity 1.356517144100617e-06
2024-04-23 20:45:03 - INFO :       moral_disputes: Total Accuracy (20, 38, 0.5263157894736842)
2024-04-23 20:45:03 - INFO :       
==================Finish================

2024-04-23 20:45:03 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:45:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:45:03 - INFO :       DATASET: tasksource/mmlu moral_scenarios
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 20:45:10 - INFO :       Use taylor pruner...
2024-04-23 20:45:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:45:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:45:11 - INFO :       Start Pruning
2024-04-23 20:45:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:45:12 - INFO :       Loss = 13.4375
2024-04-23 20:45:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:45:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:45:15 - INFO :       moral_scenarios: Total Sparsity 1.3574718775744707e-06
2024-04-23 20:45:56 - INFO :       moral_scenarios: Total Accuracy (18, 50, 0.36)
2024-04-23 20:45:56 - INFO :       
==================Finish================

2024-04-23 20:45:56 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:45:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:45:56 - INFO :       DATASET: tasksource/mmlu nutrition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 20:46:03 - INFO :       Use taylor pruner...
2024-04-23 20:46:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:46:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:46:03 - INFO :       Start Pruning
2024-04-23 20:46:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:46:05 - INFO :       Loss = 14.421875
2024-04-23 20:46:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:46:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:46:08 - INFO :       nutrition: Total Sparsity 1.3595404667678207e-06
2024-04-23 20:46:35 - INFO :       nutrition: Total Accuracy (14, 33, 0.42424242424242425)
2024-04-23 20:46:35 - INFO :       
==================Finish================

2024-04-23 20:46:35 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:46:35 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:46:35 - INFO :       DATASET: tasksource/mmlu philosophy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 20:46:42 - INFO :       Use taylor pruner...
2024-04-23 20:46:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:46:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:46:42 - INFO :       Start Pruning
2024-04-23 20:46:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:46:44 - INFO :       Loss = 14.734375
2024-04-23 20:46:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:46:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:46:47 - INFO :       philosophy: Total Sparsity 1.3589039777852514e-06
2024-04-23 20:47:15 - INFO :       philosophy: Total Accuracy (16, 34, 0.47058823529411764)
2024-04-23 20:47:15 - INFO :       
==================Finish================

2024-04-23 20:47:15 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:47:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:47:15 - INFO :       DATASET: tasksource/mmlu prehistory
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 20:47:22 - INFO :       Use taylor pruner...
2024-04-23 20:47:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:47:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:47:22 - INFO :       Start Pruning
2024-04-23 20:47:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:47:24 - INFO :       Loss = 14.0546875
2024-04-23 20:47:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:47:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:47:27 - INFO :       prehistory: Total Sparsity 1.3593813445221782e-06
2024-04-23 20:47:56 - INFO :       prehistory: Total Accuracy (20, 35, 0.5714285714285714)
2024-04-23 20:47:56 - INFO :       
==================Finish================

2024-04-23 20:47:56 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:47:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:47:56 - INFO :       DATASET: tasksource/mmlu professional_accounting
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 20:48:03 - INFO :       Use taylor pruner...
2024-04-23 20:48:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:48:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:48:04 - INFO :       Start Pruning
2024-04-23 20:48:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:48:06 - INFO :       Loss = 13.4140625
2024-04-23 20:48:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:48:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:48:09 - INFO :       professional_accounting: Total Sparsity 1.3595404667678207e-06
2024-04-23 20:48:34 - INFO :       professional_accounting: Total Accuracy (12, 31, 0.3870967741935484)
2024-04-23 20:48:34 - INFO :       
==================Finish================

2024-04-23 20:48:34 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:48:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:48:34 - INFO :       DATASET: tasksource/mmlu professional_law
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 20:48:41 - INFO :       Use taylor pruner...
2024-04-23 20:48:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:48:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:48:42 - INFO :       Start Pruning
2024-04-23 20:48:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:48:44 - INFO :       Loss = 5.30078125
2024-04-23 20:48:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:48:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:48:47 - INFO :       professional_law: Total Sparsity 1.3593813445221782e-06
2024-04-23 20:49:30 - INFO :       professional_law: Total Accuracy (9, 50, 0.18)
2024-04-23 20:49:30 - INFO :       
==================Finish================

2024-04-23 20:49:30 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:49:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:49:30 - INFO :       DATASET: tasksource/mmlu professional_medicine
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 20:49:37 - INFO :       Use taylor pruner...
2024-04-23 20:49:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:49:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:49:38 - INFO :       Start Pruning
2024-04-23 20:49:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:49:40 - INFO :       Loss = 10.34375
2024-04-23 20:49:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:49:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:49:43 - INFO :       professional_medicine: Total Sparsity 1.3557215328724054e-06
2024-04-23 20:50:09 - INFO :       professional_medicine: Total Accuracy (12, 31, 0.3870967741935484)
2024-04-23 20:50:09 - INFO :       
==================Finish================

2024-04-23 20:50:09 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:50:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:50:09 - INFO :       DATASET: tasksource/mmlu professional_psychology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:50:16 - INFO :       Use taylor pruner...
2024-04-23 20:50:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:50:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:50:17 - INFO :       Start Pruning
2024-04-23 20:50:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:50:18 - INFO :       Loss = 14.2265625
2024-04-23 20:50:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:50:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:50:21 - INFO :       professional_psychology: Total Sparsity 1.3617681782068128e-06
2024-04-23 20:51:01 - INFO :       professional_psychology: Total Accuracy (20, 50, 0.4)
2024-04-23 20:51:01 - INFO :       
==================Finish================

2024-04-23 20:51:01 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:51:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:51:01 - INFO :       DATASET: tasksource/mmlu public_relations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 20:51:09 - INFO :       Use taylor pruner...
2024-04-23 20:51:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:51:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:51:09 - INFO :       Start Pruning
2024-04-23 20:51:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:51:11 - INFO :       Loss = 15.3671875
2024-04-23 20:51:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:51:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:51:14 - INFO :       public_relations: Total Sparsity 1.3616090559611704e-06
2024-04-23 20:51:24 - INFO :       public_relations: Total Accuracy (6, 12, 0.5)
2024-04-23 20:51:24 - INFO :       
==================Finish================

2024-04-23 20:51:24 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:51:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:51:24 - INFO :       DATASET: tasksource/mmlu security_studies
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 20:51:31 - INFO :       Use taylor pruner...
2024-04-23 20:51:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:51:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:51:31 - INFO :       Start Pruning
2024-04-23 20:51:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:51:33 - INFO :       Loss = 12.90625
2024-04-23 20:51:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:51:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:51:36 - INFO :       security_studies: Total Sparsity 1.3569945108375437e-06
2024-04-23 20:51:59 - INFO :       security_studies: Total Accuracy (12, 27, 0.4444444444444444)
2024-04-23 20:52:00 - INFO :       
==================Finish================

2024-04-23 20:52:00 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:52:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:52:00 - INFO :       DATASET: tasksource/mmlu sociology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:52:07 - INFO :       Use taylor pruner...
2024-04-23 20:52:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:52:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:52:08 - INFO :       Start Pruning
2024-04-23 20:52:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:52:10 - INFO :       Loss = 14.96875
2024-04-23 20:52:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:52:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:52:13 - INFO :       sociology: Total Sparsity 1.3584266110483244e-06
2024-04-23 20:52:30 - INFO :       sociology: Total Accuracy (10, 22, 0.45454545454545453)
2024-04-23 20:52:30 - INFO :       
==================Finish================

2024-04-23 20:52:30 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:52:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:52:30 - INFO :       DATASET: tasksource/mmlu us_foreign_policy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 20:52:38 - INFO :       Use taylor pruner...
2024-04-23 20:52:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:52:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:52:38 - INFO :       Start Pruning
2024-04-23 20:52:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:52:40 - INFO :       Loss = 15.1015625
2024-04-23 20:52:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:52:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:52:43 - INFO :       us_foreign_policy: Total Sparsity 1.359699589013463e-06
2024-04-23 20:52:52 - INFO :       us_foreign_policy: Total Accuracy (6, 11, 0.5454545454545454)
2024-04-23 20:52:52 - INFO :       
==================Finish================

2024-04-23 20:52:52 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:52:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:52:52 - INFO :       DATASET: tasksource/mmlu virology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:52:59 - INFO :       Use taylor pruner...
2024-04-23 20:52:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:52:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:53:00 - INFO :       Start Pruning
2024-04-23 20:53:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:53:02 - INFO :       Loss = 14.6953125
2024-04-23 20:53:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:53:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:53:05 - INFO :       virology: Total Sparsity 1.360336077996032e-06
2024-04-23 20:53:19 - INFO :       virology: Total Accuracy (9, 18, 0.5)
2024-04-23 20:53:19 - INFO :       
==================Finish================

2024-04-23 20:53:19 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:53:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:53:19 - INFO :       DATASET: tasksource/mmlu world_religions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2024-04-23 20:53:26 - INFO :       Use taylor pruner...
2024-04-23 20:53:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:53:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:53:27 - INFO :       Start Pruning
2024-04-23 20:53:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:53:29 - INFO :       Loss = 15.140625
2024-04-23 20:53:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:53:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:53:32 - INFO :       world_religions: Total Sparsity 1.3601769557503897e-06
2024-04-23 20:53:47 - INFO :       world_religions: Total Accuracy (13, 19, 0.6842105263157895)
2024-04-23 20:53:47 - INFO :       
==================Finish================

2024-04-23 20:53:47 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:53:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:53:47 - INFO :       DATASET: math_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 20:53:55 - INFO :       Use taylor pruner...
2024-04-23 20:53:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:53:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:53:55 - INFO :       Start Pruning
2024-04-23 20:53:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:53:57 - INFO :       Loss = 14.5234375
2024-04-23 20:53:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:53:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:54:00 - INFO :       math_qa: Total Sparsity 1.3563580218549744e-06
2024-04-23 20:54:37 - INFO :       math_qa: Accuracy (12, 50, 0.24)
2024-04-23 20:54:37 - INFO :       
==================Finish================

2024-04-23 20:54:37 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:54:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:54:37 - INFO :       DATASET: EleutherAI/truthful_qa_mc
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 20:54:44 - INFO :       Use taylor pruner...
2024-04-23 20:54:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:54:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:54:44 - INFO :       Start Pruning
2024-04-23 20:54:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:54:47 - INFO :       Loss = 14.5234375
2024-04-23 20:54:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:54:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:54:50 - INFO :       truthful_qa_mc: Total Sparsity 1.3606543224873167e-06
2024-04-23 20:55:24 - INFO :       truthful_qa_mc: Accuracy (19, 50, 0.38)
2024-04-23 20:55:24 - INFO :       
==================Finish================

2024-04-23 20:55:24 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:55:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:55:24 - INFO :       DATASET: derek-thomas/ScienceQA
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 20:55:31 - INFO :       Use taylor pruner...
2024-04-23 20:55:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:55:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:55:31 - INFO :       Start Pruning
2024-04-23 20:55:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:55:33 - INFO :       Loss = 16.0625
2024-04-23 20:55:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:55:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:55:36 - INFO :       ScienceQA: Total Sparsity 1.3541303104159823e-06
2024-04-23 20:56:11 - INFO :       ScienceQA: Accuracy (34, 50, 0.68)
2024-04-23 20:56:11 - INFO :       
==================Finish================

2024-04-23 20:56:11 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 20:56:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:56:11 - INFO :       DATASET: commonsense_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 20:56:18 - INFO :       Use taylor pruner...
2024-04-23 20:56:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:56:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:56:19 - INFO :       Start Pruning
2024-04-23 20:56:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:56:21 - INFO :       Loss = 15.2265625
2024-04-23 20:56:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:56:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:56:24 - INFO :       commonsense_qa: Total Sparsity 1.3574718775744707e-06
2024-04-23 20:56:57 - INFO :       commonsense_qa: Accuracy (30, 50, 0.6)
2024-04-23 20:56:57 - INFO :       
==================Finish================

2024-04-23 20:56:57 - INFO :       Memory Requirement: 16770.79052734375 MiB

End: Memory Requirement: 3979.2666015625 MiB

Begin: Memory Requirement: 3979.2666015625 MiB

2024-04-23 20:56:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:56:57 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Index 3
Sparsity 3.5000000000000004 %
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 20:57:05 - INFO :       Use taylor pruner...
2024-04-23 20:57:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:57:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:57:05 - INFO :       Start Pruning
2024-04-23 20:57:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:57:07 - INFO :       Loss = 1.5537109375
2024-04-23 20:57:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:57:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:57:10 - INFO :       which_wiki_edit: Total Sparsity 1.3581083665570398e-06
2024-04-23 20:58:44 - INFO :       which_wiki_edit: Total Accuracy (20, 50, 0.4)
2024-04-23 20:58:45 - INFO :       
==================Finish================

2024-04-23 20:58:45 - INFO :       Memory Requirement: 16849.60302734375 MiB

2024-04-23 20:58:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:58:45 - INFO :       DATASET: tasksource/bigbench abstract_narrative_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-23 20:58:52 - INFO :       Use taylor pruner...
2024-04-23 20:58:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:58:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:58:52 - INFO :       Start Pruning
2024-04-23 20:58:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:58:55 - INFO :       Loss = 4.38671875
2024-04-23 20:58:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:58:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:58:58 - INFO :       abstract_narrative_understanding: Total Sparsity 1.3574718775744707e-06
2024-04-23 20:59:38 - INFO :       abstract_narrative_understanding: Total Accuracy (15, 50, 0.3)
2024-04-23 20:59:38 - INFO :       
==================Finish================

2024-04-23 20:59:38 - INFO :       Memory Requirement: 16772.79052734375 MiB

2024-04-23 20:59:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 20:59:38 - INFO :       DATASET: tasksource/bigbench anachronisms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2024-04-23 20:59:45 - INFO :       Use taylor pruner...
2024-04-23 20:59:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:59:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 20:59:46 - INFO :       Start Pruning
2024-04-23 20:59:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 20:59:48 - INFO :       Loss = 16.015625
2024-04-23 20:59:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 20:59:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 20:59:51 - INFO :       anachronisms: Total Sparsity 1.3579492443113975e-06
2024-04-23 21:00:27 - INFO :       anachronisms: Total Accuracy (25, 46, 0.5434782608695652)
2024-04-23 21:00:28 - INFO :       
==================Finish================

2024-04-23 21:00:28 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-23 21:00:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:00:28 - INFO :       DATASET: tasksource/bigbench analogical_similarity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 21:00:35 - INFO :       Use taylor pruner...
2024-04-23 21:00:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:00:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:00:35 - INFO :       Start Pruning
2024-04-23 21:00:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:00:37 - INFO :       Loss = 1.46875
2024-04-23 21:00:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:00:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:00:40 - INFO :       analogical_similarity: Total Sparsity 1.3584266110483244e-06
2024-04-23 21:01:33 - INFO :       analogical_similarity: Total Accuracy (3, 50, 0.06)
2024-04-23 21:01:33 - INFO :       
==================Finish================

2024-04-23 21:01:33 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-23 21:01:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:01:33 - INFO :       DATASET: tasksource/bigbench analytic_entailment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2024-04-23 21:01:40 - INFO :       Use taylor pruner...
2024-04-23 21:01:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:01:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:01:41 - INFO :       Start Pruning
2024-04-23 21:01:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:01:43 - INFO :       Loss = 14.8125
2024-04-23 21:01:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:01:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:01:46 - INFO :       analytic_entailment: Total Sparsity 1.3563580218549744e-06
2024-04-23 21:01:58 - INFO :       analytic_entailment: Total Accuracy (8, 16, 0.5)
2024-04-23 21:01:59 - INFO :       
==================Finish================

2024-04-23 21:01:59 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-23 21:01:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:01:59 - INFO :       DATASET: tasksource/bigbench arithmetic
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 21:02:06 - INFO :       Use taylor pruner...
2024-04-23 21:02:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:02:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:02:06 - INFO :       Start Pruning
2024-04-23 21:02:07 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:02:08 - INFO :       Loss = 12.0546875
2024-04-23 21:02:10 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:02:10 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:02:11 - INFO :       arithmetic: Total Sparsity 1.3569945108375437e-06
2024-04-23 21:02:51 - INFO :       arithmetic: Total Accuracy (1, 50, 0.02)
2024-04-23 21:02:51 - INFO :       
==================Finish================

2024-04-23 21:02:51 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-23 21:02:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:02:51 - INFO :       DATASET: tasksource/bigbench authorship_verification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 21:02:59 - INFO :       Use taylor pruner...
2024-04-23 21:02:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:02:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:03:00 - INFO :       Start Pruning
2024-04-23 21:03:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:03:02 - INFO :       Loss = 2.828125
2024-04-23 21:03:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:03:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:03:05 - INFO :       authorship_verification: Total Sparsity 1.3561988996093322e-06
2024-04-23 21:05:17 - INFO :       authorship_verification: Total Accuracy (28, 50, 0.56)
2024-04-23 21:05:17 - INFO :       
==================Finish================

2024-04-23 21:05:17 - INFO :       Memory Requirement: 16794.44580078125 MiB

2024-04-23 21:05:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:05:17 - INFO :       DATASET: tasksource/bigbench bbq_lite_json
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2024-04-23 21:05:25 - INFO :       Use taylor pruner...
2024-04-23 21:05:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:05:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:05:26 - INFO :       Start Pruning
2024-04-23 21:05:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:05:28 - INFO :       Loss = 13.765625
2024-04-23 21:05:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:05:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:05:31 - INFO :       bbq_lite_json: Total Sparsity 1.3595404667678207e-06
2024-04-23 21:06:12 - INFO :       bbq_lite_json: Total Accuracy (17, 50, 0.34)
2024-04-23 21:06:12 - INFO :       
==================Finish================

2024-04-23 21:06:12 - INFO :       Memory Requirement: 16771.79052734375 MiB

2024-04-23 21:06:12 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:06:12 - INFO :       DATASET: tasksource/bigbench causal_judgment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-23 21:06:20 - INFO :       Use taylor pruner...
2024-04-23 21:06:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:06:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:06:21 - INFO :       Start Pruning
2024-04-23 21:06:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:06:23 - INFO :       Loss = 8.9609375
2024-04-23 21:06:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:06:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:06:26 - INFO :       causal_judgment: Total Sparsity 1.3579492443113975e-06
2024-04-23 21:07:00 - INFO :       causal_judgment: Total Accuracy (17, 38, 0.4473684210526316)
2024-04-23 21:07:00 - INFO :       
==================Finish================

2024-04-23 21:07:00 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:07:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:07:00 - INFO :       DATASET: tasksource/bigbench cause_and_effect
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 21:07:09 - INFO :       Use taylor pruner...
2024-04-23 21:07:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:07:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:07:10 - INFO :       Start Pruning
2024-04-23 21:07:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:07:12 - INFO :       Loss = 15.0234375
2024-04-23 21:07:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:07:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:07:15 - INFO :       cause_and_effect: Total Sparsity 1.3584266110483244e-06
2024-04-23 21:07:39 - INFO :       cause_and_effect: Total Accuracy (3, 30, 0.1)
2024-04-23 21:07:39 - INFO :       
==================Finish================

2024-04-23 21:07:39 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:07:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:07:39 - INFO :       DATASET: tasksource/bigbench checkmate_in_one
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 21:07:47 - INFO :       Use taylor pruner...
2024-04-23 21:07:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:07:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:07:47 - INFO :       Start Pruning
2024-04-23 21:07:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:07:50 - INFO :       Loss = 2.001953125
2024-04-23 21:07:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:07:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:07:53 - INFO :       checkmate_in_one: Total Sparsity 1.3552441661354783e-06
2024-04-23 21:08:43 - INFO :       checkmate_in_one: Total Accuracy (13, 50, 0.26)
2024-04-23 21:08:43 - INFO :       
==================Finish================

2024-04-23 21:08:43 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:08:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:08:43 - INFO :       DATASET: tasksource/bigbench cifar10_classification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2024-04-23 21:08:53 - INFO :       Use taylor pruner...
2024-04-23 21:08:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:08:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:08:53 - INFO :       Start Pruning
2024-04-23 21:08:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:08:56 - INFO :       Loss = 4.0234375
2024-04-23 21:08:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:08:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:08:59 - INFO :       cifar10_classification: Total Sparsity 1.3574718775744707e-06
2024-04-23 21:10:53 - INFO :       cifar10_classification: Total Accuracy (5, 50, 0.1)
2024-04-23 21:10:54 - INFO :       
==================Finish================

2024-04-23 21:10:54 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:10:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:10:54 - INFO :       DATASET: tasksource/bigbench code_line_description
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2024-04-23 21:11:02 - INFO :       Use taylor pruner...
2024-04-23 21:11:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:11:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:11:03 - INFO :       Start Pruning
2024-04-23 21:11:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:11:05 - INFO :       Loss = 12.3359375
2024-04-23 21:11:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:11:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:11:10 - INFO :       code_line_description: Total Sparsity 1.3632002784175935e-06
2024-04-23 21:11:23 - INFO :       code_line_description: Total Accuracy (6, 16, 0.375)
2024-04-23 21:11:25 - INFO :       
==================Finish================

2024-04-23 21:11:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:11:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:11:25 - INFO :       DATASET: tasksource/bigbench color
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 21:11:33 - INFO :       Use taylor pruner...
2024-04-23 21:11:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:11:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:11:33 - INFO :       Start Pruning
2024-04-23 21:11:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:11:35 - INFO :       Loss = 11.078125
2024-04-23 21:11:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:11:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:11:38 - INFO :       color: Total Sparsity 1.359222222276536e-06
2024-04-23 21:12:19 - INFO :       color: Total Accuracy (13, 50, 0.26)
2024-04-23 21:12:19 - INFO :       
==================Finish================

2024-04-23 21:12:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:12:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:12:19 - INFO :       DATASET: tasksource/bigbench common_morpheme
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 21:12:26 - INFO :       Use taylor pruner...
2024-04-23 21:12:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:12:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:12:27 - INFO :       Start Pruning
2024-04-23 21:12:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:12:29 - INFO :       Loss = 13.921875
2024-04-23 21:12:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:12:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:12:32 - INFO :       common_morpheme: Total Sparsity 1.359699589013463e-06
2024-04-23 21:12:45 - INFO :       common_morpheme: Total Accuracy (3, 16, 0.1875)
2024-04-23 21:12:45 - INFO :       
==================Finish================

2024-04-23 21:12:45 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:12:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:12:45 - INFO :       DATASET: tasksource/bigbench conceptual_combinations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 21:12:53 - INFO :       Use taylor pruner...
2024-04-23 21:12:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:12:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:12:53 - INFO :       Start Pruning
2024-04-23 21:12:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:12:55 - INFO :       Loss = 12.7734375
2024-04-23 21:12:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:12:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:12:58 - INFO :       conceptual_combinations: Total Sparsity 1.3593813445221782e-06
2024-04-23 21:13:14 - INFO :       conceptual_combinations: Total Accuracy (1, 19, 0.05263157894736842)
2024-04-23 21:13:14 - INFO :       
==================Finish================

2024-04-23 21:13:14 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:13:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:13:14 - INFO :       DATASET: tasksource/bigbench crash_blossom
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 21:13:21 - INFO :       Use taylor pruner...
2024-04-23 21:13:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:13:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:13:22 - INFO :       Start Pruning
2024-04-23 21:13:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:13:24 - INFO :       Loss = 13.9375
2024-04-23 21:13:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:13:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:13:27 - INFO :       crash_blossom: Total Sparsity 1.3558806551180476e-06
2024-04-23 21:13:39 - INFO :       crash_blossom: Total Accuracy (5, 16, 0.3125)
2024-04-23 21:13:39 - INFO :       
==================Finish================

2024-04-23 21:13:39 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:13:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:13:39 - INFO :       DATASET: tasksource/bigbench crass_ai
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 21:13:47 - INFO :       Use taylor pruner...
2024-04-23 21:13:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:13:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:13:47 - INFO :       Start Pruning
2024-04-23 21:13:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:13:49 - INFO :       Loss = 12.8125
2024-04-23 21:13:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:13:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:13:52 - INFO :       crass_ai: Total Sparsity 1.3584266110483244e-06
2024-04-23 21:14:05 - INFO :       crass_ai: Total Accuracy (4, 16, 0.25)
2024-04-23 21:14:05 - INFO :       
==================Finish================

2024-04-23 21:14:05 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:14:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:14:05 - INFO :       DATASET: tasksource/bigbench cryobiology_spanish
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 21:14:13 - INFO :       Use taylor pruner...
2024-04-23 21:14:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:14:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:14:14 - INFO :       Start Pruning
2024-04-23 21:14:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:14:16 - INFO :       Loss = 14.453125
2024-04-23 21:14:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:14:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:14:19 - INFO :       cryobiology_spanish: Total Sparsity 1.359222222276536e-06
2024-04-23 21:14:42 - INFO :       cryobiology_spanish: Total Accuracy (8, 29, 0.27586206896551724)
2024-04-23 21:14:42 - INFO :       
==================Finish================

2024-04-23 21:14:42 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:14:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:14:42 - INFO :       DATASET: tasksource/bigbench cs_algorithms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 21:14:50 - INFO :       Use taylor pruner...
2024-04-23 21:14:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:14:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:14:50 - INFO :       Start Pruning
2024-04-23 21:14:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:14:53 - INFO :       Loss = 13.2265625
2024-04-23 21:14:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:14:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:14:56 - INFO :       cs_algorithms: Total Sparsity 1.361449933715528e-06
2024-04-23 21:15:37 - INFO :       cs_algorithms: Total Accuracy (3, 50, 0.06)
2024-04-23 21:15:37 - INFO :       
==================Finish================

2024-04-23 21:15:37 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:15:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:15:37 - INFO :       DATASET: tasksource/bigbench dark_humor_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 21:15:44 - INFO :       Use taylor pruner...
2024-04-23 21:15:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:15:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:15:45 - INFO :       Start Pruning
2024-04-23 21:15:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:15:47 - INFO :       Loss = 13.7421875
2024-04-23 21:15:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:15:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:15:50 - INFO :       dark_humor_detection: Total Sparsity 1.357630999820113e-06
2024-04-23 21:16:03 - INFO :       dark_humor_detection: Total Accuracy (10, 16, 0.625)
2024-04-23 21:16:03 - INFO :       
==================Finish================

2024-04-23 21:16:03 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:16:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:16:03 - INFO :       DATASET: tasksource/bigbench date_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 21:16:10 - INFO :       Use taylor pruner...
2024-04-23 21:16:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:16:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:16:11 - INFO :       Start Pruning
2024-04-23 21:16:12 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:16:13 - INFO :       Loss = 12.15625
2024-04-23 21:16:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:16:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:16:16 - INFO :       date_understanding: Total Sparsity 1.3569945108375437e-06
2024-04-23 21:16:57 - INFO :       date_understanding: Total Accuracy (2, 50, 0.04)
2024-04-23 21:16:57 - INFO :       
==================Finish================

2024-04-23 21:16:57 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:16:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:16:57 - INFO :       DATASET: tasksource/bigbench disambiguation_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 21:17:04 - INFO :       Use taylor pruner...
2024-04-23 21:17:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:17:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:17:05 - INFO :       Start Pruning
2024-04-23 21:17:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:17:07 - INFO :       Loss = 13.0234375
2024-04-23 21:17:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:17:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:17:09 - INFO :       disambiguation_qa: Total Sparsity 1.3569945108375437e-06
2024-04-23 21:17:50 - INFO :       disambiguation_qa: Total Accuracy (21, 50, 0.42)
2024-04-23 21:17:50 - INFO :       
==================Finish================

2024-04-23 21:17:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:17:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:17:50 - INFO :       DATASET: tasksource/bigbench discourse_marker_prediction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 21:17:58 - INFO :       Use taylor pruner...
2024-04-23 21:17:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:17:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:17:58 - INFO :       Start Pruning
2024-04-23 21:17:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:18:00 - INFO :       Loss = 4.6015625
2024-04-23 21:18:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:18:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:18:03 - INFO :       discourse_marker_prediction: Total Sparsity 1.360336077996032e-06
2024-04-23 21:18:50 - INFO :       discourse_marker_prediction: Total Accuracy (7, 50, 0.14)
2024-04-23 21:18:51 - INFO :       
==================Finish================

2024-04-23 21:18:51 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:18:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:18:51 - INFO :       DATASET: tasksource/bigbench dyck_languages
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 21:18:58 - INFO :       Use taylor pruner...
2024-04-23 21:18:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:18:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:18:59 - INFO :       Start Pruning
2024-04-23 21:19:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:19:01 - INFO :       Loss = 1.13671875
2024-04-23 21:19:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:19:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:19:04 - INFO :       dyck_languages: Total Sparsity 1.3547667993985515e-06
2024-04-23 21:19:53 - INFO :       dyck_languages: Total Accuracy (0, 50, 0.0)
2024-04-23 21:19:53 - INFO :       
==================Finish================

2024-04-23 21:19:53 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:19:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:19:53 - INFO :       DATASET: tasksource/bigbench elementary_math_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.81s/it]
2024-04-23 21:20:07 - INFO :       Use taylor pruner...
2024-04-23 21:20:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:20:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:20:08 - INFO :       Start Pruning
2024-04-23 21:20:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:20:10 - INFO :       Loss = 11.9765625
2024-04-23 21:20:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:20:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:20:13 - INFO :       elementary_math_qa: Total Sparsity 1.3589039777852514e-06
2024-04-23 21:20:55 - INFO :       elementary_math_qa: Total Accuracy (8, 50, 0.16)
2024-04-23 21:20:55 - INFO :       
==================Finish================

2024-04-23 21:20:55 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:20:55 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:20:55 - INFO :       DATASET: tasksource/bigbench emoji_movie
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.11s/it]
2024-04-23 21:21:09 - INFO :       Use taylor pruner...
2024-04-23 21:21:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:21:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:21:09 - INFO :       Start Pruning
2024-04-23 21:21:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:21:12 - INFO :       Loss = 13.3046875
2024-04-23 21:21:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:21:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:21:15 - INFO :       emoji_movie: Total Sparsity 1.3542894326616245e-06
2024-04-23 21:21:31 - INFO :       emoji_movie: Total Accuracy (0, 20, 0.0)
2024-04-23 21:21:31 - INFO :       
==================Finish================

2024-04-23 21:21:31 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:21:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:21:31 - INFO :       DATASET: tasksource/bigbench empirical_judgments
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 21:21:39 - INFO :       Use taylor pruner...
2024-04-23 21:21:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:21:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:21:39 - INFO :       Start Pruning
2024-04-23 21:21:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:21:41 - INFO :       Loss = 13.40625
2024-04-23 21:21:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:21:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:21:44 - INFO :       empirical_judgments: Total Sparsity 1.358744855539609e-06
2024-04-23 21:22:00 - INFO :       empirical_judgments: Total Accuracy (10, 19, 0.5263157894736842)
2024-04-23 21:22:00 - INFO :       
==================Finish================

2024-04-23 21:22:00 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:22:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:22:00 - INFO :       DATASET: tasksource/bigbench english_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 21:22:07 - INFO :       Use taylor pruner...
2024-04-23 21:22:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:22:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:22:07 - INFO :       Start Pruning
2024-04-23 21:22:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:22:10 - INFO :       Loss = 12.328125
2024-04-23 21:22:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:22:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:22:13 - INFO :       english_proverbs: Total Sparsity 1.3569945108375437e-06
2024-04-23 21:22:26 - INFO :       english_proverbs: Total Accuracy (4, 16, 0.25)
2024-04-23 21:22:26 - INFO :       
==================Finish================

2024-04-23 21:22:26 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:22:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:22:26 - INFO :       DATASET: tasksource/bigbench english_russian_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 21:22:34 - INFO :       Use taylor pruner...
2024-04-23 21:22:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:22:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:22:34 - INFO :       Start Pruning
2024-04-23 21:22:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:22:36 - INFO :       Loss = 12.0078125
2024-04-23 21:22:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:22:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:22:41 - INFO :       english_russian_proverbs: Total Sparsity 1.356517144100617e-06
2024-04-23 21:22:54 - INFO :       english_russian_proverbs: Total Accuracy (7, 16, 0.4375)
2024-04-23 21:22:54 - INFO :       
==================Finish================

2024-04-23 21:22:54 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:22:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:22:54 - INFO :       DATASET: tasksource/bigbench entailed_polarity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-23 21:23:01 - INFO :       Use taylor pruner...
2024-04-23 21:23:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:23:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:23:02 - INFO :       Start Pruning
2024-04-23 21:23:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:23:04 - INFO :       Loss = 15.6171875
2024-04-23 21:23:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:23:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:23:07 - INFO :       entailed_polarity: Total Sparsity 1.358744855539609e-06
2024-04-23 21:23:29 - INFO :       entailed_polarity: Total Accuracy (29, 29, 1.0)
2024-04-23 21:23:29 - INFO :       
==================Finish================

2024-04-23 21:23:29 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:23:29 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:23:29 - INFO :       DATASET: tasksource/bigbench entailed_polarity_hindi
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 21:23:37 - INFO :       Use taylor pruner...
2024-04-23 21:23:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:23:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:23:37 - INFO :       Start Pruning
2024-04-23 21:23:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:23:40 - INFO :       Loss = 11.265625
2024-04-23 21:23:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:23:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:23:43 - INFO :       entailed_polarity_hindi: Total Sparsity 1.3566762663462592e-06
2024-04-23 21:24:04 - INFO :       entailed_polarity_hindi: Total Accuracy (18, 27, 0.6666666666666666)
2024-04-23 21:24:04 - INFO :       
==================Finish================

2024-04-23 21:24:04 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:24:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:24:04 - INFO :       DATASET: tasksource/bigbench epistemic_reasoning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 21:24:11 - INFO :       Use taylor pruner...
2024-04-23 21:24:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:24:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:24:12 - INFO :       Start Pruning
2024-04-23 21:24:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:24:14 - INFO :       Loss = 13.3984375
2024-04-23 21:24:15 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:24:15 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:24:17 - INFO :       epistemic_reasoning: Total Sparsity 1.3577901220657553e-06
2024-04-23 21:24:57 - INFO :       epistemic_reasoning: Total Accuracy (26, 50, 0.52)
2024-04-23 21:24:57 - INFO :       
==================Finish================

2024-04-23 21:24:57 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:24:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:24:57 - INFO :       DATASET: tasksource/bigbench evaluating_information_essentiality
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 21:25:04 - INFO :       Use taylor pruner...
2024-04-23 21:25:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:25:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:25:05 - INFO :       Start Pruning
2024-04-23 21:25:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:25:07 - INFO :       Loss = 8.828125
2024-04-23 21:25:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:25:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:25:10 - INFO :       evaluating_information_essentiality: Total Sparsity 1.3558806551180476e-06
2024-04-23 21:25:24 - INFO :       evaluating_information_essentiality: Total Accuracy (4, 16, 0.25)
2024-04-23 21:25:24 - INFO :       
==================Finish================

2024-04-23 21:25:24 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:25:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:25:24 - INFO :       DATASET: tasksource/bigbench fact_checker
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 21:25:33 - INFO :       Use taylor pruner...
2024-04-23 21:25:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:25:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:25:33 - INFO :       Start Pruning
2024-04-23 21:25:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:25:35 - INFO :       Loss = 15.3203125
2024-04-23 21:25:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:25:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:25:38 - INFO :       fact_checker: Total Sparsity 1.3585857332939668e-06
2024-04-23 21:26:21 - INFO :       fact_checker: Total Accuracy (31, 50, 0.62)
2024-04-23 21:26:21 - INFO :       
==================Finish================

2024-04-23 21:26:21 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:26:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:26:21 - INFO :       DATASET: tasksource/bigbench fantasy_reasoning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 21:26:29 - INFO :       Use taylor pruner...
2024-04-23 21:26:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:26:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:26:29 - INFO :       Start Pruning
2024-04-23 21:26:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:26:31 - INFO :       Loss = 13.875
2024-04-23 21:26:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:26:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:26:34 - INFO :       fantasy_reasoning: Total Sparsity 1.3589039777852514e-06
2024-04-23 21:27:06 - INFO :       fantasy_reasoning: Total Accuracy (24, 40, 0.6)
2024-04-23 21:27:06 - INFO :       
==================Finish================

2024-04-23 21:27:06 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:27:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:27:06 - INFO :       DATASET: tasksource/bigbench figure_of_speech_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 21:27:14 - INFO :       Use taylor pruner...
2024-04-23 21:27:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:27:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:27:14 - INFO :       Start Pruning
2024-04-23 21:27:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:27:16 - INFO :       Loss = 12.640625
2024-04-23 21:27:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:27:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:27:19 - INFO :       figure_of_speech_detection: Total Sparsity 1.357153633083186e-06
2024-04-23 21:27:32 - INFO :       figure_of_speech_detection: Total Accuracy (5, 16, 0.3125)
2024-04-23 21:27:32 - INFO :       
==================Finish================

2024-04-23 21:27:32 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:27:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:27:32 - INFO :       DATASET: tasksource/bigbench formal_fallacies_syllogisms_negation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 21:27:39 - INFO :       Use taylor pruner...
2024-04-23 21:27:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:27:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:27:40 - INFO :       Start Pruning
2024-04-23 21:27:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:27:42 - INFO :       Loss = 13.0
2024-04-23 21:27:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:27:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:27:45 - INFO :       formal_fallacies_syllogisms_negation: Total Sparsity 1.3616090559611704e-06
2024-04-23 21:28:25 - INFO :       formal_fallacies_syllogisms_negation: Total Accuracy (20, 50, 0.4)
2024-04-23 21:28:25 - INFO :       
==================Finish================

2024-04-23 21:28:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:28:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:28:25 - INFO :       DATASET: tasksource/bigbench general_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 21:28:33 - INFO :       Use taylor pruner...
2024-04-23 21:28:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:28:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:28:33 - INFO :       Start Pruning
2024-04-23 21:28:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:28:35 - INFO :       Loss = 11.7109375
2024-04-23 21:28:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:28:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:28:38 - INFO :       general_knowledge: Total Sparsity 1.3598587112591052e-06
2024-04-23 21:28:51 - INFO :       general_knowledge: Total Accuracy (4, 16, 0.25)
2024-04-23 21:28:51 - INFO :       
==================Finish================

2024-04-23 21:28:51 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:28:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:28:51 - INFO :       DATASET: tasksource/bigbench geometric_shapes
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 21:28:58 - INFO :       Use taylor pruner...
2024-04-23 21:28:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:28:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:28:59 - INFO :       Start Pruning
2024-04-23 21:29:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:29:01 - INFO :       Loss = 8.7109375
2024-04-23 21:29:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:29:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:29:04 - INFO :       geometric_shapes: Total Sparsity 1.359222222276536e-06
2024-04-23 21:29:45 - INFO :       geometric_shapes: Total Accuracy (1, 50, 0.02)
2024-04-23 21:29:45 - INFO :       
==================Finish================

2024-04-23 21:29:45 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:29:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:29:45 - INFO :       DATASET: tasksource/bigbench goal_step_wikihow
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 21:29:52 - INFO :       Use taylor pruner...
2024-04-23 21:29:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:29:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:29:53 - INFO :       Start Pruning
2024-04-23 21:29:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:29:55 - INFO :       Loss = 13.71875
2024-04-23 21:29:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:29:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:29:58 - INFO :       goal_step_wikihow: Total Sparsity 1.3574718775744707e-06
2024-04-23 21:30:37 - INFO :       goal_step_wikihow: Total Accuracy (11, 50, 0.22)
2024-04-23 21:30:37 - INFO :       
==================Finish================

2024-04-23 21:30:37 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:30:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:30:37 - INFO :       DATASET: tasksource/bigbench gre_reading_comprehension
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 21:30:44 - INFO :       Use taylor pruner...
2024-04-23 21:30:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:30:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:30:45 - INFO :       Start Pruning
2024-04-23 21:30:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:30:47 - INFO :       Loss = 2.865234375
2024-04-23 21:30:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:30:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:30:50 - INFO :       gre_reading_comprehension: Total Sparsity 1.3604952002416743e-06
2024-04-23 21:31:05 - INFO :       gre_reading_comprehension: Total Accuracy (3, 16, 0.1875)
2024-04-23 21:31:05 - INFO :       
==================Finish================

2024-04-23 21:31:05 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:31:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:31:05 - INFO :       DATASET: tasksource/bigbench hhh_alignment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 21:31:13 - INFO :       Use taylor pruner...
2024-04-23 21:31:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:31:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:31:13 - INFO :       Start Pruning
2024-04-23 21:31:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:31:15 - INFO :       Loss = 9.90625
2024-04-23 21:31:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:31:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:31:18 - INFO :       hhh_alignment: Total Sparsity 1.3612908114698858e-06
2024-04-23 21:31:54 - INFO :       hhh_alignment: Total Accuracy (14, 42, 0.3333333333333333)
2024-04-23 21:31:55 - INFO :       
==================Finish================

2024-04-23 21:31:55 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:31:55 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:31:55 - INFO :       DATASET: tasksource/bigbench hindu_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 21:32:02 - INFO :       Use taylor pruner...
2024-04-23 21:32:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:32:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:32:03 - INFO :       Start Pruning
2024-04-23 21:32:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:32:05 - INFO :       Loss = 14.0625
2024-04-23 21:32:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:32:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:32:08 - INFO :       hindu_knowledge: Total Sparsity 1.3616090559611704e-06
2024-04-23 21:32:36 - INFO :       hindu_knowledge: Total Accuracy (9, 35, 0.2571428571428571)
2024-04-23 21:32:36 - INFO :       
==================Finish================

2024-04-23 21:32:36 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:32:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:32:36 - INFO :       DATASET: tasksource/bigbench hinglish_toxicity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 21:32:44 - INFO :       Use taylor pruner...
2024-04-23 21:32:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:32:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:32:44 - INFO :       Start Pruning
2024-04-23 21:32:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:32:46 - INFO :       Loss = 14.9375
2024-04-23 21:32:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:32:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:32:49 - INFO :       hinglish_toxicity: Total Sparsity 1.3552441661354783e-06
2024-04-23 21:33:21 - INFO :       hinglish_toxicity: Total Accuracy (23, 40, 0.575)
2024-04-23 21:33:21 - INFO :       
==================Finish================

2024-04-23 21:33:21 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:33:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:33:21 - INFO :       DATASET: tasksource/bigbench human_organs_senses
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 21:33:28 - INFO :       Use taylor pruner...
2024-04-23 21:33:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:33:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:33:29 - INFO :       Start Pruning
2024-04-23 21:33:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:33:31 - INFO :       Loss = 14.4921875
2024-04-23 21:33:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:33:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:33:34 - INFO :       human_organs_senses: Total Sparsity 1.3600178335047475e-06
2024-04-23 21:33:46 - INFO :       human_organs_senses: Total Accuracy (5, 16, 0.3125)
2024-04-23 21:33:46 - INFO :       
==================Finish================

2024-04-23 21:33:46 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:33:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:33:46 - INFO :       DATASET: tasksource/bigbench hyperbaton
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 21:33:54 - INFO :       Use taylor pruner...
2024-04-23 21:33:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:33:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:33:54 - INFO :       Start Pruning
2024-04-23 21:33:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:33:56 - INFO :       Loss = 15.046875
2024-04-23 21:33:58 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:33:58 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:33:59 - INFO :       hyperbaton: Total Sparsity 1.3593813445221782e-06
2024-04-23 21:34:38 - INFO :       hyperbaton: Total Accuracy (22, 50, 0.44)
2024-04-23 21:34:39 - INFO :       
==================Finish================

2024-04-23 21:34:39 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:34:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:34:39 - INFO :       DATASET: tasksource/bigbench identify_math_theorems
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 21:34:46 - INFO :       Use taylor pruner...
2024-04-23 21:34:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:34:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:34:46 - INFO :       Start Pruning
2024-04-23 21:34:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:34:48 - INFO :       Loss = 0.94091796875
2024-04-23 21:34:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:34:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:34:51 - INFO :       identify_math_theorems: Total Sparsity 1.358267488802682e-06
2024-04-23 21:35:06 - INFO :       identify_math_theorems: Total Accuracy (8, 16, 0.5)
2024-04-23 21:35:07 - INFO :       
==================Finish================

2024-04-23 21:35:07 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:35:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:35:07 - INFO :       DATASET: tasksource/bigbench identify_odd_metaphor
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 21:35:14 - INFO :       Use taylor pruner...
2024-04-23 21:35:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:35:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:35:14 - INFO :       Start Pruning
2024-04-23 21:35:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:35:17 - INFO :       Loss = 11.453125
2024-04-23 21:35:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:35:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:35:19 - INFO :       identify_odd_metaphor: Total Sparsity 1.3611316892242436e-06
2024-04-23 21:35:33 - INFO :       identify_odd_metaphor: Total Accuracy (1, 16, 0.0625)
2024-04-23 21:35:33 - INFO :       
==================Finish================

2024-04-23 21:35:33 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:35:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:35:33 - INFO :       DATASET: tasksource/bigbench implicatures
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 21:35:40 - INFO :       Use taylor pruner...
2024-04-23 21:35:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:35:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:35:40 - INFO :       Start Pruning
2024-04-23 21:35:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:35:42 - INFO :       Loss = 15.1953125
2024-04-23 21:35:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:35:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:35:45 - INFO :       implicatures: Total Sparsity 1.3604952002416743e-06
2024-04-23 21:36:26 - INFO :       implicatures: Total Accuracy (22, 50, 0.44)
2024-04-23 21:36:27 - INFO :       
==================Finish================

2024-04-23 21:36:27 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:36:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:36:27 - INFO :       DATASET: tasksource/bigbench implicit_relations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 21:36:34 - INFO :       Use taylor pruner...
2024-04-23 21:36:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:36:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:36:34 - INFO :       Start Pruning
2024-04-23 21:36:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:36:36 - INFO :       Loss = 8.234375
2024-04-23 21:36:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:36:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:36:39 - INFO :       implicit_relations: Total Sparsity 1.356517144100617e-06
2024-04-23 21:36:54 - INFO :       implicit_relations: Total Accuracy (4, 17, 0.23529411764705882)
2024-04-23 21:36:54 - INFO :       
==================Finish================

2024-04-23 21:36:54 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:36:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:36:54 - INFO :       DATASET: tasksource/bigbench indic_cause_and_effect
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 21:37:01 - INFO :       Use taylor pruner...
2024-04-23 21:37:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:37:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:37:02 - INFO :       Start Pruning
2024-04-23 21:37:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:37:04 - INFO :       Loss = 4.91796875
2024-04-23 21:37:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:37:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:37:07 - INFO :       indic_cause_and_effect: Total Sparsity 1.3579492443113975e-06
2024-04-23 21:37:48 - INFO :       indic_cause_and_effect: Total Accuracy (20, 50, 0.4)
2024-04-23 21:37:49 - INFO :       
==================Finish================

2024-04-23 21:37:49 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:37:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:37:49 - INFO :       DATASET: tasksource/bigbench intent_recognition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 21:37:56 - INFO :       Use taylor pruner...
2024-04-23 21:37:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:37:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:37:57 - INFO :       Start Pruning
2024-04-23 21:37:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:37:59 - INFO :       Loss = 11.609375
2024-04-23 21:38:00 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:38:00 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:38:02 - INFO :       intent_recognition: Total Sparsity 1.3589039777852514e-06
2024-04-23 21:38:42 - INFO :       intent_recognition: Total Accuracy (30, 50, 0.6)
2024-04-23 21:38:43 - INFO :       
==================Finish================

2024-04-23 21:38:43 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:38:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:38:43 - INFO :       DATASET: tasksource/bigbench international_phonetic_alphabet_nli
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 21:38:50 - INFO :       Use taylor pruner...
2024-04-23 21:38:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:38:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:38:51 - INFO :       Start Pruning
2024-04-23 21:38:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:38:53 - INFO :       Loss = 9.171875
2024-04-23 21:38:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:38:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:38:56 - INFO :       international_phonetic_alphabet_nli: Total Sparsity 1.358267488802682e-06
2024-04-23 21:39:17 - INFO :       international_phonetic_alphabet_nli: Total Accuracy (11, 25, 0.44)
2024-04-23 21:39:17 - INFO :       
==================Finish================

2024-04-23 21:39:17 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:39:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:39:17 - INFO :       DATASET: tasksource/bigbench intersect_geometry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 21:39:24 - INFO :       Use taylor pruner...
2024-04-23 21:39:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:39:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:39:25 - INFO :       Start Pruning
2024-04-23 21:39:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:39:27 - INFO :       Loss = 2.3984375
2024-04-23 21:39:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:39:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:39:30 - INFO :       intersect_geometry: Total Sparsity 1.3598587112591052e-06
2024-04-23 21:40:14 - INFO :       intersect_geometry: Total Accuracy (11, 50, 0.22)
2024-04-23 21:40:14 - INFO :       
==================Finish================

2024-04-23 21:40:14 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:40:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:40:14 - INFO :       DATASET: tasksource/bigbench irony_identification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 21:40:21 - INFO :       Use taylor pruner...
2024-04-23 21:40:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:40:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:40:22 - INFO :       Start Pruning
2024-04-23 21:40:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:40:24 - INFO :       Loss = 14.515625
2024-04-23 21:40:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:40:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:40:27 - INFO :       irony_identification: Total Sparsity 1.3569945108375437e-06
2024-04-23 21:40:42 - INFO :       irony_identification: Total Accuracy (8, 19, 0.42105263157894735)
2024-04-23 21:40:43 - INFO :       
==================Finish================

2024-04-23 21:40:43 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:40:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:40:43 - INFO :       DATASET: tasksource/bigbench kannada
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 21:40:50 - INFO :       Use taylor pruner...
2024-04-23 21:40:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:40:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:40:50 - INFO :       Start Pruning
2024-04-23 21:40:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:40:53 - INFO :       Loss = 6.265625
2024-04-23 21:40:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:40:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:40:55 - INFO :       kannada: Total Sparsity 1.358744855539609e-06
2024-04-23 21:41:42 - INFO :       kannada: Total Accuracy (8, 50, 0.16)
2024-04-23 21:41:43 - INFO :       
==================Finish================

2024-04-23 21:41:43 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:41:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:41:43 - INFO :       DATASET: tasksource/bigbench key_value_maps
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 21:41:50 - INFO :       Use taylor pruner...
2024-04-23 21:41:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:41:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:41:51 - INFO :       Start Pruning
2024-04-23 21:41:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:41:53 - INFO :       Loss = 7.9140625
2024-04-23 21:41:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:41:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:41:56 - INFO :       key_value_maps: Total Sparsity 1.3566762663462592e-06
2024-04-23 21:42:13 - INFO :       key_value_maps: Total Accuracy (11, 21, 0.5238095238095238)
2024-04-23 21:42:14 - INFO :       
==================Finish================

2024-04-23 21:42:14 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:42:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:42:14 - INFO :       DATASET: tasksource/bigbench known_unknowns
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 21:42:21 - INFO :       Use taylor pruner...
2024-04-23 21:42:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:42:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:42:22 - INFO :       Start Pruning
2024-04-23 21:42:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:42:24 - INFO :       Loss = 15.5546875
2024-04-23 21:42:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:42:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:42:27 - INFO :       known_unknowns: Total Sparsity 1.3585857332939668e-06
2024-04-23 21:42:39 - INFO :       known_unknowns: Total Accuracy (9, 16, 0.5625)
2024-04-23 21:42:39 - INFO :       
==================Finish================

2024-04-23 21:42:39 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:42:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:42:39 - INFO :       DATASET: tasksource/bigbench language_identification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 21:42:46 - INFO :       Use taylor pruner...
2024-04-23 21:42:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:42:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:42:47 - INFO :       Start Pruning
2024-04-23 21:42:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:42:49 - INFO :       Loss = 8.546875
2024-04-23 21:42:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:42:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:42:51 - INFO :       language_identification: Total Sparsity 1.3581083665570398e-06
2024-04-23 21:43:34 - INFO :       language_identification: Total Accuracy (2, 50, 0.04)
2024-04-23 21:43:34 - INFO :       
==================Finish================

2024-04-23 21:43:34 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:43:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:43:34 - INFO :       DATASET: tasksource/bigbench logic_grid_puzzle
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 21:43:42 - INFO :       Use taylor pruner...
2024-04-23 21:43:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:43:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:43:42 - INFO :       Start Pruning
2024-04-23 21:43:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:43:45 - INFO :       Loss = 5.7734375
2024-04-23 21:43:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:43:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:43:48 - INFO :       logic_grid_puzzle: Total Sparsity 1.359699589013463e-06
2024-04-23 21:44:32 - INFO :       logic_grid_puzzle: Total Accuracy (17, 50, 0.34)
2024-04-23 21:44:32 - INFO :       
==================Finish================

2024-04-23 21:44:32 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:44:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:44:32 - INFO :       DATASET: tasksource/bigbench logical_args
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 21:44:39 - INFO :       Use taylor pruner...
2024-04-23 21:44:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:44:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:44:40 - INFO :       Start Pruning
2024-04-23 21:44:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:44:42 - INFO :       Loss = 8.21875
2024-04-23 21:44:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:44:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:44:45 - INFO :       logical_args: Total Sparsity 1.361449933715528e-06
2024-04-23 21:44:59 - INFO :       logical_args: Total Accuracy (2, 16, 0.125)
2024-04-23 21:44:59 - INFO :       
==================Finish================

2024-04-23 21:44:59 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:44:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:44:59 - INFO :       DATASET: tasksource/bigbench logical_deduction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 21:45:06 - INFO :       Use taylor pruner...
2024-04-23 21:45:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:45:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:45:06 - INFO :       Start Pruning
2024-04-23 21:45:08 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:45:09 - INFO :       Loss = 11.4609375
2024-04-23 21:45:10 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:45:10 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:45:11 - INFO :       logical_deduction: Total Sparsity 1.3579492443113975e-06
2024-04-23 21:45:52 - INFO :       logical_deduction: Total Accuracy (15, 50, 0.3)
2024-04-23 21:45:52 - INFO :       
==================Finish================

2024-04-23 21:45:52 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:45:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:45:52 - INFO :       DATASET: tasksource/bigbench logical_fallacy_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 21:45:59 - INFO :       Use taylor pruner...
2024-04-23 21:45:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:45:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:45:59 - INFO :       Start Pruning
2024-04-23 21:46:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:46:01 - INFO :       Loss = 14.8828125
2024-04-23 21:46:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:46:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:46:04 - INFO :       logical_fallacy_detection: Total Sparsity 1.3579492443113975e-06
2024-04-23 21:46:47 - INFO :       logical_fallacy_detection: Total Accuracy (28, 50, 0.56)
2024-04-23 21:46:47 - INFO :       
==================Finish================

2024-04-23 21:46:47 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:46:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:46:47 - INFO :       DATASET: tasksource/bigbench logical_sequence
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 21:46:55 - INFO :       Use taylor pruner...
2024-04-23 21:46:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:46:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:46:55 - INFO :       Start Pruning
2024-04-23 21:46:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:46:57 - INFO :       Loss = 10.7421875
2024-04-23 21:46:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:46:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:47:00 - INFO :       logical_sequence: Total Sparsity 1.3577901220657553e-06
2024-04-23 21:47:13 - INFO :       logical_sequence: Total Accuracy (1, 16, 0.0625)
2024-04-23 21:47:13 - INFO :       
==================Finish================

2024-04-23 21:47:13 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:47:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:47:13 - INFO :       DATASET: tasksource/bigbench mathematical_induction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 21:47:21 - INFO :       Use taylor pruner...
2024-04-23 21:47:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:47:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:47:21 - INFO :       Start Pruning
2024-04-23 21:47:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:47:23 - INFO :       Loss = 15.0
2024-04-23 21:47:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:47:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:47:26 - INFO :       mathematical_induction: Total Sparsity 1.3569945108375437e-06
2024-04-23 21:47:39 - INFO :       mathematical_induction: Total Accuracy (8, 16, 0.5)
2024-04-23 21:47:39 - INFO :       
==================Finish================

2024-04-23 21:47:39 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:47:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:47:39 - INFO :       DATASET: tasksource/bigbench medical_questions_russian
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 21:47:46 - INFO :       Use taylor pruner...
2024-04-23 21:47:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:47:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:47:46 - INFO :       Start Pruning
2024-04-23 21:47:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:47:49 - INFO :       Loss = 8.1484375
2024-04-23 21:47:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:47:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:47:51 - INFO :       medical_questions_russian: Total Sparsity 1.3573127553288283e-06
2024-04-23 21:48:34 - INFO :       medical_questions_russian: Total Accuracy (27, 50, 0.54)
2024-04-23 21:48:34 - INFO :       
==================Finish================

2024-04-23 21:48:34 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:48:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:48:34 - INFO :       DATASET: tasksource/bigbench metaphor_boolean
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 21:48:42 - INFO :       Use taylor pruner...
2024-04-23 21:48:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:48:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:48:42 - INFO :       Start Pruning
2024-04-23 21:48:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:48:44 - INFO :       Loss = 14.4921875
2024-04-23 21:48:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:48:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:48:47 - INFO :       metaphor_boolean: Total Sparsity 1.3566762663462592e-06
2024-04-23 21:49:28 - INFO :       metaphor_boolean: Total Accuracy (21, 50, 0.42)
2024-04-23 21:49:28 - INFO :       
==================Finish================

2024-04-23 21:49:28 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:49:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:49:28 - INFO :       DATASET: tasksource/bigbench metaphor_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 21:49:35 - INFO :       Use taylor pruner...
2024-04-23 21:49:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:49:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:49:36 - INFO :       Start Pruning
2024-04-23 21:49:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:49:38 - INFO :       Loss = 12.0234375
2024-04-23 21:49:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:49:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:49:41 - INFO :       metaphor_understanding: Total Sparsity 1.3558806551180476e-06
2024-04-23 21:50:19 - INFO :       metaphor_understanding: Total Accuracy (9, 46, 0.1956521739130435)
2024-04-23 21:50:19 - INFO :       
==================Finish================

2024-04-23 21:50:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:50:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:50:19 - INFO :       DATASET: tasksource/bigbench misconceptions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 21:50:27 - INFO :       Use taylor pruner...
2024-04-23 21:50:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:50:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:50:27 - INFO :       Start Pruning
2024-04-23 21:50:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:50:29 - INFO :       Loss = 14.578125
2024-04-23 21:50:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:50:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:50:32 - INFO :       misconceptions: Total Sparsity 1.3546076771529093e-06
2024-04-23 21:51:06 - INFO :       misconceptions: Total Accuracy (21, 43, 0.4883720930232558)
2024-04-23 21:51:06 - INFO :       
==================Finish================

2024-04-23 21:51:06 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:51:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:51:06 - INFO :       DATASET: tasksource/bigbench mnist_ascii
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 21:51:14 - INFO :       Use taylor pruner...
2024-04-23 21:51:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:51:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:51:14 - INFO :       Start Pruning
2024-04-23 21:51:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:51:16 - INFO :       Loss = 5.00390625
2024-04-23 21:51:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:51:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:51:19 - INFO :       mnist_ascii: Total Sparsity 1.358267488802682e-06
2024-04-23 21:52:33 - INFO :       mnist_ascii: Total Accuracy (5, 50, 0.1)
2024-04-23 21:52:34 - INFO :       
==================Finish================

2024-04-23 21:52:34 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:52:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:52:34 - INFO :       DATASET: tasksource/bigbench moral_permissibility
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]
2024-04-23 21:52:42 - INFO :       Use taylor pruner...
2024-04-23 21:52:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:52:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:52:42 - INFO :       Start Pruning
2024-04-23 21:52:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:52:44 - INFO :       Loss = 13.5625
2024-04-23 21:52:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:52:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:52:47 - INFO :       moral_permissibility: Total Sparsity 1.357153633083186e-06
2024-04-23 21:53:28 - INFO :       moral_permissibility: Total Accuracy (24, 50, 0.48)
2024-04-23 21:53:28 - INFO :       
==================Finish================

2024-04-23 21:53:28 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:53:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:53:28 - INFO :       DATASET: tasksource/bigbench movie_dialog_same_or_different
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 21:53:36 - INFO :       Use taylor pruner...
2024-04-23 21:53:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:53:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:53:36 - INFO :       Start Pruning
2024-04-23 21:53:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:53:39 - INFO :       Loss = 13.5703125
2024-04-23 21:53:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:53:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:53:41 - INFO :       movie_dialog_same_or_different: Total Sparsity 1.3574718775744707e-06
2024-04-23 21:54:22 - INFO :       movie_dialog_same_or_different: Total Accuracy (27, 50, 0.54)
2024-04-23 21:54:23 - INFO :       
==================Finish================

2024-04-23 21:54:23 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:54:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:54:23 - INFO :       DATASET: tasksource/bigbench movie_recommendation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 21:54:30 - INFO :       Use taylor pruner...
2024-04-23 21:54:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:54:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:54:31 - INFO :       Start Pruning
2024-04-23 21:54:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:54:33 - INFO :       Loss = 13.890625
2024-04-23 21:54:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:54:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:54:36 - INFO :       movie_recommendation: Total Sparsity 1.3601769557503897e-06
2024-04-23 21:55:15 - INFO :       movie_recommendation: Total Accuracy (15, 50, 0.3)
2024-04-23 21:55:15 - INFO :       
==================Finish================

2024-04-23 21:55:15 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:55:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:55:15 - INFO :       DATASET: tasksource/bigbench navigate
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 21:55:23 - INFO :       Use taylor pruner...
2024-04-23 21:55:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:55:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:55:23 - INFO :       Start Pruning
2024-04-23 21:55:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:55:25 - INFO :       Loss = 15.203125
2024-04-23 21:55:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:55:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:55:28 - INFO :       navigate: Total Sparsity 1.3584266110483244e-06
2024-04-23 21:56:07 - INFO :       navigate: Total Accuracy (21, 50, 0.42)
2024-04-23 21:56:07 - INFO :       
==================Finish================

2024-04-23 21:56:07 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:56:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:56:07 - INFO :       DATASET: tasksource/bigbench nonsense_words_grammar
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 21:56:15 - INFO :       Use taylor pruner...
2024-04-23 21:56:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:56:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:56:15 - INFO :       Start Pruning
2024-04-23 21:56:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:56:18 - INFO :       Loss = 14.125
2024-04-23 21:56:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:56:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:56:21 - INFO :       nonsense_words_grammar: Total Sparsity 1.3568353885919015e-06
2024-04-23 21:56:33 - INFO :       nonsense_words_grammar: Total Accuracy (5, 16, 0.3125)
2024-04-23 21:56:33 - INFO :       
==================Finish================

2024-04-23 21:56:33 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:56:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:56:33 - INFO :       DATASET: tasksource/bigbench novel_concepts
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 21:56:41 - INFO :       Use taylor pruner...
2024-04-23 21:56:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:56:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:56:41 - INFO :       Start Pruning
2024-04-23 21:56:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:56:43 - INFO :       Loss = 13.234375
2024-04-23 21:56:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:56:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:56:46 - INFO :       novel_concepts: Total Sparsity 1.3590631000308936e-06
2024-04-23 21:56:59 - INFO :       novel_concepts: Total Accuracy (8, 16, 0.5)
2024-04-23 21:56:59 - INFO :       
==================Finish================

2024-04-23 21:56:59 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:56:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:56:59 - INFO :       DATASET: tasksource/bigbench odd_one_out
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 21:57:07 - INFO :       Use taylor pruner...
2024-04-23 21:57:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:57:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:57:07 - INFO :       Start Pruning
2024-04-23 21:57:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:57:10 - INFO :       Loss = 14.4765625
2024-04-23 21:57:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:57:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:57:12 - INFO :       odd_one_out: Total Sparsity 1.35603977736369e-06
2024-04-23 21:57:26 - INFO :       odd_one_out: Total Accuracy (1, 17, 0.058823529411764705)
2024-04-23 21:57:26 - INFO :       
==================Finish================

2024-04-23 21:57:26 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:57:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:57:26 - INFO :       DATASET: tasksource/bigbench parsinlu_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 21:57:33 - INFO :       Use taylor pruner...
2024-04-23 21:57:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:57:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:57:34 - INFO :       Start Pruning
2024-04-23 21:57:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:57:36 - INFO :       Loss = 10.0078125
2024-04-23 21:57:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:57:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:57:39 - INFO :       parsinlu_qa: Total Sparsity 1.3577901220657553e-06
2024-04-23 21:58:18 - INFO :       parsinlu_qa: Total Accuracy (11, 50, 0.22)
2024-04-23 21:58:18 - INFO :       
==================Finish================

2024-04-23 21:58:18 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:58:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:58:18 - INFO :       DATASET: tasksource/bigbench penguins_in_a_table
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 21:58:25 - INFO :       Use taylor pruner...
2024-04-23 21:58:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:58:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:58:25 - INFO :       Start Pruning
2024-04-23 21:58:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:58:27 - INFO :       Loss = 8.9765625
2024-04-23 21:58:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:58:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:58:30 - INFO :       penguins_in_a_table: Total Sparsity 1.360336077996032e-06
2024-04-23 21:58:54 - INFO :       penguins_in_a_table: Total Accuracy (12, 29, 0.41379310344827586)
2024-04-23 21:58:54 - INFO :       
==================Finish================

2024-04-23 21:58:54 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:58:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:58:54 - INFO :       DATASET: tasksource/bigbench persian_idioms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 21:59:02 - INFO :       Use taylor pruner...
2024-04-23 21:59:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:59:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:59:02 - INFO :       Start Pruning
2024-04-23 21:59:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:59:04 - INFO :       Loss = 12.1953125
2024-04-23 21:59:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:59:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:59:07 - INFO :       persian_idioms: Total Sparsity 1.3569945108375437e-06
2024-04-23 21:59:19 - INFO :       persian_idioms: Total Accuracy (1, 16, 0.0625)
2024-04-23 21:59:19 - INFO :       
==================Finish================

2024-04-23 21:59:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:59:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:59:19 - INFO :       DATASET: tasksource/bigbench phrase_relatedness
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 21:59:27 - INFO :       Use taylor pruner...
2024-04-23 21:59:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:59:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:59:27 - INFO :       Start Pruning
2024-04-23 21:59:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:59:29 - INFO :       Loss = 13.6953125
2024-04-23 21:59:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 21:59:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 21:59:32 - INFO :       phrase_relatedness: Total Sparsity 1.3579492443113975e-06
2024-04-23 21:59:48 - INFO :       phrase_relatedness: Total Accuracy (11, 20, 0.55)
2024-04-23 21:59:49 - INFO :       
==================Finish================

2024-04-23 21:59:49 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 21:59:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 21:59:49 - INFO :       DATASET: tasksource/bigbench physical_intuition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 21:59:56 - INFO :       Use taylor pruner...
2024-04-23 21:59:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:59:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 21:59:56 - INFO :       Start Pruning
2024-04-23 21:59:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 21:59:58 - INFO :       Loss = 13.6015625
2024-04-23 22:00:00 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:00:00 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:00:01 - INFO :       physical_intuition: Total Sparsity 1.3581083665570398e-06
2024-04-23 22:00:14 - INFO :       physical_intuition: Total Accuracy (9, 16, 0.5625)
2024-04-23 22:00:14 - INFO :       
==================Finish================

2024-04-23 22:00:14 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:00:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:00:14 - INFO :       DATASET: tasksource/bigbench physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 22:00:22 - INFO :       Use taylor pruner...
2024-04-23 22:00:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:00:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:00:22 - INFO :       Start Pruning
2024-04-23 22:00:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:00:24 - INFO :       Loss = 11.0234375
2024-04-23 22:00:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:00:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:00:27 - INFO :       physics: Total Sparsity 1.361449933715528e-06
2024-04-23 22:01:04 - INFO :       physics: Total Accuracy (33, 45, 0.7333333333333333)
2024-04-23 22:01:04 - INFO :       
==================Finish================

2024-04-23 22:01:04 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:01:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:01:04 - INFO :       DATASET: tasksource/bigbench play_dialog_same_or_different
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 22:01:11 - INFO :       Use taylor pruner...
2024-04-23 22:01:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:01:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:01:12 - INFO :       Start Pruning
2024-04-23 22:01:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:01:14 - INFO :       Loss = 9.203125
2024-04-23 22:01:15 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:01:15 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:01:17 - INFO :       play_dialog_same_or_different: Total Sparsity 1.359222222276536e-06
2024-04-23 22:01:58 - INFO :       play_dialog_same_or_different: Total Accuracy (34, 50, 0.68)
2024-04-23 22:01:59 - INFO :       
==================Finish================

2024-04-23 22:01:59 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:01:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:01:59 - INFO :       DATASET: tasksource/bigbench presuppositions_as_nli
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 22:02:06 - INFO :       Use taylor pruner...
2024-04-23 22:02:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:02:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:02:06 - INFO :       Start Pruning
2024-04-23 22:02:08 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:02:08 - INFO :       Loss = 10.9140625
2024-04-23 22:02:10 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:02:10 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:02:11 - INFO :       presuppositions_as_nli: Total Sparsity 1.357153633083186e-06
2024-04-23 22:02:51 - INFO :       presuppositions_as_nli: Total Accuracy (23, 50, 0.46)
2024-04-23 22:02:51 - INFO :       
==================Finish================

2024-04-23 22:02:51 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:02:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:02:51 - INFO :       DATASET: tasksource/bigbench question_selection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 22:02:59 - INFO :       Use taylor pruner...
2024-04-23 22:02:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:02:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:02:59 - INFO :       Start Pruning
2024-04-23 22:03:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:03:02 - INFO :       Loss = 8.34375
2024-04-23 22:03:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:03:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:03:04 - INFO :       question_selection: Total Sparsity 1.3569945108375437e-06
2024-04-23 22:03:50 - INFO :       question_selection: Total Accuracy (12, 50, 0.24)
2024-04-23 22:03:51 - INFO :       
==================Finish================

2024-04-23 22:03:51 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:03:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:03:51 - INFO :       DATASET: tasksource/bigbench reasoning_about_colored_objects
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 22:03:58 - INFO :       Use taylor pruner...
2024-04-23 22:03:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:03:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:03:59 - INFO :       Start Pruning
2024-04-23 22:04:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:04:01 - INFO :       Loss = 11.2109375
2024-04-23 22:04:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:04:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:04:04 - INFO :       reasoning_about_colored_objects: Total Sparsity 1.3609725669786013e-06
2024-04-23 22:04:44 - INFO :       reasoning_about_colored_objects: Total Accuracy (12, 50, 0.24)
2024-04-23 22:04:44 - INFO :       
==================Finish================

2024-04-23 22:04:44 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:04:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:04:44 - INFO :       DATASET: tasksource/bigbench riddle_sense
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 22:04:51 - INFO :       Use taylor pruner...
2024-04-23 22:04:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:04:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:04:52 - INFO :       Start Pruning
2024-04-23 22:04:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:04:54 - INFO :       Loss = 13.8984375
2024-04-23 22:04:55 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:04:55 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:04:57 - INFO :       riddle_sense: Total Sparsity 1.3617681782068128e-06
2024-04-23 22:05:09 - INFO :       riddle_sense: Total Accuracy (3, 16, 0.1875)
2024-04-23 22:05:10 - INFO :       
==================Finish================

2024-04-23 22:05:10 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:05:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:05:10 - INFO :       DATASET: tasksource/bigbench ruin_names
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 22:05:17 - INFO :       Use taylor pruner...
2024-04-23 22:05:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:05:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:05:18 - INFO :       Start Pruning
2024-04-23 22:05:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:05:20 - INFO :       Loss = 13.8828125
2024-04-23 22:05:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:05:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:05:23 - INFO :       ruin_names: Total Sparsity 1.3573127553288283e-06
2024-04-23 22:06:03 - INFO :       ruin_names: Total Accuracy (11, 50, 0.22)
2024-04-23 22:06:03 - INFO :       
==================Finish================

2024-04-23 22:06:03 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:06:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:06:03 - INFO :       DATASET: tasksource/bigbench salient_translation_error_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 22:06:10 - INFO :       Use taylor pruner...
2024-04-23 22:06:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:06:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:06:11 - INFO :       Start Pruning
2024-04-23 22:06:12 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:06:13 - INFO :       Loss = 8.609375
2024-04-23 22:06:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:06:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:06:16 - INFO :       salient_translation_error_detection: Total Sparsity 1.3558806551180476e-06
2024-04-23 22:06:59 - INFO :       salient_translation_error_detection: Total Accuracy (8, 50, 0.16)
2024-04-23 22:07:00 - INFO :       
==================Finish================

2024-04-23 22:07:00 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:07:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:07:00 - INFO :       DATASET: tasksource/bigbench sentence_ambiguity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 22:07:07 - INFO :       Use taylor pruner...
2024-04-23 22:07:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:07:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:07:08 - INFO :       Start Pruning
2024-04-23 22:07:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:07:10 - INFO :       Loss = 16.28125
2024-04-23 22:07:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:07:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:07:12 - INFO :       sentence_ambiguity: Total Sparsity 1.357153633083186e-06
2024-04-23 22:07:25 - INFO :       sentence_ambiguity: Total Accuracy (9, 16, 0.5625)
2024-04-23 22:07:25 - INFO :       
==================Finish================

2024-04-23 22:07:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:07:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:07:25 - INFO :       DATASET: tasksource/bigbench similarities_abstraction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 22:07:32 - INFO :       Use taylor pruner...
2024-04-23 22:07:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:07:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:07:33 - INFO :       Start Pruning
2024-04-23 22:07:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:07:35 - INFO :       Loss = 13.953125
2024-04-23 22:07:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:07:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:07:38 - INFO :       similarities_abstraction: Total Sparsity 1.357153633083186e-06
2024-04-23 22:07:50 - INFO :       similarities_abstraction: Total Accuracy (14, 16, 0.875)
2024-04-23 22:07:50 - INFO :       
==================Finish================

2024-04-23 22:07:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:07:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:07:50 - INFO :       DATASET: tasksource/bigbench simple_ethical_questions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 22:07:58 - INFO :       Use taylor pruner...
2024-04-23 22:07:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:07:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:07:58 - INFO :       Start Pruning
2024-04-23 22:07:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:08:00 - INFO :       Loss = 12.4296875
2024-04-23 22:08:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:08:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:08:03 - INFO :       simple_ethical_questions: Total Sparsity 1.3585857332939668e-06
2024-04-23 22:08:22 - INFO :       simple_ethical_questions: Total Accuracy (8, 23, 0.34782608695652173)
2024-04-23 22:08:22 - INFO :       
==================Finish================

2024-04-23 22:08:22 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:08:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:08:22 - INFO :       DATASET: tasksource/bigbench snarks
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 22:08:29 - INFO :       Use taylor pruner...
2024-04-23 22:08:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:08:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:08:30 - INFO :       Start Pruning
2024-04-23 22:08:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:08:32 - INFO :       Loss = 14.9765625
2024-04-23 22:08:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:08:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:08:35 - INFO :       snarks: Total Sparsity 1.3558806551180476e-06
2024-04-23 22:09:04 - INFO :       snarks: Total Accuracy (3, 36, 0.08333333333333333)
2024-04-23 22:09:05 - INFO :       
==================Finish================

2024-04-23 22:09:05 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:09:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:09:05 - INFO :       DATASET: tasksource/bigbench social_iqa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 22:09:12 - INFO :       Use taylor pruner...
2024-04-23 22:09:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:09:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:09:13 - INFO :       Start Pruning
2024-04-23 22:09:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:09:15 - INFO :       Loss = 14.4453125
2024-04-23 22:09:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:09:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:09:17 - INFO :       social_iqa: Total Sparsity 1.3557215328724054e-06
2024-04-23 22:09:57 - INFO :       social_iqa: Total Accuracy (21, 50, 0.42)
2024-04-23 22:09:57 - INFO :       
==================Finish================

2024-04-23 22:09:57 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:09:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:09:57 - INFO :       DATASET: tasksource/bigbench social_support
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 22:10:05 - INFO :       Use taylor pruner...
2024-04-23 22:10:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:10:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:10:05 - INFO :       Start Pruning
2024-04-23 22:10:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:10:07 - INFO :       Loss = 13.875
2024-04-23 22:10:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:10:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:10:10 - INFO :       social_support: Total Sparsity 1.3601769557503897e-06
2024-04-23 22:10:50 - INFO :       social_support: Total Accuracy (42, 50, 0.84)
2024-04-23 22:10:50 - INFO :       
==================Finish================

2024-04-23 22:10:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:10:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:10:50 - INFO :       DATASET: tasksource/bigbench sports_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-23 22:10:58 - INFO :       Use taylor pruner...
2024-04-23 22:10:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:10:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:10:58 - INFO :       Start Pruning
2024-04-23 22:10:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:11:00 - INFO :       Loss = 15.3984375
2024-04-23 22:11:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:11:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:11:03 - INFO :       sports_understanding: Total Sparsity 1.3574718775744707e-06
2024-04-23 22:11:42 - INFO :       sports_understanding: Total Accuracy (21, 50, 0.42)
2024-04-23 22:11:42 - INFO :       
==================Finish================

2024-04-23 22:11:42 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:11:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:11:42 - INFO :       DATASET: tasksource/bigbench strange_stories
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 22:11:49 - INFO :       Use taylor pruner...
2024-04-23 22:11:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:11:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:11:50 - INFO :       Start Pruning
2024-04-23 22:11:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:11:52 - INFO :       Loss = 12.2578125
2024-04-23 22:11:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:11:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:11:55 - INFO :       strange_stories: Total Sparsity 1.358744855539609e-06
2024-04-23 22:12:23 - INFO :       strange_stories: Total Accuracy (9, 34, 0.2647058823529412)
2024-04-23 22:12:23 - INFO :       
==================Finish================

2024-04-23 22:12:23 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:12:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:12:23 - INFO :       DATASET: tasksource/bigbench strategyqa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 22:12:30 - INFO :       Use taylor pruner...
2024-04-23 22:12:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:12:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:12:31 - INFO :       Start Pruning
2024-04-23 22:12:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:12:33 - INFO :       Loss = 16.109375
2024-04-23 22:12:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:12:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:12:36 - INFO :       strategyqa: Total Sparsity 1.356517144100617e-06
2024-04-23 22:13:17 - INFO :       strategyqa: Total Accuracy (20, 50, 0.4)
2024-04-23 22:13:17 - INFO :       
==================Finish================

2024-04-23 22:13:17 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:13:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:13:17 - INFO :       DATASET: tasksource/bigbench suicide_risk
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2024-04-23 22:13:25 - INFO :       Use taylor pruner...
2024-04-23 22:13:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:13:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:13:26 - INFO :       Start Pruning
2024-04-23 22:13:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:13:28 - INFO :       Loss = 8.6640625
2024-04-23 22:13:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:13:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:13:31 - INFO :       suicide_risk: Total Sparsity 1.3581083665570398e-06
2024-04-23 22:13:46 - INFO :       suicide_risk: Total Accuracy (4, 16, 0.25)
2024-04-23 22:13:46 - INFO :       
==================Finish================

2024-04-23 22:13:46 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:13:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:13:46 - INFO :       DATASET: tasksource/bigbench swahili_english_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.45s/it]
2024-04-23 22:13:55 - INFO :       Use taylor pruner...
2024-04-23 22:13:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:13:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:13:56 - INFO :       Start Pruning
2024-04-23 22:13:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:13:58 - INFO :       Loss = 12.234375
2024-04-23 22:14:00 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:14:00 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:14:01 - INFO :       swahili_english_proverbs: Total Sparsity 1.35603977736369e-06
2024-04-23 22:14:27 - INFO :       swahili_english_proverbs: Total Accuracy (2, 30, 0.06666666666666667)
2024-04-23 22:14:27 - INFO :       
==================Finish================

2024-04-23 22:14:27 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:14:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:14:27 - INFO :       DATASET: tasksource/bigbench swedish_to_german_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2024-04-23 22:14:36 - INFO :       Use taylor pruner...
2024-04-23 22:14:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:14:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:14:36 - INFO :       Start Pruning
2024-04-23 22:14:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:14:39 - INFO :       Loss = 11.5234375
2024-04-23 22:14:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:14:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:14:42 - INFO :       swedish_to_german_proverbs: Total Sparsity 1.3573127553288283e-06
2024-04-23 22:14:54 - INFO :       swedish_to_german_proverbs: Total Accuracy (6, 16, 0.375)
2024-04-23 22:14:54 - INFO :       
==================Finish================

2024-04-23 22:14:54 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:14:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:14:54 - INFO :       DATASET: tasksource/bigbench symbol_interpretation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 22:15:02 - INFO :       Use taylor pruner...
2024-04-23 22:15:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:15:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:15:03 - INFO :       Start Pruning
2024-04-23 22:15:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:15:05 - INFO :       Loss = 4.72265625
2024-04-23 22:15:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:15:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:15:08 - INFO :       symbol_interpretation: Total Sparsity 1.360813444732959e-06
2024-04-23 22:16:14 - INFO :       symbol_interpretation: Total Accuracy (13, 50, 0.26)
2024-04-23 22:16:14 - INFO :       
==================Finish================

2024-04-23 22:16:14 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:16:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:16:14 - INFO :       DATASET: tasksource/bigbench temporal_sequences
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2024-04-23 22:16:22 - INFO :       Use taylor pruner...
2024-04-23 22:16:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:16:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:16:23 - INFO :       Start Pruning
2024-04-23 22:16:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:16:25 - INFO :       Loss = 9.5859375
2024-04-23 22:16:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:16:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:16:28 - INFO :       temporal_sequences: Total Sparsity 1.3595404667678207e-06
2024-04-23 22:17:12 - INFO :       temporal_sequences: Total Accuracy (5, 50, 0.1)
2024-04-23 22:17:12 - INFO :       
==================Finish================

2024-04-23 22:17:12 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:17:12 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:17:12 - INFO :       DATASET: tasksource/bigbench timedial
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 22:17:20 - INFO :       Use taylor pruner...
2024-04-23 22:17:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:17:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:17:20 - INFO :       Start Pruning
2024-04-23 22:17:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:17:22 - INFO :       Loss = 4.86328125
2024-04-23 22:17:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:17:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:17:25 - INFO :       timedial: Total Sparsity 1.3584266110483244e-06
2024-04-23 22:18:12 - INFO :       timedial: Total Accuracy (0, 50, 0.0)
2024-04-23 22:18:13 - INFO :       
==================Finish================

2024-04-23 22:18:13 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:18:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:18:13 - INFO :       DATASET: tasksource/bigbench tracking_shuffled_objects
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-23 22:18:21 - INFO :       Use taylor pruner...
2024-04-23 22:18:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:18:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:18:22 - INFO :       Start Pruning
2024-04-23 22:18:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:18:24 - INFO :       Loss = 11.140625
2024-04-23 22:18:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:18:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:18:27 - INFO :       tracking_shuffled_objects: Total Sparsity 1.3584266110483244e-06
2024-04-23 22:19:11 - INFO :       tracking_shuffled_objects: Total Accuracy (10, 50, 0.2)
2024-04-23 22:19:11 - INFO :       
==================Finish================

2024-04-23 22:19:11 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:19:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:19:11 - INFO :       DATASET: tasksource/bigbench understanding_fables
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]
2024-04-23 22:19:22 - INFO :       Use taylor pruner...
2024-04-23 22:19:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:19:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:19:23 - INFO :       Start Pruning
2024-04-23 22:19:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:19:25 - INFO :       Loss = 6.9140625
2024-04-23 22:19:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:19:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:19:28 - INFO :       understanding_fables: Total Sparsity 1.3609725669786013e-06
2024-04-23 22:20:02 - INFO :       understanding_fables: Total Accuracy (5, 37, 0.13513513513513514)
2024-04-23 22:20:02 - INFO :       
==================Finish================

2024-04-23 22:20:02 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:20:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:20:02 - INFO :       DATASET: tasksource/bigbench undo_permutation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2024-04-23 22:20:10 - INFO :       Use taylor pruner...
2024-04-23 22:20:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:20:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:20:10 - INFO :       Start Pruning
2024-04-23 22:20:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:20:12 - INFO :       Loss = 4.75
2024-04-23 22:20:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:20:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:20:15 - INFO :       undo_permutation: Total Sparsity 1.359222222276536e-06
2024-04-23 22:21:02 - INFO :       undo_permutation: Total Accuracy (25, 50, 0.5)
2024-04-23 22:21:02 - INFO :       
==================Finish================

2024-04-23 22:21:02 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:21:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:21:02 - INFO :       DATASET: tasksource/bigbench unit_interpretation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.36s/it]
2024-04-23 22:21:14 - INFO :       Use taylor pruner...
2024-04-23 22:21:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:21:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:21:15 - INFO :       Start Pruning
2024-04-23 22:21:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:21:19 - INFO :       Loss = 11.9921875
2024-04-23 22:21:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:21:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:21:22 - INFO :       unit_interpretation: Total Sparsity 1.360813444732959e-06
2024-04-23 22:21:39 - INFO :       unit_interpretation: Total Accuracy (5, 20, 0.25)
2024-04-23 22:21:39 - INFO :       
==================Finish================

2024-04-23 22:21:39 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:21:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:21:39 - INFO :       DATASET: tasksource/bigbench vitaminc_fact_verification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 22:21:46 - INFO :       Use taylor pruner...
2024-04-23 22:21:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:21:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:21:47 - INFO :       Start Pruning
2024-04-23 22:21:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:21:49 - INFO :       Loss = 13.1640625
2024-04-23 22:21:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:21:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:21:52 - INFO :       vitaminc_fact_verification: Total Sparsity 1.3573127553288283e-06
2024-04-23 22:22:33 - INFO :       vitaminc_fact_verification: Total Accuracy (21, 50, 0.42)
2024-04-23 22:22:33 - INFO :       
==================Finish================

2024-04-23 22:22:33 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:22:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:22:33 - INFO :       DATASET: tasksource/bigbench what_is_the_tao
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 22:22:40 - INFO :       Use taylor pruner...
2024-04-23 22:22:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:22:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:22:41 - INFO :       Start Pruning
2024-04-23 22:22:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:22:43 - INFO :       Loss = 11.9453125
2024-04-23 22:22:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:22:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:22:46 - INFO :       what_is_the_tao: Total Sparsity 1.3632002784175935e-06
2024-04-23 22:23:00 - INFO :       what_is_the_tao: Total Accuracy (4, 16, 0.25)
2024-04-23 22:23:00 - INFO :       
==================Finish================

2024-04-23 22:23:00 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 22:23:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:23:00 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2024-04-23 22:23:08 - INFO :       Use taylor pruner...
2024-04-23 22:23:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:23:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:23:09 - INFO :       Start Pruning
2024-04-23 22:23:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:23:13 - INFO :       Loss = 1.638671875
2024-04-23 22:23:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:23:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:23:16 - INFO :       which_wiki_edit: Total Sparsity 1.3549259216441938e-06
2024-04-23 22:24:52 - INFO :       which_wiki_edit: Total Accuracy (31, 50, 0.62)
2024-04-23 22:24:53 - INFO :       
==================Finish================

2024-04-23 22:24:53 - INFO :       Memory Requirement: 16809.46826171875 MiB

2024-04-23 22:24:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:24:53 - INFO :       DATASET: tasksource/bigbench winowhy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 22:25:00 - INFO :       Use taylor pruner...
2024-04-23 22:25:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:25:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:25:01 - INFO :       Start Pruning
2024-04-23 22:25:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:25:03 - INFO :       Loss = 15.2734375
2024-04-23 22:25:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:25:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:25:06 - INFO :       winowhy: Total Sparsity 1.3595404667678207e-06
2024-04-23 22:25:46 - INFO :       winowhy: Total Accuracy (29, 50, 0.58)
2024-04-23 22:25:46 - INFO :       
==================Finish================

2024-04-23 22:25:46 - INFO :       Memory Requirement: 16777.79052734375 MiB

2024-04-23 22:25:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:25:46 - INFO :       DATASET: tasksource/mmlu abstract_algebra
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 22:25:54 - INFO :       Use taylor pruner...
2024-04-23 22:25:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:25:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:25:54 - INFO :       Start Pruning
2024-04-23 22:25:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:25:57 - INFO :       Loss = 14.2421875
2024-04-23 22:25:58 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:25:58 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:25:59 - INFO :       abstract_algebra: Total Sparsity 1.3561988996093322e-06
2024-04-23 22:26:08 - INFO :       abstract_algebra: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-23 22:26:09 - INFO :       
==================Finish================

2024-04-23 22:26:09 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:26:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:26:09 - INFO :       DATASET: tasksource/mmlu anatomy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 22:26:16 - INFO :       Use taylor pruner...
2024-04-23 22:26:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:26:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:26:17 - INFO :       Start Pruning
2024-04-23 22:26:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:26:19 - INFO :       Loss = 15.1328125
2024-04-23 22:26:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:26:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:26:22 - INFO :       anatomy: Total Sparsity 1.3598587112591052e-06
2024-04-23 22:26:33 - INFO :       anatomy: Total Accuracy (9, 14, 0.6428571428571429)
2024-04-23 22:26:33 - INFO :       
==================Finish================

2024-04-23 22:26:33 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:26:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:26:33 - INFO :       DATASET: tasksource/mmlu astronomy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 22:26:41 - INFO :       Use taylor pruner...
2024-04-23 22:26:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:26:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:26:41 - INFO :       Start Pruning
2024-04-23 22:26:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:26:43 - INFO :       Loss = 14.5390625
2024-04-23 22:26:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:26:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:26:46 - INFO :       astronomy: Total Sparsity 1.3585857332939668e-06
2024-04-23 22:26:59 - INFO :       astronomy: Total Accuracy (4, 16, 0.25)
2024-04-23 22:26:59 - INFO :       
==================Finish================

2024-04-23 22:26:59 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:26:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:26:59 - INFO :       DATASET: tasksource/mmlu business_ethics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 22:27:07 - INFO :       Use taylor pruner...
2024-04-23 22:27:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:27:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:27:07 - INFO :       Start Pruning
2024-04-23 22:27:08 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:27:09 - INFO :       Loss = 13.40625
2024-04-23 22:27:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:27:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:27:12 - INFO :       business_ethics: Total Sparsity 1.358267488802682e-06
2024-04-23 22:27:21 - INFO :       business_ethics: Total Accuracy (6, 11, 0.5454545454545454)
2024-04-23 22:27:21 - INFO :       
==================Finish================

2024-04-23 22:27:21 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:27:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:27:21 - INFO :       DATASET: tasksource/mmlu clinical_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 22:27:29 - INFO :       Use taylor pruner...
2024-04-23 22:27:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:27:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:27:29 - INFO :       Start Pruning
2024-04-23 22:27:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:27:31 - INFO :       Loss = 14.390625
2024-04-23 22:27:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:27:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:27:34 - INFO :       clinical_knowledge: Total Sparsity 1.3574718775744707e-06
2024-04-23 22:27:58 - INFO :       clinical_knowledge: Total Accuracy (14, 29, 0.4827586206896552)
2024-04-23 22:27:58 - INFO :       
==================Finish================

2024-04-23 22:27:58 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:27:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:27:58 - INFO :       DATASET: tasksource/mmlu college_biology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 22:28:05 - INFO :       Use taylor pruner...
2024-04-23 22:28:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:28:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:28:06 - INFO :       Start Pruning
2024-04-23 22:28:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:28:07 - INFO :       Loss = 12.953125
2024-04-23 22:28:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:28:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:28:10 - INFO :       college_biology: Total Sparsity 1.359222222276536e-06
2024-04-23 22:28:23 - INFO :       college_biology: Total Accuracy (8, 16, 0.5)
2024-04-23 22:28:23 - INFO :       
==================Finish================

2024-04-23 22:28:23 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:28:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:28:23 - INFO :       DATASET: tasksource/mmlu college_chemistry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-23 22:28:31 - INFO :       Use taylor pruner...
2024-04-23 22:28:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:28:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:28:31 - INFO :       Start Pruning
num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-23 22:28:32 - WARNING :       num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-23 22:28:32 - WARNING :       num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-23 22:28:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:28:33 - INFO :       Loss = 14.625
2024-04-23 22:28:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:28:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:28:36 - INFO :       college_chemistry: Total Sparsity 1.3530164546964862e-06
2024-04-23 22:28:43 - INFO :       college_chemistry: Total Accuracy (2, 8, 0.25)
2024-04-23 22:28:43 - INFO :       
==================Finish================

2024-04-23 22:28:43 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:28:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:28:43 - INFO :       DATASET: tasksource/mmlu college_computer_science
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 22:28:50 - INFO :       Use taylor pruner...
2024-04-23 22:28:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:28:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:28:51 - INFO :       Start Pruning
2024-04-23 22:28:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:28:52 - INFO :       Loss = 13.796875
2024-04-23 22:28:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:28:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:28:55 - INFO :       college_computer_science: Total Sparsity 1.3579492443113975e-06
2024-04-23 22:29:04 - INFO :       college_computer_science: Total Accuracy (1, 11, 0.09090909090909091)
2024-04-23 22:29:04 - INFO :       
==================Finish================

2024-04-23 22:29:04 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:29:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:29:04 - INFO :       DATASET: tasksource/mmlu college_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 22:29:12 - INFO :       Use taylor pruner...
2024-04-23 22:29:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:29:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:29:12 - INFO :       Start Pruning
2024-04-23 22:29:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:29:14 - INFO :       Loss = 13.28125
2024-04-23 22:29:15 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:29:15 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:29:17 - INFO :       college_mathematics: Total Sparsity 1.3585857332939668e-06
2024-04-23 22:29:26 - INFO :       college_mathematics: Total Accuracy (4, 11, 0.36363636363636365)
2024-04-23 22:29:26 - INFO :       
==================Finish================

2024-04-23 22:29:26 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:29:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:29:26 - INFO :       DATASET: tasksource/mmlu college_medicine
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 22:29:33 - INFO :       Use taylor pruner...
2024-04-23 22:29:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:29:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:29:34 - INFO :       Start Pruning
2024-04-23 22:29:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:29:36 - INFO :       Loss = 13.5546875
2024-04-23 22:29:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:29:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:29:39 - INFO :       college_medicine: Total Sparsity 1.358267488802682e-06
2024-04-23 22:29:57 - INFO :       college_medicine: Total Accuracy (10, 22, 0.45454545454545453)
2024-04-23 22:29:57 - INFO :       
==================Finish================

2024-04-23 22:29:57 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:29:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:29:57 - INFO :       DATASET: tasksource/mmlu college_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 22:30:05 - INFO :       Use taylor pruner...
2024-04-23 22:30:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:30:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:30:05 - INFO :       Start Pruning
2024-04-23 22:30:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:30:07 - INFO :       Loss = 13.96875
2024-04-23 22:30:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:30:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:30:10 - INFO :       college_physics: Total Sparsity 1.358744855539609e-06
2024-04-23 22:30:20 - INFO :       college_physics: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-23 22:30:20 - INFO :       
==================Finish================

2024-04-23 22:30:20 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:30:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:30:20 - INFO :       DATASET: tasksource/mmlu computer_security
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 22:30:27 - INFO :       Use taylor pruner...
2024-04-23 22:30:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:30:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:30:28 - INFO :       Start Pruning
2024-04-23 22:30:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:30:29 - INFO :       Loss = 13.171875
2024-04-23 22:30:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:30:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:30:32 - INFO :       computer_security: Total Sparsity 1.3593813445221782e-06
2024-04-23 22:30:42 - INFO :       computer_security: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-23 22:30:42 - INFO :       
==================Finish================

2024-04-23 22:30:42 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:30:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:30:42 - INFO :       DATASET: tasksource/mmlu conceptual_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 22:30:49 - INFO :       Use taylor pruner...
2024-04-23 22:30:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:30:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:30:50 - INFO :       Start Pruning
2024-04-23 22:30:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:30:52 - INFO :       Loss = 15.703125
2024-04-23 22:30:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:30:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:30:55 - INFO :       conceptual_physics: Total Sparsity 1.3589039777852514e-06
2024-04-23 22:31:15 - INFO :       conceptual_physics: Total Accuracy (8, 26, 0.3076923076923077)
2024-04-23 22:31:15 - INFO :       
==================Finish================

2024-04-23 22:31:15 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:31:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:31:15 - INFO :       DATASET: tasksource/mmlu econometrics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 22:31:24 - INFO :       Use taylor pruner...
2024-04-23 22:31:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:31:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:31:24 - INFO :       Start Pruning
2024-04-23 22:31:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:31:27 - INFO :       Loss = 13.5703125
2024-04-23 22:31:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:31:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:31:30 - INFO :       econometrics: Total Sparsity 1.3600178335047475e-06
2024-04-23 22:31:40 - INFO :       econometrics: Total Accuracy (3, 12, 0.25)
2024-04-23 22:31:40 - INFO :       
==================Finish================

2024-04-23 22:31:40 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:31:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:31:40 - INFO :       DATASET: tasksource/mmlu electrical_engineering
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.81s/it]
2024-04-23 22:31:54 - INFO :       Use taylor pruner...
2024-04-23 22:31:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:31:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:31:54 - INFO :       Start Pruning
2024-04-23 22:31:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:31:56 - INFO :       Loss = 15.03125
2024-04-23 22:31:58 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:31:58 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:31:59 - INFO :       electrical_engineering: Total Sparsity 1.3554032883811208e-06
2024-04-23 22:32:14 - INFO :       electrical_engineering: Total Accuracy (5, 16, 0.3125)
2024-04-23 22:32:14 - INFO :       
==================Finish================

2024-04-23 22:32:14 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:32:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:32:14 - INFO :       DATASET: tasksource/mmlu elementary_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.00s/it]
2024-04-23 22:32:29 - INFO :       Use taylor pruner...
2024-04-23 22:32:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:32:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:32:29 - INFO :       Start Pruning
2024-04-23 22:32:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:32:31 - INFO :       Loss = 14.7734375
2024-04-23 22:32:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:32:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:32:34 - INFO :       elementary_mathematics: Total Sparsity 1.3593813445221782e-06
2024-04-23 22:33:10 - INFO :       elementary_mathematics: Total Accuracy (11, 41, 0.2682926829268293)
2024-04-23 22:33:10 - INFO :       
==================Finish================

2024-04-23 22:33:10 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:33:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:33:10 - INFO :       DATASET: tasksource/mmlu formal_logic
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.01s/it]
2024-04-23 22:33:24 - INFO :       Use taylor pruner...
2024-04-23 22:33:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:33:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:33:25 - INFO :       Start Pruning
2024-04-23 22:33:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:33:27 - INFO :       Loss = 13.28125
2024-04-23 22:33:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:33:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:33:31 - INFO :       formal_logic: Total Sparsity 1.3573127553288283e-06
2024-04-23 22:33:42 - INFO :       formal_logic: Total Accuracy (3, 14, 0.21428571428571427)
2024-04-23 22:33:44 - INFO :       
==================Finish================

2024-04-23 22:33:44 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:33:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:33:44 - INFO :       DATASET: tasksource/mmlu global_facts
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 22:33:52 - INFO :       Use taylor pruner...
2024-04-23 22:33:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:33:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:33:52 - INFO :       Start Pruning
2024-04-23 22:33:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:33:54 - INFO :       Loss = 14.9609375
2024-04-23 22:33:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:33:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:33:57 - INFO :       global_facts: Total Sparsity 1.3593813445221782e-06
2024-04-23 22:34:05 - INFO :       global_facts: Total Accuracy (5, 10, 0.5)
2024-04-23 22:34:05 - INFO :       
==================Finish================

2024-04-23 22:34:05 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:34:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:34:05 - INFO :       DATASET: tasksource/mmlu high_school_biology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 22:34:13 - INFO :       Use taylor pruner...
2024-04-23 22:34:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:34:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:34:13 - INFO :       Start Pruning
2024-04-23 22:34:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:34:15 - INFO :       Loss = 12.5546875
2024-04-23 22:34:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:34:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:34:18 - INFO :       high_school_biology: Total Sparsity 1.3561988996093322e-06
2024-04-23 22:34:44 - INFO :       high_school_biology: Total Accuracy (11, 32, 0.34375)
2024-04-23 22:34:44 - INFO :       
==================Finish================

2024-04-23 22:34:44 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:34:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:34:44 - INFO :       DATASET: tasksource/mmlu high_school_chemistry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 22:34:51 - INFO :       Use taylor pruner...
2024-04-23 22:34:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:34:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:34:52 - INFO :       Start Pruning
2024-04-23 22:34:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:34:54 - INFO :       Loss = 15.6015625
2024-04-23 22:34:55 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:34:55 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:34:57 - INFO :       high_school_chemistry: Total Sparsity 1.3573127553288283e-06
2024-04-23 22:35:15 - INFO :       high_school_chemistry: Total Accuracy (6, 22, 0.2727272727272727)
2024-04-23 22:35:15 - INFO :       
==================Finish================

2024-04-23 22:35:15 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:35:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:35:15 - INFO :       DATASET: tasksource/mmlu high_school_computer_science
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 22:35:23 - INFO :       Use taylor pruner...
2024-04-23 22:35:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:35:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:35:23 - INFO :       Start Pruning
num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-23 22:35:24 - WARNING :       num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-23 22:35:24 - WARNING :       num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-23 22:35:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:35:25 - INFO :       Loss = 12.96875
2024-04-23 22:35:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:35:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:35:28 - INFO :       high_school_computer_science: Total Sparsity 1.3590631000308936e-06
2024-04-23 22:35:36 - INFO :       high_school_computer_science: Total Accuracy (6, 9, 0.6666666666666666)
2024-04-23 22:35:36 - INFO :       
==================Finish================

2024-04-23 22:35:36 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:35:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:35:36 - INFO :       DATASET: tasksource/mmlu high_school_european_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 22:35:43 - INFO :       Use taylor pruner...
2024-04-23 22:35:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:35:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:35:44 - INFO :       Start Pruning
2024-04-23 22:35:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:35:46 - INFO :       Loss = 2.7265625
2024-04-23 22:35:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:35:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:35:48 - INFO :       high_school_european_history: Total Sparsity 1.362882033926309e-06
2024-04-23 22:36:05 - INFO :       high_school_european_history: Total Accuracy (9, 18, 0.5)
2024-04-23 22:36:05 - INFO :       
==================Finish================

2024-04-23 22:36:05 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:36:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:36:05 - INFO :       DATASET: tasksource/mmlu high_school_geography
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 22:36:13 - INFO :       Use taylor pruner...
2024-04-23 22:36:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:36:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:36:13 - INFO :       Start Pruning
2024-04-23 22:36:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:36:15 - INFO :       Loss = 14.9296875
2024-04-23 22:36:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:36:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:36:18 - INFO :       high_school_geography: Total Sparsity 1.3601769557503897e-06
2024-04-23 22:36:36 - INFO :       high_school_geography: Total Accuracy (16, 22, 0.7272727272727273)
2024-04-23 22:36:36 - INFO :       
==================Finish================

2024-04-23 22:36:36 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:36:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:36:36 - INFO :       DATASET: tasksource/mmlu high_school_government_and_politics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 22:36:43 - INFO :       Use taylor pruner...
2024-04-23 22:36:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:36:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:36:44 - INFO :       Start Pruning
2024-04-23 22:36:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:36:45 - INFO :       Loss = 14.796875
2024-04-23 22:36:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:36:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:36:48 - INFO :       high_school_government_and_politics: Total Sparsity 1.3589039777852514e-06
2024-04-23 22:37:05 - INFO :       high_school_government_and_politics: Total Accuracy (6, 21, 0.2857142857142857)
2024-04-23 22:37:05 - INFO :       
==================Finish================

2024-04-23 22:37:05 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:37:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:37:05 - INFO :       DATASET: tasksource/mmlu high_school_macroeconomics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 22:37:13 - INFO :       Use taylor pruner...
2024-04-23 22:37:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:37:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:37:13 - INFO :       Start Pruning
2024-04-23 22:37:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:37:15 - INFO :       Loss = 14.515625
2024-04-23 22:37:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:37:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:37:18 - INFO :       high_school_macroeconomics: Total Sparsity 1.3609725669786013e-06
2024-04-23 22:37:54 - INFO :       high_school_macroeconomics: Total Accuracy (17, 43, 0.3953488372093023)
2024-04-23 22:37:54 - INFO :       
==================Finish================

2024-04-23 22:37:54 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:37:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:37:54 - INFO :       DATASET: tasksource/mmlu high_school_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]
2024-04-23 22:38:06 - INFO :       Use taylor pruner...
2024-04-23 22:38:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:38:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:38:06 - INFO :       Start Pruning
2024-04-23 22:38:07 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:38:08 - INFO :       Loss = 13.953125
2024-04-23 22:38:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:38:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:38:11 - INFO :       high_school_mathematics: Total Sparsity 1.3569945108375437e-06
2024-04-23 22:38:35 - INFO :       high_school_mathematics: Total Accuracy (4, 29, 0.13793103448275862)
2024-04-23 22:38:35 - INFO :       
==================Finish================

2024-04-23 22:38:35 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:38:35 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:38:35 - INFO :       DATASET: tasksource/mmlu high_school_microeconomics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 22:38:42 - INFO :       Use taylor pruner...
2024-04-23 22:38:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:38:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:38:43 - INFO :       Start Pruning
2024-04-23 22:38:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:38:45 - INFO :       Loss = 14.0234375
2024-04-23 22:38:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:38:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:38:48 - INFO :       high_school_microeconomics: Total Sparsity 1.3595404667678207e-06
2024-04-23 22:39:08 - INFO :       high_school_microeconomics: Total Accuracy (9, 26, 0.34615384615384615)
2024-04-23 22:39:08 - INFO :       
==================Finish================

2024-04-23 22:39:08 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:39:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:39:08 - INFO :       DATASET: tasksource/mmlu high_school_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 22:39:16 - INFO :       Use taylor pruner...
2024-04-23 22:39:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:39:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:39:16 - INFO :       Start Pruning
2024-04-23 22:39:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:39:18 - INFO :       Loss = 12.6015625
2024-04-23 22:39:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:39:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:39:21 - INFO :       high_school_physics: Total Sparsity 1.3595404667678207e-06
2024-04-23 22:39:35 - INFO :       high_school_physics: Total Accuracy (3, 17, 0.17647058823529413)
2024-04-23 22:39:35 - INFO :       
==================Finish================

2024-04-23 22:39:35 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:39:35 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:39:35 - INFO :       DATASET: tasksource/mmlu high_school_psychology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 22:39:43 - INFO :       Use taylor pruner...
2024-04-23 22:39:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:39:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:39:43 - INFO :       Start Pruning
2024-04-23 22:39:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:39:45 - INFO :       Loss = 14.2421875
2024-04-23 22:39:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:39:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:39:48 - INFO :       high_school_psychology: Total Sparsity 1.3585857332939668e-06
2024-04-23 22:40:29 - INFO :       high_school_psychology: Total Accuracy (29, 50, 0.58)
2024-04-23 22:40:29 - INFO :       
==================Finish================

2024-04-23 22:40:29 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:40:29 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:40:29 - INFO :       DATASET: tasksource/mmlu high_school_statistics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 22:40:37 - INFO :       Use taylor pruner...
2024-04-23 22:40:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:40:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:40:37 - INFO :       Start Pruning
2024-04-23 22:40:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:40:39 - INFO :       Loss = 11.9296875
2024-04-23 22:40:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:40:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:40:42 - INFO :       high_school_statistics: Total Sparsity 1.3609725669786013e-06
2024-04-23 22:41:01 - INFO :       high_school_statistics: Total Accuracy (5, 23, 0.21739130434782608)
2024-04-23 22:41:01 - INFO :       
==================Finish================

2024-04-23 22:41:01 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:41:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:41:01 - INFO :       DATASET: tasksource/mmlu high_school_us_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 22:41:09 - INFO :       Use taylor pruner...
2024-04-23 22:41:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:41:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:41:09 - INFO :       Start Pruning
2024-04-23 22:41:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:41:11 - INFO :       Loss = 6.71875
2024-04-23 22:41:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:41:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:41:14 - INFO :       high_school_us_history: Total Sparsity 1.358267488802682e-06
2024-04-23 22:41:33 - INFO :       high_school_us_history: Total Accuracy (12, 22, 0.5454545454545454)
2024-04-23 22:41:33 - INFO :       
==================Finish================

2024-04-23 22:41:33 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:41:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:41:33 - INFO :       DATASET: tasksource/mmlu high_school_world_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 22:41:41 - INFO :       Use taylor pruner...
2024-04-23 22:41:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:41:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:41:41 - INFO :       Start Pruning
2024-04-23 22:41:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:41:43 - INFO :       Loss = 6.296875
2024-04-23 22:41:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:41:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:41:46 - INFO :       high_school_world_history: Total Sparsity 1.3577901220657553e-06
2024-04-23 22:42:10 - INFO :       high_school_world_history: Total Accuracy (10, 26, 0.38461538461538464)
2024-04-23 22:42:10 - INFO :       
==================Finish================

2024-04-23 22:42:10 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:42:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:42:10 - INFO :       DATASET: tasksource/mmlu human_aging
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 22:42:18 - INFO :       Use taylor pruner...
2024-04-23 22:42:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:42:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:42:19 - INFO :       Start Pruning
2024-04-23 22:42:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:42:20 - INFO :       Loss = 15.1171875
2024-04-23 22:42:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:42:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:42:23 - INFO :       human_aging: Total Sparsity 1.3590631000308936e-06
2024-04-23 22:42:42 - INFO :       human_aging: Total Accuracy (12, 23, 0.5217391304347826)
2024-04-23 22:42:42 - INFO :       
==================Finish================

2024-04-23 22:42:42 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:42:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:42:42 - INFO :       DATASET: tasksource/mmlu human_sexuality
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2024-04-23 22:42:50 - INFO :       Use taylor pruner...
2024-04-23 22:42:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:42:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:42:50 - INFO :       Start Pruning
2024-04-23 22:42:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:42:52 - INFO :       Loss = 15.5
2024-04-23 22:42:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:42:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:42:55 - INFO :       human_sexuality: Total Sparsity 1.3584266110483244e-06
2024-04-23 22:43:05 - INFO :       human_sexuality: Total Accuracy (3, 12, 0.25)
2024-04-23 22:43:05 - INFO :       
==================Finish================

2024-04-23 22:43:05 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:43:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:43:05 - INFO :       DATASET: tasksource/mmlu international_law
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2024-04-23 22:43:12 - INFO :       Use taylor pruner...
2024-04-23 22:43:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:43:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:43:13 - INFO :       Start Pruning
2024-04-23 22:43:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:43:15 - INFO :       Loss = 14.390625
2024-04-23 22:43:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:43:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:43:18 - INFO :       international_law: Total Sparsity 1.3549259216441938e-06
2024-04-23 22:43:29 - INFO :       international_law: Total Accuracy (10, 13, 0.7692307692307693)
2024-04-23 22:43:29 - INFO :       
==================Finish================

2024-04-23 22:43:29 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:43:29 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:43:29 - INFO :       DATASET: tasksource/mmlu jurisprudence
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 22:43:36 - INFO :       Use taylor pruner...
2024-04-23 22:43:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:43:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:43:37 - INFO :       Start Pruning
2024-04-23 22:43:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:43:39 - INFO :       Loss = 14.2109375
2024-04-23 22:43:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:43:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:43:42 - INFO :       jurisprudence: Total Sparsity 1.3619273004524551e-06
2024-04-23 22:43:50 - INFO :       jurisprudence: Total Accuracy (4, 11, 0.36363636363636365)
2024-04-23 22:43:50 - INFO :       
==================Finish================

2024-04-23 22:43:50 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:43:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:43:50 - INFO :       DATASET: tasksource/mmlu logical_fallacies
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 22:43:58 - INFO :       Use taylor pruner...
2024-04-23 22:43:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:43:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:43:58 - INFO :       Start Pruning
2024-04-23 22:43:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:44:00 - INFO :       Loss = 14.890625
2024-04-23 22:44:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:44:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:44:03 - INFO :       logical_fallacies: Total Sparsity 1.3566762663462592e-06
2024-04-23 22:44:18 - INFO :       logical_fallacies: Total Accuracy (10, 18, 0.5555555555555556)
2024-04-23 22:44:18 - INFO :       
==================Finish================

2024-04-23 22:44:18 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:44:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:44:18 - INFO :       DATASET: tasksource/mmlu machine_learning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 22:44:25 - INFO :       Use taylor pruner...
2024-04-23 22:44:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:44:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:44:25 - INFO :       Start Pruning
2024-04-23 22:44:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:44:27 - INFO :       Loss = 13.4453125
2024-04-23 22:44:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:44:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:44:30 - INFO :       machine_learning: Total Sparsity 1.3579492443113975e-06
2024-04-23 22:44:39 - INFO :       machine_learning: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-23 22:44:39 - INFO :       
==================Finish================

2024-04-23 22:44:39 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:44:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:44:39 - INFO :       DATASET: tasksource/mmlu management
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 22:44:47 - INFO :       Use taylor pruner...
2024-04-23 22:44:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:44:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:44:47 - INFO :       Start Pruning
2024-04-23 22:44:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:44:49 - INFO :       Loss = 15.0078125
2024-04-23 22:44:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:44:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:44:52 - INFO :       management: Total Sparsity 1.3606543224873167e-06
2024-04-23 22:45:01 - INFO :       management: Total Accuracy (7, 11, 0.6363636363636364)
2024-04-23 22:45:01 - INFO :       
==================Finish================

2024-04-23 22:45:01 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:45:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:45:01 - INFO :       DATASET: tasksource/mmlu marketing
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 22:45:08 - INFO :       Use taylor pruner...
2024-04-23 22:45:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:45:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:45:09 - INFO :       Start Pruning
2024-04-23 22:45:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:45:10 - INFO :       Loss = 14.6640625
2024-04-23 22:45:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:45:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:45:13 - INFO :       marketing: Total Sparsity 1.3569945108375437e-06
2024-04-23 22:45:34 - INFO :       marketing: Total Accuracy (13, 25, 0.52)
2024-04-23 22:45:34 - INFO :       
==================Finish================

2024-04-23 22:45:34 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:45:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:45:34 - INFO :       DATASET: tasksource/mmlu medical_genetics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 22:45:41 - INFO :       Use taylor pruner...
2024-04-23 22:45:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:45:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:45:42 - INFO :       Start Pruning
2024-04-23 22:45:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:45:44 - INFO :       Loss = 14.6875
2024-04-23 22:45:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:45:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:45:47 - INFO :       medical_genetics: Total Sparsity 1.3595404667678207e-06
2024-04-23 22:45:55 - INFO :       medical_genetics: Total Accuracy (8, 11, 0.7272727272727273)
2024-04-23 22:45:55 - INFO :       
==================Finish================

2024-04-23 22:45:55 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:45:55 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:45:55 - INFO :       DATASET: tasksource/mmlu miscellaneous
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 22:46:03 - INFO :       Use taylor pruner...
2024-04-23 22:46:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:46:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:46:03 - INFO :       Start Pruning
2024-04-23 22:46:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:46:05 - INFO :       Loss = 15.609375
2024-04-23 22:46:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:46:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:46:08 - INFO :       miscellaneous: Total Sparsity 1.355562410626763e-06
2024-04-23 22:46:48 - INFO :       miscellaneous: Total Accuracy (28, 50, 0.56)
2024-04-23 22:46:48 - INFO :       
==================Finish================

2024-04-23 22:46:48 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:46:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:46:48 - INFO :       DATASET: tasksource/mmlu moral_disputes
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 22:46:56 - INFO :       Use taylor pruner...
2024-04-23 22:46:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:46:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:46:56 - INFO :       Start Pruning
2024-04-23 22:46:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:46:58 - INFO :       Loss = 14.7421875
2024-04-23 22:47:00 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:47:00 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:47:01 - INFO :       moral_disputes: Total Sparsity 1.3584266110483244e-06
2024-04-23 22:47:32 - INFO :       moral_disputes: Total Accuracy (17, 38, 0.4473684210526316)
2024-04-23 22:47:32 - INFO :       
==================Finish================

2024-04-23 22:47:32 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:47:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:47:32 - INFO :       DATASET: tasksource/mmlu moral_scenarios
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-23 22:47:40 - INFO :       Use taylor pruner...
2024-04-23 22:47:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:47:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:47:40 - INFO :       Start Pruning
2024-04-23 22:47:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:47:42 - INFO :       Loss = 13.6875
2024-04-23 22:47:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:47:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:47:45 - INFO :       moral_scenarios: Total Sparsity 1.3593813445221782e-06
2024-04-23 22:48:26 - INFO :       moral_scenarios: Total Accuracy (18, 50, 0.36)
2024-04-23 22:48:26 - INFO :       
==================Finish================

2024-04-23 22:48:26 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:48:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:48:26 - INFO :       DATASET: tasksource/mmlu nutrition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 22:48:33 - INFO :       Use taylor pruner...
2024-04-23 22:48:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:48:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:48:34 - INFO :       Start Pruning
2024-04-23 22:48:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:48:36 - INFO :       Loss = 15.0390625
2024-04-23 22:48:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:48:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:48:38 - INFO :       nutrition: Total Sparsity 1.359222222276536e-06
2024-04-23 22:49:05 - INFO :       nutrition: Total Accuracy (15, 33, 0.45454545454545453)
2024-04-23 22:49:05 - INFO :       
==================Finish================

2024-04-23 22:49:05 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:49:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:49:05 - INFO :       DATASET: tasksource/mmlu philosophy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 22:49:13 - INFO :       Use taylor pruner...
2024-04-23 22:49:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:49:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:49:13 - INFO :       Start Pruning
2024-04-23 22:49:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:49:16 - INFO :       Loss = 14.4453125
2024-04-23 22:49:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:49:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:49:18 - INFO :       philosophy: Total Sparsity 1.3589039777852514e-06
2024-04-23 22:49:45 - INFO :       philosophy: Total Accuracy (17, 34, 0.5)
2024-04-23 22:49:45 - INFO :       
==================Finish================

2024-04-23 22:49:45 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:49:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:49:45 - INFO :       DATASET: tasksource/mmlu prehistory
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 22:49:53 - INFO :       Use taylor pruner...
2024-04-23 22:49:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:49:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:49:53 - INFO :       Start Pruning
2024-04-23 22:49:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:49:55 - INFO :       Loss = 14.5546875
2024-04-23 22:49:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:49:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:49:58 - INFO :       prehistory: Total Sparsity 1.3573127553288283e-06
2024-04-23 22:50:26 - INFO :       prehistory: Total Accuracy (17, 35, 0.4857142857142857)
2024-04-23 22:50:26 - INFO :       
==================Finish================

2024-04-23 22:50:26 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:50:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:50:26 - INFO :       DATASET: tasksource/mmlu professional_accounting
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 22:50:34 - INFO :       Use taylor pruner...
2024-04-23 22:50:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:50:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:50:34 - INFO :       Start Pruning
2024-04-23 22:50:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:50:36 - INFO :       Loss = 13.6171875
2024-04-23 22:50:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:50:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:50:39 - INFO :       professional_accounting: Total Sparsity 1.3581083665570398e-06
2024-04-23 22:51:05 - INFO :       professional_accounting: Total Accuracy (11, 31, 0.3548387096774194)
2024-04-23 22:51:05 - INFO :       
==================Finish================

2024-04-23 22:51:05 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:51:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:51:05 - INFO :       DATASET: tasksource/mmlu professional_law
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 22:51:13 - INFO :       Use taylor pruner...
2024-04-23 22:51:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:51:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:51:13 - INFO :       Start Pruning
2024-04-23 22:51:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:51:15 - INFO :       Loss = 6.44140625
2024-04-23 22:51:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:51:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:51:18 - INFO :       professional_law: Total Sparsity 1.358267488802682e-06
2024-04-23 22:52:01 - INFO :       professional_law: Total Accuracy (11, 50, 0.22)
2024-04-23 22:52:01 - INFO :       
==================Finish================

2024-04-23 22:52:01 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:52:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:52:01 - INFO :       DATASET: tasksource/mmlu professional_medicine
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 22:52:09 - INFO :       Use taylor pruner...
2024-04-23 22:52:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:52:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:52:10 - INFO :       Start Pruning
2024-04-23 22:52:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:52:12 - INFO :       Loss = 10.65625
2024-04-23 22:52:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:52:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:52:14 - INFO :       professional_medicine: Total Sparsity 1.3561988996093322e-06
2024-04-23 22:52:41 - INFO :       professional_medicine: Total Accuracy (11, 31, 0.3548387096774194)
2024-04-23 22:52:41 - INFO :       
==================Finish================

2024-04-23 22:52:41 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:52:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:52:41 - INFO :       DATASET: tasksource/mmlu professional_psychology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 22:52:49 - INFO :       Use taylor pruner...
2024-04-23 22:52:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:52:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:52:50 - INFO :       Start Pruning
2024-04-23 22:52:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:52:52 - INFO :       Loss = 13.765625
2024-04-23 22:52:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:52:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:52:55 - INFO :       professional_psychology: Total Sparsity 1.358267488802682e-06
2024-04-23 22:53:35 - INFO :       professional_psychology: Total Accuracy (20, 50, 0.4)
2024-04-23 22:53:35 - INFO :       
==================Finish================

2024-04-23 22:53:35 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:53:35 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:53:35 - INFO :       DATASET: tasksource/mmlu public_relations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 22:53:43 - INFO :       Use taylor pruner...
2024-04-23 22:53:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:53:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:53:43 - INFO :       Start Pruning
2024-04-23 22:53:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:53:45 - INFO :       Loss = 15.3828125
2024-04-23 22:53:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:53:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:53:48 - INFO :       public_relations: Total Sparsity 1.3566762663462592e-06
2024-04-23 22:53:58 - INFO :       public_relations: Total Accuracy (5, 12, 0.4166666666666667)
2024-04-23 22:53:58 - INFO :       
==================Finish================

2024-04-23 22:53:58 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:53:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:53:58 - INFO :       DATASET: tasksource/mmlu security_studies
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 22:54:06 - INFO :       Use taylor pruner...
2024-04-23 22:54:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:54:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:54:06 - INFO :       Start Pruning
2024-04-23 22:54:07 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:54:08 - INFO :       Loss = 11.6796875
2024-04-23 22:54:10 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:54:10 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:54:11 - INFO :       security_studies: Total Sparsity 1.3593813445221782e-06
2024-04-23 22:54:34 - INFO :       security_studies: Total Accuracy (10, 27, 0.37037037037037035)
2024-04-23 22:54:35 - INFO :       
==================Finish================

2024-04-23 22:54:35 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:54:35 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:54:35 - INFO :       DATASET: tasksource/mmlu sociology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 22:54:43 - INFO :       Use taylor pruner...
2024-04-23 22:54:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:54:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:54:43 - INFO :       Start Pruning
2024-04-23 22:54:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:54:46 - INFO :       Loss = 15.0625
2024-04-23 22:54:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:54:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:54:48 - INFO :       sociology: Total Sparsity 1.35603977736369e-06
2024-04-23 22:55:06 - INFO :       sociology: Total Accuracy (10, 22, 0.45454545454545453)
2024-04-23 22:55:06 - INFO :       
==================Finish================

2024-04-23 22:55:06 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:55:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:55:06 - INFO :       DATASET: tasksource/mmlu us_foreign_policy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 22:55:14 - INFO :       Use taylor pruner...
2024-04-23 22:55:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:55:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:55:15 - INFO :       Start Pruning
2024-04-23 22:55:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:55:17 - INFO :       Loss = 14.984375
2024-04-23 22:55:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:55:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:55:19 - INFO :       us_foreign_policy: Total Sparsity 1.3573127553288283e-06
2024-04-23 22:55:28 - INFO :       us_foreign_policy: Total Accuracy (7, 11, 0.6363636363636364)
2024-04-23 22:55:28 - INFO :       
==================Finish================

2024-04-23 22:55:28 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:55:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:55:28 - INFO :       DATASET: tasksource/mmlu virology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 22:55:37 - INFO :       Use taylor pruner...
2024-04-23 22:55:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:55:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:55:37 - INFO :       Start Pruning
2024-04-23 22:55:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:55:39 - INFO :       Loss = 14.8984375
2024-04-23 22:55:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:55:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:55:42 - INFO :       virology: Total Sparsity 1.3542894326616245e-06
2024-04-23 22:55:56 - INFO :       virology: Total Accuracy (9, 18, 0.5)
2024-04-23 22:55:56 - INFO :       
==================Finish================

2024-04-23 22:55:56 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:55:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:55:56 - INFO :       DATASET: tasksource/mmlu world_religions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 22:56:04 - INFO :       Use taylor pruner...
2024-04-23 22:56:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:56:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:56:04 - INFO :       Start Pruning
2024-04-23 22:56:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:56:06 - INFO :       Loss = 14.9765625
2024-04-23 22:56:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:56:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:56:09 - INFO :       world_religions: Total Sparsity 1.3557215328724054e-06
2024-04-23 22:56:24 - INFO :       world_religions: Total Accuracy (12, 19, 0.631578947368421)
2024-04-23 22:56:24 - INFO :       
==================Finish================

2024-04-23 22:56:24 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:56:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:56:24 - INFO :       DATASET: math_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 22:56:32 - INFO :       Use taylor pruner...
2024-04-23 22:56:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:56:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:56:32 - INFO :       Start Pruning
2024-04-23 22:56:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:56:34 - INFO :       Loss = 13.1640625
2024-04-23 22:56:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:56:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:56:37 - INFO :       math_qa: Total Sparsity 1.3577901220657553e-06
2024-04-23 22:57:14 - INFO :       math_qa: Accuracy (9, 50, 0.18)
2024-04-23 22:57:14 - INFO :       
==================Finish================

2024-04-23 22:57:14 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:57:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:57:14 - INFO :       DATASET: EleutherAI/truthful_qa_mc
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 22:57:21 - INFO :       Use taylor pruner...
2024-04-23 22:57:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:57:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:57:22 - INFO :       Start Pruning
2024-04-23 22:57:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:57:24 - INFO :       Loss = 14.359375
2024-04-23 22:57:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:57:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:57:27 - INFO :       truthful_qa_mc: Total Sparsity 1.3609725669786013e-06
2024-04-23 22:58:01 - INFO :       truthful_qa_mc: Accuracy (17, 50, 0.34)
2024-04-23 22:58:01 - INFO :       
==================Finish================

2024-04-23 22:58:01 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:58:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:58:01 - INFO :       DATASET: derek-thomas/ScienceQA
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 22:58:10 - INFO :       Use taylor pruner...
2024-04-23 22:58:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:58:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:58:10 - INFO :       Start Pruning
2024-04-23 22:58:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:58:12 - INFO :       Loss = 15.6875
2024-04-23 22:58:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:58:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:58:15 - INFO :       ScienceQA: Total Sparsity 1.3593813445221782e-06
2024-04-23 22:58:50 - INFO :       ScienceQA: Accuracy (31, 50, 0.62)
2024-04-23 22:58:50 - INFO :       
==================Finish================

2024-04-23 22:58:50 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-23 22:58:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:58:50 - INFO :       DATASET: commonsense_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 22:58:58 - INFO :       Use taylor pruner...
2024-04-23 22:58:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:58:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:58:58 - INFO :       Start Pruning
2024-04-23 22:58:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:59:00 - INFO :       Loss = 15.09375
2024-04-23 22:59:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:59:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:59:03 - INFO :       commonsense_qa: Total Sparsity 1.356517144100617e-06
2024-04-23 22:59:37 - INFO :       commonsense_qa: Accuracy (30, 50, 0.6)
2024-04-23 22:59:37 - INFO :       
==================Finish================

2024-04-23 22:59:37 - INFO :       Memory Requirement: 16770.79052734375 MiB

End: Memory Requirement: 3979.2666015625 MiB

Begin: Memory Requirement: 3979.2666015625 MiB

2024-04-23 22:59:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 22:59:37 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Index 4
Sparsity 3.5000000000000004 %
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 22:59:46 - INFO :       Use taylor pruner...
2024-04-23 22:59:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:59:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 22:59:46 - INFO :       Start Pruning
2024-04-23 22:59:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 22:59:49 - INFO :       Loss = 1.5625
2024-04-23 22:59:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 22:59:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 22:59:52 - INFO :       which_wiki_edit: Total Sparsity 1.3554032883811208e-06
2024-04-23 23:01:26 - INFO :       which_wiki_edit: Total Accuracy (29, 50, 0.58)
2024-04-23 23:01:26 - INFO :       
==================Finish================

2024-04-23 23:01:26 - INFO :       Memory Requirement: 16849.60302734375 MiB

2024-04-23 23:01:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:01:26 - INFO :       DATASET: tasksource/bigbench abstract_narrative_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 23:01:34 - INFO :       Use taylor pruner...
2024-04-23 23:01:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:01:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:01:34 - INFO :       Start Pruning
2024-04-23 23:01:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:01:36 - INFO :       Loss = 7.375
2024-04-23 23:01:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:01:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:01:39 - INFO :       abstract_narrative_understanding: Total Sparsity 1.3590631000308936e-06
2024-04-23 23:02:20 - INFO :       abstract_narrative_understanding: Total Accuracy (13, 50, 0.26)
2024-04-23 23:02:20 - INFO :       
==================Finish================

2024-04-23 23:02:20 - INFO :       Memory Requirement: 16772.79052734375 MiB

2024-04-23 23:02:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:02:20 - INFO :       DATASET: tasksource/bigbench anachronisms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 23:02:28 - INFO :       Use taylor pruner...
2024-04-23 23:02:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:02:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:02:28 - INFO :       Start Pruning
2024-04-23 23:02:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:02:30 - INFO :       Loss = 15.9453125
2024-04-23 23:02:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:02:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:02:33 - INFO :       anachronisms: Total Sparsity 1.3584266110483244e-06
2024-04-23 23:03:09 - INFO :       anachronisms: Total Accuracy (25, 46, 0.5434782608695652)
2024-04-23 23:03:09 - INFO :       
==================Finish================

2024-04-23 23:03:09 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-23 23:03:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:03:09 - INFO :       DATASET: tasksource/bigbench analogical_similarity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 23:03:17 - INFO :       Use taylor pruner...
2024-04-23 23:03:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:03:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:03:17 - INFO :       Start Pruning
2024-04-23 23:03:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:03:19 - INFO :       Loss = 1.46875
2024-04-23 23:03:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:03:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:03:22 - INFO :       analogical_similarity: Total Sparsity 1.3584266110483244e-06
2024-04-23 23:04:15 - INFO :       analogical_similarity: Total Accuracy (3, 50, 0.06)
2024-04-23 23:04:15 - INFO :       
==================Finish================

2024-04-23 23:04:15 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-23 23:04:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:04:15 - INFO :       DATASET: tasksource/bigbench analytic_entailment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 23:04:23 - INFO :       Use taylor pruner...
2024-04-23 23:04:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:04:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:04:23 - INFO :       Start Pruning
2024-04-23 23:04:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:04:25 - INFO :       Loss = 15.203125
2024-04-23 23:04:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:04:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:04:28 - INFO :       analytic_entailment: Total Sparsity 1.3601769557503897e-06
2024-04-23 23:04:41 - INFO :       analytic_entailment: Total Accuracy (8, 16, 0.5)
2024-04-23 23:04:41 - INFO :       
==================Finish================

2024-04-23 23:04:41 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-23 23:04:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:04:41 - INFO :       DATASET: tasksource/bigbench arithmetic
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 23:04:49 - INFO :       Use taylor pruner...
2024-04-23 23:04:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:04:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:04:49 - INFO :       Start Pruning
2024-04-23 23:04:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:04:51 - INFO :       Loss = 11.84375
2024-04-23 23:04:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:04:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:04:54 - INFO :       arithmetic: Total Sparsity 1.3593813445221782e-06
2024-04-23 23:05:35 - INFO :       arithmetic: Total Accuracy (4, 50, 0.08)
2024-04-23 23:05:35 - INFO :       
==================Finish================

2024-04-23 23:05:35 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-23 23:05:35 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:05:35 - INFO :       DATASET: tasksource/bigbench authorship_verification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 23:05:42 - INFO :       Use taylor pruner...
2024-04-23 23:05:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:05:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:05:43 - INFO :       Start Pruning
2024-04-23 23:05:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:05:46 - INFO :       Loss = 2.814453125
2024-04-23 23:05:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:05:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:05:48 - INFO :       authorship_verification: Total Sparsity 1.356517144100617e-06
2024-04-23 23:07:54 - INFO :       authorship_verification: Total Accuracy (27, 50, 0.54)
2024-04-23 23:07:54 - INFO :       
==================Finish================

2024-04-23 23:07:54 - INFO :       Memory Requirement: 16794.44580078125 MiB

2024-04-23 23:07:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:07:54 - INFO :       DATASET: tasksource/bigbench bbq_lite_json
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 23:08:02 - INFO :       Use taylor pruner...
2024-04-23 23:08:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:08:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:08:02 - INFO :       Start Pruning
2024-04-23 23:08:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:08:04 - INFO :       Loss = 14.7578125
2024-04-23 23:08:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:08:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:08:07 - INFO :       bbq_lite_json: Total Sparsity 1.3581083665570398e-06
2024-04-23 23:08:48 - INFO :       bbq_lite_json: Total Accuracy (17, 50, 0.34)
2024-04-23 23:08:48 - INFO :       
==================Finish================

2024-04-23 23:08:48 - INFO :       Memory Requirement: 16771.79052734375 MiB

2024-04-23 23:08:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:08:48 - INFO :       DATASET: tasksource/bigbench causal_judgment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 23:08:55 - INFO :       Use taylor pruner...
2024-04-23 23:08:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:08:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:08:56 - INFO :       Start Pruning
2024-04-23 23:08:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:08:58 - INFO :       Loss = 8.7578125
2024-04-23 23:08:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:08:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:09:01 - INFO :       causal_judgment: Total Sparsity 1.3554032883811208e-06
2024-04-23 23:09:32 - INFO :       causal_judgment: Total Accuracy (18, 38, 0.47368421052631576)
2024-04-23 23:09:32 - INFO :       
==================Finish================

2024-04-23 23:09:32 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:09:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:09:32 - INFO :       DATASET: tasksource/bigbench cause_and_effect
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 23:09:40 - INFO :       Use taylor pruner...
2024-04-23 23:09:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:09:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:09:40 - INFO :       Start Pruning
2024-04-23 23:09:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:09:43 - INFO :       Loss = 15.0
2024-04-23 23:09:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:09:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:09:46 - INFO :       cause_and_effect: Total Sparsity 1.3585857332939668e-06
2024-04-23 23:10:10 - INFO :       cause_and_effect: Total Accuracy (2, 30, 0.06666666666666667)
2024-04-23 23:10:11 - INFO :       
==================Finish================

2024-04-23 23:10:11 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:10:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:10:11 - INFO :       DATASET: tasksource/bigbench checkmate_in_one
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 23:10:18 - INFO :       Use taylor pruner...
2024-04-23 23:10:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:10:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:10:19 - INFO :       Start Pruning
2024-04-23 23:10:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:10:21 - INFO :       Loss = 2.4765625
2024-04-23 23:10:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:10:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:10:24 - INFO :       checkmate_in_one: Total Sparsity 1.3577901220657553e-06
2024-04-23 23:11:10 - INFO :       checkmate_in_one: Total Accuracy (12, 50, 0.24)
2024-04-23 23:11:10 - INFO :       
==================Finish================

2024-04-23 23:11:10 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:11:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:11:10 - INFO :       DATASET: tasksource/bigbench cifar10_classification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 23:11:18 - INFO :       Use taylor pruner...
2024-04-23 23:11:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:11:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:11:18 - INFO :       Start Pruning
2024-04-23 23:11:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:11:20 - INFO :       Loss = 3.884765625
2024-04-23 23:11:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:11:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:11:23 - INFO :       cifar10_classification: Total Sparsity 1.3584266110483244e-06
2024-04-23 23:13:11 - INFO :       cifar10_classification: Total Accuracy (3, 50, 0.06)
2024-04-23 23:13:11 - INFO :       
==================Finish================

2024-04-23 23:13:11 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:13:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:13:11 - INFO :       DATASET: tasksource/bigbench code_line_description
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 23:13:19 - INFO :       Use taylor pruner...
2024-04-23 23:13:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:13:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:13:19 - INFO :       Start Pruning
2024-04-23 23:13:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:13:21 - INFO :       Loss = 11.4296875
2024-04-23 23:13:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:13:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:13:24 - INFO :       code_line_description: Total Sparsity 1.361449933715528e-06
2024-04-23 23:13:37 - INFO :       code_line_description: Total Accuracy (7, 16, 0.4375)
2024-04-23 23:13:37 - INFO :       
==================Finish================

2024-04-23 23:13:37 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:13:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:13:37 - INFO :       DATASET: tasksource/bigbench color
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 23:13:45 - INFO :       Use taylor pruner...
2024-04-23 23:13:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:13:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:13:45 - INFO :       Start Pruning
2024-04-23 23:13:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:13:47 - INFO :       Loss = 11.1875
2024-04-23 23:13:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:13:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:13:50 - INFO :       color: Total Sparsity 1.359699589013463e-06
2024-04-23 23:14:30 - INFO :       color: Total Accuracy (13, 50, 0.26)
2024-04-23 23:14:30 - INFO :       
==================Finish================

2024-04-23 23:14:30 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:14:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:14:30 - INFO :       DATASET: tasksource/bigbench common_morpheme
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 23:14:38 - INFO :       Use taylor pruner...
2024-04-23 23:14:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:14:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:14:38 - INFO :       Start Pruning
2024-04-23 23:14:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:14:40 - INFO :       Loss = 13.328125
2024-04-23 23:14:42 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:14:42 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:14:43 - INFO :       common_morpheme: Total Sparsity 1.3593813445221782e-06
2024-04-23 23:14:56 - INFO :       common_morpheme: Total Accuracy (4, 16, 0.25)
2024-04-23 23:14:56 - INFO :       
==================Finish================

2024-04-23 23:14:56 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:14:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:14:56 - INFO :       DATASET: tasksource/bigbench conceptual_combinations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 23:15:03 - INFO :       Use taylor pruner...
2024-04-23 23:15:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:15:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:15:04 - INFO :       Start Pruning
2024-04-23 23:15:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:15:07 - INFO :       Loss = 12.15625
2024-04-23 23:15:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:15:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:15:09 - INFO :       conceptual_combinations: Total Sparsity 1.3598587112591052e-06
2024-04-23 23:15:25 - INFO :       conceptual_combinations: Total Accuracy (2, 19, 0.10526315789473684)
2024-04-23 23:15:25 - INFO :       
==================Finish================

2024-04-23 23:15:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:15:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:15:25 - INFO :       DATASET: tasksource/bigbench crash_blossom
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 23:15:33 - INFO :       Use taylor pruner...
2024-04-23 23:15:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:15:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:15:33 - INFO :       Start Pruning
2024-04-23 23:15:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:15:35 - INFO :       Loss = 13.8671875
2024-04-23 23:15:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:15:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:15:38 - INFO :       crash_blossom: Total Sparsity 1.3566762663462592e-06
2024-04-23 23:15:51 - INFO :       crash_blossom: Total Accuracy (5, 16, 0.3125)
2024-04-23 23:15:51 - INFO :       
==================Finish================

2024-04-23 23:15:51 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:15:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:15:51 - INFO :       DATASET: tasksource/bigbench crass_ai
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 23:15:59 - INFO :       Use taylor pruner...
2024-04-23 23:15:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:15:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:15:59 - INFO :       Start Pruning
2024-04-23 23:16:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:16:01 - INFO :       Loss = 13.0
2024-04-23 23:16:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:16:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:16:04 - INFO :       crass_ai: Total Sparsity 1.3627229116806667e-06
2024-04-23 23:16:17 - INFO :       crass_ai: Total Accuracy (5, 16, 0.3125)
2024-04-23 23:16:17 - INFO :       
==================Finish================

2024-04-23 23:16:17 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:16:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:16:17 - INFO :       DATASET: tasksource/bigbench cryobiology_spanish
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 23:16:24 - INFO :       Use taylor pruner...
2024-04-23 23:16:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:16:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:16:25 - INFO :       Start Pruning
2024-04-23 23:16:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:16:27 - INFO :       Loss = 13.9375
2024-04-23 23:16:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:16:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:16:30 - INFO :       cryobiology_spanish: Total Sparsity 1.3595404667678207e-06
2024-04-23 23:16:53 - INFO :       cryobiology_spanish: Total Accuracy (7, 29, 0.2413793103448276)
2024-04-23 23:16:53 - INFO :       
==================Finish================

2024-04-23 23:16:53 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:16:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:16:53 - INFO :       DATASET: tasksource/bigbench cs_algorithms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 23:17:01 - INFO :       Use taylor pruner...
2024-04-23 23:17:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:17:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:17:01 - INFO :       Start Pruning
2024-04-23 23:17:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:17:03 - INFO :       Loss = 13.9140625
2024-04-23 23:17:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:17:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:17:06 - INFO :       cs_algorithms: Total Sparsity 1.358267488802682e-06
2024-04-23 23:17:47 - INFO :       cs_algorithms: Total Accuracy (4, 50, 0.08)
2024-04-23 23:17:47 - INFO :       
==================Finish================

2024-04-23 23:17:47 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:17:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:17:47 - INFO :       DATASET: tasksource/bigbench dark_humor_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 23:17:55 - INFO :       Use taylor pruner...
2024-04-23 23:17:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:17:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:17:55 - INFO :       Start Pruning
2024-04-23 23:17:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:17:58 - INFO :       Loss = 14.078125
2024-04-23 23:17:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:17:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:18:01 - INFO :       dark_humor_detection: Total Sparsity 1.357630999820113e-06
2024-04-23 23:18:14 - INFO :       dark_humor_detection: Total Accuracy (10, 16, 0.625)
2024-04-23 23:18:14 - INFO :       
==================Finish================

2024-04-23 23:18:14 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:18:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:18:14 - INFO :       DATASET: tasksource/bigbench date_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 23:18:21 - INFO :       Use taylor pruner...
2024-04-23 23:18:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:18:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:18:22 - INFO :       Start Pruning
2024-04-23 23:18:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:18:25 - INFO :       Loss = 12.0859375
2024-04-23 23:18:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:18:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:18:28 - INFO :       date_understanding: Total Sparsity 1.360813444732959e-06
2024-04-23 23:19:09 - INFO :       date_understanding: Total Accuracy (2, 50, 0.04)
2024-04-23 23:19:09 - INFO :       
==================Finish================

2024-04-23 23:19:09 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:19:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:19:09 - INFO :       DATASET: tasksource/bigbench disambiguation_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 23:19:17 - INFO :       Use taylor pruner...
2024-04-23 23:19:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:19:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:19:17 - INFO :       Start Pruning
2024-04-23 23:19:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:19:19 - INFO :       Loss = 13.1640625
2024-04-23 23:19:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:19:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:19:22 - INFO :       disambiguation_qa: Total Sparsity 1.3569945108375437e-06
2024-04-23 23:20:02 - INFO :       disambiguation_qa: Total Accuracy (21, 50, 0.42)
2024-04-23 23:20:02 - INFO :       
==================Finish================

2024-04-23 23:20:02 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:20:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:20:02 - INFO :       DATASET: tasksource/bigbench discourse_marker_prediction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 23:20:10 - INFO :       Use taylor pruner...
2024-04-23 23:20:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:20:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:20:10 - INFO :       Start Pruning
2024-04-23 23:20:12 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:20:13 - INFO :       Loss = 7.77734375
2024-04-23 23:20:15 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:20:15 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:20:16 - INFO :       discourse_marker_prediction: Total Sparsity 1.3601769557503897e-06
2024-04-23 23:21:03 - INFO :       discourse_marker_prediction: Total Accuracy (6, 50, 0.12)
2024-04-23 23:21:03 - INFO :       
==================Finish================

2024-04-23 23:21:03 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:21:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:21:03 - INFO :       DATASET: tasksource/bigbench dyck_languages
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 23:21:11 - INFO :       Use taylor pruner...
2024-04-23 23:21:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:21:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:21:11 - INFO :       Start Pruning
2024-04-23 23:21:12 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:21:13 - INFO :       Loss = 1.1337890625
2024-04-23 23:21:15 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:21:15 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:21:16 - INFO :       dyck_languages: Total Sparsity 1.3534938214334132e-06
2024-04-23 23:22:03 - INFO :       dyck_languages: Total Accuracy (0, 50, 0.0)
2024-04-23 23:22:03 - INFO :       
==================Finish================

2024-04-23 23:22:03 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:22:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:22:03 - INFO :       DATASET: tasksource/bigbench elementary_math_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 23:22:11 - INFO :       Use taylor pruner...
2024-04-23 23:22:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:22:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:22:11 - INFO :       Start Pruning
2024-04-23 23:22:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:22:14 - INFO :       Loss = 12.15625
2024-04-23 23:22:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:22:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:22:17 - INFO :       elementary_math_qa: Total Sparsity 1.3595404667678207e-06
2024-04-23 23:22:57 - INFO :       elementary_math_qa: Total Accuracy (8, 50, 0.16)
2024-04-23 23:22:57 - INFO :       
==================Finish================

2024-04-23 23:22:57 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:22:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:22:57 - INFO :       DATASET: tasksource/bigbench emoji_movie
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 23:23:05 - INFO :       Use taylor pruner...
2024-04-23 23:23:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:23:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:23:05 - INFO :       Start Pruning
2024-04-23 23:23:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:23:07 - INFO :       Loss = 13.09375
2024-04-23 23:23:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:23:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:23:10 - INFO :       emoji_movie: Total Sparsity 1.357153633083186e-06
2024-04-23 23:23:26 - INFO :       emoji_movie: Total Accuracy (0, 20, 0.0)
2024-04-23 23:23:26 - INFO :       
==================Finish================

2024-04-23 23:23:26 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:23:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:23:26 - INFO :       DATASET: tasksource/bigbench empirical_judgments
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 23:23:33 - INFO :       Use taylor pruner...
2024-04-23 23:23:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:23:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:23:34 - INFO :       Start Pruning
2024-04-23 23:23:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:23:36 - INFO :       Loss = 13.3828125
2024-04-23 23:23:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:23:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:23:39 - INFO :       empirical_judgments: Total Sparsity 1.3577901220657553e-06
2024-04-23 23:23:54 - INFO :       empirical_judgments: Total Accuracy (10, 19, 0.5263157894736842)
2024-04-23 23:23:54 - INFO :       
==================Finish================

2024-04-23 23:23:54 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:23:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:23:54 - INFO :       DATASET: tasksource/bigbench english_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 23:24:02 - INFO :       Use taylor pruner...
2024-04-23 23:24:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:24:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:24:03 - INFO :       Start Pruning
2024-04-23 23:24:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:24:05 - INFO :       Loss = 11.96875
2024-04-23 23:24:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:24:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:24:08 - INFO :       english_proverbs: Total Sparsity 1.3609725669786013e-06
2024-04-23 23:24:21 - INFO :       english_proverbs: Total Accuracy (4, 16, 0.25)
2024-04-23 23:24:21 - INFO :       
==================Finish================

2024-04-23 23:24:21 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:24:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:24:21 - INFO :       DATASET: tasksource/bigbench english_russian_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 23:24:29 - INFO :       Use taylor pruner...
2024-04-23 23:24:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:24:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:24:30 - INFO :       Start Pruning
2024-04-23 23:24:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:24:32 - INFO :       Loss = 11.8359375
2024-04-23 23:24:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:24:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:24:35 - INFO :       english_russian_proverbs: Total Sparsity 1.3561988996093322e-06
2024-04-23 23:24:47 - INFO :       english_russian_proverbs: Total Accuracy (7, 16, 0.4375)
2024-04-23 23:24:47 - INFO :       
==================Finish================

2024-04-23 23:24:47 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:24:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:24:47 - INFO :       DATASET: tasksource/bigbench entailed_polarity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.40s/it]
2024-04-23 23:24:58 - INFO :       Use taylor pruner...
2024-04-23 23:24:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:24:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:24:59 - INFO :       Start Pruning
2024-04-23 23:25:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:25:01 - INFO :       Loss = 15.9765625
2024-04-23 23:25:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:25:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:25:04 - INFO :       entailed_polarity: Total Sparsity 1.3557215328724054e-06
2024-04-23 23:25:27 - INFO :       entailed_polarity: Total Accuracy (29, 29, 1.0)
2024-04-23 23:25:27 - INFO :       
==================Finish================

2024-04-23 23:25:27 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:25:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:25:27 - INFO :       DATASET: tasksource/bigbench entailed_polarity_hindi
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]
2024-04-23 23:25:37 - INFO :       Use taylor pruner...
2024-04-23 23:25:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:25:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:25:37 - INFO :       Start Pruning
2024-04-23 23:25:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:25:39 - INFO :       Loss = 11.6015625
2024-04-23 23:25:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:25:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:25:42 - INFO :       entailed_polarity_hindi: Total Sparsity 1.3561988996093322e-06
2024-04-23 23:26:03 - INFO :       entailed_polarity_hindi: Total Accuracy (16, 27, 0.5925925925925926)
2024-04-23 23:26:03 - INFO :       
==================Finish================

2024-04-23 23:26:03 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:26:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:26:03 - INFO :       DATASET: tasksource/bigbench epistemic_reasoning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2024-04-23 23:26:13 - INFO :       Use taylor pruner...
2024-04-23 23:26:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:26:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:26:13 - INFO :       Start Pruning
2024-04-23 23:26:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:26:15 - INFO :       Loss = 13.5625
2024-04-23 23:26:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:26:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:26:18 - INFO :       epistemic_reasoning: Total Sparsity 1.3579492443113975e-06
2024-04-23 23:26:59 - INFO :       epistemic_reasoning: Total Accuracy (26, 50, 0.52)
2024-04-23 23:26:59 - INFO :       
==================Finish================

2024-04-23 23:26:59 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:26:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:26:59 - INFO :       DATASET: tasksource/bigbench evaluating_information_essentiality
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 23:27:07 - INFO :       Use taylor pruner...
2024-04-23 23:27:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:27:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:27:07 - INFO :       Start Pruning
2024-04-23 23:27:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:27:09 - INFO :       Loss = 8.546875
2024-04-23 23:27:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:27:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:27:12 - INFO :       evaluating_information_essentiality: Total Sparsity 1.3573127553288283e-06
2024-04-23 23:27:26 - INFO :       evaluating_information_essentiality: Total Accuracy (3, 16, 0.1875)
2024-04-23 23:27:26 - INFO :       
==================Finish================

2024-04-23 23:27:26 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:27:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:27:26 - INFO :       DATASET: tasksource/bigbench fact_checker
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-23 23:27:34 - INFO :       Use taylor pruner...
2024-04-23 23:27:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:27:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:27:34 - INFO :       Start Pruning
2024-04-23 23:27:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:27:36 - INFO :       Loss = 15.7578125
2024-04-23 23:27:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:27:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:27:39 - INFO :       fact_checker: Total Sparsity 1.35603977736369e-06
2024-04-23 23:28:19 - INFO :       fact_checker: Total Accuracy (31, 50, 0.62)
2024-04-23 23:28:19 - INFO :       
==================Finish================

2024-04-23 23:28:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:28:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:28:19 - INFO :       DATASET: tasksource/bigbench fantasy_reasoning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 23:28:27 - INFO :       Use taylor pruner...
2024-04-23 23:28:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:28:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:28:28 - INFO :       Start Pruning
2024-04-23 23:28:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:28:30 - INFO :       Loss = 14.6484375
2024-04-23 23:28:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:28:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:28:32 - INFO :       fantasy_reasoning: Total Sparsity 1.3619273004524551e-06
2024-04-23 23:29:06 - INFO :       fantasy_reasoning: Total Accuracy (25, 40, 0.625)
2024-04-23 23:29:07 - INFO :       
==================Finish================

2024-04-23 23:29:07 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:29:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:29:07 - INFO :       DATASET: tasksource/bigbench figure_of_speech_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 23:29:14 - INFO :       Use taylor pruner...
2024-04-23 23:29:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:29:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:29:15 - INFO :       Start Pruning
2024-04-23 23:29:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:29:18 - INFO :       Loss = 12.5234375
2024-04-23 23:29:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:29:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:29:21 - INFO :       figure_of_speech_detection: Total Sparsity 1.3558806551180476e-06
2024-04-23 23:29:34 - INFO :       figure_of_speech_detection: Total Accuracy (5, 16, 0.3125)
2024-04-23 23:29:34 - INFO :       
==================Finish================

2024-04-23 23:29:34 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:29:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:29:34 - INFO :       DATASET: tasksource/bigbench formal_fallacies_syllogisms_negation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 23:29:42 - INFO :       Use taylor pruner...
2024-04-23 23:29:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:29:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:29:42 - INFO :       Start Pruning
2024-04-23 23:29:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:29:46 - INFO :       Loss = 12.1171875
2024-04-23 23:29:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:29:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:29:49 - INFO :       formal_fallacies_syllogisms_negation: Total Sparsity 1.360813444732959e-06
2024-04-23 23:30:30 - INFO :       formal_fallacies_syllogisms_negation: Total Accuracy (24, 50, 0.48)
2024-04-23 23:30:30 - INFO :       
==================Finish================

2024-04-23 23:30:30 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:30:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:30:30 - INFO :       DATASET: tasksource/bigbench general_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-23 23:30:38 - INFO :       Use taylor pruner...
2024-04-23 23:30:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:30:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:30:39 - INFO :       Start Pruning
2024-04-23 23:30:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:30:42 - INFO :       Loss = 11.84375
2024-04-23 23:30:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:30:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:30:45 - INFO :       general_knowledge: Total Sparsity 1.3611316892242436e-06
2024-04-23 23:30:58 - INFO :       general_knowledge: Total Accuracy (5, 16, 0.3125)
2024-04-23 23:30:58 - INFO :       
==================Finish================

2024-04-23 23:30:58 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:30:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:30:58 - INFO :       DATASET: tasksource/bigbench geometric_shapes
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2024-04-23 23:31:09 - INFO :       Use taylor pruner...
2024-04-23 23:31:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:31:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:31:11 - INFO :       Start Pruning
2024-04-23 23:31:12 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:31:13 - INFO :       Loss = 10.1640625
2024-04-23 23:31:15 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:31:15 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:31:16 - INFO :       geometric_shapes: Total Sparsity 1.362404667189382e-06
2024-04-23 23:31:58 - INFO :       geometric_shapes: Total Accuracy (8, 50, 0.16)
2024-04-23 23:31:58 - INFO :       
==================Finish================

2024-04-23 23:31:58 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:31:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:31:58 - INFO :       DATASET: tasksource/bigbench goal_step_wikihow
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 23:32:06 - INFO :       Use taylor pruner...
2024-04-23 23:32:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:32:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:32:07 - INFO :       Start Pruning
2024-04-23 23:32:08 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:32:09 - INFO :       Loss = 13.2890625
2024-04-23 23:32:10 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:32:10 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:32:12 - INFO :       goal_step_wikihow: Total Sparsity 1.3593813445221782e-06
2024-04-23 23:32:54 - INFO :       goal_step_wikihow: Total Accuracy (8, 50, 0.16)
2024-04-23 23:32:54 - INFO :       
==================Finish================

2024-04-23 23:32:54 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:32:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:32:54 - INFO :       DATASET: tasksource/bigbench gre_reading_comprehension
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2024-04-23 23:33:03 - INFO :       Use taylor pruner...
2024-04-23 23:33:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:33:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:33:03 - INFO :       Start Pruning
2024-04-23 23:33:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:33:06 - INFO :       Loss = 2.3359375
2024-04-23 23:33:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:33:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:33:09 - INFO :       gre_reading_comprehension: Total Sparsity 1.3577901220657553e-06
2024-04-23 23:33:27 - INFO :       gre_reading_comprehension: Total Accuracy (2, 16, 0.125)
2024-04-23 23:33:27 - INFO :       
==================Finish================

2024-04-23 23:33:27 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:33:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:33:27 - INFO :       DATASET: tasksource/bigbench hhh_alignment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 23:33:35 - INFO :       Use taylor pruner...
2024-04-23 23:33:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:33:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:33:35 - INFO :       Start Pruning
2024-04-23 23:33:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:33:37 - INFO :       Loss = 14.125
2024-04-23 23:33:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:33:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:33:40 - INFO :       hhh_alignment: Total Sparsity 1.3606543224873167e-06
2024-04-23 23:34:18 - INFO :       hhh_alignment: Total Accuracy (26, 42, 0.6190476190476191)
2024-04-23 23:34:19 - INFO :       
==================Finish================

2024-04-23 23:34:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:34:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:34:19 - INFO :       DATASET: tasksource/bigbench hindu_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-23 23:34:29 - INFO :       Use taylor pruner...
2024-04-23 23:34:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:34:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:34:30 - INFO :       Start Pruning
2024-04-23 23:34:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:34:32 - INFO :       Loss = 14.296875
2024-04-23 23:34:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:34:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:34:35 - INFO :       hindu_knowledge: Total Sparsity 1.359699589013463e-06
2024-04-23 23:35:04 - INFO :       hindu_knowledge: Total Accuracy (14, 35, 0.4)
2024-04-23 23:35:04 - INFO :       
==================Finish================

2024-04-23 23:35:04 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:35:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:35:04 - INFO :       DATASET: tasksource/bigbench hinglish_toxicity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 23:35:12 - INFO :       Use taylor pruner...
2024-04-23 23:35:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:35:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:35:12 - INFO :       Start Pruning
2024-04-23 23:35:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:35:15 - INFO :       Loss = 15.234375
2024-04-23 23:35:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:35:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:35:18 - INFO :       hinglish_toxicity: Total Sparsity 1.357153633083186e-06
2024-04-23 23:35:52 - INFO :       hinglish_toxicity: Total Accuracy (23, 40, 0.575)
2024-04-23 23:35:53 - INFO :       
==================Finish================

2024-04-23 23:35:53 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:35:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:35:53 - INFO :       DATASET: tasksource/bigbench human_organs_senses
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-23 23:36:00 - INFO :       Use taylor pruner...
2024-04-23 23:36:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:36:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:36:01 - INFO :       Start Pruning
2024-04-23 23:36:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:36:03 - INFO :       Loss = 14.4921875
2024-04-23 23:36:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:36:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:36:06 - INFO :       human_organs_senses: Total Sparsity 1.358744855539609e-06
2024-04-23 23:36:18 - INFO :       human_organs_senses: Total Accuracy (5, 16, 0.3125)
2024-04-23 23:36:18 - INFO :       
==================Finish================

2024-04-23 23:36:18 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:36:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:36:18 - INFO :       DATASET: tasksource/bigbench hyperbaton
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 23:36:26 - INFO :       Use taylor pruner...
2024-04-23 23:36:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:36:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:36:27 - INFO :       Start Pruning
2024-04-23 23:36:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:36:29 - INFO :       Loss = 15.25
2024-04-23 23:36:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:36:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:36:32 - INFO :       hyperbaton: Total Sparsity 1.359222222276536e-06
2024-04-23 23:37:11 - INFO :       hyperbaton: Total Accuracy (22, 50, 0.44)
2024-04-23 23:37:11 - INFO :       
==================Finish================

2024-04-23 23:37:11 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:37:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:37:11 - INFO :       DATASET: tasksource/bigbench identify_math_theorems
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 23:37:18 - INFO :       Use taylor pruner...
2024-04-23 23:37:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:37:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:37:19 - INFO :       Start Pruning
2024-04-23 23:37:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:37:21 - INFO :       Loss = 2.1328125
2024-04-23 23:37:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:37:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:37:24 - INFO :       identify_math_theorems: Total Sparsity 1.3574718775744707e-06
2024-04-23 23:37:40 - INFO :       identify_math_theorems: Total Accuracy (8, 16, 0.5)
2024-04-23 23:37:40 - INFO :       
==================Finish================

2024-04-23 23:37:40 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:37:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:37:40 - INFO :       DATASET: tasksource/bigbench identify_odd_metaphor
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 23:37:47 - INFO :       Use taylor pruner...
2024-04-23 23:37:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:37:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:37:48 - INFO :       Start Pruning
2024-04-23 23:37:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:37:50 - INFO :       Loss = 12.5390625
2024-04-23 23:37:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:37:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:37:53 - INFO :       identify_odd_metaphor: Total Sparsity 1.3620864226980974e-06
2024-04-23 23:38:06 - INFO :       identify_odd_metaphor: Total Accuracy (0, 16, 0.0)
2024-04-23 23:38:06 - INFO :       
==================Finish================

2024-04-23 23:38:06 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:38:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:38:06 - INFO :       DATASET: tasksource/bigbench implicatures
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 23:38:14 - INFO :       Use taylor pruner...
2024-04-23 23:38:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:38:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:38:14 - INFO :       Start Pruning
2024-04-23 23:38:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:38:16 - INFO :       Loss = 15.28125
2024-04-23 23:38:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:38:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:38:19 - INFO :       implicatures: Total Sparsity 1.3577901220657553e-06
2024-04-23 23:39:01 - INFO :       implicatures: Total Accuracy (22, 50, 0.44)
2024-04-23 23:39:01 - INFO :       
==================Finish================

2024-04-23 23:39:01 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:39:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:39:01 - INFO :       DATASET: tasksource/bigbench implicit_relations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 23:39:09 - INFO :       Use taylor pruner...
2024-04-23 23:39:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:39:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:39:10 - INFO :       Start Pruning
2024-04-23 23:39:12 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:39:13 - INFO :       Loss = 5.46875
2024-04-23 23:39:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:39:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:39:15 - INFO :       implicit_relations: Total Sparsity 1.358744855539609e-06
2024-04-23 23:39:30 - INFO :       implicit_relations: Total Accuracy (4, 17, 0.23529411764705882)
2024-04-23 23:39:30 - INFO :       
==================Finish================

2024-04-23 23:39:30 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:39:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:39:30 - INFO :       DATASET: tasksource/bigbench indic_cause_and_effect
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 23:39:38 - INFO :       Use taylor pruner...
2024-04-23 23:39:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:39:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:39:38 - INFO :       Start Pruning
2024-04-23 23:39:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:39:40 - INFO :       Loss = 8.71875
2024-04-23 23:39:42 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:39:42 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:39:43 - INFO :       indic_cause_and_effect: Total Sparsity 1.3525390879595594e-06
2024-04-23 23:40:25 - INFO :       indic_cause_and_effect: Total Accuracy (18, 50, 0.36)
2024-04-23 23:40:26 - INFO :       
==================Finish================

2024-04-23 23:40:26 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:40:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:40:26 - INFO :       DATASET: tasksource/bigbench intent_recognition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 23:40:33 - INFO :       Use taylor pruner...
2024-04-23 23:40:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:40:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:40:34 - INFO :       Start Pruning
2024-04-23 23:40:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:40:36 - INFO :       Loss = 11.6796875
2024-04-23 23:40:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:40:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:40:39 - INFO :       intent_recognition: Total Sparsity 1.3569945108375437e-06
2024-04-23 23:41:20 - INFO :       intent_recognition: Total Accuracy (36, 50, 0.72)
2024-04-23 23:41:20 - INFO :       
==================Finish================

2024-04-23 23:41:20 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:41:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:41:20 - INFO :       DATASET: tasksource/bigbench international_phonetic_alphabet_nli
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 23:41:27 - INFO :       Use taylor pruner...
2024-04-23 23:41:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:41:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:41:28 - INFO :       Start Pruning
2024-04-23 23:41:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:41:30 - INFO :       Loss = 8.8515625
2024-04-23 23:41:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:41:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:41:33 - INFO :       international_phonetic_alphabet_nli: Total Sparsity 1.358267488802682e-06
2024-04-23 23:41:54 - INFO :       international_phonetic_alphabet_nli: Total Accuracy (11, 25, 0.44)
2024-04-23 23:41:54 - INFO :       
==================Finish================

2024-04-23 23:41:54 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:41:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:41:54 - INFO :       DATASET: tasksource/bigbench intersect_geometry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 23:42:01 - INFO :       Use taylor pruner...
2024-04-23 23:42:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:42:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:42:02 - INFO :       Start Pruning
2024-04-23 23:42:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:42:04 - INFO :       Loss = 2.43359375
2024-04-23 23:42:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:42:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:42:07 - INFO :       intersect_geometry: Total Sparsity 1.3604952002416743e-06
2024-04-23 23:42:52 - INFO :       intersect_geometry: Total Accuracy (11, 50, 0.22)
2024-04-23 23:42:52 - INFO :       
==================Finish================

2024-04-23 23:42:52 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:42:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:42:52 - INFO :       DATASET: tasksource/bigbench irony_identification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 23:43:00 - INFO :       Use taylor pruner...
2024-04-23 23:43:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:43:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:43:00 - INFO :       Start Pruning
2024-04-23 23:43:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:43:03 - INFO :       Loss = 14.5625
2024-04-23 23:43:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:43:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:43:05 - INFO :       irony_identification: Total Sparsity 1.3568353885919015e-06
2024-04-23 23:43:21 - INFO :       irony_identification: Total Accuracy (8, 19, 0.42105263157894735)
2024-04-23 23:43:21 - INFO :       
==================Finish================

2024-04-23 23:43:21 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:43:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:43:21 - INFO :       DATASET: tasksource/bigbench kannada
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-23 23:43:29 - INFO :       Use taylor pruner...
2024-04-23 23:43:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:43:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:43:30 - INFO :       Start Pruning
2024-04-23 23:43:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:43:32 - INFO :       Loss = 4.8046875
2024-04-23 23:43:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:43:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:43:35 - INFO :       kannada: Total Sparsity 1.3579492443113975e-06
2024-04-23 23:44:24 - INFO :       kannada: Total Accuracy (8, 50, 0.16)
2024-04-23 23:44:25 - INFO :       
==================Finish================

2024-04-23 23:44:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:44:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:44:25 - INFO :       DATASET: tasksource/bigbench key_value_maps
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.20s/it]
2024-04-23 23:44:38 - INFO :       Use taylor pruner...
2024-04-23 23:44:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:44:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:44:38 - INFO :       Start Pruning
2024-04-23 23:44:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:44:41 - INFO :       Loss = 6.8984375
2024-04-23 23:44:42 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:44:42 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:44:44 - INFO :       key_value_maps: Total Sparsity 1.358744855539609e-06
2024-04-23 23:45:02 - INFO :       key_value_maps: Total Accuracy (11, 21, 0.5238095238095238)
2024-04-23 23:45:03 - INFO :       
==================Finish================

2024-04-23 23:45:03 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:45:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:45:03 - INFO :       DATASET: tasksource/bigbench known_unknowns
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.76s/it]
2024-04-23 23:45:18 - INFO :       Use taylor pruner...
2024-04-23 23:45:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:45:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:45:19 - INFO :       Start Pruning
2024-04-23 23:45:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:45:21 - INFO :       Loss = 15.28125
2024-04-23 23:45:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:45:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:45:24 - INFO :       known_unknowns: Total Sparsity 1.359699589013463e-06
2024-04-23 23:45:38 - INFO :       known_unknowns: Total Accuracy (9, 16, 0.5625)
2024-04-23 23:45:38 - INFO :       
==================Finish================

2024-04-23 23:45:38 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:45:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:45:38 - INFO :       DATASET: tasksource/bigbench language_identification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2024-04-23 23:45:46 - INFO :       Use taylor pruner...
2024-04-23 23:45:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:45:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:45:46 - INFO :       Start Pruning
2024-04-23 23:45:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:45:49 - INFO :       Loss = 9.625
2024-04-23 23:45:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:45:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:45:54 - INFO :       language_identification: Total Sparsity 1.3606543224873167e-06
2024-04-23 23:46:37 - INFO :       language_identification: Total Accuracy (3, 50, 0.06)
2024-04-23 23:46:37 - INFO :       
==================Finish================

2024-04-23 23:46:37 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:46:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:46:37 - INFO :       DATASET: tasksource/bigbench logic_grid_puzzle
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-23 23:46:44 - INFO :       Use taylor pruner...
2024-04-23 23:46:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:46:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:46:45 - INFO :       Start Pruning
2024-04-23 23:46:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:46:47 - INFO :       Loss = 5.20703125
2024-04-23 23:46:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:46:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:46:50 - INFO :       logic_grid_puzzle: Total Sparsity 1.359222222276536e-06
2024-04-23 23:47:35 - INFO :       logic_grid_puzzle: Total Accuracy (15, 50, 0.3)
2024-04-23 23:47:36 - INFO :       
==================Finish================

2024-04-23 23:47:36 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:47:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:47:36 - INFO :       DATASET: tasksource/bigbench logical_args
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 23:47:43 - INFO :       Use taylor pruner...
2024-04-23 23:47:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:47:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:47:44 - INFO :       Start Pruning
2024-04-23 23:47:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:47:46 - INFO :       Loss = 6.73828125
2024-04-23 23:47:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:47:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:47:49 - INFO :       logical_args: Total Sparsity 1.3604952002416743e-06
2024-04-23 23:48:02 - INFO :       logical_args: Total Accuracy (1, 16, 0.0625)
2024-04-23 23:48:03 - INFO :       
==================Finish================

2024-04-23 23:48:03 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:48:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:48:03 - INFO :       DATASET: tasksource/bigbench logical_deduction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 23:48:10 - INFO :       Use taylor pruner...
2024-04-23 23:48:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:48:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:48:11 - INFO :       Start Pruning
2024-04-23 23:48:12 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:48:13 - INFO :       Loss = 11.0546875
2024-04-23 23:48:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:48:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:48:16 - INFO :       logical_deduction: Total Sparsity 1.3590631000308936e-06
2024-04-23 23:48:57 - INFO :       logical_deduction: Total Accuracy (11, 50, 0.22)
2024-04-23 23:48:57 - INFO :       
==================Finish================

2024-04-23 23:48:57 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:48:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:48:57 - INFO :       DATASET: tasksource/bigbench logical_fallacy_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 23:49:04 - INFO :       Use taylor pruner...
2024-04-23 23:49:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:49:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:49:05 - INFO :       Start Pruning
2024-04-23 23:49:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:49:07 - INFO :       Loss = 14.6640625
2024-04-23 23:49:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:49:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:49:10 - INFO :       logical_fallacy_detection: Total Sparsity 1.3568353885919015e-06
2024-04-23 23:49:56 - INFO :       logical_fallacy_detection: Total Accuracy (28, 50, 0.56)
2024-04-23 23:49:57 - INFO :       
==================Finish================

2024-04-23 23:49:57 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:49:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:49:57 - INFO :       DATASET: tasksource/bigbench logical_sequence
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.33s/it]
2024-04-23 23:50:07 - INFO :       Use taylor pruner...
2024-04-23 23:50:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:50:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:50:07 - INFO :       Start Pruning
2024-04-23 23:50:08 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:50:09 - INFO :       Loss = 12.59375
2024-04-23 23:50:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:50:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:50:14 - INFO :       logical_sequence: Total Sparsity 1.358744855539609e-06
2024-04-23 23:50:27 - INFO :       logical_sequence: Total Accuracy (2, 16, 0.125)
2024-04-23 23:50:27 - INFO :       
==================Finish================

2024-04-23 23:50:27 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:50:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:50:27 - INFO :       DATASET: tasksource/bigbench mathematical_induction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 23:50:35 - INFO :       Use taylor pruner...
2024-04-23 23:50:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:50:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:50:35 - INFO :       Start Pruning
2024-04-23 23:50:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:50:38 - INFO :       Loss = 14.3046875
2024-04-23 23:50:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:50:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:50:41 - INFO :       mathematical_induction: Total Sparsity 1.3558806551180476e-06
2024-04-23 23:50:54 - INFO :       mathematical_induction: Total Accuracy (10, 16, 0.625)
2024-04-23 23:50:54 - INFO :       
==================Finish================

2024-04-23 23:50:54 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:50:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:50:54 - INFO :       DATASET: tasksource/bigbench medical_questions_russian
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 23:51:01 - INFO :       Use taylor pruner...
2024-04-23 23:51:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:51:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:51:02 - INFO :       Start Pruning
2024-04-23 23:51:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:51:04 - INFO :       Loss = 11.015625
2024-04-23 23:51:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:51:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:51:07 - INFO :       medical_questions_russian: Total Sparsity 1.3549259216441938e-06
2024-04-23 23:51:49 - INFO :       medical_questions_russian: Total Accuracy (33, 50, 0.66)
2024-04-23 23:51:49 - INFO :       
==================Finish================

2024-04-23 23:51:49 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:51:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:51:49 - INFO :       DATASET: tasksource/bigbench metaphor_boolean
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 23:51:56 - INFO :       Use taylor pruner...
2024-04-23 23:51:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:51:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:51:57 - INFO :       Start Pruning
2024-04-23 23:51:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:51:59 - INFO :       Loss = 14.703125
2024-04-23 23:52:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:52:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:52:02 - INFO :       metaphor_boolean: Total Sparsity 1.3573127553288283e-06
2024-04-23 23:52:43 - INFO :       metaphor_boolean: Total Accuracy (17, 50, 0.34)
2024-04-23 23:52:43 - INFO :       
==================Finish================

2024-04-23 23:52:43 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:52:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:52:43 - INFO :       DATASET: tasksource/bigbench metaphor_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 23:52:51 - INFO :       Use taylor pruner...
2024-04-23 23:52:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:52:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:52:51 - INFO :       Start Pruning
2024-04-23 23:52:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:52:55 - INFO :       Loss = 11.8828125
2024-04-23 23:52:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:52:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:52:58 - INFO :       metaphor_understanding: Total Sparsity 1.3538120659246977e-06
2024-04-23 23:53:36 - INFO :       metaphor_understanding: Total Accuracy (8, 46, 0.17391304347826086)
2024-04-23 23:53:36 - INFO :       
==================Finish================

2024-04-23 23:53:36 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:53:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:53:36 - INFO :       DATASET: tasksource/bigbench misconceptions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 23:53:43 - INFO :       Use taylor pruner...
2024-04-23 23:53:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:53:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:53:44 - INFO :       Start Pruning
2024-04-23 23:53:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:53:46 - INFO :       Loss = 15.2265625
2024-04-23 23:53:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:53:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:53:49 - INFO :       misconceptions: Total Sparsity 1.357153633083186e-06
2024-04-23 23:54:22 - INFO :       misconceptions: Total Accuracy (20, 43, 0.46511627906976744)
2024-04-23 23:54:23 - INFO :       
==================Finish================

2024-04-23 23:54:23 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:54:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:54:23 - INFO :       DATASET: tasksource/bigbench mnist_ascii
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 23:54:30 - INFO :       Use taylor pruner...
2024-04-23 23:54:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:54:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:54:31 - INFO :       Start Pruning
2024-04-23 23:54:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:54:33 - INFO :       Loss = 4.86328125
2024-04-23 23:54:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:54:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:54:36 - INFO :       mnist_ascii: Total Sparsity 1.3604952002416743e-06
2024-04-23 23:55:49 - INFO :       mnist_ascii: Total Accuracy (7, 50, 0.14)
2024-04-23 23:55:50 - INFO :       
==================Finish================

2024-04-23 23:55:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:55:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:55:50 - INFO :       DATASET: tasksource/bigbench moral_permissibility
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-23 23:55:57 - INFO :       Use taylor pruner...
2024-04-23 23:55:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:55:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:55:58 - INFO :       Start Pruning
2024-04-23 23:55:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:56:00 - INFO :       Loss = 13.6640625
2024-04-23 23:56:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:56:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:56:03 - INFO :       moral_permissibility: Total Sparsity 1.35603977736369e-06
2024-04-23 23:56:43 - INFO :       moral_permissibility: Total Accuracy (24, 50, 0.48)
2024-04-23 23:56:43 - INFO :       
==================Finish================

2024-04-23 23:56:43 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:56:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:56:43 - INFO :       DATASET: tasksource/bigbench movie_dialog_same_or_different
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 23:56:51 - INFO :       Use taylor pruner...
2024-04-23 23:56:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:56:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:56:51 - INFO :       Start Pruning
2024-04-23 23:56:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:56:53 - INFO :       Loss = 12.8828125
2024-04-23 23:56:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:56:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:56:56 - INFO :       movie_dialog_same_or_different: Total Sparsity 1.3577901220657553e-06
2024-04-23 23:57:36 - INFO :       movie_dialog_same_or_different: Total Accuracy (27, 50, 0.54)
2024-04-23 23:57:36 - INFO :       
==================Finish================

2024-04-23 23:57:36 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:57:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:57:36 - INFO :       DATASET: tasksource/bigbench movie_recommendation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 23:57:44 - INFO :       Use taylor pruner...
2024-04-23 23:57:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:57:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:57:44 - INFO :       Start Pruning
2024-04-23 23:57:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:57:46 - INFO :       Loss = 13.7734375
2024-04-23 23:57:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:57:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:57:49 - INFO :       movie_recommendation: Total Sparsity 1.3617681782068128e-06
2024-04-23 23:58:29 - INFO :       movie_recommendation: Total Accuracy (18, 50, 0.36)
2024-04-23 23:58:29 - INFO :       
==================Finish================

2024-04-23 23:58:29 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:58:29 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:58:29 - INFO :       DATASET: tasksource/bigbench navigate
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-23 23:58:36 - INFO :       Use taylor pruner...
2024-04-23 23:58:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:58:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:58:37 - INFO :       Start Pruning
2024-04-23 23:58:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:58:39 - INFO :       Loss = 15.5
2024-04-23 23:58:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:58:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:58:42 - INFO :       navigate: Total Sparsity 1.3573127553288283e-06
2024-04-23 23:59:21 - INFO :       navigate: Total Accuracy (21, 50, 0.42)
2024-04-23 23:59:22 - INFO :       
==================Finish================

2024-04-23 23:59:22 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:59:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:59:22 - INFO :       DATASET: tasksource/bigbench nonsense_words_grammar
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-23 23:59:29 - INFO :       Use taylor pruner...
2024-04-23 23:59:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:59:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:59:30 - INFO :       Start Pruning
2024-04-23 23:59:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:59:32 - INFO :       Loss = 14.2109375
2024-04-23 23:59:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:59:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-23 23:59:35 - INFO :       nonsense_words_grammar: Total Sparsity 1.3579492443113975e-06
2024-04-23 23:59:47 - INFO :       nonsense_words_grammar: Total Accuracy (5, 16, 0.3125)
2024-04-23 23:59:47 - INFO :       
==================Finish================

2024-04-23 23:59:47 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-23 23:59:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-23 23:59:47 - INFO :       DATASET: tasksource/bigbench novel_concepts
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-23 23:59:55 - INFO :       Use taylor pruner...
2024-04-23 23:59:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:59:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-23 23:59:55 - INFO :       Start Pruning
2024-04-23 23:59:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-23 23:59:58 - INFO :       Loss = 13.09375
2024-04-23 23:59:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-23 23:59:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:00:00 - INFO :       novel_concepts: Total Sparsity 1.359222222276536e-06
2024-04-24 00:00:13 - INFO :       novel_concepts: Total Accuracy (7, 16, 0.4375)
2024-04-24 00:00:13 - INFO :       
==================Finish================

2024-04-24 00:00:13 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:00:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:00:13 - INFO :       DATASET: tasksource/bigbench odd_one_out
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-24 00:00:21 - INFO :       Use taylor pruner...
2024-04-24 00:00:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:00:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:00:21 - INFO :       Start Pruning
2024-04-24 00:00:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:00:23 - INFO :       Loss = 14.8046875
2024-04-24 00:00:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:00:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:00:26 - INFO :       odd_one_out: Total Sparsity 1.3552441661354783e-06
2024-04-24 00:00:39 - INFO :       odd_one_out: Total Accuracy (0, 17, 0.0)
2024-04-24 00:00:39 - INFO :       
==================Finish================

2024-04-24 00:00:39 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:00:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:00:39 - INFO :       DATASET: tasksource/bigbench parsinlu_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-24 00:00:47 - INFO :       Use taylor pruner...
2024-04-24 00:00:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:00:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:00:47 - INFO :       Start Pruning
2024-04-24 00:00:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:00:49 - INFO :       Loss = 10.3203125
2024-04-24 00:00:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:00:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:00:52 - INFO :       parsinlu_qa: Total Sparsity 1.3579492443113975e-06
2024-04-24 00:01:32 - INFO :       parsinlu_qa: Total Accuracy (13, 50, 0.26)
2024-04-24 00:01:32 - INFO :       
==================Finish================

2024-04-24 00:01:32 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:01:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:01:32 - INFO :       DATASET: tasksource/bigbench penguins_in_a_table
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-24 00:01:39 - INFO :       Use taylor pruner...
2024-04-24 00:01:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:01:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:01:40 - INFO :       Start Pruning
2024-04-24 00:01:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:01:42 - INFO :       Loss = 9.0390625
2024-04-24 00:01:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:01:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:01:45 - INFO :       penguins_in_a_table: Total Sparsity 1.3595404667678207e-06
2024-04-24 00:02:09 - INFO :       penguins_in_a_table: Total Accuracy (12, 29, 0.41379310344827586)
2024-04-24 00:02:09 - INFO :       
==================Finish================

2024-04-24 00:02:09 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:02:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:02:09 - INFO :       DATASET: tasksource/bigbench persian_idioms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 00:02:16 - INFO :       Use taylor pruner...
2024-04-24 00:02:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:02:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:02:17 - INFO :       Start Pruning
2024-04-24 00:02:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:02:19 - INFO :       Loss = 12.5390625
2024-04-24 00:02:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:02:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:02:22 - INFO :       persian_idioms: Total Sparsity 1.3584266110483244e-06
2024-04-24 00:02:34 - INFO :       persian_idioms: Total Accuracy (1, 16, 0.0625)
2024-04-24 00:02:34 - INFO :       
==================Finish================

2024-04-24 00:02:34 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:02:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:02:34 - INFO :       DATASET: tasksource/bigbench phrase_relatedness
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 00:02:42 - INFO :       Use taylor pruner...
2024-04-24 00:02:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:02:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:02:42 - INFO :       Start Pruning
2024-04-24 00:02:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:02:44 - INFO :       Loss = 13.9765625
2024-04-24 00:02:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:02:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:02:47 - INFO :       phrase_relatedness: Total Sparsity 1.3573127553288283e-06
2024-04-24 00:03:03 - INFO :       phrase_relatedness: Total Accuracy (11, 20, 0.55)
2024-04-24 00:03:03 - INFO :       
==================Finish================

2024-04-24 00:03:03 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:03:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:03:03 - INFO :       DATASET: tasksource/bigbench physical_intuition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 00:03:11 - INFO :       Use taylor pruner...
2024-04-24 00:03:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:03:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:03:11 - INFO :       Start Pruning
2024-04-24 00:03:12 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:03:13 - INFO :       Loss = 12.890625
2024-04-24 00:03:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:03:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:03:16 - INFO :       physical_intuition: Total Sparsity 1.3574718775744707e-06
2024-04-24 00:03:29 - INFO :       physical_intuition: Total Accuracy (9, 16, 0.5625)
2024-04-24 00:03:29 - INFO :       
==================Finish================

2024-04-24 00:03:29 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:03:29 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:03:29 - INFO :       DATASET: tasksource/bigbench physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 00:03:37 - INFO :       Use taylor pruner...
2024-04-24 00:03:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:03:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:03:37 - INFO :       Start Pruning
2024-04-24 00:03:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:03:40 - INFO :       Loss = 10.765625
2024-04-24 00:03:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:03:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:03:42 - INFO :       physics: Total Sparsity 1.361449933715528e-06
2024-04-24 00:04:19 - INFO :       physics: Total Accuracy (26, 45, 0.5777777777777777)
2024-04-24 00:04:19 - INFO :       
==================Finish================

2024-04-24 00:04:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:04:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:04:19 - INFO :       DATASET: tasksource/bigbench play_dialog_same_or_different
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-24 00:04:26 - INFO :       Use taylor pruner...
2024-04-24 00:04:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:04:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:04:27 - INFO :       Start Pruning
2024-04-24 00:04:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:04:29 - INFO :       Loss = 8.796875
2024-04-24 00:04:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:04:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:04:32 - INFO :       play_dialog_same_or_different: Total Sparsity 1.3579492443113975e-06
2024-04-24 00:05:14 - INFO :       play_dialog_same_or_different: Total Accuracy (34, 50, 0.68)
2024-04-24 00:05:14 - INFO :       
==================Finish================

2024-04-24 00:05:14 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:05:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:05:14 - INFO :       DATASET: tasksource/bigbench presuppositions_as_nli
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-24 00:05:22 - INFO :       Use taylor pruner...
2024-04-24 00:05:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:05:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:05:22 - INFO :       Start Pruning
2024-04-24 00:05:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:05:24 - INFO :       Loss = 10.9140625
2024-04-24 00:05:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:05:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:05:27 - INFO :       presuppositions_as_nli: Total Sparsity 1.3598587112591052e-06
2024-04-24 00:06:08 - INFO :       presuppositions_as_nli: Total Accuracy (21, 50, 0.42)
2024-04-24 00:06:08 - INFO :       
==================Finish================

2024-04-24 00:06:08 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:06:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:06:08 - INFO :       DATASET: tasksource/bigbench question_selection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 00:06:16 - INFO :       Use taylor pruner...
2024-04-24 00:06:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:06:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:06:16 - INFO :       Start Pruning
2024-04-24 00:06:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:06:18 - INFO :       Loss = 7.5546875
2024-04-24 00:06:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:06:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:06:21 - INFO :       question_selection: Total Sparsity 1.3569945108375437e-06
2024-04-24 00:07:07 - INFO :       question_selection: Total Accuracy (8, 50, 0.16)
2024-04-24 00:07:08 - INFO :       
==================Finish================

2024-04-24 00:07:08 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:07:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:07:08 - INFO :       DATASET: tasksource/bigbench reasoning_about_colored_objects
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 00:07:15 - INFO :       Use taylor pruner...
2024-04-24 00:07:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:07:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:07:16 - INFO :       Start Pruning
2024-04-24 00:07:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:07:18 - INFO :       Loss = 8.6875
2024-04-24 00:07:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:07:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:07:21 - INFO :       reasoning_about_colored_objects: Total Sparsity 1.3549259216441938e-06
2024-04-24 00:08:01 - INFO :       reasoning_about_colored_objects: Total Accuracy (10, 50, 0.2)
2024-04-24 00:08:01 - INFO :       
==================Finish================

2024-04-24 00:08:01 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:08:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:08:01 - INFO :       DATASET: tasksource/bigbench riddle_sense
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-24 00:08:09 - INFO :       Use taylor pruner...
2024-04-24 00:08:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:08:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:08:09 - INFO :       Start Pruning
2024-04-24 00:08:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:08:11 - INFO :       Loss = 13.296875
2024-04-24 00:08:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:08:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:08:14 - INFO :       riddle_sense: Total Sparsity 1.361449933715528e-06
2024-04-24 00:08:26 - INFO :       riddle_sense: Total Accuracy (3, 16, 0.1875)
2024-04-24 00:08:27 - INFO :       
==================Finish================

2024-04-24 00:08:27 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:08:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:08:27 - INFO :       DATASET: tasksource/bigbench ruin_names
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-24 00:08:35 - INFO :       Use taylor pruner...
2024-04-24 00:08:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:08:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:08:35 - INFO :       Start Pruning
2024-04-24 00:08:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:08:37 - INFO :       Loss = 14.0078125
2024-04-24 00:08:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:08:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:08:40 - INFO :       ruin_names: Total Sparsity 1.3590631000308936e-06
2024-04-24 00:09:20 - INFO :       ruin_names: Total Accuracy (11, 50, 0.22)
2024-04-24 00:09:20 - INFO :       
==================Finish================

2024-04-24 00:09:20 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:09:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:09:20 - INFO :       DATASET: tasksource/bigbench salient_translation_error_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-24 00:09:28 - INFO :       Use taylor pruner...
2024-04-24 00:09:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:09:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:09:28 - INFO :       Start Pruning
2024-04-24 00:09:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:09:30 - INFO :       Loss = 8.6015625
2024-04-24 00:09:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:09:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:09:33 - INFO :       salient_translation_error_detection: Total Sparsity 1.3569945108375437e-06
2024-04-24 00:10:17 - INFO :       salient_translation_error_detection: Total Accuracy (6, 50, 0.12)
2024-04-24 00:10:17 - INFO :       
==================Finish================

2024-04-24 00:10:17 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:10:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:10:17 - INFO :       DATASET: tasksource/bigbench sentence_ambiguity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-24 00:10:25 - INFO :       Use taylor pruner...
2024-04-24 00:10:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:10:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:10:26 - INFO :       Start Pruning
2024-04-24 00:10:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:10:28 - INFO :       Loss = 16.03125
2024-04-24 00:10:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:10:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:10:31 - INFO :       sentence_ambiguity: Total Sparsity 1.3573127553288283e-06
2024-04-24 00:10:44 - INFO :       sentence_ambiguity: Total Accuracy (9, 16, 0.5625)
2024-04-24 00:10:44 - INFO :       
==================Finish================

2024-04-24 00:10:44 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:10:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:10:44 - INFO :       DATASET: tasksource/bigbench similarities_abstraction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 00:10:51 - INFO :       Use taylor pruner...
2024-04-24 00:10:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:10:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:10:52 - INFO :       Start Pruning
2024-04-24 00:10:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:10:54 - INFO :       Loss = 13.9609375
2024-04-24 00:10:55 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:10:55 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:10:57 - INFO :       similarities_abstraction: Total Sparsity 1.3577901220657553e-06
2024-04-24 00:11:09 - INFO :       similarities_abstraction: Total Accuracy (14, 16, 0.875)
2024-04-24 00:11:09 - INFO :       
==================Finish================

2024-04-24 00:11:09 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:11:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:11:09 - INFO :       DATASET: tasksource/bigbench simple_ethical_questions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-24 00:11:17 - INFO :       Use taylor pruner...
2024-04-24 00:11:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:11:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:11:17 - INFO :       Start Pruning
2024-04-24 00:11:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:11:19 - INFO :       Loss = 11.0390625
2024-04-24 00:11:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:11:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:11:22 - INFO :       simple_ethical_questions: Total Sparsity 1.359699589013463e-06
2024-04-24 00:11:41 - INFO :       simple_ethical_questions: Total Accuracy (7, 23, 0.30434782608695654)
2024-04-24 00:11:41 - INFO :       
==================Finish================

2024-04-24 00:11:41 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:11:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:11:41 - INFO :       DATASET: tasksource/bigbench snarks
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-24 00:11:49 - INFO :       Use taylor pruner...
2024-04-24 00:11:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:11:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:11:49 - INFO :       Start Pruning
2024-04-24 00:11:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:11:52 - INFO :       Loss = 14.328125
2024-04-24 00:11:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:11:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:11:54 - INFO :       snarks: Total Sparsity 1.3557215328724054e-06
2024-04-24 00:12:23 - INFO :       snarks: Total Accuracy (10, 36, 0.2777777777777778)
2024-04-24 00:12:24 - INFO :       
==================Finish================

2024-04-24 00:12:24 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:12:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:12:24 - INFO :       DATASET: tasksource/bigbench social_iqa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-24 00:12:31 - INFO :       Use taylor pruner...
2024-04-24 00:12:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:12:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:12:32 - INFO :       Start Pruning
2024-04-24 00:12:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:12:34 - INFO :       Loss = 14.6328125
2024-04-24 00:12:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:12:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:12:37 - INFO :       social_iqa: Total Sparsity 1.3593813445221782e-06
2024-04-24 00:13:17 - INFO :       social_iqa: Total Accuracy (20, 50, 0.4)
2024-04-24 00:13:17 - INFO :       
==================Finish================

2024-04-24 00:13:17 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:13:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:13:17 - INFO :       DATASET: tasksource/bigbench social_support
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-24 00:13:25 - INFO :       Use taylor pruner...
2024-04-24 00:13:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:13:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:13:25 - INFO :       Start Pruning
2024-04-24 00:13:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:13:33 - INFO :       Loss = 14.1171875
2024-04-24 00:13:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:13:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:13:36 - INFO :       social_support: Total Sparsity 1.357630999820113e-06
2024-04-24 00:14:16 - INFO :       social_support: Total Accuracy (42, 50, 0.84)
2024-04-24 00:14:16 - INFO :       
==================Finish================

2024-04-24 00:14:16 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:14:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:14:16 - INFO :       DATASET: tasksource/bigbench sports_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-24 00:14:24 - INFO :       Use taylor pruner...
2024-04-24 00:14:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:14:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:14:24 - INFO :       Start Pruning
2024-04-24 00:14:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:14:27 - INFO :       Loss = 15.59375
2024-04-24 00:14:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:14:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:14:30 - INFO :       sports_understanding: Total Sparsity 1.3568353885919015e-06
2024-04-24 00:15:09 - INFO :       sports_understanding: Total Accuracy (21, 50, 0.42)
2024-04-24 00:15:09 - INFO :       
==================Finish================

2024-04-24 00:15:09 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:15:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:15:09 - INFO :       DATASET: tasksource/bigbench strange_stories
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-24 00:15:17 - INFO :       Use taylor pruner...
2024-04-24 00:15:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:15:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:15:17 - INFO :       Start Pruning
2024-04-24 00:15:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:15:19 - INFO :       Loss = 10.8515625
2024-04-24 00:15:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:15:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:15:22 - INFO :       strange_stories: Total Sparsity 1.3574718775744707e-06
2024-04-24 00:15:50 - INFO :       strange_stories: Total Accuracy (9, 34, 0.2647058823529412)
2024-04-24 00:15:50 - INFO :       
==================Finish================

2024-04-24 00:15:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:15:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:15:50 - INFO :       DATASET: tasksource/bigbench strategyqa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2024-04-24 00:15:57 - INFO :       Use taylor pruner...
2024-04-24 00:15:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:15:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:15:58 - INFO :       Start Pruning
2024-04-24 00:15:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:16:00 - INFO :       Loss = 16.3125
2024-04-24 00:16:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:16:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:16:03 - INFO :       strategyqa: Total Sparsity 1.3566762663462592e-06
2024-04-24 00:16:41 - INFO :       strategyqa: Total Accuracy (19, 50, 0.38)
2024-04-24 00:16:41 - INFO :       
==================Finish================

2024-04-24 00:16:41 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:16:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:16:41 - INFO :       DATASET: tasksource/bigbench suicide_risk
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-24 00:16:49 - INFO :       Use taylor pruner...
2024-04-24 00:16:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:16:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:16:49 - INFO :       Start Pruning
2024-04-24 00:16:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:16:51 - INFO :       Loss = 9.5234375
2024-04-24 00:16:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:16:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:16:54 - INFO :       suicide_risk: Total Sparsity 1.3573127553288283e-06
2024-04-24 00:17:07 - INFO :       suicide_risk: Total Accuracy (4, 16, 0.25)
2024-04-24 00:17:07 - INFO :       
==================Finish================

2024-04-24 00:17:07 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:17:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:17:07 - INFO :       DATASET: tasksource/bigbench swahili_english_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 00:17:15 - INFO :       Use taylor pruner...
2024-04-24 00:17:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:17:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:17:15 - INFO :       Start Pruning
2024-04-24 00:17:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:17:18 - INFO :       Loss = 11.90625
2024-04-24 00:17:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:17:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:17:20 - INFO :       swahili_english_proverbs: Total Sparsity 1.3579492443113975e-06
2024-04-24 00:17:45 - INFO :       swahili_english_proverbs: Total Accuracy (2, 30, 0.06666666666666667)
2024-04-24 00:17:45 - INFO :       
==================Finish================

2024-04-24 00:17:45 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:17:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:17:45 - INFO :       DATASET: tasksource/bigbench swedish_to_german_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 00:17:52 - INFO :       Use taylor pruner...
2024-04-24 00:17:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:17:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:17:53 - INFO :       Start Pruning
2024-04-24 00:17:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:17:56 - INFO :       Loss = 11.7109375
2024-04-24 00:17:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:17:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:17:59 - INFO :       swedish_to_german_proverbs: Total Sparsity 1.3595404667678207e-06
2024-04-24 00:18:11 - INFO :       swedish_to_german_proverbs: Total Accuracy (6, 16, 0.375)
2024-04-24 00:18:11 - INFO :       
==================Finish================

2024-04-24 00:18:11 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:18:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:18:11 - INFO :       DATASET: tasksource/bigbench symbol_interpretation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-24 00:18:19 - INFO :       Use taylor pruner...
2024-04-24 00:18:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:18:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:18:20 - INFO :       Start Pruning
2024-04-24 00:18:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:18:22 - INFO :       Loss = 4.8515625
2024-04-24 00:18:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:18:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:18:24 - INFO :       symbol_interpretation: Total Sparsity 1.363995889645805e-06
2024-04-24 00:19:25 - INFO :       symbol_interpretation: Total Accuracy (15, 50, 0.3)
2024-04-24 00:19:25 - INFO :       
==================Finish================

2024-04-24 00:19:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:19:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:19:25 - INFO :       DATASET: tasksource/bigbench temporal_sequences
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-24 00:19:33 - INFO :       Use taylor pruner...
2024-04-24 00:19:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:19:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:19:33 - INFO :       Start Pruning
2024-04-24 00:19:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:19:35 - INFO :       Loss = 9.2265625
2024-04-24 00:19:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:19:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:19:38 - INFO :       temporal_sequences: Total Sparsity 1.3617681782068128e-06
2024-04-24 00:20:20 - INFO :       temporal_sequences: Total Accuracy (5, 50, 0.1)
2024-04-24 00:20:20 - INFO :       
==================Finish================

2024-04-24 00:20:20 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:20:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:20:20 - INFO :       DATASET: tasksource/bigbench timedial
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-24 00:20:27 - INFO :       Use taylor pruner...
2024-04-24 00:20:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:20:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:20:28 - INFO :       Start Pruning
2024-04-24 00:20:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:20:30 - INFO :       Loss = 5.81640625
2024-04-24 00:20:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:20:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:20:33 - INFO :       timedial: Total Sparsity 1.3561988996093322e-06
2024-04-24 00:21:17 - INFO :       timedial: Total Accuracy (1, 50, 0.02)
2024-04-24 00:21:17 - INFO :       
==================Finish================

2024-04-24 00:21:17 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:21:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:21:17 - INFO :       DATASET: tasksource/bigbench tracking_shuffled_objects
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-24 00:21:25 - INFO :       Use taylor pruner...
2024-04-24 00:21:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:21:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:21:25 - INFO :       Start Pruning
2024-04-24 00:21:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:21:28 - INFO :       Loss = 10.703125
2024-04-24 00:21:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:21:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:21:31 - INFO :       tracking_shuffled_objects: Total Sparsity 1.3609725669786013e-06
2024-04-24 00:22:11 - INFO :       tracking_shuffled_objects: Total Accuracy (10, 50, 0.2)
2024-04-24 00:22:11 - INFO :       
==================Finish================

2024-04-24 00:22:11 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:22:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:22:11 - INFO :       DATASET: tasksource/bigbench understanding_fables
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 00:22:19 - INFO :       Use taylor pruner...
2024-04-24 00:22:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:22:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:22:19 - INFO :       Start Pruning
2024-04-24 00:22:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:22:21 - INFO :       Loss = 8.03125
2024-04-24 00:22:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:22:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:22:24 - INFO :       understanding_fables: Total Sparsity 1.361449933715528e-06
2024-04-24 00:22:56 - INFO :       understanding_fables: Total Accuracy (5, 37, 0.13513513513513514)
2024-04-24 00:22:56 - INFO :       
==================Finish================

2024-04-24 00:22:56 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:22:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:22:56 - INFO :       DATASET: tasksource/bigbench undo_permutation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-24 00:23:03 - INFO :       Use taylor pruner...
2024-04-24 00:23:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:23:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:23:04 - INFO :       Start Pruning
2024-04-24 00:23:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:23:06 - INFO :       Loss = 8.6875
2024-04-24 00:23:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:23:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:23:09 - INFO :       undo_permutation: Total Sparsity 1.3595404667678207e-06
2024-04-24 00:23:52 - INFO :       undo_permutation: Total Accuracy (23, 50, 0.46)
2024-04-24 00:23:52 - INFO :       
==================Finish================

2024-04-24 00:23:52 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:23:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:23:52 - INFO :       DATASET: tasksource/bigbench unit_interpretation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-24 00:23:59 - INFO :       Use taylor pruner...
2024-04-24 00:23:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:23:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:24:00 - INFO :       Start Pruning
2024-04-24 00:24:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:24:02 - INFO :       Loss = 11.9453125
2024-04-24 00:24:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:24:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:24:05 - INFO :       unit_interpretation: Total Sparsity 1.357153633083186e-06
2024-04-24 00:24:21 - INFO :       unit_interpretation: Total Accuracy (5, 20, 0.25)
2024-04-24 00:24:21 - INFO :       
==================Finish================

2024-04-24 00:24:21 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:24:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:24:21 - INFO :       DATASET: tasksource/bigbench vitaminc_fact_verification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 00:24:28 - INFO :       Use taylor pruner...
2024-04-24 00:24:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:24:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:24:29 - INFO :       Start Pruning
2024-04-24 00:24:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:24:31 - INFO :       Loss = 12.7421875
2024-04-24 00:24:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:24:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:24:34 - INFO :       vitaminc_fact_verification: Total Sparsity 1.3590631000308936e-06
2024-04-24 00:25:14 - INFO :       vitaminc_fact_verification: Total Accuracy (21, 50, 0.42)
2024-04-24 00:25:14 - INFO :       
==================Finish================

2024-04-24 00:25:14 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:25:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:25:14 - INFO :       DATASET: tasksource/bigbench what_is_the_tao
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-24 00:25:21 - INFO :       Use taylor pruner...
2024-04-24 00:25:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:25:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:25:22 - INFO :       Start Pruning
2024-04-24 00:25:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:25:24 - INFO :       Loss = 12.71875
2024-04-24 00:25:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:25:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:25:27 - INFO :       what_is_the_tao: Total Sparsity 1.3606543224873167e-06
2024-04-24 00:25:40 - INFO :       what_is_the_tao: Total Accuracy (4, 16, 0.25)
2024-04-24 00:25:40 - INFO :       
==================Finish================

2024-04-24 00:25:40 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-24 00:25:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:25:40 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-24 00:25:47 - INFO :       Use taylor pruner...
2024-04-24 00:25:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:25:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:25:48 - INFO :       Start Pruning
2024-04-24 00:25:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:25:50 - INFO :       Loss = 2.19140625
2024-04-24 00:25:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:25:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:25:53 - INFO :       which_wiki_edit: Total Sparsity 1.3566762663462592e-06
2024-04-24 00:27:27 - INFO :       which_wiki_edit: Total Accuracy (32, 50, 0.64)
2024-04-24 00:27:27 - INFO :       
==================Finish================

2024-04-24 00:27:27 - INFO :       Memory Requirement: 16809.46826171875 MiB

2024-04-24 00:27:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:27:27 - INFO :       DATASET: tasksource/bigbench winowhy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-24 00:27:35 - INFO :       Use taylor pruner...
2024-04-24 00:27:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:27:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:27:35 - INFO :       Start Pruning
2024-04-24 00:27:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:27:37 - INFO :       Loss = 15.0
2024-04-24 00:27:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:27:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:27:40 - INFO :       winowhy: Total Sparsity 1.356517144100617e-06
2024-04-24 00:28:20 - INFO :       winowhy: Total Accuracy (30, 50, 0.6)
2024-04-24 00:28:20 - INFO :       
==================Finish================

2024-04-24 00:28:20 - INFO :       Memory Requirement: 16777.79052734375 MiB

2024-04-24 00:28:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:28:20 - INFO :       DATASET: tasksource/mmlu abstract_algebra
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-24 00:28:28 - INFO :       Use taylor pruner...
2024-04-24 00:28:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:28:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:28:28 - INFO :       Start Pruning
2024-04-24 00:28:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:28:30 - INFO :       Loss = 13.7578125
2024-04-24 00:28:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:28:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:28:33 - INFO :       abstract_algebra: Total Sparsity 1.356517144100617e-06
2024-04-24 00:28:42 - INFO :       abstract_algebra: Total Accuracy (4, 11, 0.36363636363636365)
2024-04-24 00:28:42 - INFO :       
==================Finish================

2024-04-24 00:28:42 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:28:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:28:42 - INFO :       DATASET: tasksource/mmlu anatomy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-24 00:28:50 - INFO :       Use taylor pruner...
2024-04-24 00:28:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:28:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:28:50 - INFO :       Start Pruning
2024-04-24 00:28:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:28:52 - INFO :       Loss = 14.3125
2024-04-24 00:28:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:28:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:28:55 - INFO :       anatomy: Total Sparsity 1.3600178335047475e-06
2024-04-24 00:29:06 - INFO :       anatomy: Total Accuracy (9, 14, 0.6428571428571429)
2024-04-24 00:29:06 - INFO :       
==================Finish================

2024-04-24 00:29:06 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:29:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:29:06 - INFO :       DATASET: tasksource/mmlu astronomy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-24 00:29:14 - INFO :       Use taylor pruner...
2024-04-24 00:29:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:29:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:29:15 - INFO :       Start Pruning
2024-04-24 00:29:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:29:17 - INFO :       Loss = 13.46875
2024-04-24 00:29:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:29:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:29:20 - INFO :       astronomy: Total Sparsity 1.3579492443113975e-06
2024-04-24 00:29:32 - INFO :       astronomy: Total Accuracy (2, 16, 0.125)
2024-04-24 00:29:32 - INFO :       
==================Finish================

2024-04-24 00:29:32 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:29:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:29:32 - INFO :       DATASET: tasksource/mmlu business_ethics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 00:29:40 - INFO :       Use taylor pruner...
2024-04-24 00:29:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:29:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:29:40 - INFO :       Start Pruning
2024-04-24 00:29:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:29:43 - INFO :       Loss = 14.2734375
2024-04-24 00:29:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:29:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:29:45 - INFO :       business_ethics: Total Sparsity 1.3598587112591052e-06
2024-04-24 00:29:54 - INFO :       business_ethics: Total Accuracy (5, 11, 0.45454545454545453)
2024-04-24 00:29:54 - INFO :       
==================Finish================

2024-04-24 00:29:54 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:29:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:29:54 - INFO :       DATASET: tasksource/mmlu clinical_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-24 00:30:02 - INFO :       Use taylor pruner...
2024-04-24 00:30:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:30:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:30:03 - INFO :       Start Pruning
2024-04-24 00:30:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:30:05 - INFO :       Loss = 14.9921875
2024-04-24 00:30:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:30:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:30:07 - INFO :       clinical_knowledge: Total Sparsity 1.355562410626763e-06
2024-04-24 00:30:31 - INFO :       clinical_knowledge: Total Accuracy (15, 29, 0.5172413793103449)
2024-04-24 00:30:31 - INFO :       
==================Finish================

2024-04-24 00:30:31 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:30:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:30:31 - INFO :       DATASET: tasksource/mmlu college_biology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2024-04-24 00:30:39 - INFO :       Use taylor pruner...
2024-04-24 00:30:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:30:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:30:39 - INFO :       Start Pruning
2024-04-24 00:30:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:30:41 - INFO :       Loss = 14.1015625
2024-04-24 00:30:42 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:30:42 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:30:44 - INFO :       college_biology: Total Sparsity 1.3558806551180476e-06
2024-04-24 00:30:57 - INFO :       college_biology: Total Accuracy (7, 16, 0.4375)
2024-04-24 00:30:57 - INFO :       
==================Finish================

2024-04-24 00:30:57 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:30:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:30:57 - INFO :       DATASET: tasksource/mmlu college_chemistry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-24 00:31:05 - INFO :       Use taylor pruner...
2024-04-24 00:31:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:31:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:31:05 - INFO :       Start Pruning
num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-24 00:31:06 - WARNING :       num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-24 00:31:06 - WARNING :       num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-24 00:31:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:31:07 - INFO :       Loss = 12.6328125
2024-04-24 00:31:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:31:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:31:10 - INFO :       college_chemistry: Total Sparsity 1.3557215328724054e-06
2024-04-24 00:31:16 - INFO :       college_chemistry: Total Accuracy (1, 8, 0.125)
2024-04-24 00:31:16 - INFO :       
==================Finish================

2024-04-24 00:31:16 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:31:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:31:16 - INFO :       DATASET: tasksource/mmlu college_computer_science
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-24 00:31:24 - INFO :       Use taylor pruner...
2024-04-24 00:31:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:31:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:31:24 - INFO :       Start Pruning
2024-04-24 00:31:25 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:31:26 - INFO :       Loss = 12.828125
2024-04-24 00:31:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:31:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:31:29 - INFO :       college_computer_science: Total Sparsity 1.3584266110483244e-06
2024-04-24 00:31:38 - INFO :       college_computer_science: Total Accuracy (1, 11, 0.09090909090909091)
2024-04-24 00:31:38 - INFO :       
==================Finish================

2024-04-24 00:31:38 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:31:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:31:38 - INFO :       DATASET: tasksource/mmlu college_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-24 00:31:46 - INFO :       Use taylor pruner...
2024-04-24 00:31:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:31:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:31:46 - INFO :       Start Pruning
2024-04-24 00:31:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:31:48 - INFO :       Loss = 13.5546875
2024-04-24 00:31:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:31:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:31:51 - INFO :       college_mathematics: Total Sparsity 1.3585857332939668e-06
2024-04-24 00:32:00 - INFO :       college_mathematics: Total Accuracy (4, 11, 0.36363636363636365)
2024-04-24 00:32:00 - INFO :       
==================Finish================

2024-04-24 00:32:00 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:32:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:32:00 - INFO :       DATASET: tasksource/mmlu college_medicine
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 00:32:08 - INFO :       Use taylor pruner...
2024-04-24 00:32:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:32:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:32:08 - INFO :       Start Pruning
2024-04-24 00:32:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:32:10 - INFO :       Loss = 14.1875
2024-04-24 00:32:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:32:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:32:13 - INFO :       college_medicine: Total Sparsity 1.3566762663462592e-06
2024-04-24 00:32:31 - INFO :       college_medicine: Total Accuracy (10, 22, 0.45454545454545453)
2024-04-24 00:32:31 - INFO :       
==================Finish================

2024-04-24 00:32:31 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:32:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:32:31 - INFO :       DATASET: tasksource/mmlu college_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-24 00:32:38 - INFO :       Use taylor pruner...
2024-04-24 00:32:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:32:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:32:39 - INFO :       Start Pruning
2024-04-24 00:32:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:32:41 - INFO :       Loss = 12.8515625
2024-04-24 00:32:42 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:32:42 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:32:44 - INFO :       college_physics: Total Sparsity 1.359222222276536e-06
2024-04-24 00:32:53 - INFO :       college_physics: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-24 00:32:53 - INFO :       
==================Finish================

2024-04-24 00:32:53 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:32:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:32:53 - INFO :       DATASET: tasksource/mmlu computer_security
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 00:33:01 - INFO :       Use taylor pruner...
2024-04-24 00:33:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:33:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:33:01 - INFO :       Start Pruning
2024-04-24 00:33:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:33:03 - INFO :       Loss = 13.140625
2024-04-24 00:33:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:33:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:33:06 - INFO :       computer_security: Total Sparsity 1.3558806551180476e-06
2024-04-24 00:33:15 - INFO :       computer_security: Total Accuracy (2, 11, 0.18181818181818182)
2024-04-24 00:33:15 - INFO :       
==================Finish================

2024-04-24 00:33:15 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:33:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:33:15 - INFO :       DATASET: tasksource/mmlu conceptual_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-24 00:33:23 - INFO :       Use taylor pruner...
2024-04-24 00:33:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:33:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:33:23 - INFO :       Start Pruning
2024-04-24 00:33:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:33:25 - INFO :       Loss = 14.6328125
2024-04-24 00:33:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:33:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:33:28 - INFO :       conceptual_physics: Total Sparsity 1.3566762663462592e-06
2024-04-24 00:33:48 - INFO :       conceptual_physics: Total Accuracy (8, 26, 0.3076923076923077)
2024-04-24 00:33:48 - INFO :       
==================Finish================

2024-04-24 00:33:48 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:33:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:33:48 - INFO :       DATASET: tasksource/mmlu econometrics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2024-04-24 00:33:56 - INFO :       Use taylor pruner...
2024-04-24 00:33:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:33:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:33:56 - INFO :       Start Pruning
2024-04-24 00:33:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:33:58 - INFO :       Loss = 12.9296875
2024-04-24 00:34:00 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:34:00 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:34:01 - INFO :       econometrics: Total Sparsity 1.362882033926309e-06
2024-04-24 00:34:11 - INFO :       econometrics: Total Accuracy (2, 12, 0.16666666666666666)
2024-04-24 00:34:11 - INFO :       
==================Finish================

2024-04-24 00:34:11 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:34:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:34:11 - INFO :       DATASET: tasksource/mmlu electrical_engineering
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-24 00:34:19 - INFO :       Use taylor pruner...
2024-04-24 00:34:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:34:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:34:19 - INFO :       Start Pruning
2024-04-24 00:34:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:34:21 - INFO :       Loss = 15.21875
2024-04-24 00:34:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:34:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:34:24 - INFO :       electrical_engineering: Total Sparsity 1.3569945108375437e-06
2024-04-24 00:34:37 - INFO :       electrical_engineering: Total Accuracy (5, 16, 0.3125)
2024-04-24 00:34:37 - INFO :       
==================Finish================

2024-04-24 00:34:37 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:34:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:34:37 - INFO :       DATASET: tasksource/mmlu elementary_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-24 00:34:45 - INFO :       Use taylor pruner...
2024-04-24 00:34:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:34:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:34:45 - INFO :       Start Pruning
2024-04-24 00:34:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:34:47 - INFO :       Loss = 14.40625
2024-04-24 00:34:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:34:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:34:50 - INFO :       elementary_mathematics: Total Sparsity 1.356517144100617e-06
2024-04-24 00:35:23 - INFO :       elementary_mathematics: Total Accuracy (10, 41, 0.24390243902439024)
2024-04-24 00:35:24 - INFO :       
==================Finish================

2024-04-24 00:35:24 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:35:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:35:24 - INFO :       DATASET: tasksource/mmlu formal_logic
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-24 00:35:31 - INFO :       Use taylor pruner...
2024-04-24 00:35:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:35:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:35:32 - INFO :       Start Pruning
2024-04-24 00:35:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:35:34 - INFO :       Loss = 12.6953125
2024-04-24 00:35:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:35:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:35:37 - INFO :       formal_logic: Total Sparsity 1.3547667993985515e-06
2024-04-24 00:35:48 - INFO :       formal_logic: Total Accuracy (4, 14, 0.2857142857142857)
2024-04-24 00:35:48 - INFO :       
==================Finish================

2024-04-24 00:35:48 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:35:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:35:48 - INFO :       DATASET: tasksource/mmlu global_facts
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-24 00:35:56 - INFO :       Use taylor pruner...
2024-04-24 00:35:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:35:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:35:57 - INFO :       Start Pruning
2024-04-24 00:35:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:35:59 - INFO :       Loss = 14.28125
2024-04-24 00:36:00 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:36:00 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:36:01 - INFO :       global_facts: Total Sparsity 1.3584266110483244e-06
2024-04-24 00:36:10 - INFO :       global_facts: Total Accuracy (5, 10, 0.5)
2024-04-24 00:36:10 - INFO :       
==================Finish================

2024-04-24 00:36:10 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:36:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:36:10 - INFO :       DATASET: tasksource/mmlu high_school_biology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-24 00:36:17 - INFO :       Use taylor pruner...
2024-04-24 00:36:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:36:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:36:18 - INFO :       Start Pruning
2024-04-24 00:36:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:36:19 - INFO :       Loss = 14.8046875
2024-04-24 00:36:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:36:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:36:22 - INFO :       high_school_biology: Total Sparsity 1.35603977736369e-06
2024-04-24 00:36:48 - INFO :       high_school_biology: Total Accuracy (12, 32, 0.375)
2024-04-24 00:36:49 - INFO :       
==================Finish================

2024-04-24 00:36:49 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:36:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:36:49 - INFO :       DATASET: tasksource/mmlu high_school_chemistry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2024-04-24 00:36:59 - INFO :       Use taylor pruner...
2024-04-24 00:36:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:36:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:36:59 - INFO :       Start Pruning
2024-04-24 00:37:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:37:01 - INFO :       Loss = 14.75
2024-04-24 00:37:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:37:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:37:04 - INFO :       high_school_chemistry: Total Sparsity 1.354448554907267e-06
2024-04-24 00:37:23 - INFO :       high_school_chemistry: Total Accuracy (6, 22, 0.2727272727272727)
2024-04-24 00:37:23 - INFO :       
==================Finish================

2024-04-24 00:37:23 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:37:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:37:23 - INFO :       DATASET: tasksource/mmlu high_school_computer_science
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.22s/it]
2024-04-24 00:37:33 - INFO :       Use taylor pruner...
2024-04-24 00:37:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:37:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:37:33 - INFO :       Start Pruning
num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-24 00:37:34 - WARNING :       num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-24 00:37:34 - WARNING :       num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-24 00:37:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:37:35 - INFO :       Loss = 13.9296875
2024-04-24 00:37:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:37:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:37:38 - INFO :       high_school_computer_science: Total Sparsity 1.3574718775744707e-06
2024-04-24 00:37:46 - INFO :       high_school_computer_science: Total Accuracy (5, 9, 0.5555555555555556)
2024-04-24 00:37:46 - INFO :       
==================Finish================

2024-04-24 00:37:46 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:37:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:37:46 - INFO :       DATASET: tasksource/mmlu high_school_european_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 00:37:57 - INFO :       Use taylor pruner...
2024-04-24 00:37:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:37:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:37:58 - INFO :       Start Pruning
2024-04-24 00:37:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:38:00 - INFO :       Loss = 7.10546875
2024-04-24 00:38:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:38:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:38:03 - INFO :       high_school_european_history: Total Sparsity 1.3595404667678207e-06
2024-04-24 00:38:19 - INFO :       high_school_european_history: Total Accuracy (10, 18, 0.5555555555555556)
2024-04-24 00:38:20 - INFO :       
==================Finish================

2024-04-24 00:38:20 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:38:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:38:20 - INFO :       DATASET: tasksource/mmlu high_school_geography
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]
2024-04-24 00:38:28 - INFO :       Use taylor pruner...
2024-04-24 00:38:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:38:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:38:29 - INFO :       Start Pruning
2024-04-24 00:38:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:38:31 - INFO :       Loss = 14.6640625
2024-04-24 00:38:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:38:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:38:34 - INFO :       high_school_geography: Total Sparsity 1.3581083665570398e-06
2024-04-24 00:38:52 - INFO :       high_school_geography: Total Accuracy (14, 22, 0.6363636363636364)
2024-04-24 00:38:52 - INFO :       
==================Finish================

2024-04-24 00:38:52 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:38:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:38:52 - INFO :       DATASET: tasksource/mmlu high_school_government_and_politics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
2024-04-24 00:39:00 - INFO :       Use taylor pruner...
2024-04-24 00:39:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:39:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:39:01 - INFO :       Start Pruning
2024-04-24 00:39:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:39:03 - INFO :       Loss = 14.59375
2024-04-24 00:39:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:39:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:39:06 - INFO :       high_school_government_and_politics: Total Sparsity 1.3581083665570398e-06
2024-04-24 00:39:22 - INFO :       high_school_government_and_politics: Total Accuracy (7, 21, 0.3333333333333333)
2024-04-24 00:39:22 - INFO :       
==================Finish================

2024-04-24 00:39:22 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:39:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:39:22 - INFO :       DATASET: tasksource/mmlu high_school_macroeconomics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-24 00:39:30 - INFO :       Use taylor pruner...
2024-04-24 00:39:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:39:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:39:31 - INFO :       Start Pruning
2024-04-24 00:39:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:39:33 - INFO :       Loss = 14.640625
2024-04-24 00:39:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:39:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:39:36 - INFO :       high_school_macroeconomics: Total Sparsity 1.360336077996032e-06
2024-04-24 00:40:11 - INFO :       high_school_macroeconomics: Total Accuracy (17, 43, 0.3953488372093023)
2024-04-24 00:40:12 - INFO :       
==================Finish================

2024-04-24 00:40:12 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:40:12 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:40:12 - INFO :       DATASET: tasksource/mmlu high_school_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-24 00:40:20 - INFO :       Use taylor pruner...
2024-04-24 00:40:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:40:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:40:21 - INFO :       Start Pruning
2024-04-24 00:40:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:40:23 - INFO :       Loss = 13.671875
2024-04-24 00:40:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:40:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:40:26 - INFO :       high_school_mathematics: Total Sparsity 1.357153633083186e-06
2024-04-24 00:40:50 - INFO :       high_school_mathematics: Total Accuracy (4, 29, 0.13793103448275862)
2024-04-24 00:40:50 - INFO :       
==================Finish================

2024-04-24 00:40:50 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:40:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:40:50 - INFO :       DATASET: tasksource/mmlu high_school_microeconomics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 00:40:58 - INFO :       Use taylor pruner...
2024-04-24 00:40:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:40:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:40:58 - INFO :       Start Pruning
2024-04-24 00:40:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:41:00 - INFO :       Loss = 13.9140625
2024-04-24 00:41:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:41:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:41:03 - INFO :       high_school_microeconomics: Total Sparsity 1.360813444732959e-06
2024-04-24 00:41:25 - INFO :       high_school_microeconomics: Total Accuracy (10, 26, 0.38461538461538464)
2024-04-24 00:41:25 - INFO :       
==================Finish================

2024-04-24 00:41:25 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:41:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:41:25 - INFO :       DATASET: tasksource/mmlu high_school_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-24 00:41:33 - INFO :       Use taylor pruner...
2024-04-24 00:41:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:41:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:41:33 - INFO :       Start Pruning
2024-04-24 00:41:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:41:36 - INFO :       Loss = 12.765625
2024-04-24 00:41:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:41:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:41:39 - INFO :       high_school_physics: Total Sparsity 1.3593813445221782e-06
2024-04-24 00:41:53 - INFO :       high_school_physics: Total Accuracy (3, 17, 0.17647058823529413)
2024-04-24 00:41:53 - INFO :       
==================Finish================

2024-04-24 00:41:53 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:41:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:41:53 - INFO :       DATASET: tasksource/mmlu high_school_psychology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2024-04-24 00:42:01 - INFO :       Use taylor pruner...
2024-04-24 00:42:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:42:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:42:02 - INFO :       Start Pruning
2024-04-24 00:42:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:42:03 - INFO :       Loss = 14.7109375
2024-04-24 00:42:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:42:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:42:06 - INFO :       high_school_psychology: Total Sparsity 1.3595404667678207e-06
2024-04-24 00:42:49 - INFO :       high_school_psychology: Total Accuracy (31, 50, 0.62)
2024-04-24 00:42:49 - INFO :       
==================Finish================

2024-04-24 00:42:49 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:42:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:42:49 - INFO :       DATASET: tasksource/mmlu high_school_statistics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2024-04-24 00:42:57 - INFO :       Use taylor pruner...
2024-04-24 00:42:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:42:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:42:57 - INFO :       Start Pruning
2024-04-24 00:42:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:42:59 - INFO :       Loss = 14.890625
2024-04-24 00:43:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:43:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:43:02 - INFO :       high_school_statistics: Total Sparsity 1.3563580218549744e-06
2024-04-24 00:43:23 - INFO :       high_school_statistics: Total Accuracy (5, 23, 0.21739130434782608)
2024-04-24 00:43:23 - INFO :       
==================Finish================

2024-04-24 00:43:23 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:43:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:43:23 - INFO :       DATASET: tasksource/mmlu high_school_us_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]
2024-04-24 00:43:32 - INFO :       Use taylor pruner...
2024-04-24 00:43:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:43:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:43:33 - INFO :       Start Pruning
2024-04-24 00:43:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:43:37 - INFO :       Loss = 7.85546875
2024-04-24 00:43:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:43:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:43:40 - INFO :       high_school_us_history: Total Sparsity 1.357630999820113e-06
2024-04-24 00:43:59 - INFO :       high_school_us_history: Total Accuracy (13, 22, 0.5909090909090909)
2024-04-24 00:44:00 - INFO :       
==================Finish================

2024-04-24 00:44:00 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:44:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:44:00 - INFO :       DATASET: tasksource/mmlu high_school_world_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 00:44:08 - INFO :       Use taylor pruner...
2024-04-24 00:44:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:44:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:44:08 - INFO :       Start Pruning
2024-04-24 00:44:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:44:10 - INFO :       Loss = 5.40234375
2024-04-24 00:44:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:44:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:44:13 - INFO :       high_school_world_history: Total Sparsity 1.356517144100617e-06
2024-04-24 00:44:38 - INFO :       high_school_world_history: Total Accuracy (9, 26, 0.34615384615384615)
2024-04-24 00:44:38 - INFO :       
==================Finish================

2024-04-24 00:44:38 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:44:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:44:38 - INFO :       DATASET: tasksource/mmlu human_aging
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.43s/it]
2024-04-24 00:44:51 - INFO :       Use taylor pruner...
2024-04-24 00:44:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:44:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:44:52 - INFO :       Start Pruning
2024-04-24 00:44:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:44:54 - INFO :       Loss = 15.515625
2024-04-24 00:44:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:44:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:44:59 - INFO :       human_aging: Total Sparsity 1.3577901220657553e-06
2024-04-24 00:45:18 - INFO :       human_aging: Total Accuracy (12, 23, 0.5217391304347826)
2024-04-24 00:45:18 - INFO :       
==================Finish================

2024-04-24 00:45:18 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:45:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:45:18 - INFO :       DATASET: tasksource/mmlu human_sexuality
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.58s/it]
2024-04-24 00:45:28 - INFO :       Use taylor pruner...
2024-04-24 00:45:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:45:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:45:29 - INFO :       Start Pruning
2024-04-24 00:45:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:45:32 - INFO :       Loss = 15.015625
2024-04-24 00:45:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:45:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:45:35 - INFO :       human_sexuality: Total Sparsity 1.3598587112591052e-06
2024-04-24 00:45:45 - INFO :       human_sexuality: Total Accuracy (2, 12, 0.16666666666666666)
2024-04-24 00:45:45 - INFO :       
==================Finish================

2024-04-24 00:45:45 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:45:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:45:45 - INFO :       DATASET: tasksource/mmlu international_law
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-24 00:45:52 - INFO :       Use taylor pruner...
2024-04-24 00:45:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:45:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:45:53 - INFO :       Start Pruning
2024-04-24 00:45:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:45:55 - INFO :       Loss = 14.171875
2024-04-24 00:45:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:45:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:45:58 - INFO :       international_law: Total Sparsity 1.3595404667678207e-06
2024-04-24 00:46:09 - INFO :       international_law: Total Accuracy (10, 13, 0.7692307692307693)
2024-04-24 00:46:09 - INFO :       
==================Finish================

2024-04-24 00:46:09 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:46:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:46:09 - INFO :       DATASET: tasksource/mmlu jurisprudence
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 00:46:16 - INFO :       Use taylor pruner...
2024-04-24 00:46:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:46:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:46:17 - INFO :       Start Pruning
2024-04-24 00:46:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:46:19 - INFO :       Loss = 15.0234375
2024-04-24 00:46:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:46:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:46:22 - INFO :       jurisprudence: Total Sparsity 1.360336077996032e-06
2024-04-24 00:46:31 - INFO :       jurisprudence: Total Accuracy (4, 11, 0.36363636363636365)
2024-04-24 00:46:31 - INFO :       
==================Finish================

2024-04-24 00:46:31 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:46:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:46:31 - INFO :       DATASET: tasksource/mmlu logical_fallacies
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-24 00:46:39 - INFO :       Use taylor pruner...
2024-04-24 00:46:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:46:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:46:39 - INFO :       Start Pruning
2024-04-24 00:46:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:46:41 - INFO :       Loss = 15.2578125
2024-04-24 00:46:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:46:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:46:44 - INFO :       logical_fallacies: Total Sparsity 1.3557215328724054e-06
2024-04-24 00:46:59 - INFO :       logical_fallacies: Total Accuracy (9, 18, 0.5)
2024-04-24 00:46:59 - INFO :       
==================Finish================

2024-04-24 00:46:59 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:46:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:46:59 - INFO :       DATASET: tasksource/mmlu machine_learning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 00:47:06 - INFO :       Use taylor pruner...
2024-04-24 00:47:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:47:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:47:07 - INFO :       Start Pruning
2024-04-24 00:47:08 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:47:09 - INFO :       Loss = 11.9765625
2024-04-24 00:47:10 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:47:10 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:47:12 - INFO :       machine_learning: Total Sparsity 1.358744855539609e-06
2024-04-24 00:47:21 - INFO :       machine_learning: Total Accuracy (5, 11, 0.45454545454545453)
2024-04-24 00:47:21 - INFO :       
==================Finish================

2024-04-24 00:47:21 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:47:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:47:21 - INFO :       DATASET: tasksource/mmlu management
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-24 00:47:28 - INFO :       Use taylor pruner...
2024-04-24 00:47:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:47:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:47:29 - INFO :       Start Pruning
2024-04-24 00:47:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:47:31 - INFO :       Loss = 15.6875
2024-04-24 00:47:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:47:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:47:34 - INFO :       management: Total Sparsity 1.357153633083186e-06
2024-04-24 00:47:43 - INFO :       management: Total Accuracy (8, 11, 0.7272727272727273)
2024-04-24 00:47:44 - INFO :       
==================Finish================

2024-04-24 00:47:44 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:47:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:47:44 - INFO :       DATASET: tasksource/mmlu marketing
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-24 00:47:51 - INFO :       Use taylor pruner...
2024-04-24 00:47:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:47:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:47:52 - INFO :       Start Pruning
2024-04-24 00:47:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:47:54 - INFO :       Loss = 14.46875
2024-04-24 00:47:55 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:47:55 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:47:57 - INFO :       marketing: Total Sparsity 1.359699589013463e-06
2024-04-24 00:48:17 - INFO :       marketing: Total Accuracy (13, 25, 0.52)
2024-04-24 00:48:17 - INFO :       
==================Finish================

2024-04-24 00:48:17 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:48:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:48:17 - INFO :       DATASET: tasksource/mmlu medical_genetics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-24 00:48:25 - INFO :       Use taylor pruner...
2024-04-24 00:48:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:48:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:48:25 - INFO :       Start Pruning
2024-04-24 00:48:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:48:27 - INFO :       Loss = 14.1875
2024-04-24 00:48:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:48:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:48:30 - INFO :       medical_genetics: Total Sparsity 1.3577901220657553e-06
2024-04-24 00:48:39 - INFO :       medical_genetics: Total Accuracy (8, 11, 0.7272727272727273)
2024-04-24 00:48:39 - INFO :       
==================Finish================

2024-04-24 00:48:39 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:48:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:48:39 - INFO :       DATASET: tasksource/mmlu miscellaneous
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 00:48:47 - INFO :       Use taylor pruner...
2024-04-24 00:48:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:48:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:48:47 - INFO :       Start Pruning
2024-04-24 00:48:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:48:49 - INFO :       Loss = 15.0234375
2024-04-24 00:48:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:48:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:48:52 - INFO :       miscellaneous: Total Sparsity 1.360336077996032e-06
2024-04-24 00:49:33 - INFO :       miscellaneous: Total Accuracy (29, 50, 0.58)
2024-04-24 00:49:33 - INFO :       
==================Finish================

2024-04-24 00:49:33 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:49:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:49:33 - INFO :       DATASET: tasksource/mmlu moral_disputes
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-24 00:49:40 - INFO :       Use taylor pruner...
2024-04-24 00:49:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:49:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:49:41 - INFO :       Start Pruning
2024-04-24 00:49:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:49:43 - INFO :       Loss = 14.0703125
2024-04-24 00:49:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:49:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:49:46 - INFO :       moral_disputes: Total Sparsity 1.3579492443113975e-06
2024-04-24 00:50:16 - INFO :       moral_disputes: Total Accuracy (18, 38, 0.47368421052631576)
2024-04-24 00:50:16 - INFO :       
==================Finish================

2024-04-24 00:50:16 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:50:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:50:16 - INFO :       DATASET: tasksource/mmlu moral_scenarios
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-24 00:50:24 - INFO :       Use taylor pruner...
2024-04-24 00:50:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:50:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:50:24 - INFO :       Start Pruning
2024-04-24 00:50:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:50:27 - INFO :       Loss = 13.421875
2024-04-24 00:50:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:50:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:50:29 - INFO :       moral_scenarios: Total Sparsity 1.3606543224873167e-06
2024-04-24 00:51:10 - INFO :       moral_scenarios: Total Accuracy (18, 50, 0.36)
2024-04-24 00:51:11 - INFO :       
==================Finish================

2024-04-24 00:51:11 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:51:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:51:11 - INFO :       DATASET: tasksource/mmlu nutrition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-24 00:51:18 - INFO :       Use taylor pruner...
2024-04-24 00:51:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:51:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:51:18 - INFO :       Start Pruning
2024-04-24 00:51:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:51:20 - INFO :       Loss = 14.03125
2024-04-24 00:51:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:51:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:51:23 - INFO :       nutrition: Total Sparsity 1.3581083665570398e-06
2024-04-24 00:51:50 - INFO :       nutrition: Total Accuracy (16, 33, 0.48484848484848486)
2024-04-24 00:51:50 - INFO :       
==================Finish================

2024-04-24 00:51:50 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:51:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:51:50 - INFO :       DATASET: tasksource/mmlu philosophy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-24 00:51:58 - INFO :       Use taylor pruner...
2024-04-24 00:51:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:51:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:51:58 - INFO :       Start Pruning
2024-04-24 00:51:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:52:00 - INFO :       Loss = 15.0
2024-04-24 00:52:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:52:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:52:03 - INFO :       philosophy: Total Sparsity 1.3577901220657553e-06
2024-04-24 00:52:30 - INFO :       philosophy: Total Accuracy (17, 34, 0.5)
2024-04-24 00:52:30 - INFO :       
==================Finish================

2024-04-24 00:52:30 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:52:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:52:30 - INFO :       DATASET: tasksource/mmlu prehistory
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-24 00:52:38 - INFO :       Use taylor pruner...
2024-04-24 00:52:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:52:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:52:38 - INFO :       Start Pruning
2024-04-24 00:52:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:52:42 - INFO :       Loss = 14.953125
2024-04-24 00:52:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:52:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:52:45 - INFO :       prehistory: Total Sparsity 1.355085043889836e-06
2024-04-24 00:53:13 - INFO :       prehistory: Total Accuracy (17, 35, 0.4857142857142857)
2024-04-24 00:53:13 - INFO :       
==================Finish================

2024-04-24 00:53:13 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:53:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:53:13 - INFO :       DATASET: tasksource/mmlu professional_accounting
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-24 00:53:21 - INFO :       Use taylor pruner...
2024-04-24 00:53:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:53:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:53:21 - INFO :       Start Pruning
2024-04-24 00:53:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:53:23 - INFO :       Loss = 13.28125
2024-04-24 00:53:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:53:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:53:26 - INFO :       professional_accounting: Total Sparsity 1.3566762663462592e-06
2024-04-24 00:53:52 - INFO :       professional_accounting: Total Accuracy (11, 31, 0.3548387096774194)
2024-04-24 00:53:52 - INFO :       
==================Finish================

2024-04-24 00:53:52 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:53:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:53:52 - INFO :       DATASET: tasksource/mmlu professional_law
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-24 00:53:59 - INFO :       Use taylor pruner...
2024-04-24 00:53:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:53:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:54:00 - INFO :       Start Pruning
2024-04-24 00:54:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:54:02 - INFO :       Loss = 7.98828125
2024-04-24 00:54:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:54:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:54:05 - INFO :       professional_law: Total Sparsity 1.3581083665570398e-06
2024-04-24 00:54:48 - INFO :       professional_law: Total Accuracy (9, 50, 0.18)
2024-04-24 00:54:48 - INFO :       
==================Finish================

2024-04-24 00:54:48 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:54:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:54:48 - INFO :       DATASET: tasksource/mmlu professional_medicine
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-24 00:54:56 - INFO :       Use taylor pruner...
2024-04-24 00:54:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:54:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:54:56 - INFO :       Start Pruning
2024-04-24 00:54:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:54:58 - INFO :       Loss = 9.453125
2024-04-24 00:54:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:54:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:55:01 - INFO :       professional_medicine: Total Sparsity 1.3584266110483244e-06
2024-04-24 00:55:27 - INFO :       professional_medicine: Total Accuracy (12, 31, 0.3870967741935484)
2024-04-24 00:55:27 - INFO :       
==================Finish================

2024-04-24 00:55:27 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:55:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:55:27 - INFO :       DATASET: tasksource/mmlu professional_psychology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 00:55:35 - INFO :       Use taylor pruner...
2024-04-24 00:55:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:55:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:55:36 - INFO :       Start Pruning
2024-04-24 00:55:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:55:37 - INFO :       Loss = 13.8125
2024-04-24 00:55:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:55:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:55:40 - INFO :       professional_psychology: Total Sparsity 1.3569945108375437e-06
2024-04-24 00:56:24 - INFO :       professional_psychology: Total Accuracy (19, 50, 0.38)
2024-04-24 00:56:24 - INFO :       
==================Finish================

2024-04-24 00:56:24 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:56:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:56:24 - INFO :       DATASET: tasksource/mmlu public_relations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.33s/it]
2024-04-24 00:56:38 - INFO :       Use taylor pruner...
2024-04-24 00:56:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:56:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:56:38 - INFO :       Start Pruning
2024-04-24 00:56:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:56:40 - INFO :       Loss = 13.6171875
2024-04-24 00:56:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:56:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:56:43 - INFO :       public_relations: Total Sparsity 1.3573127553288283e-06
2024-04-24 00:56:53 - INFO :       public_relations: Total Accuracy (6, 12, 0.5)
2024-04-24 00:56:53 - INFO :       
==================Finish================

2024-04-24 00:56:53 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:56:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:56:53 - INFO :       DATASET: tasksource/mmlu security_studies
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-24 00:57:04 - INFO :       Use taylor pruner...
2024-04-24 00:57:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:57:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:57:05 - INFO :       Start Pruning
2024-04-24 00:57:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:57:07 - INFO :       Loss = 12.046875
2024-04-24 00:57:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:57:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:57:10 - INFO :       security_studies: Total Sparsity 1.357630999820113e-06
2024-04-24 00:57:36 - INFO :       security_studies: Total Accuracy (11, 27, 0.4074074074074074)
2024-04-24 00:57:36 - INFO :       
==================Finish================

2024-04-24 00:57:36 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:57:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:57:36 - INFO :       DATASET: tasksource/mmlu sociology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.89s/it]
2024-04-24 00:57:47 - INFO :       Use taylor pruner...
2024-04-24 00:57:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:57:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:57:48 - INFO :       Start Pruning
2024-04-24 00:57:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:57:50 - INFO :       Loss = 13.875
2024-04-24 00:57:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:57:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:57:53 - INFO :       sociology: Total Sparsity 1.3585857332939668e-06
2024-04-24 00:58:12 - INFO :       sociology: Total Accuracy (9, 22, 0.4090909090909091)
2024-04-24 00:58:12 - INFO :       
==================Finish================

2024-04-24 00:58:12 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:58:12 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:58:12 - INFO :       DATASET: tasksource/mmlu us_foreign_policy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-24 00:58:20 - INFO :       Use taylor pruner...
2024-04-24 00:58:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:58:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:58:20 - INFO :       Start Pruning
2024-04-24 00:58:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:58:22 - INFO :       Loss = 14.96875
2024-04-24 00:58:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:58:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:58:25 - INFO :       us_foreign_policy: Total Sparsity 1.3590631000308936e-06
2024-04-24 00:58:34 - INFO :       us_foreign_policy: Total Accuracy (7, 11, 0.6363636363636364)
2024-04-24 00:58:34 - INFO :       
==================Finish================

2024-04-24 00:58:34 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:58:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:58:34 - INFO :       DATASET: tasksource/mmlu virology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-24 00:58:42 - INFO :       Use taylor pruner...
2024-04-24 00:58:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:58:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:58:42 - INFO :       Start Pruning
2024-04-24 00:58:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:58:44 - INFO :       Loss = 15.1484375
2024-04-24 00:58:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:58:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:58:47 - INFO :       virology: Total Sparsity 1.3528573324508439e-06
2024-04-24 00:59:02 - INFO :       virology: Total Accuracy (7, 18, 0.3888888888888889)
2024-04-24 00:59:02 - INFO :       
==================Finish================

2024-04-24 00:59:02 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:59:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:59:02 - INFO :       DATASET: tasksource/mmlu world_religions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2024-04-24 00:59:10 - INFO :       Use taylor pruner...
2024-04-24 00:59:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:59:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:59:10 - INFO :       Start Pruning
2024-04-24 00:59:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:59:12 - INFO :       Loss = 14.8203125
2024-04-24 00:59:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:59:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:59:18 - INFO :       world_religions: Total Sparsity 1.360336077996032e-06
2024-04-24 00:59:33 - INFO :       world_religions: Total Accuracy (13, 19, 0.6842105263157895)
2024-04-24 00:59:33 - INFO :       
==================Finish================

2024-04-24 00:59:33 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 00:59:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 00:59:33 - INFO :       DATASET: math_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-24 00:59:40 - INFO :       Use taylor pruner...
2024-04-24 00:59:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:59:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 00:59:41 - INFO :       Start Pruning
2024-04-24 00:59:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 00:59:43 - INFO :       Loss = 13.21875
2024-04-24 00:59:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 00:59:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 00:59:46 - INFO :       math_qa: Total Sparsity 1.3593813445221782e-06
2024-04-24 01:00:23 - INFO :       math_qa: Accuracy (7, 50, 0.14)
2024-04-24 01:00:23 - INFO :       
==================Finish================

2024-04-24 01:00:23 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 01:00:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 01:00:23 - INFO :       DATASET: EleutherAI/truthful_qa_mc
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-24 01:00:30 - INFO :       Use taylor pruner...
2024-04-24 01:00:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 01:00:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 01:00:31 - INFO :       Start Pruning
2024-04-24 01:00:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 01:00:33 - INFO :       Loss = 14.078125
2024-04-24 01:00:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 01:00:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 01:00:36 - INFO :       truthful_qa_mc: Total Sparsity 1.3620864226980974e-06
2024-04-24 01:01:11 - INFO :       truthful_qa_mc: Accuracy (19, 50, 0.38)
2024-04-24 01:01:11 - INFO :       
==================Finish================

2024-04-24 01:01:11 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 01:01:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 01:01:11 - INFO :       DATASET: derek-thomas/ScienceQA
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-24 01:01:18 - INFO :       Use taylor pruner...
2024-04-24 01:01:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 01:01:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 01:01:19 - INFO :       Start Pruning
2024-04-24 01:01:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 01:01:21 - INFO :       Loss = 16.34375
2024-04-24 01:01:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 01:01:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 01:01:24 - INFO :       ScienceQA: Total Sparsity 1.3563580218549744e-06
2024-04-24 01:02:00 - INFO :       ScienceQA: Accuracy (34, 50, 0.68)
2024-04-24 01:02:00 - INFO :       
==================Finish================

2024-04-24 01:02:00 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-24 01:02:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-24 01:02:00 - INFO :       DATASET: commonsense_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.64s/it]
2024-04-24 01:02:09 - INFO :       Use taylor pruner...
2024-04-24 01:02:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 01:02:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-24 01:02:10 - INFO :       Start Pruning
2024-04-24 01:02:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-24 01:02:12 - INFO :       Loss = 15.1875
2024-04-24 01:02:15 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-24 01:02:15 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-24 01:02:17 - INFO :       commonsense_qa: Total Sparsity 1.3573127553288283e-06
2024-04-24 01:02:51 - INFO :       commonsense_qa: Accuracy (30, 50, 0.6)
2024-04-24 01:02:51 - INFO :       
==================Finish================

2024-04-24 01:02:51 - INFO :       Memory Requirement: 16770.79052734375 MiB

End: Memory Requirement: 3979.2666015625 MiB

******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
