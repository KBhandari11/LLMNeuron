2023-12-01 15:52:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:52:12 - INFO :       DATASET: commonsense_qa
Single
Index 0
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.54s/it]
2023-12-01 15:52:27 - INFO :       Use random pruner...
2023-12-01 15:52:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:52:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:52:28 - INFO :       Start Pruning
2023-12-01 15:52:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:52:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:52:30 - INFO :       commonsense_qa: Total Sparsity 1.3645985528115216e-06
2023-12-01 15:52:30 - INFO :       
==================Finish================

2023-12-01 15:52:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:52:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:52:30 - INFO :       DATASET: tasksource/bigbench abstract_narrative_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.46s/it]
2023-12-01 15:52:43 - INFO :       Use random pruner...
2023-12-01 15:52:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:52:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:52:43 - INFO :       Start Pruning
2023-12-01 15:52:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:52:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:52:45 - INFO :       abstract_narrative_understanding: Total Sparsity 1.3524350984588547e-06
2023-12-01 15:52:45 - INFO :       
==================Finish================

2023-12-01 15:52:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:52:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:52:45 - INFO :       DATASET: tasksource/bigbench anachronisms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.55s/it]
2023-12-01 15:52:58 - INFO :       Use random pruner...
2023-12-01 15:52:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:52:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:52:58 - INFO :       Start Pruning
2023-12-01 15:52:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:52:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:53:00 - INFO :       anachronisms: Total Sparsity 1.3631882972344008e-06
2023-12-01 15:53:00 - INFO :       
==================Finish================

2023-12-01 15:53:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:53:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:53:00 - INFO :       DATASET: tasksource/bigbench analogical_similarity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.28s/it]
2023-12-01 15:53:14 - INFO :       Use random pruner...
2023-12-01 15:53:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:53:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:53:14 - INFO :       Start Pruning
2023-12-01 15:53:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:53:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:53:16 - INFO :       analogical_similarity: Total Sparsity 1.3550793276659562e-06
2023-12-01 15:53:16 - INFO :       
==================Finish================

2023-12-01 15:53:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:53:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:53:16 - INFO :       DATASET: tasksource/bigbench analytic_entailment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.36s/it]
2023-12-01 15:53:29 - INFO :       Use random pruner...
2023-12-01 15:53:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:53:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:53:29 - INFO :       Start Pruning
2023-12-01 15:53:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:53:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:53:31 - INFO :       analytic_entailment: Total Sparsity 1.3607203499744394e-06
2023-12-01 15:53:31 - INFO :       
==================Finish================

2023-12-01 15:53:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:53:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:53:31 - INFO :       DATASET: tasksource/bigbench arithmetic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.34s/it]
2023-12-01 15:53:44 - INFO :       Use random pruner...
2023-12-01 15:53:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:53:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:53:45 - INFO :       Start Pruning
2023-12-01 15:53:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:53:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:53:47 - INFO :       arithmetic: Total Sparsity 1.360015222185879e-06
2023-12-01 15:53:47 - INFO :       
==================Finish================

2023-12-01 15:53:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:53:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:53:47 - INFO :       DATASET: tasksource/bigbench authorship_verification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.57s/it]
2023-12-01 15:54:00 - INFO :       Use random pruner...
2023-12-01 15:54:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:54:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:54:00 - INFO :       Start Pruning
2023-12-01 15:54:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:54:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:54:02 - INFO :       authorship_verification: Total Sparsity 1.3612491958158596e-06
2023-12-01 15:54:02 - INFO :       
==================Finish================

2023-12-01 15:54:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:54:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:54:02 - INFO :       DATASET: tasksource/bigbench bbq_lite_json
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.45s/it]
2023-12-01 15:54:15 - INFO :       Use random pruner...
2023-12-01 15:54:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:54:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:54:15 - INFO :       Start Pruning
2023-12-01 15:54:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:54:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:54:17 - INFO :       bbq_lite_json: Total Sparsity 1.3593100943973186e-06
2023-12-01 15:54:17 - INFO :       
==================Finish================

2023-12-01 15:54:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:54:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:54:17 - INFO :       DATASET: tasksource/bigbench causal_judgment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.49s/it]
2023-12-01 15:54:31 - INFO :       Use random pruner...
2023-12-01 15:54:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:54:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:54:31 - INFO :       Start Pruning
2023-12-01 15:54:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:54:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:54:33 - INFO :       causal_judgment: Total Sparsity 1.3577235568730577e-06
2023-12-01 15:54:33 - INFO :       
==================Finish================

2023-12-01 15:54:33 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:54:33 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:54:33 - INFO :       DATASET: tasksource/bigbench cause_and_effect
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.31s/it]
2023-12-01 15:54:45 - INFO :       Use random pruner...
2023-12-01 15:54:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:54:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:54:46 - INFO :       Start Pruning
2023-12-01 15:54:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:54:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:54:48 - INFO :       cause_and_effect: Total Sparsity 1.363540861128681e-06
2023-12-01 15:54:48 - INFO :       
==================Finish================

2023-12-01 15:54:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:54:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:54:48 - INFO :       DATASET: tasksource/bigbench checkmate_in_one
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2023-12-01 15:54:59 - INFO :       Use random pruner...
2023-12-01 15:54:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:54:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:55:00 - INFO :       Start Pruning
2023-12-01 15:55:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:55:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:55:01 - INFO :       checkmate_in_one: Total Sparsity 1.3589575305030384e-06
2023-12-01 15:55:01 - INFO :       
==================Finish================

2023-12-01 15:55:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:55:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:55:01 - INFO :       DATASET: tasksource/bigbench cifar10_classification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.34s/it]
2023-12-01 15:55:14 - INFO :       Use random pruner...
2023-12-01 15:55:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:55:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:55:14 - INFO :       Start Pruning
2023-12-01 15:55:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:55:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:55:16 - INFO :       cifar10_classification: Total Sparsity 1.3683004737014638e-06
2023-12-01 15:55:16 - INFO :       
==================Finish================

2023-12-01 15:55:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:55:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:55:16 - INFO :       DATASET: tasksource/bigbench code_line_description
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2023-12-01 15:55:28 - INFO :       Use random pruner...
2023-12-01 15:55:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:55:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:55:28 - INFO :       Start Pruning
2023-12-01 15:55:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:55:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:55:30 - INFO :       code_line_description: Total Sparsity 1.3541979179302557e-06
2023-12-01 15:55:30 - INFO :       
==================Finish================

2023-12-01 15:55:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:55:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:55:30 - INFO :       DATASET: tasksource/bigbench color
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.64s/it]
2023-12-01 15:55:43 - INFO :       Use random pruner...
2023-12-01 15:55:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:55:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:55:43 - INFO :       Start Pruning
2023-12-01 15:55:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:55:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:55:45 - INFO :       color: Total Sparsity 1.3644222708643816e-06
2023-12-01 15:55:45 - INFO :       
==================Finish================

2023-12-01 15:55:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:55:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:55:45 - INFO :       DATASET: tasksource/bigbench common_morpheme
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.41s/it]
2023-12-01 15:55:58 - INFO :       Use random pruner...
2023-12-01 15:55:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:55:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:55:59 - INFO :       Start Pruning
2023-12-01 15:56:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:56:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:56:00 - INFO :       common_morpheme: Total Sparsity 1.3691818834371643e-06
2023-12-01 15:56:00 - INFO :       
==================Finish================

2023-12-01 15:56:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:56:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:56:00 - INFO :       DATASET: tasksource/bigbench conceptual_combinations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]
2023-12-01 15:56:11 - INFO :       Use random pruner...
2023-12-01 15:56:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:56:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:56:12 - INFO :       Start Pruning
2023-12-01 15:56:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:56:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:56:14 - INFO :       conceptual_combinations: Total Sparsity 1.3573709929787774e-06
2023-12-01 15:56:14 - INFO :       
==================Finish================

2023-12-01 15:56:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:56:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:56:14 - INFO :       DATASET: tasksource/bigbench crash_blossom
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]
2023-12-01 15:56:26 - INFO :       Use random pruner...
2023-12-01 15:56:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:56:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:56:26 - INFO :       Start Pruning
2023-12-01 15:56:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:56:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:56:28 - INFO :       crash_blossom: Total Sparsity 1.3716498306971257e-06
2023-12-01 15:56:28 - INFO :       
==================Finish================

2023-12-01 15:56:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:56:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:56:28 - INFO :       DATASET: tasksource/bigbench crass_ai
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2023-12-01 15:56:39 - INFO :       Use random pruner...
2023-12-01 15:56:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:56:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:56:40 - INFO :       Start Pruning
2023-12-01 15:56:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:56:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:56:41 - INFO :       crass_ai: Total Sparsity 1.3684767556486038e-06
2023-12-01 15:56:41 - INFO :       
==================Finish================

2023-12-01 15:56:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:56:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:56:41 - INFO :       DATASET: tasksource/bigbench cryobiology_spanish
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 15:56:54 - INFO :       Use random pruner...
2023-12-01 15:56:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:56:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:56:54 - INFO :       Start Pruning
2023-12-01 15:56:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:56:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:56:56 - INFO :       cryobiology_spanish: Total Sparsity 1.3610729138687196e-06
2023-12-01 15:56:56 - INFO :       
==================Finish================

2023-12-01 15:56:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:56:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:56:56 - INFO :       DATASET: tasksource/bigbench cs_algorithms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.21s/it]
2023-12-01 15:57:06 - INFO :       Use random pruner...
2023-12-01 15:57:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:57:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:57:06 - INFO :       Start Pruning
2023-12-01 15:57:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:57:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:57:08 - INFO :       cs_algorithms: Total Sparsity 1.367242782018623e-06
2023-12-01 15:57:08 - INFO :       
==================Finish================

2023-12-01 15:57:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:57:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:57:08 - INFO :       DATASET: tasksource/bigbench dark_humor_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 15:57:19 - INFO :       Use random pruner...
2023-12-01 15:57:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:57:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:57:20 - INFO :       Start Pruning
2023-12-01 15:57:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:57:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:57:21 - INFO :       dark_humor_detection: Total Sparsity 1.3675953459129033e-06
2023-12-01 15:57:21 - INFO :       
==================Finish================

2023-12-01 15:57:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:57:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:57:21 - INFO :       DATASET: tasksource/bigbench date_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 15:57:33 - INFO :       Use random pruner...
2023-12-01 15:57:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:57:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:57:33 - INFO :       Start Pruning
2023-12-01 15:57:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:57:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:57:35 - INFO :       date_understanding: Total Sparsity 1.370415857067145e-06
2023-12-01 15:57:35 - INFO :       
==================Finish================

2023-12-01 15:57:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:57:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:57:35 - INFO :       DATASET: tasksource/bigbench disambiguation_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2023-12-01 15:57:44 - INFO :       Use random pruner...
2023-12-01 15:57:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:57:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:57:44 - INFO :       Start Pruning
2023-12-01 15:57:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:57:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:57:46 - INFO :       disambiguation_qa: Total Sparsity 1.370415857067145e-06
2023-12-01 15:57:46 - INFO :       
==================Finish================

2023-12-01 15:57:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:57:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:57:46 - INFO :       DATASET: tasksource/bigbench discourse_marker_prediction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2023-12-01 15:57:56 - INFO :       Use random pruner...
2023-12-01 15:57:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:57:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:57:57 - INFO :       Start Pruning
2023-12-01 15:57:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:57:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:57:58 - INFO :       discourse_marker_prediction: Total Sparsity 1.349614587304613e-06
2023-12-01 15:57:58 - INFO :       
==================Finish================

2023-12-01 15:57:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:57:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:57:58 - INFO :       DATASET: tasksource/bigbench dyck_languages
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2023-12-01 15:58:08 - INFO :       Use random pruner...
2023-12-01 15:58:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:58:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:58:08 - INFO :       Start Pruning
2023-12-01 15:58:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:58:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:58:10 - INFO :       dyck_languages: Total Sparsity 1.360015222185879e-06
2023-12-01 15:58:10 - INFO :       
==================Finish================

2023-12-01 15:58:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:58:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:58:10 - INFO :       DATASET: tasksource/bigbench elementary_math_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]
2023-12-01 15:58:19 - INFO :       Use random pruner...
2023-12-01 15:58:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:58:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:58:19 - INFO :       Start Pruning
2023-12-01 15:58:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:58:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:58:21 - INFO :       elementary_math_qa: Total Sparsity 1.3591338124501784e-06
2023-12-01 15:58:21 - INFO :       
==================Finish================

2023-12-01 15:58:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:58:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:58:21 - INFO :       DATASET: tasksource/bigbench emoji_movie
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2023-12-01 15:58:31 - INFO :       Use random pruner...
2023-12-01 15:58:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:58:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:58:31 - INFO :       Start Pruning
2023-12-01 15:58:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:58:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:58:33 - INFO :       emoji_movie: Total Sparsity 1.3702395751200048e-06
2023-12-01 15:58:33 - INFO :       
==================Finish================

2023-12-01 15:58:33 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:58:33 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:58:33 - INFO :       DATASET: tasksource/bigbench empirical_judgments
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2023-12-01 15:58:42 - INFO :       Use random pruner...
2023-12-01 15:58:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:58:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:58:43 - INFO :       Start Pruning
2023-12-01 15:58:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:58:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:58:45 - INFO :       empirical_judgments: Total Sparsity 1.3570184290844972e-06
2023-12-01 15:58:45 - INFO :       
==================Finish================

2023-12-01 15:58:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:58:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:58:45 - INFO :       DATASET: tasksource/bigbench english_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]
2023-12-01 15:58:54 - INFO :       Use random pruner...
2023-12-01 15:58:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:58:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:58:54 - INFO :       Start Pruning
2023-12-01 15:58:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:58:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:58:56 - INFO :       english_proverbs: Total Sparsity 1.3656562444943623e-06
2023-12-01 15:58:56 - INFO :       
==================Finish================

2023-12-01 15:58:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:58:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:58:56 - INFO :       DATASET: tasksource/bigbench english_russian_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
2023-12-01 15:59:05 - INFO :       Use random pruner...
2023-12-01 15:59:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:59:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:59:06 - INFO :       Start Pruning
2023-12-01 15:59:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:59:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:59:08 - INFO :       english_russian_proverbs: Total Sparsity 1.358252402714478e-06
2023-12-01 15:59:08 - INFO :       
==================Finish================

2023-12-01 15:59:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:59:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:59:08 - INFO :       DATASET: tasksource/bigbench entailed_polarity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2023-12-01 15:59:17 - INFO :       Use random pruner...
2023-12-01 15:59:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:59:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:59:17 - INFO :       Start Pruning
2023-12-01 15:59:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:59:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:59:19 - INFO :       entailed_polarity: Total Sparsity 1.3614254777629999e-06
2023-12-01 15:59:19 - INFO :       
==================Finish================

2023-12-01 15:59:19 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:59:19 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:59:19 - INFO :       DATASET: tasksource/bigbench entailed_polarity_hindi
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]
2023-12-01 15:59:29 - INFO :       Use random pruner...
2023-12-01 15:59:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:59:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:59:29 - INFO :       Start Pruning
2023-12-01 15:59:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:59:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:59:31 - INFO :       entailed_polarity_hindi: Total Sparsity 1.369005601490024e-06
2023-12-01 15:59:31 - INFO :       
==================Finish================

2023-12-01 15:59:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:59:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:59:31 - INFO :       DATASET: tasksource/bigbench epistemic_reasoning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.98s/it]
2023-12-01 15:59:40 - INFO :       Use random pruner...
2023-12-01 15:59:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:59:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:59:41 - INFO :       Start Pruning
2023-12-01 15:59:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:59:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:59:42 - INFO :       epistemic_reasoning: Total Sparsity 1.3608966319215796e-06
2023-12-01 15:59:42 - INFO :       
==================Finish================

2023-12-01 15:59:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:59:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:59:42 - INFO :       DATASET: tasksource/bigbench evaluating_information_essentiality
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 15:59:50 - INFO :       Use random pruner...
2023-12-01 15:59:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:59:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 15:59:51 - INFO :       Start Pruning
2023-12-01 15:59:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 15:59:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 15:59:52 - INFO :       evaluating_information_essentiality: Total Sparsity 1.3577235568730577e-06
2023-12-01 15:59:52 - INFO :       
==================Finish================

2023-12-01 15:59:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 15:59:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 15:59:52 - INFO :       DATASET: tasksource/bigbench fact_checker
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2023-12-01 16:00:01 - INFO :       Use random pruner...
2023-12-01 16:00:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:00:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:00:01 - INFO :       Start Pruning
2023-12-01 16:00:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:00:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:00:03 - INFO :       fact_checker: Total Sparsity 1.3608966319215796e-06
2023-12-01 16:00:03 - INFO :       
==================Finish================

2023-12-01 16:00:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:00:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:00:03 - INFO :       DATASET: tasksource/bigbench fantasy_reasoning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2023-12-01 16:00:13 - INFO :       Use random pruner...
2023-12-01 16:00:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:00:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:00:14 - INFO :       Start Pruning
2023-12-01 16:00:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:00:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:00:15 - INFO :       fantasy_reasoning: Total Sparsity 1.363717143075821e-06
2023-12-01 16:00:15 - INFO :       
==================Finish================

2023-12-01 16:00:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:00:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:00:15 - INFO :       DATASET: tasksource/bigbench figure_of_speech_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 16:00:24 - INFO :       Use random pruner...
2023-12-01 16:00:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:00:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:00:24 - INFO :       Start Pruning
2023-12-01 16:00:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:00:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:00:26 - INFO :       figure_of_speech_detection: Total Sparsity 1.3630120152872606e-06
2023-12-01 16:00:26 - INFO :       
==================Finish================

2023-12-01 16:00:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:00:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:00:26 - INFO :       DATASET: tasksource/bigbench formal_fallacies_syllogisms_negation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
2023-12-01 16:00:36 - INFO :       Use random pruner...
2023-12-01 16:00:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:00:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:00:36 - INFO :       Start Pruning
2023-12-01 16:00:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:00:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:00:38 - INFO :       formal_fallacies_syllogisms_negation: Total Sparsity 1.3575472749259176e-06
2023-12-01 16:00:38 - INFO :       
==================Finish================

2023-12-01 16:00:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:00:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:00:38 - INFO :       DATASET: tasksource/bigbench general_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 16:00:45 - INFO :       Use random pruner...
2023-12-01 16:00:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:00:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:00:45 - INFO :       Start Pruning
2023-12-01 16:00:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:00:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:00:47 - INFO :       general_knowledge: Total Sparsity 1.3571947110316374e-06
2023-12-01 16:00:47 - INFO :       
==================Finish================

2023-12-01 16:00:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:00:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:00:47 - INFO :       DATASET: tasksource/bigbench geometric_shapes
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2023-12-01 16:00:57 - INFO :       Use random pruner...
2023-12-01 16:00:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:00:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:00:57 - INFO :       Start Pruning
2023-12-01 16:00:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:00:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:00:59 - INFO :       geometric_shapes: Total Sparsity 1.3633645791815409e-06
2023-12-01 16:00:59 - INFO :       
==================Finish================

2023-12-01 16:00:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:00:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:00:59 - INFO :       DATASET: tasksource/bigbench goal_step_wikihow
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.49s/it]
2023-12-01 16:01:08 - INFO :       Use random pruner...
2023-12-01 16:01:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:01:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:01:09 - INFO :       Start Pruning
2023-12-01 16:01:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:01:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:01:10 - INFO :       goal_step_wikihow: Total Sparsity 1.3683004737014638e-06
2023-12-01 16:01:10 - INFO :       
==================Finish================

2023-12-01 16:01:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:01:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:01:10 - INFO :       DATASET: tasksource/bigbench gre_reading_comprehension
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.46s/it]
2023-12-01 16:01:22 - INFO :       Use random pruner...
2023-12-01 16:01:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:01:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:01:22 - INFO :       Start Pruning
2023-12-01 16:01:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:01:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:01:24 - INFO :       gre_reading_comprehension: Total Sparsity 1.3598389402387389e-06
2023-12-01 16:01:24 - INFO :       
==================Finish================

2023-12-01 16:01:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:01:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:01:24 - INFO :       DATASET: tasksource/bigbench hhh_alignment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]
2023-12-01 16:01:36 - INFO :       Use random pruner...
2023-12-01 16:01:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:01:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:01:36 - INFO :       Start Pruning
2023-12-01 16:01:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:01:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:01:38 - INFO :       hhh_alignment: Total Sparsity 1.3661850903357826e-06
2023-12-01 16:01:38 - INFO :       
==================Finish================

2023-12-01 16:01:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:01:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:01:38 - INFO :       DATASET: tasksource/bigbench hindu_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.38s/it]
2023-12-01 16:01:50 - INFO :       Use random pruner...
2023-12-01 16:01:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:01:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:01:51 - INFO :       Start Pruning
2023-12-01 16:01:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:01:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:01:53 - INFO :       hindu_knowledge: Total Sparsity 1.360015222185879e-06
2023-12-01 16:01:53 - INFO :       
==================Finish================

2023-12-01 16:01:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:01:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:01:53 - INFO :       DATASET: tasksource/bigbench hinglish_toxicity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.22s/it]
2023-12-01 16:02:05 - INFO :       Use random pruner...
2023-12-01 16:02:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:02:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:02:05 - INFO :       Start Pruning
2023-12-01 16:02:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:02:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:02:07 - INFO :       hinglish_toxicity: Total Sparsity 1.3677716278600435e-06
2023-12-01 16:02:07 - INFO :       
==================Finish================

2023-12-01 16:02:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:02:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:02:07 - INFO :       DATASET: tasksource/bigbench human_organs_senses
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.30s/it]
2023-12-01 16:02:19 - INFO :       Use random pruner...
2023-12-01 16:02:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:02:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:02:19 - INFO :       Start Pruning
2023-12-01 16:02:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:02:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:02:21 - INFO :       human_organs_senses: Total Sparsity 1.3644222708643816e-06
2023-12-01 16:02:21 - INFO :       
==================Finish================

2023-12-01 16:02:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:02:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:02:21 - INFO :       DATASET: tasksource/bigbench hyperbaton
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.21s/it]
2023-12-01 16:02:33 - INFO :       Use random pruner...
2023-12-01 16:02:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:02:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:02:33 - INFO :       Start Pruning
2023-12-01 16:02:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:02:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:02:35 - INFO :       hyperbaton: Total Sparsity 1.3614254777629999e-06
2023-12-01 16:02:35 - INFO :       
==================Finish================

2023-12-01 16:02:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:02:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:02:35 - INFO :       DATASET: tasksource/bigbench identify_math_theorems
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.35s/it]
2023-12-01 16:02:47 - INFO :       Use random pruner...
2023-12-01 16:02:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:02:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:02:48 - INFO :       Start Pruning
2023-12-01 16:02:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:02:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:02:50 - INFO :       identify_math_theorems: Total Sparsity 1.3628357333401206e-06
2023-12-01 16:02:50 - INFO :       
==================Finish================

2023-12-01 16:02:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:02:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:02:50 - INFO :       DATASET: tasksource/bigbench identify_odd_metaphor
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
2023-12-01 16:03:01 - INFO :       Use random pruner...
2023-12-01 16:03:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:03:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:03:02 - INFO :       Start Pruning
2023-12-01 16:03:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:03:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:03:04 - INFO :       identify_odd_metaphor: Total Sparsity 1.368829319542884e-06
2023-12-01 16:03:04 - INFO :       
==================Finish================

2023-12-01 16:03:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:03:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:03:04 - INFO :       DATASET: tasksource/bigbench implicatures
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.42s/it]
2023-12-01 16:03:15 - INFO :       Use random pruner...
2023-12-01 16:03:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:03:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:03:15 - INFO :       Start Pruning
2023-12-01 16:03:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:03:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:03:17 - INFO :       implicatures: Total Sparsity 1.3577235568730577e-06
2023-12-01 16:03:17 - INFO :       
==================Finish================

2023-12-01 16:03:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:03:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:03:17 - INFO :       DATASET: tasksource/bigbench implicit_relations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
2023-12-01 16:03:29 - INFO :       Use random pruner...
2023-12-01 16:03:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:03:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:03:29 - INFO :       Start Pruning
2023-12-01 16:03:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:03:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:03:31 - INFO :       implicit_relations: Total Sparsity 1.367242782018623e-06
2023-12-01 16:03:31 - INFO :       
==================Finish================

2023-12-01 16:03:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:03:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:03:31 - INFO :       DATASET: tasksource/bigbench indic_cause_and_effect
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]
2023-12-01 16:03:44 - INFO :       Use random pruner...
2023-12-01 16:03:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:03:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:03:44 - INFO :       Start Pruning
2023-12-01 16:03:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:03:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:03:46 - INFO :       indic_cause_and_effect: Total Sparsity 1.3591338124501784e-06
2023-12-01 16:03:46 - INFO :       
==================Finish================

2023-12-01 16:03:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:03:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:03:46 - INFO :       DATASET: tasksource/bigbench intent_recognition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 16:03:58 - INFO :       Use random pruner...
2023-12-01 16:03:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:03:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:03:59 - INFO :       Start Pruning
2023-12-01 16:04:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:04:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:04:00 - INFO :       intent_recognition: Total Sparsity 1.3665376542300628e-06
2023-12-01 16:04:00 - INFO :       
==================Finish================

2023-12-01 16:04:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:04:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:04:00 - INFO :       DATASET: tasksource/bigbench international_phonetic_alphabet_nli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 16:04:09 - INFO :       Use random pruner...
2023-12-01 16:04:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:04:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:04:10 - INFO :       Start Pruning
2023-12-01 16:04:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:04:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:04:11 - INFO :       international_phonetic_alphabet_nli: Total Sparsity 1.3550793276659562e-06
2023-12-01 16:04:11 - INFO :       
==================Finish================

2023-12-01 16:04:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:04:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:04:11 - INFO :       DATASET: tasksource/bigbench intersect_geometry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2023-12-01 16:04:20 - INFO :       Use random pruner...
2023-12-01 16:04:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:04:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:04:21 - INFO :       Start Pruning
2023-12-01 16:04:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:04:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:04:22 - INFO :       intersect_geometry: Total Sparsity 1.3607203499744394e-06
2023-12-01 16:04:22 - INFO :       
==================Finish================

2023-12-01 16:04:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:04:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:04:22 - INFO :       DATASET: tasksource/bigbench irony_identification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]
2023-12-01 16:04:32 - INFO :       Use random pruner...
2023-12-01 16:04:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:04:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:04:33 - INFO :       Start Pruning
2023-12-01 16:04:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:04:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:04:34 - INFO :       irony_identification: Total Sparsity 1.3598389402387389e-06
2023-12-01 16:04:34 - INFO :       
==================Finish================

2023-12-01 16:04:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:04:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:04:34 - INFO :       DATASET: tasksource/bigbench kannada
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 16:04:44 - INFO :       Use random pruner...
2023-12-01 16:04:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:04:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:04:44 - INFO :       Start Pruning
2023-12-01 16:04:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:04:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:04:46 - INFO :       kannada: Total Sparsity 1.3645985528115216e-06
2023-12-01 16:04:46 - INFO :       
==================Finish================

2023-12-01 16:04:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:04:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:04:46 - INFO :       DATASET: tasksource/bigbench key_value_maps
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2023-12-01 16:04:56 - INFO :       Use random pruner...
2023-12-01 16:04:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:04:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:04:56 - INFO :       Start Pruning
2023-12-01 16:04:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:04:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:04:58 - INFO :       key_value_maps: Total Sparsity 1.3728838043271063e-06
2023-12-01 16:04:58 - INFO :       
==================Finish================

2023-12-01 16:04:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:04:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:04:58 - INFO :       DATASET: tasksource/bigbench known_unknowns
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]
2023-12-01 16:05:06 - INFO :       Use random pruner...
2023-12-01 16:05:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:05:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:05:07 - INFO :       Start Pruning
2023-12-01 16:05:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:05:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:05:09 - INFO :       known_unknowns: Total Sparsity 1.3720023945914058e-06
2023-12-01 16:05:09 - INFO :       
==================Finish================

2023-12-01 16:05:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:05:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:05:09 - INFO :       DATASET: tasksource/bigbench language_identification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]
2023-12-01 16:05:18 - INFO :       Use random pruner...
2023-12-01 16:05:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:05:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:05:18 - INFO :       Start Pruning
2023-12-01 16:05:19 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:05:19 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:05:20 - INFO :       language_identification: Total Sparsity 1.3550793276659562e-06
2023-12-01 16:05:20 - INFO :       
==================Finish================

2023-12-01 16:05:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:05:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:05:20 - INFO :       DATASET: tasksource/bigbench logic_grid_puzzle
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]
2023-12-01 16:05:29 - INFO :       Use random pruner...
2023-12-01 16:05:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:05:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:05:29 - INFO :       Start Pruning
2023-12-01 16:05:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:05:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:05:31 - INFO :       logic_grid_puzzle: Total Sparsity 1.3709447029085653e-06
2023-12-01 16:05:31 - INFO :       
==================Finish================

2023-12-01 16:05:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:05:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:05:31 - INFO :       DATASET: tasksource/bigbench logical_args
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]
2023-12-01 16:05:40 - INFO :       Use random pruner...
2023-12-01 16:05:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:05:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:05:41 - INFO :       Start Pruning
2023-12-01 16:05:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:05:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:05:42 - INFO :       logical_args: Total Sparsity 1.3681241917543236e-06
2023-12-01 16:05:42 - INFO :       
==================Finish================

2023-12-01 16:05:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:05:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:05:42 - INFO :       DATASET: tasksource/bigbench logical_deduction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2023-12-01 16:05:52 - INFO :       Use random pruner...
2023-12-01 16:05:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:05:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:05:53 - INFO :       Start Pruning
2023-12-01 16:05:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:05:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:05:54 - INFO :       logical_deduction: Total Sparsity 1.3561370193487967e-06
2023-12-01 16:05:54 - INFO :       
==================Finish================

2023-12-01 16:05:54 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:05:54 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:05:54 - INFO :       DATASET: tasksource/bigbench logical_fallacy_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2023-12-01 16:06:03 - INFO :       Use random pruner...
2023-12-01 16:06:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:06:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:06:03 - INFO :       Start Pruning
2023-12-01 16:06:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:06:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:06:05 - INFO :       logical_fallacy_detection: Total Sparsity 1.3598389402387389e-06
2023-12-01 16:06:05 - INFO :       
==================Finish================

2023-12-01 16:06:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:06:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:06:05 - INFO :       DATASET: tasksource/bigbench logical_sequence
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2023-12-01 16:06:14 - INFO :       Use random pruner...
2023-12-01 16:06:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:06:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:06:14 - INFO :       Start Pruning
2023-12-01 16:06:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:06:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:06:16 - INFO :       logical_sequence: Total Sparsity 1.3605440680272994e-06
2023-12-01 16:06:16 - INFO :       
==================Finish================

2023-12-01 16:06:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:06:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:06:16 - INFO :       DATASET: tasksource/bigbench mathematical_induction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]
2023-12-01 16:06:25 - INFO :       Use random pruner...
2023-12-01 16:06:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:06:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:06:26 - INFO :       Start Pruning
2023-12-01 16:06:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:06:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:06:27 - INFO :       mathematical_induction: Total Sparsity 1.3684767556486038e-06
2023-12-01 16:06:27 - INFO :       
==================Finish================

2023-12-01 16:06:27 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:06:27 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:06:27 - INFO :       DATASET: tasksource/bigbench medical_questions_russian
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 16:06:35 - INFO :       Use random pruner...
2023-12-01 16:06:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:06:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:06:35 - INFO :       Start Pruning
2023-12-01 16:06:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:06:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:06:37 - INFO :       medical_questions_russian: Total Sparsity 1.3621306055515601e-06
2023-12-01 16:06:37 - INFO :       
==================Finish================

2023-12-01 16:06:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:06:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:06:37 - INFO :       DATASET: tasksource/bigbench metaphor_boolean
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]
2023-12-01 16:06:46 - INFO :       Use random pruner...
2023-12-01 16:06:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:06:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:06:47 - INFO :       Start Pruning
2023-12-01 16:06:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:06:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:06:49 - INFO :       metaphor_boolean: Total Sparsity 1.358076120767338e-06
2023-12-01 16:06:49 - INFO :       
==================Finish================

2023-12-01 16:06:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:06:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:06:49 - INFO :       DATASET: tasksource/bigbench metaphor_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 16:06:57 - INFO :       Use random pruner...
2023-12-01 16:06:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:06:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:06:58 - INFO :       Start Pruning
2023-12-01 16:06:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:06:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:06:59 - INFO :       metaphor_understanding: Total Sparsity 1.3665376542300628e-06
2023-12-01 16:06:59 - INFO :       
==================Finish================

2023-12-01 16:06:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:06:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:06:59 - INFO :       DATASET: tasksource/bigbench misconceptions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.23s/it]
2023-12-01 16:07:09 - INFO :       Use random pruner...
2023-12-01 16:07:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:07:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:07:10 - INFO :       Start Pruning
2023-12-01 16:07:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:07:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:07:11 - INFO :       misconceptions: Total Sparsity 1.3575472749259176e-06
2023-12-01 16:07:11 - INFO :       
==================Finish================

2023-12-01 16:07:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:07:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:07:11 - INFO :       DATASET: tasksource/bigbench misconceptions_russian
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
2023-12-01 16:07:21 - INFO :       Use random pruner...
2023-12-01 16:07:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:07:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:07:21 - INFO :       Start Pruning
2023-12-01 16:07:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:07:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:07:23 - INFO :       misconceptions_russian: Total Sparsity 1.3675953459129033e-06
2023-12-01 16:07:23 - INFO :       
==================Finish================

2023-12-01 16:07:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:07:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:07:23 - INFO :       DATASET: tasksource/bigbench mnist_ascii
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 16:07:32 - INFO :       Use random pruner...
2023-12-01 16:07:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:07:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:07:33 - INFO :       Start Pruning
2023-12-01 16:07:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:07:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:07:34 - INFO :       mnist_ascii: Total Sparsity 1.3610729138687196e-06
2023-12-01 16:07:34 - INFO :       
==================Finish================

2023-12-01 16:07:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:07:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:07:34 - INFO :       DATASET: tasksource/bigbench moral_permissibility
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.19s/it]
2023-12-01 16:07:44 - INFO :       Use random pruner...
2023-12-01 16:07:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:07:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:07:44 - INFO :       Start Pruning
2023-12-01 16:07:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:07:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:07:46 - INFO :       moral_permissibility: Total Sparsity 1.372354958485686e-06
2023-12-01 16:07:46 - INFO :       
==================Finish================

2023-12-01 16:07:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:07:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:07:46 - INFO :       DATASET: tasksource/bigbench movie_dialog_same_or_different
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2023-12-01 16:07:54 - INFO :       Use random pruner...
2023-12-01 16:07:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:07:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:07:55 - INFO :       Start Pruning
2023-12-01 16:07:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:07:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:07:56 - INFO :       movie_dialog_same_or_different: Total Sparsity 1.3630120152872606e-06
2023-12-01 16:07:56 - INFO :       
==================Finish================

2023-12-01 16:07:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:07:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:07:56 - INFO :       DATASET: tasksource/bigbench movie_recommendation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 16:08:07 - INFO :       Use random pruner...
2023-12-01 16:08:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:08:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:08:07 - INFO :       Start Pruning
2023-12-01 16:08:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:08:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:08:09 - INFO :       movie_recommendation: Total Sparsity 1.3660088083886423e-06
2023-12-01 16:08:09 - INFO :       
==================Finish================

2023-12-01 16:08:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:08:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:08:09 - INFO :       DATASET: tasksource/bigbench navigate
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 16:08:18 - INFO :       Use random pruner...
2023-12-01 16:08:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:08:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:08:19 - INFO :       Start Pruning
2023-12-01 16:08:19 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:08:19 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:08:20 - INFO :       navigate: Total Sparsity 1.3626594513929806e-06
2023-12-01 16:08:20 - INFO :       
==================Finish================

2023-12-01 16:08:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:08:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:08:20 - INFO :       DATASET: tasksource/bigbench nonsense_words_grammar
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2023-12-01 16:08:30 - INFO :       Use random pruner...
2023-12-01 16:08:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:08:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:08:31 - INFO :       Start Pruning
2023-12-01 16:08:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:08:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:08:32 - INFO :       nonsense_words_grammar: Total Sparsity 1.3610729138687196e-06
2023-12-01 16:08:32 - INFO :       
==================Finish================

2023-12-01 16:08:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:08:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:08:32 - INFO :       DATASET: tasksource/bigbench novel_concepts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 16:08:42 - INFO :       Use random pruner...
2023-12-01 16:08:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:08:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:08:42 - INFO :       Start Pruning
2023-12-01 16:08:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:08:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:08:44 - INFO :       novel_concepts: Total Sparsity 1.360015222185879e-06
2023-12-01 16:08:44 - INFO :       
==================Finish================

2023-12-01 16:08:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:08:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:08:44 - INFO :       DATASET: tasksource/bigbench odd_one_out
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 16:08:53 - INFO :       Use random pruner...
2023-12-01 16:08:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:08:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:08:53 - INFO :       Start Pruning
2023-12-01 16:08:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:08:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:08:55 - INFO :       odd_one_out: Total Sparsity 1.3612491958158596e-06
2023-12-01 16:08:55 - INFO :       
==================Finish================

2023-12-01 16:08:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:08:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:08:55 - INFO :       DATASET: tasksource/bigbench parsinlu_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 16:09:04 - INFO :       Use random pruner...
2023-12-01 16:09:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:09:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:09:05 - INFO :       Start Pruning
2023-12-01 16:09:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:09:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:09:06 - INFO :       parsinlu_qa: Total Sparsity 1.3628357333401206e-06
2023-12-01 16:09:06 - INFO :       
==================Finish================

2023-12-01 16:09:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:09:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:09:06 - INFO :       DATASET: tasksource/bigbench penguins_in_a_table
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]
2023-12-01 16:09:15 - INFO :       Use random pruner...
2023-12-01 16:09:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:09:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:09:16 - INFO :       Start Pruning
2023-12-01 16:09:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:09:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:09:17 - INFO :       penguins_in_a_table: Total Sparsity 1.3591338124501784e-06
2023-12-01 16:09:17 - INFO :       
==================Finish================

2023-12-01 16:09:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:09:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:09:17 - INFO :       DATASET: tasksource/bigbench persian_idioms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 16:09:28 - INFO :       Use random pruner...
2023-12-01 16:09:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:09:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:09:28 - INFO :       Start Pruning
2023-12-01 16:09:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:09:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:09:30 - INFO :       persian_idioms: Total Sparsity 1.3577235568730577e-06
2023-12-01 16:09:30 - INFO :       
==================Finish================

2023-12-01 16:09:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:09:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:09:30 - INFO :       DATASET: tasksource/bigbench phrase_relatedness
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]
2023-12-01 16:09:38 - INFO :       Use random pruner...
2023-12-01 16:09:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:09:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:09:39 - INFO :       Start Pruning
2023-12-01 16:09:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:09:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:09:41 - INFO :       phrase_relatedness: Total Sparsity 1.3628357333401206e-06
2023-12-01 16:09:41 - INFO :       
==================Finish================

2023-12-01 16:09:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:09:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:09:41 - INFO :       DATASET: tasksource/bigbench physical_intuition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]
2023-12-01 16:09:51 - INFO :       Use random pruner...
2023-12-01 16:09:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:09:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:09:52 - INFO :       Start Pruning
2023-12-01 16:09:53 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:09:53 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:09:53 - INFO :       physical_intuition: Total Sparsity 1.3679479098071835e-06
2023-12-01 16:09:53 - INFO :       
==================Finish================

2023-12-01 16:09:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:09:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:09:53 - INFO :       DATASET: tasksource/bigbench physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2023-12-01 16:10:03 - INFO :       Use random pruner...
2023-12-01 16:10:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:10:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:10:03 - INFO :       Start Pruning
2023-12-01 16:10:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:10:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:10:05 - INFO :       physics: Total Sparsity 1.3616017597101399e-06
2023-12-01 16:10:05 - INFO :       
==================Finish================

2023-12-01 16:10:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:10:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:10:05 - INFO :       DATASET: tasksource/bigbench play_dialog_same_or_different
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]
2023-12-01 16:10:14 - INFO :       Use random pruner...
2023-12-01 16:10:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:10:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:10:14 - INFO :       Start Pruning
2023-12-01 16:10:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:10:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:10:16 - INFO :       play_dialog_same_or_different: Total Sparsity 1.3610729138687196e-06
2023-12-01 16:10:16 - INFO :       
==================Finish================

2023-12-01 16:10:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:10:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:10:16 - INFO :       DATASET: tasksource/bigbench presuppositions_as_nli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
2023-12-01 16:10:26 - INFO :       Use random pruner...
2023-12-01 16:10:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:10:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:10:26 - INFO :       Start Pruning
2023-12-01 16:10:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:10:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:10:28 - INFO :       presuppositions_as_nli: Total Sparsity 1.3665376542300628e-06
2023-12-01 16:10:28 - INFO :       
==================Finish================

2023-12-01 16:10:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:10:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:10:28 - INFO :       DATASET: tasksource/bigbench question_selection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 16:10:37 - INFO :       Use random pruner...
2023-12-01 16:10:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:10:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:10:37 - INFO :       Start Pruning
2023-12-01 16:10:38 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:10:38 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:10:39 - INFO :       question_selection: Total Sparsity 1.3612491958158596e-06
2023-12-01 16:10:39 - INFO :       
==================Finish================

2023-12-01 16:10:39 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:10:39 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:10:39 - INFO :       DATASET: tasksource/bigbench reasoning_about_colored_objects
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2023-12-01 16:10:49 - INFO :       Use random pruner...
2023-12-01 16:10:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:10:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:10:49 - INFO :       Start Pruning
2023-12-01 16:10:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:10:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:10:51 - INFO :       reasoning_about_colored_objects: Total Sparsity 1.351377406776014e-06
2023-12-01 16:10:51 - INFO :       
==================Finish================

2023-12-01 16:10:51 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:10:51 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:10:51 - INFO :       DATASET: tasksource/bigbench riddle_sense
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]
2023-12-01 16:11:01 - INFO :       Use random pruner...
2023-12-01 16:11:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:11:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:11:01 - INFO :       Start Pruning
2023-12-01 16:11:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:11:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:11:03 - INFO :       riddle_sense: Total Sparsity 1.3679479098071835e-06
2023-12-01 16:11:03 - INFO :       
==================Finish================

2023-12-01 16:11:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:11:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:11:03 - INFO :       DATASET: tasksource/bigbench ruin_names
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 16:11:10 - INFO :       Use random pruner...
2023-12-01 16:11:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:11:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:11:11 - INFO :       Start Pruning
2023-12-01 16:11:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:11:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:11:13 - INFO :       ruin_names: Total Sparsity 1.3536690720888354e-06
2023-12-01 16:11:13 - INFO :       
==================Finish================

2023-12-01 16:11:13 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:11:13 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:11:13 - INFO :       DATASET: tasksource/bigbench salient_translation_error_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]
2023-12-01 16:11:22 - INFO :       Use random pruner...
2023-12-01 16:11:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:11:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:11:23 - INFO :       Start Pruning
2023-12-01 16:11:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:11:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:11:24 - INFO :       salient_translation_error_detection: Total Sparsity 1.363540861128681e-06
2023-12-01 16:11:24 - INFO :       
==================Finish================

2023-12-01 16:11:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:11:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:11:24 - INFO :       DATASET: tasksource/bigbench sentence_ambiguity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 16:11:34 - INFO :       Use random pruner...
2023-12-01 16:11:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:11:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:11:35 - INFO :       Start Pruning
2023-12-01 16:11:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:11:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:11:37 - INFO :       sentence_ambiguity: Total Sparsity 1.3536690720888354e-06
2023-12-01 16:11:37 - INFO :       
==================Finish================

2023-12-01 16:11:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:11:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:11:37 - INFO :       DATASET: tasksource/bigbench similarities_abstraction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 16:11:46 - INFO :       Use random pruner...
2023-12-01 16:11:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:11:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:11:46 - INFO :       Start Pruning
2023-12-01 16:11:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:11:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:11:48 - INFO :       similarities_abstraction: Total Sparsity 1.3728838043271063e-06
2023-12-01 16:11:48 - INFO :       
==================Finish================

2023-12-01 16:11:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:11:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:11:48 - INFO :       DATASET: tasksource/bigbench simple_ethical_questions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]
2023-12-01 16:11:58 - INFO :       Use random pruner...
2023-12-01 16:11:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:11:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:11:58 - INFO :       Start Pruning
2023-12-01 16:11:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:11:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:12:00 - INFO :       simple_ethical_questions: Total Sparsity 1.3633645791815409e-06
2023-12-01 16:12:00 - INFO :       
==================Finish================

2023-12-01 16:12:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:12:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:12:00 - INFO :       DATASET: tasksource/bigbench snarks
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
2023-12-01 16:12:09 - INFO :       Use random pruner...
2023-12-01 16:12:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:12:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:12:10 - INFO :       Start Pruning
2023-12-01 16:12:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:12:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:12:12 - INFO :       snarks: Total Sparsity 1.372354958485686e-06
2023-12-01 16:12:12 - INFO :       
==================Finish================

2023-12-01 16:12:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:12:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:12:12 - INFO :       DATASET: tasksource/bigbench social_iqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]
2023-12-01 16:12:19 - INFO :       Use random pruner...
2023-12-01 16:12:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:12:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:12:20 - INFO :       Start Pruning
2023-12-01 16:12:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:12:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:12:22 - INFO :       social_iqa: Total Sparsity 1.3607203499744394e-06
2023-12-01 16:12:22 - INFO :       
==================Finish================

2023-12-01 16:12:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:12:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:12:22 - INFO :       DATASET: tasksource/bigbench social_support
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]
2023-12-01 16:12:30 - INFO :       Use random pruner...
2023-12-01 16:12:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:12:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:12:30 - INFO :       Start Pruning
2023-12-01 16:12:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:12:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:12:32 - INFO :       social_support: Total Sparsity 1.3665376542300628e-06
2023-12-01 16:12:32 - INFO :       
==================Finish================

2023-12-01 16:12:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:12:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:12:32 - INFO :       DATASET: tasksource/bigbench sports_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 16:12:40 - INFO :       Use random pruner...
2023-12-01 16:12:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:12:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:12:40 - INFO :       Start Pruning
2023-12-01 16:12:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:12:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:12:42 - INFO :       sports_understanding: Total Sparsity 1.372354958485686e-06
2023-12-01 16:12:42 - INFO :       
==================Finish================

2023-12-01 16:12:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:12:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:12:42 - INFO :       DATASET: tasksource/bigbench strange_stories
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 16:12:52 - INFO :       Use random pruner...
2023-12-01 16:12:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:12:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:12:52 - INFO :       Start Pruning
2023-12-01 16:12:53 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:12:53 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:12:54 - INFO :       strange_stories: Total Sparsity 1.3716498306971257e-06
2023-12-01 16:12:54 - INFO :       
==================Finish================

2023-12-01 16:12:54 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:12:54 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:12:54 - INFO :       DATASET: tasksource/bigbench strategyqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]
2023-12-01 16:13:03 - INFO :       Use random pruner...
2023-12-01 16:13:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:13:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:13:04 - INFO :       Start Pruning
2023-12-01 16:13:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:13:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:13:05 - INFO :       strategyqa: Total Sparsity 1.3674190639657633e-06
2023-12-01 16:13:05 - INFO :       
==================Finish================

2023-12-01 16:13:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:13:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:13:05 - INFO :       DATASET: tasksource/bigbench suicide_risk
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]
2023-12-01 16:13:16 - INFO :       Use random pruner...
2023-12-01 16:13:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:13:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:13:16 - INFO :       Start Pruning
2023-12-01 16:13:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:13:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:13:18 - INFO :       suicide_risk: Total Sparsity 1.3720023945914058e-06
2023-12-01 16:13:18 - INFO :       
==================Finish================

2023-12-01 16:13:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:13:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:13:18 - INFO :       DATASET: tasksource/bigbench swahili_english_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 16:13:27 - INFO :       Use random pruner...
2023-12-01 16:13:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:13:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:13:28 - INFO :       Start Pruning
2023-12-01 16:13:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:13:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:13:29 - INFO :       swahili_english_proverbs: Total Sparsity 1.3601915041330191e-06
2023-12-01 16:13:29 - INFO :       
==================Finish================

2023-12-01 16:13:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:13:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:13:29 - INFO :       DATASET: tasksource/bigbench swedish_to_german_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.49s/it]
2023-12-01 16:13:38 - INFO :       Use random pruner...
2023-12-01 16:13:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:13:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:13:39 - INFO :       Start Pruning
2023-12-01 16:13:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:13:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:13:40 - INFO :       swedish_to_german_proverbs: Total Sparsity 1.3577235568730577e-06
2023-12-01 16:13:40 - INFO :       
==================Finish================

2023-12-01 16:13:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:13:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:13:40 - INFO :       DATASET: tasksource/bigbench symbol_interpretation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2023-12-01 16:13:50 - INFO :       Use random pruner...
2023-12-01 16:13:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:13:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:13:50 - INFO :       Start Pruning
2023-12-01 16:13:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:13:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:13:52 - INFO :       symbol_interpretation: Total Sparsity 1.3626594513929806e-06
2023-12-01 16:13:52 - INFO :       
==================Finish================

2023-12-01 16:13:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:13:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:13:52 - INFO :       DATASET: tasksource/bigbench temporal_sequences
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2023-12-01 16:14:02 - INFO :       Use random pruner...
2023-12-01 16:14:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:14:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:14:02 - INFO :       Start Pruning
2023-12-01 16:14:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:14:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:14:04 - INFO :       temporal_sequences: Total Sparsity 1.3578998388201979e-06
2023-12-01 16:14:04 - INFO :       
==================Finish================

2023-12-01 16:14:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:14:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:14:04 - INFO :       DATASET: tasksource/bigbench timedial
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]
2023-12-01 16:14:11 - INFO :       Use random pruner...
2023-12-01 16:14:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:14:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:14:12 - INFO :       Start Pruning
2023-12-01 16:14:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:14:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:14:14 - INFO :       timedial: Total Sparsity 1.3691818834371643e-06
2023-12-01 16:14:14 - INFO :       
==================Finish================

2023-12-01 16:14:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:14:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:14:14 - INFO :       DATASET: tasksource/bigbench tracking_shuffled_objects
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2023-12-01 16:14:22 - INFO :       Use random pruner...
2023-12-01 16:14:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:14:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:14:22 - INFO :       Start Pruning
2023-12-01 16:14:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:14:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:14:24 - INFO :       tracking_shuffled_objects: Total Sparsity 1.3621306055515601e-06
2023-12-01 16:14:24 - INFO :       
==================Finish================

2023-12-01 16:14:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:14:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:14:24 - INFO :       DATASET: tasksource/bigbench understanding_fables
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]
2023-12-01 16:14:35 - INFO :       Use random pruner...
2023-12-01 16:14:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:14:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:14:35 - INFO :       Start Pruning
2023-12-01 16:14:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:14:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:14:37 - INFO :       understanding_fables: Total Sparsity 1.3614254777629999e-06
2023-12-01 16:14:37 - INFO :       
==================Finish================

2023-12-01 16:14:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:14:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:14:37 - INFO :       DATASET: tasksource/bigbench undo_permutation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]
2023-12-01 16:14:45 - INFO :       Use random pruner...
2023-12-01 16:14:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:14:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:14:46 - INFO :       Start Pruning
2023-12-01 16:14:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:14:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:14:48 - INFO :       undo_permutation: Total Sparsity 1.3621306055515601e-06
2023-12-01 16:14:48 - INFO :       
==================Finish================

2023-12-01 16:14:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:14:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:14:48 - INFO :       DATASET: tasksource/bigbench unit_interpretation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]
2023-12-01 16:14:55 - INFO :       Use random pruner...
2023-12-01 16:14:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:14:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:14:56 - INFO :       Start Pruning
2023-12-01 16:14:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:14:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:14:58 - INFO :       unit_interpretation: Total Sparsity 1.3543741998773957e-06
2023-12-01 16:14:58 - INFO :       
==================Finish================

2023-12-01 16:14:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:14:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:14:58 - INFO :       DATASET: tasksource/bigbench vitaminc_fact_verification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 16:15:06 - INFO :       Use random pruner...
2023-12-01 16:15:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:15:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:15:07 - INFO :       Start Pruning
2023-12-01 16:15:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:15:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:15:08 - INFO :       vitaminc_fact_verification: Total Sparsity 1.3667139361772028e-06
2023-12-01 16:15:08 - INFO :       
==================Finish================

2023-12-01 16:15:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:15:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:15:08 - INFO :       DATASET: tasksource/bigbench what_is_the_tao
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 16:15:18 - INFO :       Use random pruner...
2023-12-01 16:15:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:15:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:15:18 - INFO :       Start Pruning
2023-12-01 16:15:19 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:15:19 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:15:20 - INFO :       what_is_the_tao: Total Sparsity 1.3656562444943623e-06
2023-12-01 16:15:20 - INFO :       
==================Finish================

2023-12-01 16:15:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:15:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:15:20 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2023-12-01 16:15:30 - INFO :       Use random pruner...
2023-12-01 16:15:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:15:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:15:30 - INFO :       Start Pruning
2023-12-01 16:15:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:15:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:15:32 - INFO :       which_wiki_edit: Total Sparsity 1.3621306055515601e-06
2023-12-01 16:15:32 - INFO :       
==================Finish================

2023-12-01 16:15:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:15:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:15:32 - INFO :       DATASET: tasksource/bigbench winowhy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]
2023-12-01 16:15:41 - INFO :       Use random pruner...
2023-12-01 16:15:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:15:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:15:41 - INFO :       Start Pruning
2023-12-01 16:15:42 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:15:42 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:15:43 - INFO :       winowhy: Total Sparsity 1.3607203499744394e-06
2023-12-01 16:15:43 - INFO :       
==================Finish================

2023-12-01 16:15:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:15:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:15:43 - INFO :       DATASET: tasksource/mmlu abstract_algebra
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 16:15:51 - INFO :       Use random pruner...
2023-12-01 16:15:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:15:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:15:51 - INFO :       Start Pruning
2023-12-01 16:15:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:15:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:15:53 - INFO :       abstract_algebra: Total Sparsity 1.3702395751200048e-06
2023-12-01 16:15:53 - INFO :       
==================Finish================

2023-12-01 16:15:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:15:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:15:53 - INFO :       DATASET: tasksource/mmlu anatomy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 16:16:02 - INFO :       Use random pruner...
2023-12-01 16:16:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:16:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:16:02 - INFO :       Start Pruning
2023-12-01 16:16:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:16:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:16:04 - INFO :       anatomy: Total Sparsity 1.360015222185879e-06
2023-12-01 16:16:04 - INFO :       
==================Finish================

2023-12-01 16:16:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:16:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:16:04 - INFO :       DATASET: tasksource/mmlu astronomy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 16:16:14 - INFO :       Use random pruner...
2023-12-01 16:16:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:16:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:16:14 - INFO :       Start Pruning
2023-12-01 16:16:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:16:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:16:16 - INFO :       astronomy: Total Sparsity 1.3570184290844972e-06
2023-12-01 16:16:16 - INFO :       
==================Finish================

2023-12-01 16:16:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:16:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:16:16 - INFO :       DATASET: tasksource/mmlu business_ethics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]
2023-12-01 16:16:25 - INFO :       Use random pruner...
2023-12-01 16:16:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:16:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:16:26 - INFO :       Start Pruning
2023-12-01 16:16:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:16:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:16:28 - INFO :       business_ethics: Total Sparsity 1.3492620234103328e-06
2023-12-01 16:16:28 - INFO :       
==================Finish================

2023-12-01 16:16:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:16:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:16:28 - INFO :       DATASET: tasksource/mmlu clinical_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]
2023-12-01 16:16:36 - INFO :       Use random pruner...
2023-12-01 16:16:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:16:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:16:36 - INFO :       Start Pruning
2023-12-01 16:16:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:16:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:16:38 - INFO :       clinical_knowledge: Total Sparsity 1.3628357333401206e-06
2023-12-01 16:16:38 - INFO :       
==================Finish================

2023-12-01 16:16:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:16:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:16:38 - INFO :       DATASET: tasksource/mmlu college_biology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]
2023-12-01 16:16:45 - INFO :       Use random pruner...
2023-12-01 16:16:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:16:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:16:45 - INFO :       Start Pruning
2023-12-01 16:16:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:16:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:16:47 - INFO :       college_biology: Total Sparsity 1.3614254777629999e-06
2023-12-01 16:16:47 - INFO :       
==================Finish================

2023-12-01 16:16:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:16:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:16:47 - INFO :       DATASET: tasksource/mmlu college_chemistry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.19s/it]
2023-12-01 16:16:57 - INFO :       Use random pruner...
2023-12-01 16:16:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:16:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:16:58 - INFO :       Start Pruning
2023-12-01 16:16:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:16:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:16:59 - INFO :       college_chemistry: Total Sparsity 1.3584286846616181e-06
2023-12-01 16:16:59 - INFO :       
==================Finish================

2023-12-01 16:16:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:16:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:16:59 - INFO :       DATASET: tasksource/mmlu college_computer_science
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 16:17:06 - INFO :       Use random pruner...
2023-12-01 16:17:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:17:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:17:06 - INFO :       Start Pruning
2023-12-01 16:17:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:17:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:17:08 - INFO :       college_computer_science: Total Sparsity 1.3638934250229613e-06
2023-12-01 16:17:08 - INFO :       
==================Finish================

2023-12-01 16:17:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:17:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:17:08 - INFO :       DATASET: tasksource/mmlu college_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 16:17:15 - INFO :       Use random pruner...
2023-12-01 16:17:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:17:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:17:15 - INFO :       Start Pruning
2023-12-01 16:17:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:17:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:17:17 - INFO :       college_mathematics: Total Sparsity 1.3711209848557053e-06
2023-12-01 16:17:17 - INFO :       
==================Finish================

2023-12-01 16:17:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:17:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:17:17 - INFO :       DATASET: tasksource/mmlu college_medicine
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 16:17:25 - INFO :       Use random pruner...
2023-12-01 16:17:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:17:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:17:25 - INFO :       Start Pruning
2023-12-01 16:17:26 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:17:26 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:17:27 - INFO :       college_medicine: Total Sparsity 1.3681241917543236e-06
2023-12-01 16:17:27 - INFO :       
==================Finish================

2023-12-01 16:17:27 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:17:27 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:17:27 - INFO :       DATASET: tasksource/mmlu college_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]
2023-12-01 16:17:36 - INFO :       Use random pruner...
2023-12-01 16:17:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:17:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:17:36 - INFO :       Start Pruning
2023-12-01 16:17:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:17:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:17:38 - INFO :       college_physics: Total Sparsity 1.3573709929787774e-06
2023-12-01 16:17:38 - INFO :       
==================Finish================

2023-12-01 16:17:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:17:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:17:38 - INFO :       DATASET: tasksource/mmlu computer_security
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]
2023-12-01 16:17:48 - INFO :       Use random pruner...
2023-12-01 16:17:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:17:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:17:48 - INFO :       Start Pruning
2023-12-01 16:17:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:17:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:17:50 - INFO :       computer_security: Total Sparsity 1.3630120152872606e-06
2023-12-01 16:17:50 - INFO :       
==================Finish================

2023-12-01 16:17:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:17:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:17:50 - INFO :       DATASET: tasksource/mmlu conceptual_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]
2023-12-01 16:17:58 - INFO :       Use random pruner...
2023-12-01 16:17:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:17:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:17:59 - INFO :       Start Pruning
2023-12-01 16:17:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:17:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:18:00 - INFO :       conceptual_physics: Total Sparsity 1.3608966319215796e-06
2023-12-01 16:18:00 - INFO :       
==================Finish================

2023-12-01 16:18:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:18:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:18:00 - INFO :       DATASET: tasksource/mmlu econometrics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]
2023-12-01 16:18:09 - INFO :       Use random pruner...
2023-12-01 16:18:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:18:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:18:09 - INFO :       Start Pruning
2023-12-01 16:18:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:18:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:18:11 - INFO :       econometrics: Total Sparsity 1.3534927901416952e-06
2023-12-01 16:18:11 - INFO :       
==================Finish================

2023-12-01 16:18:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:18:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:18:11 - INFO :       DATASET: tasksource/mmlu electrical_engineering
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]
2023-12-01 16:18:18 - INFO :       Use random pruner...
2023-12-01 16:18:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:18:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:18:19 - INFO :       Start Pruning
2023-12-01 16:18:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:18:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:18:21 - INFO :       electrical_engineering: Total Sparsity 1.3578998388201979e-06
2023-12-01 16:18:21 - INFO :       
==================Finish================

2023-12-01 16:18:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:18:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:18:21 - INFO :       DATASET: tasksource/mmlu elementary_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2023-12-01 16:18:30 - INFO :       Use random pruner...
2023-12-01 16:18:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:18:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:18:31 - INFO :       Start Pruning
2023-12-01 16:18:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:18:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:18:32 - INFO :       elementary_mathematics: Total Sparsity 1.3575472749259176e-06
2023-12-01 16:18:32 - INFO :       
==================Finish================

2023-12-01 16:18:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:18:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:18:32 - INFO :       DATASET: tasksource/mmlu formal_logic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]
2023-12-01 16:18:42 - INFO :       Use random pruner...
2023-12-01 16:18:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:18:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:18:43 - INFO :       Start Pruning
2023-12-01 16:18:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:18:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:18:45 - INFO :       formal_logic: Total Sparsity 1.3621306055515601e-06
2023-12-01 16:18:45 - INFO :       
==================Finish================

2023-12-01 16:18:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:18:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:18:45 - INFO :       DATASET: tasksource/mmlu global_facts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
2023-12-01 16:18:54 - INFO :       Use random pruner...
2023-12-01 16:18:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:18:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:18:55 - INFO :       Start Pruning
2023-12-01 16:18:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:18:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:18:56 - INFO :       global_facts: Total Sparsity 1.3603677860801591e-06
2023-12-01 16:18:56 - INFO :       
==================Finish================

2023-12-01 16:18:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:18:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:18:56 - INFO :       DATASET: tasksource/mmlu high_school_biology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 16:19:07 - INFO :       Use random pruner...
2023-12-01 16:19:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:19:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:19:07 - INFO :       Start Pruning
2023-12-01 16:19:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:19:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:19:09 - INFO :       high_school_biology: Total Sparsity 1.3644222708643816e-06
2023-12-01 16:19:09 - INFO :       
==================Finish================

2023-12-01 16:19:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:19:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:19:09 - INFO :       DATASET: tasksource/mmlu high_school_chemistry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 16:19:19 - INFO :       Use random pruner...
2023-12-01 16:19:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:19:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:19:19 - INFO :       Start Pruning
2023-12-01 16:19:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:19:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:19:21 - INFO :       high_school_chemistry: Total Sparsity 1.3691818834371643e-06
2023-12-01 16:19:21 - INFO :       
==================Finish================

2023-12-01 16:19:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:19:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:19:21 - INFO :       DATASET: tasksource/mmlu high_school_computer_science
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]
2023-12-01 16:19:30 - INFO :       Use random pruner...
2023-12-01 16:19:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:19:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:19:30 - INFO :       Start Pruning
2023-12-01 16:19:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:19:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:19:32 - INFO :       high_school_computer_science: Total Sparsity 1.358252402714478e-06
2023-12-01 16:19:32 - INFO :       
==================Finish================

2023-12-01 16:19:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:19:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:19:32 - INFO :       DATASET: tasksource/mmlu high_school_european_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 16:19:39 - INFO :       Use random pruner...
2023-12-01 16:19:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:19:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:19:39 - INFO :       Start Pruning
2023-12-01 16:19:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:19:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:19:41 - INFO :       high_school_european_history: Total Sparsity 1.3594863763444586e-06
2023-12-01 16:19:41 - INFO :       
==================Finish================

2023-12-01 16:19:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:19:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:19:41 - INFO :       DATASET: tasksource/mmlu high_school_geography
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 16:19:48 - INFO :       Use random pruner...
2023-12-01 16:19:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:19:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:19:48 - INFO :       Start Pruning
2023-12-01 16:19:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:19:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:19:50 - INFO :       high_school_geography: Total Sparsity 1.3677716278600435e-06
2023-12-01 16:19:50 - INFO :       
==================Finish================

2023-12-01 16:19:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:19:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:19:50 - INFO :       DATASET: tasksource/mmlu high_school_government_and_politics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2023-12-01 16:20:00 - INFO :       Use random pruner...
2023-12-01 16:20:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:20:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:20:00 - INFO :       Start Pruning
2023-12-01 16:20:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:20:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:20:02 - INFO :       high_school_government_and_politics: Total Sparsity 1.3612491958158596e-06
2023-12-01 16:20:02 - INFO :       
==================Finish================

2023-12-01 16:20:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:20:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:20:02 - INFO :       DATASET: tasksource/mmlu high_school_macroeconomics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.34s/it]
2023-12-01 16:20:12 - INFO :       Use random pruner...
2023-12-01 16:20:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:20:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:20:13 - INFO :       Start Pruning
2023-12-01 16:20:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:20:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:20:14 - INFO :       high_school_macroeconomics: Total Sparsity 1.3638934250229613e-06
2023-12-01 16:20:14 - INFO :       
==================Finish================

2023-12-01 16:20:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:20:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:20:14 - INFO :       DATASET: tasksource/mmlu high_school_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
2023-12-01 16:20:23 - INFO :       Use random pruner...
2023-12-01 16:20:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:20:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:20:24 - INFO :       Start Pruning
2023-12-01 16:20:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:20:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:20:26 - INFO :       high_school_mathematics: Total Sparsity 1.3647748347586618e-06
2023-12-01 16:20:26 - INFO :       
==================Finish================

2023-12-01 16:20:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:20:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:20:26 - INFO :       DATASET: tasksource/mmlu high_school_microeconomics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]
2023-12-01 16:20:34 - INFO :       Use random pruner...
2023-12-01 16:20:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:20:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:20:35 - INFO :       Start Pruning
2023-12-01 16:20:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:20:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:20:37 - INFO :       high_school_microeconomics: Total Sparsity 1.3538453540359754e-06
2023-12-01 16:20:37 - INFO :       
==================Finish================

2023-12-01 16:20:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:20:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:20:37 - INFO :       DATASET: tasksource/mmlu high_school_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 16:20:43 - INFO :       Use random pruner...
2023-12-01 16:20:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:20:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:20:44 - INFO :       Start Pruning
2023-12-01 16:20:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:20:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:20:45 - INFO :       high_school_physics: Total Sparsity 1.356489583243077e-06
2023-12-01 16:20:45 - INFO :       
==================Finish================

2023-12-01 16:20:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:20:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:20:45 - INFO :       DATASET: tasksource/mmlu high_school_psychology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  2.00s/it]
2023-12-01 16:20:56 - INFO :       Use random pruner...
2023-12-01 16:20:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:20:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:20:57 - INFO :       Start Pruning
2023-12-01 16:20:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:20:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:20:58 - INFO :       high_school_psychology: Total Sparsity 1.3663613722829226e-06
2023-12-01 16:20:58 - INFO :       
==================Finish================

2023-12-01 16:20:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:20:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:20:58 - INFO :       DATASET: tasksource/mmlu high_school_statistics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]
2023-12-01 16:21:07 - INFO :       Use random pruner...
2023-12-01 16:21:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:21:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:21:08 - INFO :       Start Pruning
2023-12-01 16:21:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:21:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:21:10 - INFO :       high_school_statistics: Total Sparsity 1.367242782018623e-06
2023-12-01 16:21:10 - INFO :       
==================Finish================

2023-12-01 16:21:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:21:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:21:10 - INFO :       DATASET: tasksource/mmlu high_school_us_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.35s/it]
2023-12-01 16:21:22 - INFO :       Use random pruner...
2023-12-01 16:21:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:21:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:21:22 - INFO :       Start Pruning
2023-12-01 16:21:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:21:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:21:24 - INFO :       high_school_us_history: Total Sparsity 1.3549030457188162e-06
2023-12-01 16:21:24 - INFO :       
==================Finish================

2023-12-01 16:21:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:21:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:21:24 - INFO :       DATASET: tasksource/mmlu high_school_world_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]
2023-12-01 16:21:36 - INFO :       Use random pruner...
2023-12-01 16:21:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:21:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:21:36 - INFO :       Start Pruning
2023-12-01 16:21:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:21:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:21:38 - INFO :       high_school_world_history: Total Sparsity 1.3561370193487967e-06
2023-12-01 16:21:38 - INFO :       
==================Finish================

2023-12-01 16:21:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:21:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:21:38 - INFO :       DATASET: tasksource/mmlu human_aging
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.50s/it]
2023-12-01 16:21:51 - INFO :       Use random pruner...
2023-12-01 16:21:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:21:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:21:51 - INFO :       Start Pruning
2023-12-01 16:21:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:21:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:21:53 - INFO :       human_aging: Total Sparsity 1.3598389402387389e-06
2023-12-01 16:21:53 - INFO :       
==================Finish================

2023-12-01 16:21:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:21:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:21:53 - INFO :       DATASET: tasksource/mmlu human_sexuality
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
2023-12-01 16:22:04 - INFO :       Use random pruner...
2023-12-01 16:22:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:22:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:22:05 - INFO :       Start Pruning
2023-12-01 16:22:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:22:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:22:07 - INFO :       human_sexuality: Total Sparsity 1.3640697069701013e-06
2023-12-01 16:22:07 - INFO :       
==================Finish================

2023-12-01 16:22:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:22:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:22:07 - INFO :       DATASET: tasksource/mmlu international_law
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.30s/it]
2023-12-01 16:22:18 - INFO :       Use random pruner...
2023-12-01 16:22:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:22:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:22:18 - INFO :       Start Pruning
2023-12-01 16:22:19 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:22:19 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:22:20 - INFO :       international_law: Total Sparsity 1.3716498306971257e-06
2023-12-01 16:22:20 - INFO :       
==================Finish================

2023-12-01 16:22:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:22:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:22:20 - INFO :       DATASET: tasksource/mmlu jurisprudence
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.27s/it]
2023-12-01 16:22:32 - INFO :       Use random pruner...
2023-12-01 16:22:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:22:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:22:32 - INFO :       Start Pruning
2023-12-01 16:22:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:22:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:22:34 - INFO :       jurisprudence: Total Sparsity 1.3644222708643816e-06
2023-12-01 16:22:34 - INFO :       
==================Finish================

2023-12-01 16:22:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:22:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:22:34 - INFO :       DATASET: tasksource/mmlu logical_fallacies
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2023-12-01 16:22:44 - INFO :       Use random pruner...
2023-12-01 16:22:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:22:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:22:44 - INFO :       Start Pruning
2023-12-01 16:22:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:22:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:22:46 - INFO :       logical_fallacies: Total Sparsity 1.3605440680272994e-06
2023-12-01 16:22:46 - INFO :       
==================Finish================

2023-12-01 16:22:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:22:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:22:46 - INFO :       DATASET: tasksource/mmlu machine_learning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]
2023-12-01 16:22:55 - INFO :       Use random pruner...
2023-12-01 16:22:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:22:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:22:56 - INFO :       Start Pruning
2023-12-01 16:22:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:22:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:22:58 - INFO :       machine_learning: Total Sparsity 1.3728838043271063e-06
2023-12-01 16:22:58 - INFO :       
==================Finish================

2023-12-01 16:22:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:22:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:22:58 - INFO :       DATASET: tasksource/mmlu management
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2023-12-01 16:23:08 - INFO :       Use random pruner...
2023-12-01 16:23:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:23:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:23:08 - INFO :       Start Pruning
2023-12-01 16:23:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:23:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:23:10 - INFO :       management: Total Sparsity 1.368653037595744e-06
2023-12-01 16:23:10 - INFO :       
==================Finish================

2023-12-01 16:23:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:23:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:23:10 - INFO :       DATASET: tasksource/mmlu marketing
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]
2023-12-01 16:23:19 - INFO :       Use random pruner...
2023-12-01 16:23:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:23:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:23:19 - INFO :       Start Pruning
2023-12-01 16:23:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:23:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:23:21 - INFO :       marketing: Total Sparsity 1.3656562444943623e-06
2023-12-01 16:23:21 - INFO :       
==================Finish================

2023-12-01 16:23:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:23:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:23:21 - INFO :       DATASET: tasksource/mmlu medical_genetics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2023-12-01 16:23:30 - INFO :       Use random pruner...
2023-12-01 16:23:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:23:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:23:30 - INFO :       Start Pruning
2023-12-01 16:23:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:23:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:23:32 - INFO :       medical_genetics: Total Sparsity 1.3693581653843043e-06
2023-12-01 16:23:32 - INFO :       
==================Finish================

2023-12-01 16:23:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:23:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:23:32 - INFO :       DATASET: tasksource/mmlu miscellaneous
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.46s/it]
2023-12-01 16:23:41 - INFO :       Use random pruner...
2023-12-01 16:23:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:23:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:23:42 - INFO :       Start Pruning
2023-12-01 16:23:42 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:23:42 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:23:43 - INFO :       miscellaneous: Total Sparsity 1.3681241917543236e-06
2023-12-01 16:23:43 - INFO :       
==================Finish================

2023-12-01 16:23:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:23:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:23:43 - INFO :       DATASET: tasksource/mmlu moral_disputes
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.50s/it]
2023-12-01 16:23:53 - INFO :       Use random pruner...
2023-12-01 16:23:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:23:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:23:54 - INFO :       Start Pruning
2023-12-01 16:23:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:23:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:23:55 - INFO :       moral_disputes: Total Sparsity 1.3633645791815409e-06
2023-12-01 16:23:55 - INFO :       
==================Finish================

2023-12-01 16:23:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:23:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:23:55 - INFO :       DATASET: tasksource/mmlu moral_scenarios
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]
2023-12-01 16:24:05 - INFO :       Use random pruner...
2023-12-01 16:24:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:24:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:24:06 - INFO :       Start Pruning
2023-12-01 16:24:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:24:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:24:08 - INFO :       moral_scenarios: Total Sparsity 1.3616017597101399e-06
2023-12-01 16:24:08 - INFO :       
==================Finish================

2023-12-01 16:24:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:24:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:24:08 - INFO :       DATASET: tasksource/mmlu nutrition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2023-12-01 16:24:16 - INFO :       Use random pruner...
2023-12-01 16:24:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:24:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:24:16 - INFO :       Start Pruning
2023-12-01 16:24:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:24:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:24:18 - INFO :       nutrition: Total Sparsity 1.349614587304613e-06
2023-12-01 16:24:18 - INFO :       
==================Finish================

2023-12-01 16:24:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:24:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:24:18 - INFO :       DATASET: tasksource/mmlu philosophy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2023-12-01 16:24:28 - INFO :       Use random pruner...
2023-12-01 16:24:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:24:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:24:28 - INFO :       Start Pruning
2023-12-01 16:24:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:24:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:24:30 - INFO :       philosophy: Total Sparsity 1.3587812485558984e-06
2023-12-01 16:24:30 - INFO :       
==================Finish================

2023-12-01 16:24:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:24:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:24:30 - INFO :       DATASET: tasksource/mmlu prehistory
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]
2023-12-01 16:24:39 - INFO :       Use random pruner...
2023-12-01 16:24:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:24:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:24:39 - INFO :       Start Pruning
2023-12-01 16:24:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:24:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:24:41 - INFO :       prehistory: Total Sparsity 1.3624831694458404e-06
2023-12-01 16:24:41 - INFO :       
==================Finish================

2023-12-01 16:24:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:24:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:24:41 - INFO :       DATASET: tasksource/mmlu professional_accounting
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]
2023-12-01 16:24:50 - INFO :       Use random pruner...
2023-12-01 16:24:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:24:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:24:51 - INFO :       Start Pruning
2023-12-01 16:24:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:24:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:24:52 - INFO :       professional_accounting: Total Sparsity 1.360015222185879e-06
2023-12-01 16:24:52 - INFO :       
==================Finish================

2023-12-01 16:24:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:24:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:24:52 - INFO :       DATASET: tasksource/mmlu professional_law
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 16:25:03 - INFO :       Use random pruner...
2023-12-01 16:25:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:25:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:25:03 - INFO :       Start Pruning
2023-12-01 16:25:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:25:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:25:05 - INFO :       professional_law: Total Sparsity 1.3640697069701013e-06
2023-12-01 16:25:05 - INFO :       
==================Finish================

2023-12-01 16:25:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:25:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:25:05 - INFO :       DATASET: tasksource/mmlu professional_medicine
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]
2023-12-01 16:25:15 - INFO :       Use random pruner...
2023-12-01 16:25:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:25:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:25:15 - INFO :       Start Pruning
2023-12-01 16:25:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:25:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:25:17 - INFO :       professional_medicine: Total Sparsity 1.369005601490024e-06
2023-12-01 16:25:17 - INFO :       
==================Finish================

2023-12-01 16:25:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:25:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:25:17 - INFO :       DATASET: tasksource/mmlu professional_psychology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2023-12-01 16:25:26 - INFO :       Use random pruner...
2023-12-01 16:25:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:25:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:25:26 - INFO :       Start Pruning
2023-12-01 16:25:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:25:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:25:28 - INFO :       professional_psychology: Total Sparsity 1.367242782018623e-06
2023-12-01 16:25:28 - INFO :       
==================Finish================

2023-12-01 16:25:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:25:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:25:28 - INFO :       DATASET: tasksource/mmlu public_relations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.49s/it]
2023-12-01 16:25:36 - INFO :       Use random pruner...
2023-12-01 16:25:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:25:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:25:36 - INFO :       Start Pruning
2023-12-01 16:25:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:25:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:25:38 - INFO :       public_relations: Total Sparsity 1.3707684209614252e-06
2023-12-01 16:25:38 - INFO :       
==================Finish================

2023-12-01 16:25:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:25:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:25:38 - INFO :       DATASET: tasksource/mmlu security_studies
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2023-12-01 16:25:47 - INFO :       Use random pruner...
2023-12-01 16:25:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:25:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:25:48 - INFO :       Start Pruning
2023-12-01 16:25:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:25:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:25:49 - INFO :       security_studies: Total Sparsity 1.3697107292785845e-06
2023-12-01 16:25:49 - INFO :       
==================Finish================

2023-12-01 16:25:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:25:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:25:49 - INFO :       DATASET: tasksource/mmlu sociology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]
2023-12-01 16:26:00 - INFO :       Use random pruner...
2023-12-01 16:26:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:26:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:26:01 - INFO :       Start Pruning
2023-12-01 16:26:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:26:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:26:02 - INFO :       sociology: Total Sparsity 1.3661850903357826e-06
2023-12-01 16:26:02 - INFO :       
==================Finish================

2023-12-01 16:26:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:26:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:26:02 - INFO :       DATASET: tasksource/mmlu us_foreign_policy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]
2023-12-01 16:26:12 - INFO :       Use random pruner...
2023-12-01 16:26:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:26:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:26:12 - INFO :       Start Pruning
2023-12-01 16:26:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:26:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:26:14 - INFO :       us_foreign_policy: Total Sparsity 1.3586049666087581e-06
2023-12-01 16:26:14 - INFO :       
==================Finish================

2023-12-01 16:26:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:26:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:26:14 - INFO :       DATASET: tasksource/mmlu virology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 16:26:24 - INFO :       Use random pruner...
2023-12-01 16:26:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:26:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:26:24 - INFO :       Start Pruning
2023-12-01 16:26:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:26:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:26:26 - INFO :       virology: Total Sparsity 1.3570184290844972e-06
2023-12-01 16:26:26 - INFO :       
==================Finish================

2023-12-01 16:26:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:26:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:26:26 - INFO :       DATASET: tasksource/mmlu world_religions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]
2023-12-01 16:26:35 - INFO :       Use random pruner...
2023-12-01 16:26:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:26:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:26:35 - INFO :       Start Pruning
2023-12-01 16:26:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:26:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:26:37 - INFO :       world_religions: Total Sparsity 1.3628357333401206e-06
2023-12-01 16:26:37 - INFO :       
==================Finish================

2023-12-01 16:26:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:26:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:26:37 - INFO :       DATASET: math_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
2023-12-01 16:26:47 - INFO :       Use random pruner...
2023-12-01 16:26:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:26:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:26:47 - INFO :       Start Pruning
2023-12-01 16:26:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:26:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:26:49 - INFO :       math_qa: Total Sparsity 1.3605440680272994e-06
2023-12-01 16:26:49 - INFO :       
==================Finish================

2023-12-01 16:26:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:26:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:26:49 - INFO :       DATASET: EleutherAI/truthful_qa_mc
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.38s/it]
2023-12-01 16:27:00 - INFO :       Use random pruner...
2023-12-01 16:27:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:27:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:27:01 - INFO :       Start Pruning
2023-12-01 16:27:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:27:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:27:02 - INFO :       truthful_qa_mc: Total Sparsity 1.3663613722829226e-06
2023-12-01 16:27:02 - INFO :       
==================Finish================

2023-12-01 16:27:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:27:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:27:02 - INFO :       DATASET: derek-thomas/ScienceQA
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2023-12-01 16:27:14 - INFO :       Use random pruner...
2023-12-01 16:27:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:27:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:27:14 - INFO :       Start Pruning
2023-12-01 16:27:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:27:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:27:16 - INFO :       ScienceQA: Total Sparsity 1.3661850903357826e-06
2023-12-01 16:27:16 - INFO :       
==================Finish================

2023-12-01 16:27:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:27:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:27:16 - INFO :       DATASET: commonsense_qa
Index 1
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.27s/it]
2023-12-01 16:27:28 - INFO :       Use random pruner...
2023-12-01 16:27:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:27:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:27:28 - INFO :       Start Pruning
2023-12-01 16:27:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:27:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:27:30 - INFO :       commonsense_qa: Total Sparsity 1.3549030457188162e-06
2023-12-01 16:27:30 - INFO :       
==================Finish================

2023-12-01 16:27:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:27:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:27:30 - INFO :       DATASET: tasksource/bigbench abstract_narrative_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2023-12-01 16:27:38 - INFO :       Use random pruner...
2023-12-01 16:27:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:27:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:27:38 - INFO :       Start Pruning
2023-12-01 16:27:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:27:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:27:40 - INFO :       abstract_narrative_understanding: Total Sparsity 1.3534927901416952e-06
2023-12-01 16:27:40 - INFO :       
==================Finish================

2023-12-01 16:27:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:27:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:27:40 - INFO :       DATASET: tasksource/bigbench anachronisms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.91s/it]
2023-12-01 16:27:49 - INFO :       Use random pruner...
2023-12-01 16:27:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:27:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:27:50 - INFO :       Start Pruning
2023-12-01 16:27:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:27:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:27:51 - INFO :       anachronisms: Total Sparsity 1.3568421471373572e-06
2023-12-01 16:27:51 - INFO :       
==================Finish================

2023-12-01 16:27:51 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:27:51 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:27:51 - INFO :       DATASET: tasksource/bigbench analogical_similarity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2023-12-01 16:28:02 - INFO :       Use random pruner...
2023-12-01 16:28:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:28:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:28:02 - INFO :       Start Pruning
2023-12-01 16:28:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:28:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:28:04 - INFO :       analogical_similarity: Total Sparsity 1.3700632931728648e-06
2023-12-01 16:28:04 - INFO :       
==================Finish================

2023-12-01 16:28:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:28:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:28:04 - INFO :       DATASET: tasksource/bigbench analytic_entailment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2023-12-01 16:28:13 - INFO :       Use random pruner...
2023-12-01 16:28:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:28:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:28:14 - INFO :       Start Pruning
2023-12-01 16:28:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:28:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:28:15 - INFO :       analytic_entailment: Total Sparsity 1.3561370193487967e-06
2023-12-01 16:28:15 - INFO :       
==================Finish================

2023-12-01 16:28:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:28:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:28:15 - INFO :       DATASET: tasksource/bigbench arithmetic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]
2023-12-01 16:28:25 - INFO :       Use random pruner...
2023-12-01 16:28:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:28:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:28:25 - INFO :       Start Pruning
2023-12-01 16:28:26 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:28:26 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:28:27 - INFO :       arithmetic: Total Sparsity 1.3594863763444586e-06
2023-12-01 16:28:27 - INFO :       
==================Finish================

2023-12-01 16:28:27 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:28:27 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:28:27 - INFO :       DATASET: tasksource/bigbench authorship_verification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2023-12-01 16:28:36 - INFO :       Use random pruner...
2023-12-01 16:28:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:28:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:28:36 - INFO :       Start Pruning
2023-12-01 16:28:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:28:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:28:38 - INFO :       authorship_verification: Total Sparsity 1.3644222708643816e-06
2023-12-01 16:28:38 - INFO :       
==================Finish================

2023-12-01 16:28:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:28:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:28:38 - INFO :       DATASET: tasksource/bigbench bbq_lite_json
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
2023-12-01 16:28:46 - INFO :       Use random pruner...
2023-12-01 16:28:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:28:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:28:47 - INFO :       Start Pruning
2023-12-01 16:28:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:28:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:28:48 - INFO :       bbq_lite_json: Total Sparsity 1.3644222708643816e-06
2023-12-01 16:28:48 - INFO :       
==================Finish================

2023-12-01 16:28:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:28:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:28:48 - INFO :       DATASET: tasksource/bigbench causal_judgment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2023-12-01 16:28:56 - INFO :       Use random pruner...
2023-12-01 16:28:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:28:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:28:56 - INFO :       Start Pruning
2023-12-01 16:28:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:28:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:28:58 - INFO :       causal_judgment: Total Sparsity 1.3677716278600435e-06
2023-12-01 16:28:58 - INFO :       
==================Finish================

2023-12-01 16:28:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:28:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:28:58 - INFO :       DATASET: tasksource/bigbench cause_and_effect
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]
2023-12-01 16:29:07 - INFO :       Use random pruner...
2023-12-01 16:29:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:29:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:29:07 - INFO :       Start Pruning
2023-12-01 16:29:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:29:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:29:09 - INFO :       cause_and_effect: Total Sparsity 1.3658325264415023e-06
2023-12-01 16:29:09 - INFO :       
==================Finish================

2023-12-01 16:29:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:29:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:29:09 - INFO :       DATASET: tasksource/bigbench checkmate_in_one
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]
2023-12-01 16:29:19 - INFO :       Use random pruner...
2023-12-01 16:29:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:29:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:29:19 - INFO :       Start Pruning
2023-12-01 16:29:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:29:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:29:21 - INFO :       checkmate_in_one: Total Sparsity 1.3587812485558984e-06
2023-12-01 16:29:21 - INFO :       
==================Finish================

2023-12-01 16:29:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:29:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:29:21 - INFO :       DATASET: tasksource/bigbench cifar10_classification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2023-12-01 16:29:30 - INFO :       Use random pruner...
2023-12-01 16:29:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:29:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:29:31 - INFO :       Start Pruning
2023-12-01 16:29:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:29:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:29:32 - INFO :       cifar10_classification: Total Sparsity 1.3677716278600435e-06
2023-12-01 16:29:32 - INFO :       
==================Finish================

2023-12-01 16:29:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:29:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:29:32 - INFO :       DATASET: tasksource/bigbench code_line_description
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]
2023-12-01 16:29:41 - INFO :       Use random pruner...
2023-12-01 16:29:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:29:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:29:42 - INFO :       Start Pruning
2023-12-01 16:29:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:29:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:29:43 - INFO :       code_line_description: Total Sparsity 1.3570184290844972e-06
2023-12-01 16:29:43 - INFO :       
==================Finish================

2023-12-01 16:29:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:29:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:29:43 - INFO :       DATASET: tasksource/bigbench color
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]
2023-12-01 16:29:53 - INFO :       Use random pruner...
2023-12-01 16:29:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:29:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:29:53 - INFO :       Start Pruning
2023-12-01 16:29:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:29:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:29:55 - INFO :       color: Total Sparsity 1.3593100943973186e-06
2023-12-01 16:29:55 - INFO :       
==================Finish================

2023-12-01 16:29:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:29:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:29:55 - INFO :       DATASET: tasksource/bigbench common_morpheme
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]
2023-12-01 16:30:03 - INFO :       Use random pruner...
2023-12-01 16:30:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:30:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:30:04 - INFO :       Start Pruning
2023-12-01 16:30:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:30:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:30:06 - INFO :       common_morpheme: Total Sparsity 1.3577235568730577e-06
2023-12-01 16:30:06 - INFO :       
==================Finish================

2023-12-01 16:30:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:30:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:30:06 - INFO :       DATASET: tasksource/bigbench conceptual_combinations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2023-12-01 16:30:15 - INFO :       Use random pruner...
2023-12-01 16:30:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:30:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:30:16 - INFO :       Start Pruning
2023-12-01 16:30:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:30:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:30:17 - INFO :       conceptual_combinations: Total Sparsity 1.3638934250229613e-06
2023-12-01 16:30:17 - INFO :       
==================Finish================

2023-12-01 16:30:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:30:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:30:17 - INFO :       DATASET: tasksource/bigbench crash_blossom
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2023-12-01 16:30:27 - INFO :       Use random pruner...
2023-12-01 16:30:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:30:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:30:27 - INFO :       Start Pruning
2023-12-01 16:30:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:30:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:30:29 - INFO :       crash_blossom: Total Sparsity 1.3586049666087581e-06
2023-12-01 16:30:29 - INFO :       
==================Finish================

2023-12-01 16:30:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:30:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:30:29 - INFO :       DATASET: tasksource/bigbench crass_ai
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2023-12-01 16:30:38 - INFO :       Use random pruner...
2023-12-01 16:30:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:30:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:30:38 - INFO :       Start Pruning
2023-12-01 16:30:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:30:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:30:40 - INFO :       crass_ai: Total Sparsity 1.3660088083886423e-06
2023-12-01 16:30:40 - INFO :       
==================Finish================

2023-12-01 16:30:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:30:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:30:40 - INFO :       DATASET: tasksource/bigbench cryobiology_spanish
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 16:30:49 - INFO :       Use random pruner...
2023-12-01 16:30:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:30:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:30:49 - INFO :       Start Pruning
2023-12-01 16:30:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:30:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:30:51 - INFO :       cryobiology_spanish: Total Sparsity 1.3698870112257248e-06
2023-12-01 16:30:51 - INFO :       
==================Finish================

2023-12-01 16:30:51 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:30:51 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:30:51 - INFO :       DATASET: tasksource/bigbench cs_algorithms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]
2023-12-01 16:31:00 - INFO :       Use random pruner...
2023-12-01 16:31:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:31:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:31:01 - INFO :       Start Pruning
2023-12-01 16:31:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:31:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:31:03 - INFO :       cs_algorithms: Total Sparsity 1.3714735487499855e-06
2023-12-01 16:31:03 - INFO :       
==================Finish================

2023-12-01 16:31:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:31:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:31:03 - INFO :       DATASET: tasksource/bigbench dark_humor_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.91s/it]
2023-12-01 16:31:13 - INFO :       Use random pruner...
2023-12-01 16:31:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:31:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:31:13 - INFO :       Start Pruning
2023-12-01 16:31:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:31:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:31:15 - INFO :       dark_humor_detection: Total Sparsity 1.353140226247415e-06
2023-12-01 16:31:15 - INFO :       
==================Finish================

2023-12-01 16:31:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:31:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:31:15 - INFO :       DATASET: tasksource/bigbench date_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2023-12-01 16:31:24 - INFO :       Use random pruner...
2023-12-01 16:31:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:31:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:31:24 - INFO :       Start Pruning
2023-12-01 16:31:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:31:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:31:26 - INFO :       date_understanding: Total Sparsity 1.3608966319215796e-06
2023-12-01 16:31:26 - INFO :       
==================Finish================

2023-12-01 16:31:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:31:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:31:26 - INFO :       DATASET: tasksource/bigbench disambiguation_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]
2023-12-01 16:31:35 - INFO :       Use random pruner...
2023-12-01 16:31:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:31:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:31:36 - INFO :       Start Pruning
2023-12-01 16:31:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:31:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:31:38 - INFO :       disambiguation_qa: Total Sparsity 1.3631882972344008e-06
2023-12-01 16:31:38 - INFO :       
==================Finish================

2023-12-01 16:31:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:31:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:31:38 - INFO :       DATASET: tasksource/bigbench discourse_marker_prediction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]
2023-12-01 16:31:47 - INFO :       Use random pruner...
2023-12-01 16:31:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:31:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:31:48 - INFO :       Start Pruning
2023-12-01 16:31:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:31:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:31:50 - INFO :       discourse_marker_prediction: Total Sparsity 1.3658325264415023e-06
2023-12-01 16:31:50 - INFO :       
==================Finish================

2023-12-01 16:31:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:31:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:31:50 - INFO :       DATASET: tasksource/bigbench dyck_languages
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]
2023-12-01 16:31:58 - INFO :       Use random pruner...
2023-12-01 16:31:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:31:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:31:59 - INFO :       Start Pruning
2023-12-01 16:32:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:32:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:32:01 - INFO :       dyck_languages: Total Sparsity 1.3675953459129033e-06
2023-12-01 16:32:01 - INFO :       
==================Finish================

2023-12-01 16:32:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:32:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:32:01 - INFO :       DATASET: tasksource/bigbench elementary_math_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]
2023-12-01 16:32:09 - INFO :       Use random pruner...
2023-12-01 16:32:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:32:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:32:10 - INFO :       Start Pruning
2023-12-01 16:32:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:32:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:32:11 - INFO :       elementary_math_qa: Total Sparsity 1.3631882972344008e-06
2023-12-01 16:32:11 - INFO :       
==================Finish================

2023-12-01 16:32:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:32:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:32:11 - INFO :       DATASET: tasksource/bigbench emoji_movie
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]
2023-12-01 16:32:20 - INFO :       Use random pruner...
2023-12-01 16:32:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:32:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:32:20 - INFO :       Start Pruning
2023-12-01 16:32:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:32:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:32:22 - INFO :       emoji_movie: Total Sparsity 1.3584286846616181e-06
2023-12-01 16:32:22 - INFO :       
==================Finish================

2023-12-01 16:32:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:32:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:32:22 - INFO :       DATASET: tasksource/bigbench empirical_judgments
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]
2023-12-01 16:32:32 - INFO :       Use random pruner...
2023-12-01 16:32:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:32:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:32:32 - INFO :       Start Pruning
2023-12-01 16:32:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:32:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:32:34 - INFO :       empirical_judgments: Total Sparsity 1.3607203499744394e-06
2023-12-01 16:32:34 - INFO :       
==================Finish================

2023-12-01 16:32:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:32:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:32:34 - INFO :       DATASET: tasksource/bigbench english_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]
2023-12-01 16:32:42 - INFO :       Use random pruner...
2023-12-01 16:32:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:32:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:32:42 - INFO :       Start Pruning
2023-12-01 16:32:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:32:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:32:44 - INFO :       english_proverbs: Total Sparsity 1.3656562444943623e-06
2023-12-01 16:32:44 - INFO :       
==================Finish================

2023-12-01 16:32:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:32:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:32:44 - INFO :       DATASET: tasksource/bigbench english_russian_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2023-12-01 16:32:53 - INFO :       Use random pruner...
2023-12-01 16:32:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:32:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:32:53 - INFO :       Start Pruning
2023-12-01 16:32:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:32:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:32:55 - INFO :       english_russian_proverbs: Total Sparsity 1.3702395751200048e-06
2023-12-01 16:32:55 - INFO :       
==================Finish================

2023-12-01 16:32:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:32:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:32:55 - INFO :       DATASET: tasksource/bigbench entailed_polarity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]
2023-12-01 16:33:05 - INFO :       Use random pruner...
2023-12-01 16:33:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:33:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:33:05 - INFO :       Start Pruning
2023-12-01 16:33:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:33:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:33:07 - INFO :       entailed_polarity: Total Sparsity 1.3587812485558984e-06
2023-12-01 16:33:07 - INFO :       
==================Finish================

2023-12-01 16:33:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:33:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:33:07 - INFO :       DATASET: tasksource/bigbench entailed_polarity_hindi
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 16:33:14 - INFO :       Use random pruner...
2023-12-01 16:33:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:33:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:33:14 - INFO :       Start Pruning
2023-12-01 16:33:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:33:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:33:16 - INFO :       entailed_polarity_hindi: Total Sparsity 1.3536690720888354e-06
2023-12-01 16:33:16 - INFO :       
==================Finish================

2023-12-01 16:33:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:33:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:33:16 - INFO :       DATASET: tasksource/bigbench epistemic_reasoning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2023-12-01 16:33:26 - INFO :       Use random pruner...
2023-12-01 16:33:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:33:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:33:27 - INFO :       Start Pruning
2023-12-01 16:33:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:33:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:33:29 - INFO :       epistemic_reasoning: Total Sparsity 1.3727075223799662e-06
2023-12-01 16:33:29 - INFO :       
==================Finish================

2023-12-01 16:33:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:33:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:33:29 - INFO :       DATASET: tasksource/bigbench evaluating_information_essentiality
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]
2023-12-01 16:33:36 - INFO :       Use random pruner...
2023-12-01 16:33:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:33:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:33:37 - INFO :       Start Pruning
2023-12-01 16:33:38 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:33:38 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:33:38 - INFO :       evaluating_information_essentiality: Total Sparsity 1.3591338124501784e-06
2023-12-01 16:33:38 - INFO :       
==================Finish================

2023-12-01 16:33:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:33:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:33:38 - INFO :       DATASET: tasksource/bigbench fact_checker
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]
2023-12-01 16:33:47 - INFO :       Use random pruner...
2023-12-01 16:33:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:33:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:33:48 - INFO :       Start Pruning
2023-12-01 16:33:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:33:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:33:50 - INFO :       fact_checker: Total Sparsity 1.3605440680272994e-06
2023-12-01 16:33:50 - INFO :       
==================Finish================

2023-12-01 16:33:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:33:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:33:50 - INFO :       DATASET: tasksource/bigbench fantasy_reasoning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]
2023-12-01 16:33:58 - INFO :       Use random pruner...
2023-12-01 16:33:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:33:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:33:59 - INFO :       Start Pruning
2023-12-01 16:33:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:33:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:34:00 - INFO :       fantasy_reasoning: Total Sparsity 1.368829319542884e-06
2023-12-01 16:34:00 - INFO :       
==================Finish================

2023-12-01 16:34:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:34:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:34:00 - INFO :       DATASET: tasksource/bigbench figure_of_speech_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]
2023-12-01 16:34:10 - INFO :       Use random pruner...
2023-12-01 16:34:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:34:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:34:10 - INFO :       Start Pruning
2023-12-01 16:34:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:34:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:34:12 - INFO :       figure_of_speech_detection: Total Sparsity 1.3638934250229613e-06
2023-12-01 16:34:12 - INFO :       
==================Finish================

2023-12-01 16:34:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:34:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:34:12 - INFO :       DATASET: tasksource/bigbench formal_fallacies_syllogisms_negation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
2023-12-01 16:34:23 - INFO :       Use random pruner...
2023-12-01 16:34:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:34:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:34:23 - INFO :       Start Pruning
2023-12-01 16:34:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:34:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:34:25 - INFO :       formal_fallacies_syllogisms_negation: Total Sparsity 1.3751754696399277e-06
2023-12-01 16:34:25 - INFO :       
==================Finish================

2023-12-01 16:34:25 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:34:25 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:34:25 - INFO :       DATASET: tasksource/bigbench general_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2023-12-01 16:34:34 - INFO :       Use random pruner...
2023-12-01 16:34:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:34:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:34:35 - INFO :       Start Pruning
2023-12-01 16:34:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:34:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:34:37 - INFO :       general_knowledge: Total Sparsity 1.3675953459129033e-06
2023-12-01 16:34:37 - INFO :       
==================Finish================

2023-12-01 16:34:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:34:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:34:37 - INFO :       DATASET: tasksource/bigbench geometric_shapes
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]
2023-12-01 16:34:46 - INFO :       Use random pruner...
2023-12-01 16:34:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:34:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:34:46 - INFO :       Start Pruning
2023-12-01 16:34:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:34:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:34:48 - INFO :       geometric_shapes: Total Sparsity 1.3645985528115216e-06
2023-12-01 16:34:48 - INFO :       
==================Finish================

2023-12-01 16:34:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:34:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:34:48 - INFO :       DATASET: tasksource/bigbench goal_step_wikihow
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2023-12-01 16:34:57 - INFO :       Use random pruner...
2023-12-01 16:34:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:34:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:34:57 - INFO :       Start Pruning
2023-12-01 16:34:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:34:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:34:59 - INFO :       goal_step_wikihow: Total Sparsity 1.3695344473314445e-06
2023-12-01 16:34:59 - INFO :       
==================Finish================

2023-12-01 16:34:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:34:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:34:59 - INFO :       DATASET: tasksource/bigbench gre_reading_comprehension
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]
2023-12-01 16:35:08 - INFO :       Use random pruner...
2023-12-01 16:35:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:35:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:35:08 - INFO :       Start Pruning
2023-12-01 16:35:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:35:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:35:10 - INFO :       gre_reading_comprehension: Total Sparsity 1.3698870112257248e-06
2023-12-01 16:35:10 - INFO :       
==================Finish================

2023-12-01 16:35:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:35:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:35:10 - INFO :       DATASET: tasksource/bigbench hhh_alignment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
2023-12-01 16:35:19 - INFO :       Use random pruner...
2023-12-01 16:35:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:35:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:35:20 - INFO :       Start Pruning
2023-12-01 16:35:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:35:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:35:21 - INFO :       hhh_alignment: Total Sparsity 1.3614254777629999e-06
2023-12-01 16:35:21 - INFO :       
==================Finish================

2023-12-01 16:35:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:35:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:35:21 - INFO :       DATASET: tasksource/bigbench hindu_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]
2023-12-01 16:35:30 - INFO :       Use random pruner...
2023-12-01 16:35:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:35:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:35:31 - INFO :       Start Pruning
2023-12-01 16:35:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:35:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:35:32 - INFO :       hindu_knowledge: Total Sparsity 1.3712972668028455e-06
2023-12-01 16:35:32 - INFO :       
==================Finish================

2023-12-01 16:35:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:35:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:35:32 - INFO :       DATASET: tasksource/bigbench hinglish_toxicity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2023-12-01 16:35:42 - INFO :       Use random pruner...
2023-12-01 16:35:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:35:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:35:43 - INFO :       Start Pruning
2023-12-01 16:35:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:35:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:35:44 - INFO :       hinglish_toxicity: Total Sparsity 1.36177804165728e-06
2023-12-01 16:35:44 - INFO :       
==================Finish================

2023-12-01 16:35:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:35:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:35:44 - INFO :       DATASET: tasksource/bigbench human_organs_senses
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]
2023-12-01 16:35:53 - INFO :       Use random pruner...
2023-12-01 16:35:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:35:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:35:54 - INFO :       Start Pruning
2023-12-01 16:35:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:35:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:35:55 - INFO :       human_organs_senses: Total Sparsity 1.3517299706702942e-06
2023-12-01 16:35:55 - INFO :       
==================Finish================

2023-12-01 16:35:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:35:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:35:55 - INFO :       DATASET: tasksource/bigbench hyperbaton
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]
2023-12-01 16:36:05 - INFO :       Use random pruner...
2023-12-01 16:36:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:36:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:36:06 - INFO :       Start Pruning
2023-12-01 16:36:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:36:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:36:07 - INFO :       hyperbaton: Total Sparsity 1.3608966319215796e-06
2023-12-01 16:36:07 - INFO :       
==================Finish================

2023-12-01 16:36:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:36:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:36:07 - INFO :       DATASET: tasksource/bigbench identify_math_theorems
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]
2023-12-01 16:36:16 - INFO :       Use random pruner...
2023-12-01 16:36:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:36:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:36:17 - INFO :       Start Pruning
2023-12-01 16:36:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:36:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:36:18 - INFO :       identify_math_theorems: Total Sparsity 1.3520825345645745e-06
2023-12-01 16:36:18 - INFO :       
==================Finish================

2023-12-01 16:36:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:36:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:36:18 - INFO :       DATASET: tasksource/bigbench identify_odd_metaphor
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]
2023-12-01 16:36:28 - INFO :       Use random pruner...
2023-12-01 16:36:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:36:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:36:28 - INFO :       Start Pruning
2023-12-01 16:36:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:36:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:36:30 - INFO :       identify_odd_metaphor: Total Sparsity 1.368829319542884e-06
2023-12-01 16:36:30 - INFO :       
==================Finish================

2023-12-01 16:36:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:36:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:36:30 - INFO :       DATASET: tasksource/bigbench implicatures
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2023-12-01 16:36:39 - INFO :       Use random pruner...
2023-12-01 16:36:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:36:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:36:39 - INFO :       Start Pruning
2023-12-01 16:36:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:36:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:36:41 - INFO :       implicatures: Total Sparsity 1.358252402714478e-06
2023-12-01 16:36:41 - INFO :       
==================Finish================

2023-12-01 16:36:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:36:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:36:41 - INFO :       DATASET: tasksource/bigbench implicit_relations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]
2023-12-01 16:36:50 - INFO :       Use random pruner...
2023-12-01 16:36:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:36:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:36:51 - INFO :       Start Pruning
2023-12-01 16:36:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:36:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:36:53 - INFO :       implicit_relations: Total Sparsity 1.3621306055515601e-06
2023-12-01 16:36:53 - INFO :       
==================Finish================

2023-12-01 16:36:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:36:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:36:53 - INFO :       DATASET: tasksource/bigbench indic_cause_and_effect
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2023-12-01 16:37:02 - INFO :       Use random pruner...
2023-12-01 16:37:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:37:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:37:02 - INFO :       Start Pruning
2023-12-01 16:37:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:37:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:37:04 - INFO :       indic_cause_and_effect: Total Sparsity 1.3640697069701013e-06
2023-12-01 16:37:04 - INFO :       
==================Finish================

2023-12-01 16:37:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:37:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:37:04 - INFO :       DATASET: tasksource/bigbench intent_recognition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
2023-12-01 16:37:12 - INFO :       Use random pruner...
2023-12-01 16:37:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:37:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:37:13 - INFO :       Start Pruning
2023-12-01 16:37:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:37:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:37:14 - INFO :       intent_recognition: Total Sparsity 1.363540861128681e-06
2023-12-01 16:37:14 - INFO :       
==================Finish================

2023-12-01 16:37:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:37:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:37:14 - INFO :       DATASET: tasksource/bigbench international_phonetic_alphabet_nli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]
2023-12-01 16:37:23 - INFO :       Use random pruner...
2023-12-01 16:37:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:37:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:37:24 - INFO :       Start Pruning
2023-12-01 16:37:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:37:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:37:25 - INFO :       international_phonetic_alphabet_nli: Total Sparsity 1.3610729138687196e-06
2023-12-01 16:37:25 - INFO :       
==================Finish================

2023-12-01 16:37:25 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:37:25 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:37:25 - INFO :       DATASET: tasksource/bigbench intersect_geometry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]
2023-12-01 16:37:34 - INFO :       Use random pruner...
2023-12-01 16:37:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:37:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:37:35 - INFO :       Start Pruning
2023-12-01 16:37:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:37:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:37:37 - INFO :       intersect_geometry: Total Sparsity 1.3510248428817337e-06
2023-12-01 16:37:37 - INFO :       
==================Finish================

2023-12-01 16:37:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:37:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:37:37 - INFO :       DATASET: tasksource/bigbench irony_identification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  3.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 16:37:47 - INFO :       Use random pruner...
2023-12-01 16:37:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:37:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:37:47 - INFO :       Start Pruning
2023-12-01 16:37:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:37:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:37:49 - INFO :       irony_identification: Total Sparsity 1.356313301295937e-06
2023-12-01 16:37:49 - INFO :       
==================Finish================

2023-12-01 16:37:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:37:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:37:49 - INFO :       DATASET: tasksource/bigbench kannada
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]
2023-12-01 16:37:59 - INFO :       Use random pruner...
2023-12-01 16:37:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:37:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:37:59 - INFO :       Start Pruning
2023-12-01 16:38:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:38:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:38:01 - INFO :       kannada: Total Sparsity 1.3586049666087581e-06
2023-12-01 16:38:01 - INFO :       
==================Finish================

2023-12-01 16:38:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:38:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:38:01 - INFO :       DATASET: tasksource/bigbench key_value_maps
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 16:38:10 - INFO :       Use random pruner...
2023-12-01 16:38:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:38:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:38:10 - INFO :       Start Pruning
2023-12-01 16:38:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:38:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:38:12 - INFO :       key_value_maps: Total Sparsity 1.3577235568730577e-06
2023-12-01 16:38:12 - INFO :       
==================Finish================

2023-12-01 16:38:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:38:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:38:12 - INFO :       DATASET: tasksource/bigbench known_unknowns
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]
2023-12-01 16:38:22 - INFO :       Use random pruner...
2023-12-01 16:38:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:38:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:38:22 - INFO :       Start Pruning
2023-12-01 16:38:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:38:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:38:24 - INFO :       known_unknowns: Total Sparsity 1.3550793276659562e-06
2023-12-01 16:38:24 - INFO :       
==================Finish================

2023-12-01 16:38:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:38:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:38:24 - INFO :       DATASET: tasksource/bigbench language_identification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2023-12-01 16:38:33 - INFO :       Use random pruner...
2023-12-01 16:38:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:38:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:38:33 - INFO :       Start Pruning
2023-12-01 16:38:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:38:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:38:35 - INFO :       language_identification: Total Sparsity 1.3610729138687196e-06
2023-12-01 16:38:35 - INFO :       
==================Finish================

2023-12-01 16:38:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:38:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:38:35 - INFO :       DATASET: tasksource/bigbench logic_grid_puzzle
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2023-12-01 16:38:44 - INFO :       Use random pruner...
2023-12-01 16:38:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:38:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:38:44 - INFO :       Start Pruning
2023-12-01 16:38:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:38:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:38:46 - INFO :       logic_grid_puzzle: Total Sparsity 1.3561370193487967e-06
2023-12-01 16:38:46 - INFO :       
==================Finish================

2023-12-01 16:38:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:38:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:38:46 - INFO :       DATASET: tasksource/bigbench logical_args
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 16:38:54 - INFO :       Use random pruner...
2023-12-01 16:38:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:38:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:38:55 - INFO :       Start Pruning
2023-12-01 16:38:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:38:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:38:56 - INFO :       logical_args: Total Sparsity 1.3633645791815409e-06
2023-12-01 16:38:56 - INFO :       
==================Finish================

2023-12-01 16:38:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:38:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:38:56 - INFO :       DATASET: tasksource/bigbench logical_deduction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 16:39:06 - INFO :       Use random pruner...
2023-12-01 16:39:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:39:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:39:06 - INFO :       Start Pruning
2023-12-01 16:39:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:39:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:39:08 - INFO :       logical_deduction: Total Sparsity 1.3711209848557053e-06
2023-12-01 16:39:08 - INFO :       
==================Finish================

2023-12-01 16:39:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:39:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:39:08 - INFO :       DATASET: tasksource/bigbench logical_fallacy_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]
2023-12-01 16:39:17 - INFO :       Use random pruner...
2023-12-01 16:39:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:39:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:39:18 - INFO :       Start Pruning
2023-12-01 16:39:19 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:39:19 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:39:20 - INFO :       logical_fallacy_detection: Total Sparsity 1.3660088083886423e-06
2023-12-01 16:39:20 - INFO :       
==================Finish================

2023-12-01 16:39:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:39:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:39:20 - INFO :       DATASET: tasksource/bigbench logical_sequence
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]
2023-12-01 16:39:29 - INFO :       Use random pruner...
2023-12-01 16:39:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:39:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:39:29 - INFO :       Start Pruning
2023-12-01 16:39:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:39:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:39:31 - INFO :       logical_sequence: Total Sparsity 1.3607203499744394e-06
2023-12-01 16:39:31 - INFO :       
==================Finish================

2023-12-01 16:39:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:39:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:39:31 - INFO :       DATASET: tasksource/bigbench mathematical_induction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]
2023-12-01 16:39:41 - INFO :       Use random pruner...
2023-12-01 16:39:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:39:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:39:41 - INFO :       Start Pruning
2023-12-01 16:39:42 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:39:42 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:39:43 - INFO :       mathematical_induction: Total Sparsity 1.3667139361772028e-06
2023-12-01 16:39:43 - INFO :       
==================Finish================

2023-12-01 16:39:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:39:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:39:43 - INFO :       DATASET: tasksource/bigbench medical_questions_russian
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2023-12-01 16:39:52 - INFO :       Use random pruner...
2023-12-01 16:39:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:39:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:39:53 - INFO :       Start Pruning
2023-12-01 16:39:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:39:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:39:54 - INFO :       medical_questions_russian: Total Sparsity 1.3621306055515601e-06
2023-12-01 16:39:54 - INFO :       
==================Finish================

2023-12-01 16:39:54 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:39:54 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:39:54 - INFO :       DATASET: tasksource/bigbench metaphor_boolean
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2023-12-01 16:40:04 - INFO :       Use random pruner...
2023-12-01 16:40:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:40:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:40:04 - INFO :       Start Pruning
2023-12-01 16:40:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:40:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:40:06 - INFO :       metaphor_boolean: Total Sparsity 1.363717143075821e-06
2023-12-01 16:40:06 - INFO :       
==================Finish================

2023-12-01 16:40:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:40:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:40:06 - INFO :       DATASET: tasksource/bigbench metaphor_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2023-12-01 16:40:16 - INFO :       Use random pruner...
2023-12-01 16:40:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:40:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:40:16 - INFO :       Start Pruning
2023-12-01 16:40:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:40:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:40:18 - INFO :       metaphor_understanding: Total Sparsity 1.3568421471373572e-06
2023-12-01 16:40:18 - INFO :       
==================Finish================

2023-12-01 16:40:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:40:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:40:18 - INFO :       DATASET: tasksource/bigbench misconceptions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2023-12-01 16:40:26 - INFO :       Use random pruner...
2023-12-01 16:40:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:40:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:40:26 - INFO :       Start Pruning
2023-12-01 16:40:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:40:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:40:28 - INFO :       misconceptions: Total Sparsity 1.3698870112257248e-06
2023-12-01 16:40:28 - INFO :       
==================Finish================

2023-12-01 16:40:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:40:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:40:28 - INFO :       DATASET: tasksource/bigbench misconceptions_russian
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2023-12-01 16:40:38 - INFO :       Use random pruner...
2023-12-01 16:40:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:40:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:40:38 - INFO :       Start Pruning
2023-12-01 16:40:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:40:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:40:40 - INFO :       misconceptions_russian: Total Sparsity 1.3610729138687196e-06
2023-12-01 16:40:40 - INFO :       
==================Finish================

2023-12-01 16:40:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:40:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:40:40 - INFO :       DATASET: tasksource/bigbench mnist_ascii
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]
2023-12-01 16:40:50 - INFO :       Use random pruner...
2023-12-01 16:40:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:40:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:40:50 - INFO :       Start Pruning
2023-12-01 16:40:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:40:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:40:52 - INFO :       mnist_ascii: Total Sparsity 1.3674190639657633e-06
2023-12-01 16:40:52 - INFO :       
==================Finish================

2023-12-01 16:40:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:40:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:40:52 - INFO :       DATASET: tasksource/bigbench moral_permissibility
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 16:41:03 - INFO :       Use random pruner...
2023-12-01 16:41:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:41:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:41:03 - INFO :       Start Pruning
2023-12-01 16:41:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:41:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:41:05 - INFO :       moral_permissibility: Total Sparsity 1.3633645791815409e-06
2023-12-01 16:41:05 - INFO :       
==================Finish================

2023-12-01 16:41:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:41:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:41:05 - INFO :       DATASET: tasksource/bigbench movie_dialog_same_or_different
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 16:41:14 - INFO :       Use random pruner...
2023-12-01 16:41:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:41:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:41:14 - INFO :       Start Pruning
2023-12-01 16:41:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:41:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:41:16 - INFO :       movie_dialog_same_or_different: Total Sparsity 1.3594863763444586e-06
2023-12-01 16:41:16 - INFO :       
==================Finish================

2023-12-01 16:41:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:41:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:41:16 - INFO :       DATASET: tasksource/bigbench movie_recommendation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]
2023-12-01 16:41:26 - INFO :       Use random pruner...
2023-12-01 16:41:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:41:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:41:26 - INFO :       Start Pruning
2023-12-01 16:41:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:41:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:41:28 - INFO :       movie_recommendation: Total Sparsity 1.3538453540359754e-06
2023-12-01 16:41:28 - INFO :       
==================Finish================

2023-12-01 16:41:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:41:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:41:28 - INFO :       DATASET: tasksource/bigbench navigate
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 16:41:38 - INFO :       Use random pruner...
2023-12-01 16:41:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:41:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:41:38 - INFO :       Start Pruning
2023-12-01 16:41:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:41:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:41:40 - INFO :       navigate: Total Sparsity 1.367242782018623e-06
2023-12-01 16:41:40 - INFO :       
==================Finish================

2023-12-01 16:41:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:41:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:41:40 - INFO :       DATASET: tasksource/bigbench nonsense_words_grammar
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]
2023-12-01 16:41:49 - INFO :       Use random pruner...
2023-12-01 16:41:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:41:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:41:50 - INFO :       Start Pruning
2023-12-01 16:41:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:41:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:41:51 - INFO :       nonsense_words_grammar: Total Sparsity 1.3616017597101399e-06
2023-12-01 16:41:52 - INFO :       
==================Finish================

2023-12-01 16:41:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:41:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:41:52 - INFO :       DATASET: tasksource/bigbench novel_concepts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2023-12-01 16:42:01 - INFO :       Use random pruner...
2023-12-01 16:42:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:42:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:42:01 - INFO :       Start Pruning
2023-12-01 16:42:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:42:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:42:03 - INFO :       novel_concepts: Total Sparsity 1.3593100943973186e-06
2023-12-01 16:42:03 - INFO :       
==================Finish================

2023-12-01 16:42:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:42:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:42:03 - INFO :       DATASET: tasksource/bigbench odd_one_out
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]
2023-12-01 16:42:11 - INFO :       Use random pruner...
2023-12-01 16:42:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:42:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:42:11 - INFO :       Start Pruning
2023-12-01 16:42:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:42:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:42:13 - INFO :       odd_one_out: Total Sparsity 1.366890218124343e-06
2023-12-01 16:42:13 - INFO :       
==================Finish================

2023-12-01 16:42:13 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:42:13 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:42:13 - INFO :       DATASET: tasksource/bigbench parsinlu_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2023-12-01 16:42:23 - INFO :       Use random pruner...
2023-12-01 16:42:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:42:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:42:23 - INFO :       Start Pruning
2023-12-01 16:42:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:42:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:42:25 - INFO :       parsinlu_qa: Total Sparsity 1.3707684209614252e-06
2023-12-01 16:42:25 - INFO :       
==================Finish================

2023-12-01 16:42:25 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:42:25 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:42:25 - INFO :       DATASET: tasksource/bigbench penguins_in_a_table
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2023-12-01 16:42:34 - INFO :       Use random pruner...
2023-12-01 16:42:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:42:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:42:35 - INFO :       Start Pruning
2023-12-01 16:42:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:42:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:42:36 - INFO :       penguins_in_a_table: Total Sparsity 1.3667139361772028e-06
2023-12-01 16:42:36 - INFO :       
==================Finish================

2023-12-01 16:42:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:42:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:42:36 - INFO :       DATASET: tasksource/bigbench persian_idioms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.49s/it]
2023-12-01 16:42:46 - INFO :       Use random pruner...
2023-12-01 16:42:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:42:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:42:46 - INFO :       Start Pruning
2023-12-01 16:42:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:42:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:42:48 - INFO :       persian_idioms: Total Sparsity 1.3614254777629999e-06
2023-12-01 16:42:48 - INFO :       
==================Finish================

2023-12-01 16:42:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:42:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:42:48 - INFO :       DATASET: tasksource/bigbench phrase_relatedness
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]
2023-12-01 16:42:57 - INFO :       Use random pruner...
2023-12-01 16:42:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:42:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:42:57 - INFO :       Start Pruning
2023-12-01 16:42:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:42:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:42:59 - INFO :       phrase_relatedness: Total Sparsity 1.3610729138687196e-06
2023-12-01 16:42:59 - INFO :       
==================Finish================

2023-12-01 16:42:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:42:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:42:59 - INFO :       DATASET: tasksource/bigbench physical_intuition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]
2023-12-01 16:43:08 - INFO :       Use random pruner...
2023-12-01 16:43:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:43:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:43:08 - INFO :       Start Pruning
2023-12-01 16:43:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:43:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:43:10 - INFO :       physical_intuition: Total Sparsity 1.3677716278600435e-06
2023-12-01 16:43:10 - INFO :       
==================Finish================

2023-12-01 16:43:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:43:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:43:10 - INFO :       DATASET: tasksource/bigbench physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]
2023-12-01 16:43:19 - INFO :       Use random pruner...
2023-12-01 16:43:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:43:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:43:20 - INFO :       Start Pruning
2023-12-01 16:43:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:43:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:43:21 - INFO :       physics: Total Sparsity 1.368653037595744e-06
2023-12-01 16:43:21 - INFO :       
==================Finish================

2023-12-01 16:43:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:43:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:43:21 - INFO :       DATASET: tasksource/bigbench play_dialog_same_or_different
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.28s/it]
2023-12-01 16:43:33 - INFO :       Use random pruner...
2023-12-01 16:43:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:43:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:43:34 - INFO :       Start Pruning
2023-12-01 16:43:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:43:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:43:36 - INFO :       play_dialog_same_or_different: Total Sparsity 1.3707684209614252e-06
2023-12-01 16:43:36 - INFO :       
==================Finish================

2023-12-01 16:43:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:43:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:43:36 - INFO :       DATASET: tasksource/bigbench presuppositions_as_nli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]
2023-12-01 16:43:47 - INFO :       Use random pruner...
2023-12-01 16:43:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:43:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:43:47 - INFO :       Start Pruning
2023-12-01 16:43:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:43:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:43:49 - INFO :       presuppositions_as_nli: Total Sparsity 1.3720023945914058e-06
2023-12-01 16:43:49 - INFO :       
==================Finish================

2023-12-01 16:43:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:43:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:43:49 - INFO :       DATASET: tasksource/bigbench question_selection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2023-12-01 16:44:00 - INFO :       Use random pruner...
2023-12-01 16:44:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:44:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:44:01 - INFO :       Start Pruning
2023-12-01 16:44:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:44:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:44:02 - INFO :       question_selection: Total Sparsity 1.3503197150931735e-06
2023-12-01 16:44:02 - INFO :       
==================Finish================

2023-12-01 16:44:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:44:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:44:02 - INFO :       DATASET: tasksource/bigbench reasoning_about_colored_objects
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.49s/it]
2023-12-01 16:44:12 - INFO :       Use random pruner...
2023-12-01 16:44:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:44:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:44:12 - INFO :       Start Pruning
2023-12-01 16:44:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:44:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:44:14 - INFO :       reasoning_about_colored_objects: Total Sparsity 1.3677716278600435e-06
2023-12-01 16:44:14 - INFO :       
==================Finish================

2023-12-01 16:44:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:44:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:44:14 - INFO :       DATASET: tasksource/bigbench riddle_sense
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2023-12-01 16:44:24 - INFO :       Use random pruner...
2023-12-01 16:44:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:44:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:44:24 - INFO :       Start Pruning
2023-12-01 16:44:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:44:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:44:26 - INFO :       riddle_sense: Total Sparsity 1.3665376542300628e-06
2023-12-01 16:44:26 - INFO :       
==================Finish================

2023-12-01 16:44:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:44:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:44:26 - INFO :       DATASET: tasksource/bigbench ruin_names
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 16:44:35 - INFO :       Use random pruner...
2023-12-01 16:44:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:44:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:44:36 - INFO :       Start Pruning
2023-12-01 16:44:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:44:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:44:38 - INFO :       ruin_names: Total Sparsity 1.3608966319215796e-06
2023-12-01 16:44:38 - INFO :       
==================Finish================

2023-12-01 16:44:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:44:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:44:38 - INFO :       DATASET: tasksource/bigbench salient_translation_error_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
2023-12-01 16:44:47 - INFO :       Use random pruner...
2023-12-01 16:44:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:44:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:44:47 - INFO :       Start Pruning
2023-12-01 16:44:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:44:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:44:49 - INFO :       salient_translation_error_detection: Total Sparsity 1.3596626582915989e-06
2023-12-01 16:44:49 - INFO :       
==================Finish================

2023-12-01 16:44:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:44:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:44:49 - INFO :       DATASET: tasksource/bigbench sentence_ambiguity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]
2023-12-01 16:44:58 - INFO :       Use random pruner...
2023-12-01 16:44:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:44:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:44:58 - INFO :       Start Pruning
2023-12-01 16:44:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:44:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:45:00 - INFO :       sentence_ambiguity: Total Sparsity 1.3619543236044201e-06
2023-12-01 16:45:00 - INFO :       
==================Finish================

2023-12-01 16:45:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:45:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:45:00 - INFO :       DATASET: tasksource/bigbench similarities_abstraction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 16:45:07 - INFO :       Use random pruner...
2023-12-01 16:45:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:45:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:45:08 - INFO :       Start Pruning
2023-12-01 16:45:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:45:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:45:09 - INFO :       similarities_abstraction: Total Sparsity 1.367242782018623e-06
2023-12-01 16:45:09 - INFO :       
==================Finish================

2023-12-01 16:45:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:45:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:45:09 - INFO :       DATASET: tasksource/bigbench simple_ethical_questions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 16:45:19 - INFO :       Use random pruner...
2023-12-01 16:45:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:45:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:45:20 - INFO :       Start Pruning
2023-12-01 16:45:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:45:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:45:21 - INFO :       simple_ethical_questions: Total Sparsity 1.3619543236044201e-06
2023-12-01 16:45:21 - INFO :       
==================Finish================

2023-12-01 16:45:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:45:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:45:21 - INFO :       DATASET: tasksource/bigbench snarks
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]
2023-12-01 16:45:31 - INFO :       Use random pruner...
2023-12-01 16:45:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:45:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:45:32 - INFO :       Start Pruning
2023-12-01 16:45:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:45:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:45:33 - INFO :       snarks: Total Sparsity 1.365303680600082e-06
2023-12-01 16:45:33 - INFO :       
==================Finish================

2023-12-01 16:45:33 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:45:33 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:45:33 - INFO :       DATASET: tasksource/bigbench social_iqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.23s/it]
2023-12-01 16:45:45 - INFO :       Use random pruner...
2023-12-01 16:45:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:45:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:45:45 - INFO :       Start Pruning
2023-12-01 16:45:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:45:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:45:47 - INFO :       social_iqa: Total Sparsity 1.366890218124343e-06
2023-12-01 16:45:47 - INFO :       
==================Finish================

2023-12-01 16:45:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:45:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:45:47 - INFO :       DATASET: tasksource/bigbench social_support
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.31s/it]
2023-12-01 16:45:59 - INFO :       Use random pruner...
2023-12-01 16:45:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:45:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:45:59 - INFO :       Start Pruning
2023-12-01 16:46:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:46:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:46:01 - INFO :       social_support: Total Sparsity 1.3591338124501784e-06
2023-12-01 16:46:01 - INFO :       
==================Finish================

2023-12-01 16:46:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:46:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:46:01 - INFO :       DATASET: tasksource/bigbench sports_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.28s/it]
2023-12-01 16:46:13 - INFO :       Use random pruner...
2023-12-01 16:46:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:46:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:46:13 - INFO :       Start Pruning
2023-12-01 16:46:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:46:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:46:15 - INFO :       sports_understanding: Total Sparsity 1.3626594513929806e-06
2023-12-01 16:46:15 - INFO :       
==================Finish================

2023-12-01 16:46:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:46:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:46:15 - INFO :       DATASET: tasksource/bigbench strange_stories
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.21s/it]
2023-12-01 16:46:26 - INFO :       Use random pruner...
2023-12-01 16:46:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:46:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:46:27 - INFO :       Start Pruning
2023-12-01 16:46:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:46:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:46:29 - INFO :       strange_stories: Total Sparsity 1.3645985528115216e-06
2023-12-01 16:46:29 - INFO :       
==================Finish================

2023-12-01 16:46:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:46:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:46:29 - INFO :       DATASET: tasksource/bigbench strategyqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.27s/it]
2023-12-01 16:46:41 - INFO :       Use random pruner...
2023-12-01 16:46:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:46:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:46:41 - INFO :       Start Pruning
2023-12-01 16:46:42 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:46:42 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:46:43 - INFO :       strategyqa: Total Sparsity 1.3614254777629999e-06
2023-12-01 16:46:43 - INFO :       
==================Finish================

2023-12-01 16:46:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:46:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:46:43 - INFO :       DATASET: tasksource/bigbench suicide_risk
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]
2023-12-01 16:46:54 - INFO :       Use random pruner...
2023-12-01 16:46:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:46:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:46:54 - INFO :       Start Pruning
2023-12-01 16:46:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:46:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:46:56 - INFO :       suicide_risk: Total Sparsity 1.3490857414631927e-06
2023-12-01 16:46:56 - INFO :       
==================Finish================

2023-12-01 16:46:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:46:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:46:56 - INFO :       DATASET: tasksource/bigbench swahili_english_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 16:47:07 - INFO :       Use random pruner...
2023-12-01 16:47:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:47:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:47:08 - INFO :       Start Pruning
2023-12-01 16:47:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:47:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:47:10 - INFO :       swahili_english_proverbs: Total Sparsity 1.3596626582915989e-06
2023-12-01 16:47:10 - INFO :       
==================Finish================

2023-12-01 16:47:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:47:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:47:10 - INFO :       DATASET: tasksource/bigbench swedish_to_german_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.29s/it]
2023-12-01 16:47:21 - INFO :       Use random pruner...
2023-12-01 16:47:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:47:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:47:22 - INFO :       Start Pruning
2023-12-01 16:47:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:47:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:47:24 - INFO :       swedish_to_german_proverbs: Total Sparsity 1.3624831694458404e-06
2023-12-01 16:47:24 - INFO :       
==================Finish================

2023-12-01 16:47:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:47:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:47:24 - INFO :       DATASET: tasksource/bigbench symbol_interpretation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 16:47:35 - INFO :       Use random pruner...
2023-12-01 16:47:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:47:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:47:35 - INFO :       Start Pruning
2023-12-01 16:47:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:47:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:47:37 - INFO :       symbol_interpretation: Total Sparsity 1.3610729138687196e-06
2023-12-01 16:47:37 - INFO :       
==================Finish================

2023-12-01 16:47:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:47:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:47:37 - INFO :       DATASET: tasksource/bigbench temporal_sequences
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.33s/it]
2023-12-01 16:47:48 - INFO :       Use random pruner...
2023-12-01 16:47:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:47:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:47:49 - INFO :       Start Pruning
2023-12-01 16:47:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:47:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:47:50 - INFO :       temporal_sequences: Total Sparsity 1.3623068874987003e-06
2023-12-01 16:47:50 - INFO :       
==================Finish================

2023-12-01 16:47:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:47:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:47:50 - INFO :       DATASET: tasksource/bigbench timedial
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 16:48:01 - INFO :       Use random pruner...
2023-12-01 16:48:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:48:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:48:01 - INFO :       Start Pruning
2023-12-01 16:48:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:48:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:48:03 - INFO :       timedial: Total Sparsity 1.370415857067145e-06
2023-12-01 16:48:03 - INFO :       
==================Finish================

2023-12-01 16:48:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:48:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:48:03 - INFO :       DATASET: tasksource/bigbench tracking_shuffled_objects
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]
2023-12-01 16:48:12 - INFO :       Use random pruner...
2023-12-01 16:48:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:48:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:48:12 - INFO :       Start Pruning
2023-12-01 16:48:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:48:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:48:14 - INFO :       tracking_shuffled_objects: Total Sparsity 1.3661850903357826e-06
2023-12-01 16:48:14 - INFO :       
==================Finish================

2023-12-01 16:48:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:48:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:48:14 - INFO :       DATASET: tasksource/bigbench understanding_fables
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]
2023-12-01 16:48:23 - INFO :       Use random pruner...
2023-12-01 16:48:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:48:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:48:23 - INFO :       Start Pruning
2023-12-01 16:48:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:48:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:48:25 - INFO :       understanding_fables: Total Sparsity 1.3621306055515601e-06
2023-12-01 16:48:25 - INFO :       
==================Finish================

2023-12-01 16:48:25 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:48:25 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:48:25 - INFO :       DATASET: tasksource/bigbench undo_permutation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
2023-12-01 16:48:35 - INFO :       Use random pruner...
2023-12-01 16:48:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:48:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:48:35 - INFO :       Start Pruning
2023-12-01 16:48:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:48:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:48:37 - INFO :       undo_permutation: Total Sparsity 1.3658325264415023e-06
2023-12-01 16:48:37 - INFO :       
==================Finish================

2023-12-01 16:48:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:48:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:48:37 - INFO :       DATASET: tasksource/bigbench unit_interpretation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]
2023-12-01 16:48:45 - INFO :       Use random pruner...
2023-12-01 16:48:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:48:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:48:46 - INFO :       Start Pruning
2023-12-01 16:48:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:48:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:48:47 - INFO :       unit_interpretation: Total Sparsity 1.3506722789874537e-06
2023-12-01 16:48:47 - INFO :       
==================Finish================

2023-12-01 16:48:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:48:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:48:47 - INFO :       DATASET: tasksource/bigbench vitaminc_fact_verification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2023-12-01 16:48:56 - INFO :       Use random pruner...
2023-12-01 16:48:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:48:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:48:56 - INFO :       Start Pruning
2023-12-01 16:48:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:48:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:48:58 - INFO :       vitaminc_fact_verification: Total Sparsity 1.365303680600082e-06
2023-12-01 16:48:58 - INFO :       
==================Finish================

2023-12-01 16:48:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:48:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:48:58 - INFO :       DATASET: tasksource/bigbench what_is_the_tao
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2023-12-01 16:49:08 - INFO :       Use random pruner...
2023-12-01 16:49:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:49:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:49:09 - INFO :       Start Pruning
2023-12-01 16:49:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:49:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:49:10 - INFO :       what_is_the_tao: Total Sparsity 1.369005601490024e-06
2023-12-01 16:49:10 - INFO :       
==================Finish================

2023-12-01 16:49:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:49:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:49:10 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 16:49:20 - INFO :       Use random pruner...
2023-12-01 16:49:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:49:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:49:21 - INFO :       Start Pruning
2023-12-01 16:49:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:49:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:49:23 - INFO :       which_wiki_edit: Total Sparsity 1.3711209848557053e-06
2023-12-01 16:49:23 - INFO :       
==================Finish================

2023-12-01 16:49:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:49:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:49:23 - INFO :       DATASET: tasksource/bigbench winowhy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2023-12-01 16:49:32 - INFO :       Use random pruner...
2023-12-01 16:49:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:49:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:49:32 - INFO :       Start Pruning
2023-12-01 16:49:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:49:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:49:34 - INFO :       winowhy: Total Sparsity 1.3667139361772028e-06
2023-12-01 16:49:34 - INFO :       
==================Finish================

2023-12-01 16:49:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:49:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:49:34 - INFO :       DATASET: tasksource/mmlu abstract_algebra
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2023-12-01 16:49:43 - INFO :       Use random pruner...
2023-12-01 16:49:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:49:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:49:44 - INFO :       Start Pruning
2023-12-01 16:49:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:49:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:49:45 - INFO :       abstract_algebra: Total Sparsity 1.3608966319215796e-06
2023-12-01 16:49:45 - INFO :       
==================Finish================

2023-12-01 16:49:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:49:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:49:45 - INFO :       DATASET: tasksource/mmlu anatomy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 16:49:55 - INFO :       Use random pruner...
2023-12-01 16:49:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:49:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:49:55 - INFO :       Start Pruning
2023-12-01 16:49:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:49:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:49:57 - INFO :       anatomy: Total Sparsity 1.3697107292785845e-06
2023-12-01 16:49:57 - INFO :       
==================Finish================

2023-12-01 16:49:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:49:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:49:57 - INFO :       DATASET: tasksource/mmlu astronomy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 16:50:07 - INFO :       Use random pruner...
2023-12-01 16:50:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:50:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:50:08 - INFO :       Start Pruning
2023-12-01 16:50:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:50:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:50:09 - INFO :       astronomy: Total Sparsity 1.354726763771676e-06
2023-12-01 16:50:09 - INFO :       
==================Finish================

2023-12-01 16:50:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:50:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:50:09 - INFO :       DATASET: tasksource/mmlu business_ethics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.23s/it]
2023-12-01 16:50:21 - INFO :       Use random pruner...
2023-12-01 16:50:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:50:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:50:21 - INFO :       Start Pruning
2023-12-01 16:50:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:50:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:50:23 - INFO :       business_ethics: Total Sparsity 1.3656562444943623e-06
2023-12-01 16:50:23 - INFO :       
==================Finish================

2023-12-01 16:50:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:50:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:50:23 - INFO :       DATASET: tasksource/mmlu clinical_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 16:50:33 - INFO :       Use random pruner...
2023-12-01 16:50:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:50:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:50:33 - INFO :       Start Pruning
2023-12-01 16:50:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:50:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:50:35 - INFO :       clinical_knowledge: Total Sparsity 1.36177804165728e-06
2023-12-01 16:50:35 - INFO :       
==================Finish================

2023-12-01 16:50:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:50:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:50:35 - INFO :       DATASET: tasksource/mmlu college_biology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 16:50:46 - INFO :       Use random pruner...
2023-12-01 16:50:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:50:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:50:46 - INFO :       Start Pruning
2023-12-01 16:50:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:50:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:50:48 - INFO :       college_biology: Total Sparsity 1.3660088083886423e-06
2023-12-01 16:50:48 - INFO :       
==================Finish================

2023-12-01 16:50:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:50:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:50:48 - INFO :       DATASET: tasksource/mmlu college_chemistry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2023-12-01 16:50:58 - INFO :       Use random pruner...
2023-12-01 16:50:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:50:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:50:58 - INFO :       Start Pruning
2023-12-01 16:50:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:50:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:51:00 - INFO :       college_chemistry: Total Sparsity 1.3674190639657633e-06
2023-12-01 16:51:00 - INFO :       
==================Finish================

2023-12-01 16:51:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:51:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:51:00 - INFO :       DATASET: tasksource/mmlu college_computer_science
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2023-12-01 16:51:10 - INFO :       Use random pruner...
2023-12-01 16:51:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:51:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:51:10 - INFO :       Start Pruning
2023-12-01 16:51:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:51:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:51:12 - INFO :       college_computer_science: Total Sparsity 1.3667139361772028e-06
2023-12-01 16:51:12 - INFO :       
==================Finish================

2023-12-01 16:51:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:51:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:51:12 - INFO :       DATASET: tasksource/mmlu college_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]
2023-12-01 16:51:23 - INFO :       Use random pruner...
2023-12-01 16:51:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:51:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:51:23 - INFO :       Start Pruning
2023-12-01 16:51:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:51:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:51:25 - INFO :       college_mathematics: Total Sparsity 1.3623068874987003e-06
2023-12-01 16:51:25 - INFO :       
==================Finish================

2023-12-01 16:51:25 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:51:25 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:51:25 - INFO :       DATASET: tasksource/mmlu college_medicine
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2023-12-01 16:51:34 - INFO :       Use random pruner...
2023-12-01 16:51:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:51:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:51:35 - INFO :       Start Pruning
2023-12-01 16:51:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:51:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:51:36 - INFO :       college_medicine: Total Sparsity 1.3543741998773957e-06
2023-12-01 16:51:36 - INFO :       
==================Finish================

2023-12-01 16:51:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:51:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:51:36 - INFO :       DATASET: tasksource/mmlu college_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]
2023-12-01 16:51:46 - INFO :       Use random pruner...
2023-12-01 16:51:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:51:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:51:46 - INFO :       Start Pruning
2023-12-01 16:51:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:51:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:51:48 - INFO :       college_physics: Total Sparsity 1.358252402714478e-06
2023-12-01 16:51:48 - INFO :       
==================Finish================

2023-12-01 16:51:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:51:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:51:48 - INFO :       DATASET: tasksource/mmlu computer_security
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]
2023-12-01 16:51:58 - INFO :       Use random pruner...
2023-12-01 16:51:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:51:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:51:58 - INFO :       Start Pruning
2023-12-01 16:51:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:51:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:52:00 - INFO :       computer_security: Total Sparsity 1.3497908692517532e-06
2023-12-01 16:52:00 - INFO :       
==================Finish================

2023-12-01 16:52:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:52:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:52:00 - INFO :       DATASET: tasksource/mmlu conceptual_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]
2023-12-01 16:52:09 - INFO :       Use random pruner...
2023-12-01 16:52:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:52:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:52:09 - INFO :       Start Pruning
2023-12-01 16:52:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:52:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:52:11 - INFO :       conceptual_physics: Total Sparsity 1.3610729138687196e-06
2023-12-01 16:52:11 - INFO :       
==================Finish================

2023-12-01 16:52:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:52:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:52:11 - INFO :       DATASET: tasksource/mmlu econometrics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2023-12-01 16:52:21 - INFO :       Use random pruner...
2023-12-01 16:52:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:52:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:52:21 - INFO :       Start Pruning
2023-12-01 16:52:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:52:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:52:23 - INFO :       econometrics: Total Sparsity 1.3612491958158596e-06
2023-12-01 16:52:23 - INFO :       
==================Finish================

2023-12-01 16:52:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:52:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:52:23 - INFO :       DATASET: tasksource/mmlu electrical_engineering
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2023-12-01 16:52:34 - INFO :       Use random pruner...
2023-12-01 16:52:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:52:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:52:34 - INFO :       Start Pruning
2023-12-01 16:52:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:52:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:52:36 - INFO :       electrical_engineering: Total Sparsity 1.356313301295937e-06
2023-12-01 16:52:36 - INFO :       
==================Finish================

2023-12-01 16:52:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:52:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:52:36 - INFO :       DATASET: tasksource/mmlu elementary_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]
2023-12-01 16:52:45 - INFO :       Use random pruner...
2023-12-01 16:52:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:52:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:52:46 - INFO :       Start Pruning
2023-12-01 16:52:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:52:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:52:47 - INFO :       elementary_mathematics: Total Sparsity 1.3649511167058018e-06
2023-12-01 16:52:47 - INFO :       
==================Finish================

2023-12-01 16:52:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:52:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:52:47 - INFO :       DATASET: tasksource/mmlu formal_logic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2023-12-01 16:52:57 - INFO :       Use random pruner...
2023-12-01 16:52:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:52:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:52:57 - INFO :       Start Pruning
2023-12-01 16:52:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:52:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:52:59 - INFO :       formal_logic: Total Sparsity 1.3683004737014638e-06
2023-12-01 16:52:59 - INFO :       
==================Finish================

2023-12-01 16:52:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:52:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:52:59 - INFO :       DATASET: tasksource/mmlu global_facts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]
2023-12-01 16:53:08 - INFO :       Use random pruner...
2023-12-01 16:53:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:53:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:53:09 - INFO :       Start Pruning
2023-12-01 16:53:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:53:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:53:10 - INFO :       global_facts: Total Sparsity 1.358076120767338e-06
2023-12-01 16:53:11 - INFO :       
==================Finish================

2023-12-01 16:53:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:53:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:53:11 - INFO :       DATASET: tasksource/mmlu high_school_biology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]
2023-12-01 16:53:20 - INFO :       Use random pruner...
2023-12-01 16:53:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:53:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:53:20 - INFO :       Start Pruning
2023-12-01 16:53:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:53:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:53:22 - INFO :       high_school_biology: Total Sparsity 1.3610729138687196e-06
2023-12-01 16:53:22 - INFO :       
==================Finish================

2023-12-01 16:53:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:53:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:53:22 - INFO :       DATASET: tasksource/mmlu high_school_chemistry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]
2023-12-01 16:53:31 - INFO :       Use random pruner...
2023-12-01 16:53:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:53:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:53:32 - INFO :       Start Pruning
2023-12-01 16:53:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:53:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:53:34 - INFO :       high_school_chemistry: Total Sparsity 1.3543741998773957e-06
2023-12-01 16:53:34 - INFO :       
==================Finish================

2023-12-01 16:53:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:53:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:53:34 - INFO :       DATASET: tasksource/mmlu high_school_computer_science
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
2023-12-01 16:53:44 - INFO :       Use random pruner...
2023-12-01 16:53:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:53:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:53:44 - INFO :       Start Pruning
2023-12-01 16:53:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:53:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:53:46 - INFO :       high_school_computer_science: Total Sparsity 1.3624831694458404e-06
2023-12-01 16:53:46 - INFO :       
==================Finish================

2023-12-01 16:53:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:53:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:53:46 - INFO :       DATASET: tasksource/mmlu high_school_european_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]
2023-12-01 16:53:54 - INFO :       Use random pruner...
2023-12-01 16:53:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:53:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:53:54 - INFO :       Start Pruning
2023-12-01 16:53:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:53:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:53:56 - INFO :       high_school_european_history: Total Sparsity 1.3621306055515601e-06
2023-12-01 16:53:56 - INFO :       
==================Finish================

2023-12-01 16:53:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:53:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:53:56 - INFO :       DATASET: tasksource/mmlu high_school_geography
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  2.00s/it]
2023-12-01 16:54:05 - INFO :       Use random pruner...
2023-12-01 16:54:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:54:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:54:06 - INFO :       Start Pruning
2023-12-01 16:54:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:54:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:54:07 - INFO :       high_school_geography: Total Sparsity 1.3728838043271063e-06
2023-12-01 16:54:07 - INFO :       
==================Finish================

2023-12-01 16:54:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:54:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:54:07 - INFO :       DATASET: tasksource/mmlu high_school_government_and_politics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
2023-12-01 16:54:16 - INFO :       Use random pruner...
2023-12-01 16:54:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:54:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:54:17 - INFO :       Start Pruning
2023-12-01 16:54:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:54:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:54:18 - INFO :       high_school_government_and_politics: Total Sparsity 1.3584286846616181e-06
2023-12-01 16:54:18 - INFO :       
==================Finish================

2023-12-01 16:54:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:54:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:54:18 - INFO :       DATASET: tasksource/mmlu high_school_macroeconomics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 16:54:28 - INFO :       Use random pruner...
2023-12-01 16:54:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:54:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:54:28 - INFO :       Start Pruning
2023-12-01 16:54:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:54:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:54:30 - INFO :       high_school_macroeconomics: Total Sparsity 1.3536690720888354e-06
2023-12-01 16:54:30 - INFO :       
==================Finish================

2023-12-01 16:54:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:54:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:54:30 - INFO :       DATASET: tasksource/mmlu high_school_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 16:54:37 - INFO :       Use random pruner...
2023-12-01 16:54:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:54:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:54:37 - INFO :       Start Pruning
2023-12-01 16:54:38 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:54:38 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:54:39 - INFO :       high_school_mathematics: Total Sparsity 1.3681241917543236e-06
2023-12-01 16:54:39 - INFO :       
==================Finish================

2023-12-01 16:54:39 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:54:39 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:54:39 - INFO :       DATASET: tasksource/mmlu high_school_microeconomics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]
2023-12-01 16:54:48 - INFO :       Use random pruner...
2023-12-01 16:54:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:54:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:54:48 - INFO :       Start Pruning
2023-12-01 16:54:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:54:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:54:50 - INFO :       high_school_microeconomics: Total Sparsity 1.3683004737014638e-06
2023-12-01 16:54:50 - INFO :       
==================Finish================

2023-12-01 16:54:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:54:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:54:50 - INFO :       DATASET: tasksource/mmlu high_school_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2023-12-01 16:54:59 - INFO :       Use random pruner...
2023-12-01 16:54:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:54:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:54:59 - INFO :       Start Pruning
2023-12-01 16:55:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:55:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:55:01 - INFO :       high_school_physics: Total Sparsity 1.3711209848557053e-06
2023-12-01 16:55:01 - INFO :       
==================Finish================

2023-12-01 16:55:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:55:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:55:01 - INFO :       DATASET: tasksource/mmlu high_school_psychology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2023-12-01 16:55:11 - INFO :       Use random pruner...
2023-12-01 16:55:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:55:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:55:12 - INFO :       Start Pruning
2023-12-01 16:55:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:55:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:55:13 - INFO :       high_school_psychology: Total Sparsity 1.3683004737014638e-06
2023-12-01 16:55:13 - INFO :       
==================Finish================

2023-12-01 16:55:13 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:55:13 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:55:13 - INFO :       DATASET: tasksource/mmlu high_school_statistics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
2023-12-01 16:55:22 - INFO :       Use random pruner...
2023-12-01 16:55:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:55:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:55:22 - INFO :       Start Pruning
2023-12-01 16:55:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:55:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:55:24 - INFO :       high_school_statistics: Total Sparsity 1.3623068874987003e-06
2023-12-01 16:55:24 - INFO :       
==================Finish================

2023-12-01 16:55:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:55:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:55:24 - INFO :       DATASET: tasksource/mmlu high_school_us_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
2023-12-01 16:55:34 - INFO :       Use random pruner...
2023-12-01 16:55:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:55:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:55:35 - INFO :       Start Pruning
2023-12-01 16:55:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:55:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:55:37 - INFO :       high_school_us_history: Total Sparsity 1.358076120767338e-06
2023-12-01 16:55:37 - INFO :       
==================Finish================

2023-12-01 16:55:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:55:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:55:37 - INFO :       DATASET: tasksource/mmlu high_school_world_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.49s/it]
2023-12-01 16:55:46 - INFO :       Use random pruner...
2023-12-01 16:55:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:55:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:55:47 - INFO :       Start Pruning
2023-12-01 16:55:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:55:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:55:48 - INFO :       high_school_world_history: Total Sparsity 1.3566658651902172e-06
2023-12-01 16:55:48 - INFO :       
==================Finish================

2023-12-01 16:55:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:55:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:55:48 - INFO :       DATASET: tasksource/mmlu human_aging
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2023-12-01 16:55:58 - INFO :       Use random pruner...
2023-12-01 16:55:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:55:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:55:59 - INFO :       Start Pruning
2023-12-01 16:56:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:56:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:56:00 - INFO :       human_aging: Total Sparsity 1.3616017597101399e-06
2023-12-01 16:56:00 - INFO :       
==================Finish================

2023-12-01 16:56:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:56:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:56:00 - INFO :       DATASET: tasksource/mmlu human_sexuality
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2023-12-01 16:56:11 - INFO :       Use random pruner...
2023-12-01 16:56:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:56:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:56:11 - INFO :       Start Pruning
2023-12-01 16:56:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:56:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:56:13 - INFO :       human_sexuality: Total Sparsity 1.3591338124501784e-06
2023-12-01 16:56:13 - INFO :       
==================Finish================

2023-12-01 16:56:13 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:56:13 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:56:13 - INFO :       DATASET: tasksource/mmlu international_law
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 16:56:22 - INFO :       Use random pruner...
2023-12-01 16:56:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:56:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:56:22 - INFO :       Start Pruning
2023-12-01 16:56:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:56:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:56:24 - INFO :       international_law: Total Sparsity 1.3559607374016567e-06
2023-12-01 16:56:24 - INFO :       
==================Finish================

2023-12-01 16:56:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:56:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:56:24 - INFO :       DATASET: tasksource/mmlu jurisprudence
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2023-12-01 16:56:33 - INFO :       Use random pruner...
2023-12-01 16:56:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:56:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:56:33 - INFO :       Start Pruning
2023-12-01 16:56:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:56:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:56:35 - INFO :       jurisprudence: Total Sparsity 1.3596626582915989e-06
2023-12-01 16:56:35 - INFO :       
==================Finish================

2023-12-01 16:56:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:56:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:56:35 - INFO :       DATASET: tasksource/mmlu logical_fallacies
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.21s/it]
2023-12-01 16:56:45 - INFO :       Use random pruner...
2023-12-01 16:56:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:56:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:56:45 - INFO :       Start Pruning
2023-12-01 16:56:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:56:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:56:47 - INFO :       logical_fallacies: Total Sparsity 1.3603677860801591e-06
2023-12-01 16:56:47 - INFO :       
==================Finish================

2023-12-01 16:56:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:56:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:56:47 - INFO :       DATASET: tasksource/mmlu machine_learning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2023-12-01 16:56:56 - INFO :       Use random pruner...
2023-12-01 16:56:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:56:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:56:57 - INFO :       Start Pruning
2023-12-01 16:56:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:56:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:56:59 - INFO :       machine_learning: Total Sparsity 1.3538453540359754e-06
2023-12-01 16:56:59 - INFO :       
==================Finish================

2023-12-01 16:56:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:56:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:56:59 - INFO :       DATASET: tasksource/mmlu management
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 16:57:09 - INFO :       Use random pruner...
2023-12-01 16:57:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:57:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:57:09 - INFO :       Start Pruning
2023-12-01 16:57:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:57:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:57:11 - INFO :       management: Total Sparsity 1.3621306055515601e-06
2023-12-01 16:57:11 - INFO :       
==================Finish================

2023-12-01 16:57:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:57:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:57:11 - INFO :       DATASET: tasksource/mmlu marketing
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 16:57:21 - INFO :       Use random pruner...
2023-12-01 16:57:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:57:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:57:22 - INFO :       Start Pruning
2023-12-01 16:57:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:57:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:57:23 - INFO :       marketing: Total Sparsity 1.363717143075821e-06
2023-12-01 16:57:23 - INFO :       
==================Finish================

2023-12-01 16:57:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:57:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:57:23 - INFO :       DATASET: tasksource/mmlu medical_genetics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2023-12-01 16:57:33 - INFO :       Use random pruner...
2023-12-01 16:57:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:57:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:57:33 - INFO :       Start Pruning
2023-12-01 16:57:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:57:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:57:35 - INFO :       medical_genetics: Total Sparsity 1.3571947110316374e-06
2023-12-01 16:57:35 - INFO :       
==================Finish================

2023-12-01 16:57:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:57:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:57:35 - INFO :       DATASET: tasksource/mmlu miscellaneous
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 16:57:42 - INFO :       Use random pruner...
2023-12-01 16:57:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:57:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:57:42 - INFO :       Start Pruning
2023-12-01 16:57:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:57:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:57:44 - INFO :       miscellaneous: Total Sparsity 1.3658325264415023e-06
2023-12-01 16:57:44 - INFO :       
==================Finish================

2023-12-01 16:57:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:57:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:57:44 - INFO :       DATASET: tasksource/mmlu moral_disputes
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]
2023-12-01 16:57:54 - INFO :       Use random pruner...
2023-12-01 16:57:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:57:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:57:54 - INFO :       Start Pruning
2023-12-01 16:57:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:57:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:57:56 - INFO :       moral_disputes: Total Sparsity 1.3621306055515601e-06
2023-12-01 16:57:56 - INFO :       
==================Finish================

2023-12-01 16:57:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:57:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:57:56 - INFO :       DATASET: tasksource/mmlu moral_scenarios
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 16:58:05 - INFO :       Use random pruner...
2023-12-01 16:58:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:58:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:58:05 - INFO :       Start Pruning
2023-12-01 16:58:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:58:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:58:07 - INFO :       moral_scenarios: Total Sparsity 1.3624831694458404e-06
2023-12-01 16:58:07 - INFO :       
==================Finish================

2023-12-01 16:58:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:58:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:58:07 - INFO :       DATASET: tasksource/mmlu nutrition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]
2023-12-01 16:58:16 - INFO :       Use random pruner...
2023-12-01 16:58:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:58:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:58:17 - INFO :       Start Pruning
2023-12-01 16:58:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:58:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:58:18 - INFO :       nutrition: Total Sparsity 1.356313301295937e-06
2023-12-01 16:58:18 - INFO :       
==================Finish================

2023-12-01 16:58:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:58:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:58:18 - INFO :       DATASET: tasksource/mmlu philosophy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]
2023-12-01 16:58:27 - INFO :       Use random pruner...
2023-12-01 16:58:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:58:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:58:28 - INFO :       Start Pruning
2023-12-01 16:58:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:58:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:58:29 - INFO :       philosophy: Total Sparsity 1.3631882972344008e-06
2023-12-01 16:58:29 - INFO :       
==================Finish================

2023-12-01 16:58:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:58:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:58:29 - INFO :       DATASET: tasksource/mmlu prehistory
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.98s/it]
2023-12-01 16:58:39 - INFO :       Use random pruner...
2023-12-01 16:58:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:58:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:58:39 - INFO :       Start Pruning
2023-12-01 16:58:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:58:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:58:41 - INFO :       prehistory: Total Sparsity 1.3663613722829226e-06
2023-12-01 16:58:41 - INFO :       
==================Finish================

2023-12-01 16:58:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:58:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:58:41 - INFO :       DATASET: tasksource/mmlu professional_accounting
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.46s/it]
2023-12-01 16:58:49 - INFO :       Use random pruner...
2023-12-01 16:58:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:58:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:58:49 - INFO :       Start Pruning
2023-12-01 16:58:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:58:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:58:51 - INFO :       professional_accounting: Total Sparsity 1.3631882972344008e-06
2023-12-01 16:58:51 - INFO :       
==================Finish================

2023-12-01 16:58:51 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:58:51 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:58:51 - INFO :       DATASET: tasksource/mmlu professional_law
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2023-12-01 16:59:00 - INFO :       Use random pruner...
2023-12-01 16:59:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:59:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:59:00 - INFO :       Start Pruning
2023-12-01 16:59:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:59:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:59:02 - INFO :       professional_law: Total Sparsity 1.3621306055515601e-06
2023-12-01 16:59:02 - INFO :       
==================Finish================

2023-12-01 16:59:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:59:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:59:02 - INFO :       DATASET: tasksource/mmlu professional_medicine
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2023-12-01 16:59:10 - INFO :       Use random pruner...
2023-12-01 16:59:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:59:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:59:11 - INFO :       Start Pruning
2023-12-01 16:59:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:59:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:59:13 - INFO :       professional_medicine: Total Sparsity 1.3621306055515601e-06
2023-12-01 16:59:13 - INFO :       
==================Finish================

2023-12-01 16:59:13 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:59:13 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:59:13 - INFO :       DATASET: tasksource/mmlu professional_psychology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2023-12-01 16:59:22 - INFO :       Use random pruner...
2023-12-01 16:59:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:59:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:59:23 - INFO :       Start Pruning
2023-12-01 16:59:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:59:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:59:24 - INFO :       professional_psychology: Total Sparsity 1.377290853005609e-06
2023-12-01 16:59:24 - INFO :       
==================Finish================

2023-12-01 16:59:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:59:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:59:24 - INFO :       DATASET: tasksource/mmlu public_relations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 16:59:33 - INFO :       Use random pruner...
2023-12-01 16:59:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:59:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:59:34 - INFO :       Start Pruning
2023-12-01 16:59:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:59:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:59:35 - INFO :       public_relations: Total Sparsity 1.3725312404328262e-06
2023-12-01 16:59:35 - INFO :       
==================Finish================

2023-12-01 16:59:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:59:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:59:35 - INFO :       DATASET: tasksource/mmlu security_studies
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2023-12-01 16:59:45 - INFO :       Use random pruner...
2023-12-01 16:59:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:59:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:59:45 - INFO :       Start Pruning
2023-12-01 16:59:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:59:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:59:47 - INFO :       security_studies: Total Sparsity 1.3598389402387389e-06
2023-12-01 16:59:47 - INFO :       
==================Finish================

2023-12-01 16:59:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:59:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:59:47 - INFO :       DATASET: tasksource/mmlu sociology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 16:59:56 - INFO :       Use random pruner...
2023-12-01 16:59:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:59:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 16:59:56 - INFO :       Start Pruning
2023-12-01 16:59:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 16:59:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 16:59:58 - INFO :       sociology: Total Sparsity 1.3610729138687196e-06
2023-12-01 16:59:58 - INFO :       
==================Finish================

2023-12-01 16:59:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 16:59:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 16:59:58 - INFO :       DATASET: tasksource/mmlu us_foreign_policy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]
2023-12-01 17:00:07 - INFO :       Use random pruner...
2023-12-01 17:00:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:00:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:00:07 - INFO :       Start Pruning
2023-12-01 17:00:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:00:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:00:09 - INFO :       us_foreign_policy: Total Sparsity 1.3610729138687196e-06
2023-12-01 17:00:09 - INFO :       
==================Finish================

2023-12-01 17:00:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:00:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:00:09 - INFO :       DATASET: tasksource/mmlu virology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 17:00:19 - INFO :       Use random pruner...
2023-12-01 17:00:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:00:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:00:19 - INFO :       Start Pruning
2023-12-01 17:00:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:00:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:00:21 - INFO :       virology: Total Sparsity 1.3566658651902172e-06
2023-12-01 17:00:21 - INFO :       
==================Finish================

2023-12-01 17:00:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:00:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:00:21 - INFO :       DATASET: tasksource/mmlu world_religions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2023-12-01 17:00:31 - INFO :       Use random pruner...
2023-12-01 17:00:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:00:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:00:31 - INFO :       Start Pruning
2023-12-01 17:00:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:00:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:00:33 - INFO :       world_religions: Total Sparsity 1.3630120152872606e-06
2023-12-01 17:00:33 - INFO :       
==================Finish================

2023-12-01 17:00:33 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:00:33 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:00:33 - INFO :       DATASET: math_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2023-12-01 17:00:43 - INFO :       Use random pruner...
2023-12-01 17:00:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:00:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:00:44 - INFO :       Start Pruning
2023-12-01 17:00:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:00:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:00:45 - INFO :       math_qa: Total Sparsity 1.354550481824536e-06
2023-12-01 17:00:45 - INFO :       
==================Finish================

2023-12-01 17:00:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:00:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:00:45 - INFO :       DATASET: EleutherAI/truthful_qa_mc
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2023-12-01 17:00:55 - INFO :       Use random pruner...
2023-12-01 17:00:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:00:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:00:55 - INFO :       Start Pruning
2023-12-01 17:00:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:00:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:00:57 - INFO :       truthful_qa_mc: Total Sparsity 1.3594863763444586e-06
2023-12-01 17:00:57 - INFO :       
==================Finish================

2023-12-01 17:00:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:00:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:00:57 - INFO :       DATASET: derek-thomas/ScienceQA
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]
2023-12-01 17:01:06 - INFO :       Use random pruner...
2023-12-01 17:01:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:01:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:01:06 - INFO :       Start Pruning
2023-12-01 17:01:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:01:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:01:08 - INFO :       ScienceQA: Total Sparsity 1.3649511167058018e-06
2023-12-01 17:01:08 - INFO :       
==================Finish================

2023-12-01 17:01:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:01:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:01:08 - INFO :       DATASET: commonsense_qa
Index 2
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]
2023-12-01 17:01:18 - INFO :       Use random pruner...
2023-12-01 17:01:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:01:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:01:19 - INFO :       Start Pruning
2023-12-01 17:01:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:01:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:01:21 - INFO :       commonsense_qa: Total Sparsity 1.358252402714478e-06
2023-12-01 17:01:21 - INFO :       
==================Finish================

2023-12-01 17:01:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:01:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:01:21 - INFO :       DATASET: tasksource/bigbench abstract_narrative_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]
2023-12-01 17:01:29 - INFO :       Use random pruner...
2023-12-01 17:01:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:01:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:01:30 - INFO :       Start Pruning
2023-12-01 17:01:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:01:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:01:32 - INFO :       abstract_narrative_understanding: Total Sparsity 1.3626594513929806e-06
2023-12-01 17:01:32 - INFO :       
==================Finish================

2023-12-01 17:01:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:01:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:01:32 - INFO :       DATASET: tasksource/bigbench anachronisms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 17:01:39 - INFO :       Use random pruner...
2023-12-01 17:01:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:01:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:01:40 - INFO :       Start Pruning
2023-12-01 17:01:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:01:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:01:42 - INFO :       anachronisms: Total Sparsity 1.3663613722829226e-06
2023-12-01 17:01:42 - INFO :       
==================Finish================

2023-12-01 17:01:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:01:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:01:42 - INFO :       DATASET: tasksource/bigbench analogical_similarity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2023-12-01 17:01:51 - INFO :       Use random pruner...
2023-12-01 17:01:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:01:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:01:52 - INFO :       Start Pruning
2023-12-01 17:01:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:01:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:01:53 - INFO :       analogical_similarity: Total Sparsity 1.3677716278600435e-06
2023-12-01 17:01:53 - INFO :       
==================Finish================

2023-12-01 17:01:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:01:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:01:53 - INFO :       DATASET: tasksource/bigbench analytic_entailment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 17:02:03 - INFO :       Use random pruner...
2023-12-01 17:02:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:02:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:02:03 - INFO :       Start Pruning
2023-12-01 17:02:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:02:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:02:05 - INFO :       analytic_entailment: Total Sparsity 1.3612491958158596e-06
2023-12-01 17:02:05 - INFO :       
==================Finish================

2023-12-01 17:02:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:02:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:02:05 - INFO :       DATASET: tasksource/bigbench arithmetic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2023-12-01 17:02:14 - INFO :       Use random pruner...
2023-12-01 17:02:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:02:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:02:14 - INFO :       Start Pruning
2023-12-01 17:02:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:02:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:02:16 - INFO :       arithmetic: Total Sparsity 1.3651273986529418e-06
2023-12-01 17:02:16 - INFO :       
==================Finish================

2023-12-01 17:02:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:02:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:02:16 - INFO :       DATASET: tasksource/bigbench authorship_verification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]
2023-12-01 17:02:26 - INFO :       Use random pruner...
2023-12-01 17:02:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:02:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:02:26 - INFO :       Start Pruning
2023-12-01 17:02:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:02:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:02:28 - INFO :       authorship_verification: Total Sparsity 1.353140226247415e-06
2023-12-01 17:02:28 - INFO :       
==================Finish================

2023-12-01 17:02:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:02:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:02:28 - INFO :       DATASET: tasksource/bigbench bbq_lite_json
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2023-12-01 17:02:37 - INFO :       Use random pruner...
2023-12-01 17:02:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:02:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:02:38 - INFO :       Start Pruning
2023-12-01 17:02:38 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:02:38 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:02:39 - INFO :       bbq_lite_json: Total Sparsity 1.3661850903357826e-06
2023-12-01 17:02:39 - INFO :       
==================Finish================

2023-12-01 17:02:39 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:02:39 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:02:39 - INFO :       DATASET: tasksource/bigbench causal_judgment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]
2023-12-01 17:02:47 - INFO :       Use random pruner...
2023-12-01 17:02:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:02:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:02:48 - INFO :       Start Pruning
2023-12-01 17:02:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:02:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:02:49 - INFO :       causal_judgment: Total Sparsity 1.3735889321156667e-06
2023-12-01 17:02:49 - INFO :       
==================Finish================

2023-12-01 17:02:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:02:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:02:49 - INFO :       DATASET: tasksource/bigbench cause_and_effect
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]
2023-12-01 17:02:58 - INFO :       Use random pruner...
2023-12-01 17:02:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:02:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:02:58 - INFO :       Start Pruning
2023-12-01 17:02:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:02:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:03:00 - INFO :       cause_and_effect: Total Sparsity 1.363540861128681e-06
2023-12-01 17:03:00 - INFO :       
==================Finish================

2023-12-01 17:03:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:03:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:03:00 - INFO :       DATASET: tasksource/bigbench checkmate_in_one
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2023-12-01 17:03:09 - INFO :       Use random pruner...
2023-12-01 17:03:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:03:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:03:09 - INFO :       Start Pruning
2023-12-01 17:03:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:03:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:03:11 - INFO :       checkmate_in_one: Total Sparsity 1.3598389402387389e-06
2023-12-01 17:03:11 - INFO :       
==================Finish================

2023-12-01 17:03:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:03:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:03:11 - INFO :       DATASET: tasksource/bigbench cifar10_classification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2023-12-01 17:03:21 - INFO :       Use random pruner...
2023-12-01 17:03:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:03:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:03:21 - INFO :       Start Pruning
2023-12-01 17:03:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:03:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:03:23 - INFO :       cifar10_classification: Total Sparsity 1.3607203499744394e-06
2023-12-01 17:03:23 - INFO :       
==================Finish================

2023-12-01 17:03:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:03:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:03:23 - INFO :       DATASET: tasksource/bigbench code_line_description
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2023-12-01 17:03:32 - INFO :       Use random pruner...
2023-12-01 17:03:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:03:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:03:33 - INFO :       Start Pruning
2023-12-01 17:03:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:03:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:03:34 - INFO :       code_line_description: Total Sparsity 1.365479962547222e-06
2023-12-01 17:03:34 - INFO :       
==================Finish================

2023-12-01 17:03:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:03:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:03:34 - INFO :       DATASET: tasksource/bigbench color
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2023-12-01 17:03:43 - INFO :       Use random pruner...
2023-12-01 17:03:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:03:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:03:44 - INFO :       Start Pruning
2023-12-01 17:03:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:03:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:03:46 - INFO :       color: Total Sparsity 1.366890218124343e-06
2023-12-01 17:03:46 - INFO :       
==================Finish================

2023-12-01 17:03:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:03:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:03:46 - INFO :       DATASET: tasksource/bigbench common_morpheme
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2023-12-01 17:03:56 - INFO :       Use random pruner...
2023-12-01 17:03:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:03:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:03:56 - INFO :       Start Pruning
2023-12-01 17:03:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:03:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:03:58 - INFO :       common_morpheme: Total Sparsity 1.3661850903357826e-06
2023-12-01 17:03:58 - INFO :       
==================Finish================

2023-12-01 17:03:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:03:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:03:58 - INFO :       DATASET: tasksource/bigbench conceptual_combinations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]
2023-12-01 17:04:08 - INFO :       Use random pruner...
2023-12-01 17:04:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:04:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:04:09 - INFO :       Start Pruning
2023-12-01 17:04:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:04:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:04:10 - INFO :       conceptual_combinations: Total Sparsity 1.3601915041330191e-06
2023-12-01 17:04:10 - INFO :       
==================Finish================

2023-12-01 17:04:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:04:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:04:10 - INFO :       DATASET: tasksource/bigbench crash_blossom
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.33s/it]
2023-12-01 17:04:21 - INFO :       Use random pruner...
2023-12-01 17:04:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:04:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:04:21 - INFO :       Start Pruning
2023-12-01 17:04:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:04:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:04:23 - INFO :       crash_blossom: Total Sparsity 1.3630120152872606e-06
2023-12-01 17:04:23 - INFO :       
==================Finish================

2023-12-01 17:04:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:04:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:04:23 - INFO :       DATASET: tasksource/bigbench crass_ai
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2023-12-01 17:04:32 - INFO :       Use random pruner...
2023-12-01 17:04:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:04:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:04:33 - INFO :       Start Pruning
2023-12-01 17:04:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:04:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:04:34 - INFO :       crass_ai: Total Sparsity 1.3490857414631927e-06
2023-12-01 17:04:34 - INFO :       
==================Finish================

2023-12-01 17:04:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:04:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:04:34 - INFO :       DATASET: tasksource/bigbench cryobiology_spanish
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]
2023-12-01 17:04:43 - INFO :       Use random pruner...
2023-12-01 17:04:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:04:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:04:43 - INFO :       Start Pruning
2023-12-01 17:04:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:04:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:04:45 - INFO :       cryobiology_spanish: Total Sparsity 1.370592139014285e-06
2023-12-01 17:04:45 - INFO :       
==================Finish================

2023-12-01 17:04:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:04:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:04:45 - INFO :       DATASET: tasksource/bigbench cs_algorithms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]
2023-12-01 17:04:53 - INFO :       Use random pruner...
2023-12-01 17:04:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:04:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:04:53 - INFO :       Start Pruning
2023-12-01 17:04:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:04:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:04:55 - INFO :       cs_algorithms: Total Sparsity 1.365303680600082e-06
2023-12-01 17:04:55 - INFO :       
==================Finish================

2023-12-01 17:04:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:04:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:04:55 - INFO :       DATASET: tasksource/bigbench dark_humor_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]
2023-12-01 17:05:04 - INFO :       Use random pruner...
2023-12-01 17:05:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:05:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:05:04 - INFO :       Start Pruning
2023-12-01 17:05:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:05:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:05:06 - INFO :       dark_humor_detection: Total Sparsity 1.3730600862742465e-06
2023-12-01 17:05:06 - INFO :       
==================Finish================

2023-12-01 17:05:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:05:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:05:06 - INFO :       DATASET: tasksource/bigbench date_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2023-12-01 17:05:17 - INFO :       Use random pruner...
2023-12-01 17:05:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:05:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:05:17 - INFO :       Start Pruning
2023-12-01 17:05:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:05:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:05:19 - INFO :       date_understanding: Total Sparsity 1.3649511167058018e-06
2023-12-01 17:05:19 - INFO :       
==================Finish================

2023-12-01 17:05:19 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:05:19 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:05:19 - INFO :       DATASET: tasksource/bigbench disambiguation_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.36s/it]
2023-12-01 17:05:31 - INFO :       Use random pruner...
2023-12-01 17:05:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:05:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:05:32 - INFO :       Start Pruning
2023-12-01 17:05:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:05:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:05:34 - INFO :       disambiguation_qa: Total Sparsity 1.3570184290844972e-06
2023-12-01 17:05:34 - INFO :       
==================Finish================

2023-12-01 17:05:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:05:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:05:34 - INFO :       DATASET: tasksource/bigbench discourse_marker_prediction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]
2023-12-01 17:05:44 - INFO :       Use random pruner...
2023-12-01 17:05:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:05:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:05:45 - INFO :       Start Pruning
2023-12-01 17:05:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:05:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:05:46 - INFO :       discourse_marker_prediction: Total Sparsity 1.366890218124343e-06
2023-12-01 17:05:46 - INFO :       
==================Finish================

2023-12-01 17:05:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:05:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:05:46 - INFO :       DATASET: tasksource/bigbench dyck_languages
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2023-12-01 17:05:56 - INFO :       Use random pruner...
2023-12-01 17:05:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:05:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:05:57 - INFO :       Start Pruning
2023-12-01 17:05:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:05:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:05:58 - INFO :       dyck_languages: Total Sparsity 1.3575472749259176e-06
2023-12-01 17:05:58 - INFO :       
==================Finish================

2023-12-01 17:05:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:05:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:05:58 - INFO :       DATASET: tasksource/bigbench elementary_math_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]
2023-12-01 17:06:09 - INFO :       Use random pruner...
2023-12-01 17:06:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:06:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:06:10 - INFO :       Start Pruning
2023-12-01 17:06:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:06:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:06:11 - INFO :       elementary_math_qa: Total Sparsity 1.3681241917543236e-06
2023-12-01 17:06:11 - INFO :       
==================Finish================

2023-12-01 17:06:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:06:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:06:11 - INFO :       DATASET: tasksource/bigbench emoji_movie
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2023-12-01 17:06:22 - INFO :       Use random pruner...
2023-12-01 17:06:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:06:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:06:22 - INFO :       Start Pruning
2023-12-01 17:06:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:06:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:06:24 - INFO :       emoji_movie: Total Sparsity 1.3630120152872606e-06
2023-12-01 17:06:24 - INFO :       
==================Finish================

2023-12-01 17:06:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:06:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:06:24 - INFO :       DATASET: tasksource/bigbench empirical_judgments
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.35s/it]
2023-12-01 17:06:35 - INFO :       Use random pruner...
2023-12-01 17:06:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:06:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:06:36 - INFO :       Start Pruning
2023-12-01 17:06:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:06:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:06:38 - INFO :       empirical_judgments: Total Sparsity 1.356489583243077e-06
2023-12-01 17:06:38 - INFO :       
==================Finish================

2023-12-01 17:06:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:06:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:06:38 - INFO :       DATASET: tasksource/bigbench english_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 17:06:49 - INFO :       Use random pruner...
2023-12-01 17:06:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:06:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:06:49 - INFO :       Start Pruning
2023-12-01 17:06:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:06:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:06:51 - INFO :       english_proverbs: Total Sparsity 1.3578998388201979e-06
2023-12-01 17:06:51 - INFO :       
==================Finish================

2023-12-01 17:06:51 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:06:51 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:06:51 - INFO :       DATASET: tasksource/bigbench english_russian_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.31s/it]
2023-12-01 17:07:02 - INFO :       Use random pruner...
2023-12-01 17:07:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:07:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:07:02 - INFO :       Start Pruning
2023-12-01 17:07:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:07:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:07:04 - INFO :       english_russian_proverbs: Total Sparsity 1.3616017597101399e-06
2023-12-01 17:07:04 - INFO :       
==================Finish================

2023-12-01 17:07:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:07:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:07:04 - INFO :       DATASET: tasksource/bigbench entailed_polarity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2023-12-01 17:07:16 - INFO :       Use random pruner...
2023-12-01 17:07:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:07:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:07:16 - INFO :       Start Pruning
2023-12-01 17:07:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:07:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:07:18 - INFO :       entailed_polarity: Total Sparsity 1.358076120767338e-06
2023-12-01 17:07:18 - INFO :       
==================Finish================

2023-12-01 17:07:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:07:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:07:18 - INFO :       DATASET: tasksource/bigbench entailed_polarity_hindi
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.21s/it]
2023-12-01 17:07:29 - INFO :       Use random pruner...
2023-12-01 17:07:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:07:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:07:30 - INFO :       Start Pruning
2023-12-01 17:07:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:07:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:07:31 - INFO :       entailed_polarity_hindi: Total Sparsity 1.3626594513929806e-06
2023-12-01 17:07:31 - INFO :       
==================Finish================

2023-12-01 17:07:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:07:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:07:31 - INFO :       DATASET: tasksource/bigbench epistemic_reasoning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2023-12-01 17:07:42 - INFO :       Use random pruner...
2023-12-01 17:07:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:07:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:07:42 - INFO :       Start Pruning
2023-12-01 17:07:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:07:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:07:44 - INFO :       epistemic_reasoning: Total Sparsity 1.358252402714478e-06
2023-12-01 17:07:44 - INFO :       
==================Finish================

2023-12-01 17:07:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:07:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:07:44 - INFO :       DATASET: tasksource/bigbench evaluating_information_essentiality
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]
2023-12-01 17:07:52 - INFO :       Use random pruner...
2023-12-01 17:07:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:07:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:07:53 - INFO :       Start Pruning
2023-12-01 17:07:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:07:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:07:54 - INFO :       evaluating_information_essentiality: Total Sparsity 1.3601915041330191e-06
2023-12-01 17:07:54 - INFO :       
==================Finish================

2023-12-01 17:07:54 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:07:54 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:07:54 - INFO :       DATASET: tasksource/bigbench fact_checker
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]
2023-12-01 17:08:02 - INFO :       Use random pruner...
2023-12-01 17:08:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:08:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:08:02 - INFO :       Start Pruning
2023-12-01 17:08:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:08:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:08:04 - INFO :       fact_checker: Total Sparsity 1.3663613722829226e-06
2023-12-01 17:08:04 - INFO :       
==================Finish================

2023-12-01 17:08:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:08:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:08:04 - INFO :       DATASET: tasksource/bigbench fantasy_reasoning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2023-12-01 17:08:13 - INFO :       Use random pruner...
2023-12-01 17:08:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:08:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:08:13 - INFO :       Start Pruning
2023-12-01 17:08:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:08:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:08:15 - INFO :       fantasy_reasoning: Total Sparsity 1.3554318915602364e-06
2023-12-01 17:08:15 - INFO :       
==================Finish================

2023-12-01 17:08:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:08:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:08:15 - INFO :       DATASET: tasksource/bigbench figure_of_speech_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]
2023-12-01 17:08:23 - INFO :       Use random pruner...
2023-12-01 17:08:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:08:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:08:24 - INFO :       Start Pruning
2023-12-01 17:08:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:08:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:08:26 - INFO :       figure_of_speech_detection: Total Sparsity 1.356313301295937e-06
2023-12-01 17:08:26 - INFO :       
==================Finish================

2023-12-01 17:08:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:08:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:08:26 - INFO :       DATASET: tasksource/bigbench formal_fallacies_syllogisms_negation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 17:08:33 - INFO :       Use random pruner...
2023-12-01 17:08:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:08:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:08:33 - INFO :       Start Pruning
2023-12-01 17:08:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:08:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:08:35 - INFO :       formal_fallacies_syllogisms_negation: Total Sparsity 1.3573709929787774e-06
2023-12-01 17:08:35 - INFO :       
==================Finish================

2023-12-01 17:08:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:08:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:08:35 - INFO :       DATASET: tasksource/bigbench general_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]
2023-12-01 17:08:45 - INFO :       Use random pruner...
2023-12-01 17:08:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:08:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:08:45 - INFO :       Start Pruning
2023-12-01 17:08:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:08:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:08:47 - INFO :       general_knowledge: Total Sparsity 1.3658325264415023e-06
2023-12-01 17:08:47 - INFO :       
==================Finish================

2023-12-01 17:08:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:08:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:08:47 - INFO :       DATASET: tasksource/bigbench geometric_shapes
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 17:08:55 - INFO :       Use random pruner...
2023-12-01 17:08:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:08:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:08:55 - INFO :       Start Pruning
2023-12-01 17:08:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:08:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:08:57 - INFO :       geometric_shapes: Total Sparsity 1.3645985528115216e-06
2023-12-01 17:08:57 - INFO :       
==================Finish================

2023-12-01 17:08:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:08:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:08:57 - INFO :       DATASET: tasksource/bigbench goal_step_wikihow
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
2023-12-01 17:09:07 - INFO :       Use random pruner...
2023-12-01 17:09:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:09:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:09:07 - INFO :       Start Pruning
2023-12-01 17:09:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:09:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:09:09 - INFO :       goal_step_wikihow: Total Sparsity 1.3633645791815409e-06
2023-12-01 17:09:09 - INFO :       
==================Finish================

2023-12-01 17:09:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:09:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:09:09 - INFO :       DATASET: tasksource/bigbench gre_reading_comprehension
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]
2023-12-01 17:09:18 - INFO :       Use random pruner...
2023-12-01 17:09:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:09:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:09:18 - INFO :       Start Pruning
2023-12-01 17:09:19 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:09:19 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:09:20 - INFO :       gre_reading_comprehension: Total Sparsity 1.3610729138687196e-06
2023-12-01 17:09:20 - INFO :       
==================Finish================

2023-12-01 17:09:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:09:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:09:20 - INFO :       DATASET: tasksource/bigbench hhh_alignment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2023-12-01 17:09:29 - INFO :       Use random pruner...
2023-12-01 17:09:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:09:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:09:29 - INFO :       Start Pruning
2023-12-01 17:09:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:09:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:09:31 - INFO :       hhh_alignment: Total Sparsity 1.3640697069701013e-06
2023-12-01 17:09:31 - INFO :       
==================Finish================

2023-12-01 17:09:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:09:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:09:31 - INFO :       DATASET: tasksource/bigbench hindu_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.46s/it]
2023-12-01 17:09:40 - INFO :       Use random pruner...
2023-12-01 17:09:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:09:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:09:41 - INFO :       Start Pruning
2023-12-01 17:09:42 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:09:42 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:09:43 - INFO :       hindu_knowledge: Total Sparsity 1.372178676538546e-06
2023-12-01 17:09:43 - INFO :       
==================Finish================

2023-12-01 17:09:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:09:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:09:43 - INFO :       DATASET: tasksource/bigbench hinglish_toxicity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]
2023-12-01 17:09:53 - INFO :       Use random pruner...
2023-12-01 17:09:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:09:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:09:54 - INFO :       Start Pruning
2023-12-01 17:09:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:09:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:09:55 - INFO :       hinglish_toxicity: Total Sparsity 1.3645985528115216e-06
2023-12-01 17:09:55 - INFO :       
==================Finish================

2023-12-01 17:09:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:09:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:09:55 - INFO :       DATASET: tasksource/bigbench human_organs_senses
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 17:10:06 - INFO :       Use random pruner...
2023-12-01 17:10:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:10:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:10:06 - INFO :       Start Pruning
2023-12-01 17:10:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:10:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:10:08 - INFO :       human_organs_senses: Total Sparsity 1.3702395751200048e-06
2023-12-01 17:10:08 - INFO :       
==================Finish================

2023-12-01 17:10:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:10:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:10:08 - INFO :       DATASET: tasksource/bigbench hyperbaton
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]
2023-12-01 17:10:17 - INFO :       Use random pruner...
2023-12-01 17:10:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:10:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:10:17 - INFO :       Start Pruning
2023-12-01 17:10:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:10:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:10:19 - INFO :       hyperbaton: Total Sparsity 1.3712972668028455e-06
2023-12-01 17:10:19 - INFO :       
==================Finish================

2023-12-01 17:10:19 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:10:19 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:10:19 - INFO :       DATASET: tasksource/bigbench identify_math_theorems
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2023-12-01 17:10:27 - INFO :       Use random pruner...
2023-12-01 17:10:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:10:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:10:28 - INFO :       Start Pruning
2023-12-01 17:10:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:10:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:10:30 - INFO :       identify_math_theorems: Total Sparsity 1.370415857067145e-06
2023-12-01 17:10:30 - INFO :       
==================Finish================

2023-12-01 17:10:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:10:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:10:30 - INFO :       DATASET: tasksource/bigbench identify_odd_metaphor
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2023-12-01 17:10:39 - INFO :       Use random pruner...
2023-12-01 17:10:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:10:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:10:39 - INFO :       Start Pruning
2023-12-01 17:10:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:10:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:10:41 - INFO :       identify_odd_metaphor: Total Sparsity 1.3691818834371643e-06
2023-12-01 17:10:41 - INFO :       
==================Finish================

2023-12-01 17:10:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:10:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:10:41 - INFO :       DATASET: tasksource/bigbench implicatures
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]
2023-12-01 17:10:50 - INFO :       Use random pruner...
2023-12-01 17:10:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:10:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:10:50 - INFO :       Start Pruning
2023-12-01 17:10:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:10:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:10:52 - INFO :       implicatures: Total Sparsity 1.3647748347586618e-06
2023-12-01 17:10:52 - INFO :       
==================Finish================

2023-12-01 17:10:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:10:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:10:52 - INFO :       DATASET: tasksource/bigbench implicit_relations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.23s/it]
2023-12-01 17:11:02 - INFO :       Use random pruner...
2023-12-01 17:11:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:11:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:11:02 - INFO :       Start Pruning
2023-12-01 17:11:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:11:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:11:04 - INFO :       implicit_relations: Total Sparsity 1.3616017597101399e-06
2023-12-01 17:11:04 - INFO :       
==================Finish================

2023-12-01 17:11:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:11:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:11:04 - INFO :       DATASET: tasksource/bigbench indic_cause_and_effect
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
2023-12-01 17:11:13 - INFO :       Use random pruner...
2023-12-01 17:11:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:11:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:11:13 - INFO :       Start Pruning
2023-12-01 17:11:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:11:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:11:15 - INFO :       indic_cause_and_effect: Total Sparsity 1.3596626582915989e-06
2023-12-01 17:11:15 - INFO :       
==================Finish================

2023-12-01 17:11:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:11:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:11:15 - INFO :       DATASET: tasksource/bigbench intent_recognition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2023-12-01 17:11:26 - INFO :       Use random pruner...
2023-12-01 17:11:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:11:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:11:26 - INFO :       Start Pruning
2023-12-01 17:11:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:11:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:11:28 - INFO :       intent_recognition: Total Sparsity 1.3677716278600435e-06
2023-12-01 17:11:28 - INFO :       
==================Finish================

2023-12-01 17:11:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:11:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:11:28 - INFO :       DATASET: tasksource/bigbench international_phonetic_alphabet_nli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2023-12-01 17:11:38 - INFO :       Use random pruner...
2023-12-01 17:11:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:11:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:11:38 - INFO :       Start Pruning
2023-12-01 17:11:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:11:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:11:40 - INFO :       international_phonetic_alphabet_nli: Total Sparsity 1.360015222185879e-06
2023-12-01 17:11:40 - INFO :       
==================Finish================

2023-12-01 17:11:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:11:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:11:40 - INFO :       DATASET: tasksource/bigbench intersect_geometry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2023-12-01 17:11:50 - INFO :       Use random pruner...
2023-12-01 17:11:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:11:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:11:50 - INFO :       Start Pruning
2023-12-01 17:11:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:11:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:11:52 - INFO :       intersect_geometry: Total Sparsity 1.3601915041330191e-06
2023-12-01 17:11:52 - INFO :       
==================Finish================

2023-12-01 17:11:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:11:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:11:52 - INFO :       DATASET: tasksource/bigbench irony_identification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2023-12-01 17:12:00 - INFO :       Use random pruner...
2023-12-01 17:12:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:12:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:12:00 - INFO :       Start Pruning
2023-12-01 17:12:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:12:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:12:02 - INFO :       irony_identification: Total Sparsity 1.3631882972344008e-06
2023-12-01 17:12:02 - INFO :       
==================Finish================

2023-12-01 17:12:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:12:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:12:02 - INFO :       DATASET: tasksource/bigbench kannada
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
2023-12-01 17:12:10 - INFO :       Use random pruner...
2023-12-01 17:12:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:12:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:12:11 - INFO :       Start Pruning
2023-12-01 17:12:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:12:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:12:12 - INFO :       kannada: Total Sparsity 1.3642459889172413e-06
2023-12-01 17:12:12 - INFO :       
==================Finish================

2023-12-01 17:12:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:12:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:12:12 - INFO :       DATASET: tasksource/bigbench key_value_maps
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2023-12-01 17:12:21 - INFO :       Use random pruner...
2023-12-01 17:12:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:12:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:12:22 - INFO :       Start Pruning
2023-12-01 17:12:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:12:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:12:23 - INFO :       key_value_maps: Total Sparsity 1.3510248428817337e-06
2023-12-01 17:12:23 - INFO :       
==================Finish================

2023-12-01 17:12:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:12:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:12:23 - INFO :       DATASET: tasksource/bigbench known_unknowns
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.91s/it]
2023-12-01 17:12:33 - INFO :       Use random pruner...
2023-12-01 17:12:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:12:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:12:34 - INFO :       Start Pruning
2023-12-01 17:12:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:12:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:12:36 - INFO :       known_unknowns: Total Sparsity 1.3628357333401206e-06
2023-12-01 17:12:36 - INFO :       
==================Finish================

2023-12-01 17:12:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:12:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:12:36 - INFO :       DATASET: tasksource/bigbench language_identification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]
2023-12-01 17:12:44 - INFO :       Use random pruner...
2023-12-01 17:12:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:12:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:12:44 - INFO :       Start Pruning
2023-12-01 17:12:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:12:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:12:46 - INFO :       language_identification: Total Sparsity 1.3536690720888354e-06
2023-12-01 17:12:46 - INFO :       
==================Finish================

2023-12-01 17:12:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:12:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:12:46 - INFO :       DATASET: tasksource/bigbench logic_grid_puzzle
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]
2023-12-01 17:12:56 - INFO :       Use random pruner...
2023-12-01 17:12:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:12:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:12:56 - INFO :       Start Pruning
2023-12-01 17:12:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:12:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:12:58 - INFO :       logic_grid_puzzle: Total Sparsity 1.3663613722829226e-06
2023-12-01 17:12:58 - INFO :       
==================Finish================

2023-12-01 17:12:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:12:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:12:58 - INFO :       DATASET: tasksource/bigbench logical_args
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]
2023-12-01 17:13:07 - INFO :       Use random pruner...
2023-12-01 17:13:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:13:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:13:08 - INFO :       Start Pruning
2023-12-01 17:13:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:13:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:13:09 - INFO :       logical_args: Total Sparsity 1.3638934250229613e-06
2023-12-01 17:13:09 - INFO :       
==================Finish================

2023-12-01 17:13:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:13:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:13:09 - INFO :       DATASET: tasksource/bigbench logical_deduction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2023-12-01 17:13:19 - INFO :       Use random pruner...
2023-12-01 17:13:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:13:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:13:19 - INFO :       Start Pruning
2023-12-01 17:13:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:13:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:13:21 - INFO :       logical_deduction: Total Sparsity 1.3649511167058018e-06
2023-12-01 17:13:21 - INFO :       
==================Finish================

2023-12-01 17:13:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:13:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:13:21 - INFO :       DATASET: tasksource/bigbench logical_fallacy_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]
2023-12-01 17:13:29 - INFO :       Use random pruner...
2023-12-01 17:13:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:13:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:13:29 - INFO :       Start Pruning
2023-12-01 17:13:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:13:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:13:31 - INFO :       logical_fallacy_detection: Total Sparsity 1.3605440680272994e-06
2023-12-01 17:13:31 - INFO :       
==================Finish================

2023-12-01 17:13:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:13:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:13:31 - INFO :       DATASET: tasksource/bigbench logical_sequence
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2023-12-01 17:13:41 - INFO :       Use random pruner...
2023-12-01 17:13:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:13:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:13:41 - INFO :       Start Pruning
2023-12-01 17:13:42 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:13:42 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:13:43 - INFO :       logical_sequence: Total Sparsity 1.3677716278600435e-06
2023-12-01 17:13:43 - INFO :       
==================Finish================

2023-12-01 17:13:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:13:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:13:43 - INFO :       DATASET: tasksource/bigbench mathematical_induction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2023-12-01 17:13:51 - INFO :       Use random pruner...
2023-12-01 17:13:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:13:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:13:51 - INFO :       Start Pruning
2023-12-01 17:13:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:13:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:13:53 - INFO :       mathematical_induction: Total Sparsity 1.370592139014285e-06
2023-12-01 17:13:53 - INFO :       
==================Finish================

2023-12-01 17:13:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:13:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:13:53 - INFO :       DATASET: tasksource/bigbench medical_questions_russian
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2023-12-01 17:14:03 - INFO :       Use random pruner...
2023-12-01 17:14:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:14:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:14:03 - INFO :       Start Pruning
2023-12-01 17:14:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:14:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:14:05 - INFO :       medical_questions_russian: Total Sparsity 1.3568421471373572e-06
2023-12-01 17:14:05 - INFO :       
==================Finish================

2023-12-01 17:14:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:14:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:14:05 - INFO :       DATASET: tasksource/bigbench metaphor_boolean
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 17:14:13 - INFO :       Use random pruner...
2023-12-01 17:14:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:14:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:14:14 - INFO :       Start Pruning
2023-12-01 17:14:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:14:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:14:16 - INFO :       metaphor_boolean: Total Sparsity 1.367242782018623e-06
2023-12-01 17:14:16 - INFO :       
==================Finish================

2023-12-01 17:14:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:14:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:14:16 - INFO :       DATASET: tasksource/bigbench metaphor_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
2023-12-01 17:14:25 - INFO :       Use random pruner...
2023-12-01 17:14:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:14:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:14:25 - INFO :       Start Pruning
2023-12-01 17:14:26 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:14:26 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:14:27 - INFO :       metaphor_understanding: Total Sparsity 1.367066500071483e-06
2023-12-01 17:14:27 - INFO :       
==================Finish================

2023-12-01 17:14:27 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:14:27 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:14:27 - INFO :       DATASET: tasksource/bigbench misconceptions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]
2023-12-01 17:14:36 - INFO :       Use random pruner...
2023-12-01 17:14:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:14:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:14:36 - INFO :       Start Pruning
2023-12-01 17:14:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:14:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:14:38 - INFO :       misconceptions: Total Sparsity 1.358076120767338e-06
2023-12-01 17:14:38 - INFO :       
==================Finish================

2023-12-01 17:14:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:14:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:14:38 - INFO :       DATASET: tasksource/bigbench misconceptions_russian
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]
2023-12-01 17:14:47 - INFO :       Use random pruner...
2023-12-01 17:14:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:14:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:14:47 - INFO :       Start Pruning
2023-12-01 17:14:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:14:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:14:49 - INFO :       misconceptions_russian: Total Sparsity 1.3607203499744394e-06
2023-12-01 17:14:49 - INFO :       
==================Finish================

2023-12-01 17:14:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:14:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:14:49 - INFO :       DATASET: tasksource/bigbench mnist_ascii
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]
2023-12-01 17:14:59 - INFO :       Use random pruner...
2023-12-01 17:14:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:14:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:14:59 - INFO :       Start Pruning
2023-12-01 17:15:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:15:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:15:01 - INFO :       mnist_ascii: Total Sparsity 1.363717143075821e-06
2023-12-01 17:15:01 - INFO :       
==================Finish================

2023-12-01 17:15:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:15:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:15:01 - INFO :       DATASET: tasksource/bigbench moral_permissibility
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 17:15:09 - INFO :       Use random pruner...
2023-12-01 17:15:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:15:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:15:10 - INFO :       Start Pruning
2023-12-01 17:15:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:15:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:15:11 - INFO :       moral_permissibility: Total Sparsity 1.3559607374016567e-06
2023-12-01 17:15:11 - INFO :       
==================Finish================

2023-12-01 17:15:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:15:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:15:11 - INFO :       DATASET: tasksource/bigbench movie_dialog_same_or_different
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 17:15:18 - INFO :       Use random pruner...
2023-12-01 17:15:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:15:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:15:19 - INFO :       Start Pruning
2023-12-01 17:15:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:15:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:15:20 - INFO :       movie_dialog_same_or_different: Total Sparsity 1.3533165081945552e-06
2023-12-01 17:15:20 - INFO :       
==================Finish================

2023-12-01 17:15:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:15:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:15:20 - INFO :       DATASET: tasksource/bigbench movie_recommendation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2023-12-01 17:15:29 - INFO :       Use random pruner...
2023-12-01 17:15:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:15:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:15:30 - INFO :       Start Pruning
2023-12-01 17:15:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:15:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:15:32 - INFO :       movie_recommendation: Total Sparsity 1.3612491958158596e-06
2023-12-01 17:15:32 - INFO :       
==================Finish================

2023-12-01 17:15:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:15:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:15:32 - INFO :       DATASET: tasksource/bigbench navigate
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2023-12-01 17:15:41 - INFO :       Use random pruner...
2023-12-01 17:15:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:15:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:15:42 - INFO :       Start Pruning
2023-12-01 17:15:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:15:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:15:43 - INFO :       navigate: Total Sparsity 1.3624831694458404e-06
2023-12-01 17:15:43 - INFO :       
==================Finish================

2023-12-01 17:15:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:15:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:15:43 - INFO :       DATASET: tasksource/bigbench nonsense_words_grammar
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.31s/it]
2023-12-01 17:15:56 - INFO :       Use random pruner...
2023-12-01 17:15:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:15:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:15:56 - INFO :       Start Pruning
2023-12-01 17:15:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:15:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:15:58 - INFO :       nonsense_words_grammar: Total Sparsity 1.370592139014285e-06
2023-12-01 17:15:58 - INFO :       
==================Finish================

2023-12-01 17:15:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:15:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:15:58 - INFO :       DATASET: tasksource/bigbench novel_concepts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]
2023-12-01 17:16:10 - INFO :       Use random pruner...
2023-12-01 17:16:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:16:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:16:10 - INFO :       Start Pruning
2023-12-01 17:16:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:16:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:16:12 - INFO :       novel_concepts: Total Sparsity 1.3651273986529418e-06
2023-12-01 17:16:12 - INFO :       
==================Finish================

2023-12-01 17:16:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:16:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:16:12 - INFO :       DATASET: tasksource/bigbench odd_one_out
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2023-12-01 17:16:21 - INFO :       Use random pruner...
2023-12-01 17:16:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:16:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:16:22 - INFO :       Start Pruning
2023-12-01 17:16:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:16:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:16:23 - INFO :       odd_one_out: Total Sparsity 1.3573709929787774e-06
2023-12-01 17:16:24 - INFO :       
==================Finish================

2023-12-01 17:16:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:16:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:16:24 - INFO :       DATASET: tasksource/bigbench parsinlu_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]
2023-12-01 17:16:33 - INFO :       Use random pruner...
2023-12-01 17:16:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:16:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:16:33 - INFO :       Start Pruning
2023-12-01 17:16:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:16:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:16:35 - INFO :       parsinlu_qa: Total Sparsity 1.3541979179302557e-06
2023-12-01 17:16:35 - INFO :       
==================Finish================

2023-12-01 17:16:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:16:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:16:35 - INFO :       DATASET: tasksource/bigbench penguins_in_a_table
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]
2023-12-01 17:16:43 - INFO :       Use random pruner...
2023-12-01 17:16:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:16:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:16:43 - INFO :       Start Pruning
2023-12-01 17:16:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:16:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:16:45 - INFO :       penguins_in_a_table: Total Sparsity 1.3536690720888354e-06
2023-12-01 17:16:45 - INFO :       
==================Finish================

2023-12-01 17:16:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:16:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:16:45 - INFO :       DATASET: tasksource/bigbench persian_idioms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]
2023-12-01 17:16:53 - INFO :       Use random pruner...
2023-12-01 17:16:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:16:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:16:53 - INFO :       Start Pruning
2023-12-01 17:16:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:16:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:16:55 - INFO :       persian_idioms: Total Sparsity 1.367242782018623e-06
2023-12-01 17:16:55 - INFO :       
==================Finish================

2023-12-01 17:16:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:16:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:16:55 - INFO :       DATASET: tasksource/bigbench phrase_relatedness
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 17:17:03 - INFO :       Use random pruner...
2023-12-01 17:17:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:17:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:17:04 - INFO :       Start Pruning
2023-12-01 17:17:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:17:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:17:05 - INFO :       phrase_relatedness: Total Sparsity 1.3594863763444586e-06
2023-12-01 17:17:05 - INFO :       
==================Finish================

2023-12-01 17:17:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:17:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:17:05 - INFO :       DATASET: tasksource/bigbench physical_intuition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 17:17:12 - INFO :       Use random pruner...
2023-12-01 17:17:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:17:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:17:13 - INFO :       Start Pruning
2023-12-01 17:17:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:17:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:17:15 - INFO :       physical_intuition: Total Sparsity 1.3642459889172413e-06
2023-12-01 17:17:15 - INFO :       
==================Finish================

2023-12-01 17:17:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:17:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:17:15 - INFO :       DATASET: tasksource/bigbench physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 17:17:21 - INFO :       Use random pruner...
2023-12-01 17:17:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:17:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:17:22 - INFO :       Start Pruning
2023-12-01 17:17:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:17:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:17:23 - INFO :       physics: Total Sparsity 1.3735889321156667e-06
2023-12-01 17:17:23 - INFO :       
==================Finish================

2023-12-01 17:17:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:17:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:17:23 - INFO :       DATASET: tasksource/bigbench play_dialog_same_or_different
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]
2023-12-01 17:17:32 - INFO :       Use random pruner...
2023-12-01 17:17:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:17:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:17:33 - INFO :       Start Pruning
2023-12-01 17:17:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:17:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:17:34 - INFO :       play_dialog_same_or_different: Total Sparsity 1.3501434331460332e-06
2023-12-01 17:17:34 - INFO :       
==================Finish================

2023-12-01 17:17:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:17:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:17:34 - INFO :       DATASET: tasksource/bigbench presuppositions_as_nli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2023-12-01 17:17:44 - INFO :       Use random pruner...
2023-12-01 17:17:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:17:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:17:45 - INFO :       Start Pruning
2023-12-01 17:17:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:17:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:17:47 - INFO :       presuppositions_as_nli: Total Sparsity 1.3642459889172413e-06
2023-12-01 17:17:47 - INFO :       
==================Finish================

2023-12-01 17:17:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:17:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:17:47 - INFO :       DATASET: tasksource/bigbench question_selection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]
2023-12-01 17:17:55 - INFO :       Use random pruner...
2023-12-01 17:17:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:17:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:17:56 - INFO :       Start Pruning
2023-12-01 17:17:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:17:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:17:57 - INFO :       question_selection: Total Sparsity 1.3700632931728648e-06
2023-12-01 17:17:57 - INFO :       
==================Finish================

2023-12-01 17:17:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:17:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:17:57 - INFO :       DATASET: tasksource/bigbench reasoning_about_colored_objects
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 17:18:07 - INFO :       Use random pruner...
2023-12-01 17:18:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:18:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:18:08 - INFO :       Start Pruning
2023-12-01 17:18:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:18:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:18:09 - INFO :       reasoning_about_colored_objects: Total Sparsity 1.3631882972344008e-06
2023-12-01 17:18:09 - INFO :       
==================Finish================

2023-12-01 17:18:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:18:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:18:09 - INFO :       DATASET: tasksource/bigbench riddle_sense
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2023-12-01 17:18:19 - INFO :       Use random pruner...
2023-12-01 17:18:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:18:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:18:19 - INFO :       Start Pruning
2023-12-01 17:18:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:18:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:18:21 - INFO :       riddle_sense: Total Sparsity 1.3642459889172413e-06
2023-12-01 17:18:21 - INFO :       
==================Finish================

2023-12-01 17:18:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:18:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:18:21 - INFO :       DATASET: tasksource/bigbench ruin_names
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]
2023-12-01 17:18:31 - INFO :       Use random pruner...
2023-12-01 17:18:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:18:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:18:31 - INFO :       Start Pruning
2023-12-01 17:18:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:18:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:18:33 - INFO :       ruin_names: Total Sparsity 1.354550481824536e-06
2023-12-01 17:18:33 - INFO :       
==================Finish================

2023-12-01 17:18:33 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:18:33 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:18:33 - INFO :       DATASET: tasksource/bigbench salient_translation_error_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2023-12-01 17:18:43 - INFO :       Use random pruner...
2023-12-01 17:18:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:18:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:18:43 - INFO :       Start Pruning
2023-12-01 17:18:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:18:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:18:45 - INFO :       salient_translation_error_detection: Total Sparsity 1.353140226247415e-06
2023-12-01 17:18:45 - INFO :       
==================Finish================

2023-12-01 17:18:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:18:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:18:45 - INFO :       DATASET: tasksource/bigbench sentence_ambiguity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  2.00s/it]
2023-12-01 17:18:54 - INFO :       Use random pruner...
2023-12-01 17:18:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:18:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:18:55 - INFO :       Start Pruning
2023-12-01 17:18:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:18:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:18:57 - INFO :       sentence_ambiguity: Total Sparsity 1.3749991876927875e-06
2023-12-01 17:18:57 - INFO :       
==================Finish================

2023-12-01 17:18:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:18:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:18:57 - INFO :       DATASET: tasksource/bigbench similarities_abstraction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]
2023-12-01 17:19:05 - INFO :       Use random pruner...
2023-12-01 17:19:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:19:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:19:05 - INFO :       Start Pruning
2023-12-01 17:19:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:19:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:19:07 - INFO :       similarities_abstraction: Total Sparsity 1.3621306055515601e-06
2023-12-01 17:19:07 - INFO :       
==================Finish================

2023-12-01 17:19:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:19:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:19:07 - INFO :       DATASET: tasksource/bigbench simple_ethical_questions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 17:19:16 - INFO :       Use random pruner...
2023-12-01 17:19:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:19:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:19:16 - INFO :       Start Pruning
2023-12-01 17:19:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:19:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:19:18 - INFO :       simple_ethical_questions: Total Sparsity 1.365303680600082e-06
2023-12-01 17:19:18 - INFO :       
==================Finish================

2023-12-01 17:19:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:19:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:19:18 - INFO :       DATASET: tasksource/bigbench snarks
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]
2023-12-01 17:19:27 - INFO :       Use random pruner...
2023-12-01 17:19:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:19:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:19:28 - INFO :       Start Pruning
2023-12-01 17:19:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:19:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:19:29 - INFO :       snarks: Total Sparsity 1.3598389402387389e-06
2023-12-01 17:19:29 - INFO :       
==================Finish================

2023-12-01 17:19:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:19:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:19:29 - INFO :       DATASET: tasksource/bigbench social_iqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2023-12-01 17:19:39 - INFO :       Use random pruner...
2023-12-01 17:19:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:19:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:19:39 - INFO :       Start Pruning
2023-12-01 17:19:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:19:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:19:41 - INFO :       social_iqa: Total Sparsity 1.3661850903357826e-06
2023-12-01 17:19:41 - INFO :       
==================Finish================

2023-12-01 17:19:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:19:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:19:41 - INFO :       DATASET: tasksource/bigbench social_support
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2023-12-01 17:19:50 - INFO :       Use random pruner...
2023-12-01 17:19:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:19:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:19:51 - INFO :       Start Pruning
2023-12-01 17:19:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:19:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:19:52 - INFO :       social_support: Total Sparsity 1.3536690720888354e-06
2023-12-01 17:19:52 - INFO :       
==================Finish================

2023-12-01 17:19:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:19:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:19:52 - INFO :       DATASET: tasksource/bigbench sports_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 17:20:02 - INFO :       Use random pruner...
2023-12-01 17:20:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:20:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:20:03 - INFO :       Start Pruning
2023-12-01 17:20:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:20:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:20:05 - INFO :       sports_understanding: Total Sparsity 1.3628357333401206e-06
2023-12-01 17:20:05 - INFO :       
==================Finish================

2023-12-01 17:20:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:20:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:20:05 - INFO :       DATASET: tasksource/bigbench strange_stories
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2023-12-01 17:20:13 - INFO :       Use random pruner...
2023-12-01 17:20:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:20:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:20:14 - INFO :       Start Pruning
2023-12-01 17:20:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:20:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:20:16 - INFO :       strange_stories: Total Sparsity 1.3619543236044201e-06
2023-12-01 17:20:16 - INFO :       
==================Finish================

2023-12-01 17:20:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:20:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:20:16 - INFO :       DATASET: tasksource/bigbench strategyqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
2023-12-01 17:20:27 - INFO :       Use random pruner...
2023-12-01 17:20:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:20:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:20:27 - INFO :       Start Pruning
2023-12-01 17:20:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:20:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:20:29 - INFO :       strategyqa: Total Sparsity 1.3577235568730577e-06
2023-12-01 17:20:29 - INFO :       
==================Finish================

2023-12-01 17:20:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:20:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:20:29 - INFO :       DATASET: tasksource/bigbench suicide_risk
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 17:20:41 - INFO :       Use random pruner...
2023-12-01 17:20:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:20:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:20:41 - INFO :       Start Pruning
2023-12-01 17:20:42 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:20:42 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:20:43 - INFO :       suicide_risk: Total Sparsity 1.3577235568730577e-06
2023-12-01 17:20:43 - INFO :       
==================Finish================

2023-12-01 17:20:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:20:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:20:43 - INFO :       DATASET: tasksource/bigbench swahili_english_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.38s/it]
2023-12-01 17:20:56 - INFO :       Use random pruner...
2023-12-01 17:20:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:20:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:20:56 - INFO :       Start Pruning
2023-12-01 17:20:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:20:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:20:58 - INFO :       swahili_english_proverbs: Total Sparsity 1.3601915041330191e-06
2023-12-01 17:20:58 - INFO :       
==================Finish================

2023-12-01 17:20:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:20:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:20:58 - INFO :       DATASET: tasksource/bigbench swedish_to_german_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 17:21:07 - INFO :       Use random pruner...
2023-12-01 17:21:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:21:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:21:08 - INFO :       Start Pruning
2023-12-01 17:21:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:21:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:21:10 - INFO :       swedish_to_german_proverbs: Total Sparsity 1.367066500071483e-06
2023-12-01 17:21:10 - INFO :       
==================Finish================

2023-12-01 17:21:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:21:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:21:10 - INFO :       DATASET: tasksource/bigbench symbol_interpretation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]
2023-12-01 17:21:19 - INFO :       Use random pruner...
2023-12-01 17:21:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:21:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:21:19 - INFO :       Start Pruning
2023-12-01 17:21:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:21:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:21:21 - INFO :       symbol_interpretation: Total Sparsity 1.3524350984588547e-06
2023-12-01 17:21:21 - INFO :       
==================Finish================

2023-12-01 17:21:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:21:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:21:21 - INFO :       DATASET: tasksource/bigbench temporal_sequences
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]
2023-12-01 17:21:31 - INFO :       Use random pruner...
2023-12-01 17:21:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:21:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:21:31 - INFO :       Start Pruning
2023-12-01 17:21:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:21:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:21:33 - INFO :       temporal_sequences: Total Sparsity 1.3598389402387389e-06
2023-12-01 17:21:33 - INFO :       
==================Finish================

2023-12-01 17:21:33 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:21:33 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:21:33 - INFO :       DATASET: tasksource/bigbench timedial
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.22s/it]
2023-12-01 17:21:43 - INFO :       Use random pruner...
2023-12-01 17:21:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:21:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:21:43 - INFO :       Start Pruning
2023-12-01 17:21:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:21:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:21:45 - INFO :       timedial: Total Sparsity 1.3695344473314445e-06
2023-12-01 17:21:45 - INFO :       
==================Finish================

2023-12-01 17:21:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:21:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:21:45 - INFO :       DATASET: tasksource/bigbench tracking_shuffled_objects
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2023-12-01 17:21:54 - INFO :       Use random pruner...
2023-12-01 17:21:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:21:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:21:55 - INFO :       Start Pruning
2023-12-01 17:21:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:21:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:21:56 - INFO :       tracking_shuffled_objects: Total Sparsity 1.3693581653843043e-06
2023-12-01 17:21:56 - INFO :       
==================Finish================

2023-12-01 17:21:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:21:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:21:56 - INFO :       DATASET: tasksource/bigbench understanding_fables
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]
2023-12-01 17:22:04 - INFO :       Use random pruner...
2023-12-01 17:22:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:22:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:22:05 - INFO :       Start Pruning
2023-12-01 17:22:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:22:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:22:07 - INFO :       understanding_fables: Total Sparsity 1.3645985528115216e-06
2023-12-01 17:22:07 - INFO :       
==================Finish================

2023-12-01 17:22:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:22:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:22:07 - INFO :       DATASET: tasksource/bigbench undo_permutation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]
2023-12-01 17:22:15 - INFO :       Use random pruner...
2023-12-01 17:22:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:22:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:22:16 - INFO :       Start Pruning
2023-12-01 17:22:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:22:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:22:18 - INFO :       undo_permutation: Total Sparsity 1.3674190639657633e-06
2023-12-01 17:22:18 - INFO :       
==================Finish================

2023-12-01 17:22:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:22:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:22:18 - INFO :       DATASET: tasksource/bigbench unit_interpretation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]
2023-12-01 17:22:27 - INFO :       Use random pruner...
2023-12-01 17:22:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:22:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:22:27 - INFO :       Start Pruning
2023-12-01 17:22:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:22:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:22:29 - INFO :       unit_interpretation: Total Sparsity 1.356313301295937e-06
2023-12-01 17:22:29 - INFO :       
==================Finish================

2023-12-01 17:22:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:22:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:22:29 - INFO :       DATASET: tasksource/bigbench vitaminc_fact_verification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]
2023-12-01 17:22:39 - INFO :       Use random pruner...
2023-12-01 17:22:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:22:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:22:39 - INFO :       Start Pruning
2023-12-01 17:22:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:22:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:22:41 - INFO :       vitaminc_fact_verification: Total Sparsity 1.3638934250229613e-06
2023-12-01 17:22:41 - INFO :       
==================Finish================

2023-12-01 17:22:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:22:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:22:41 - INFO :       DATASET: tasksource/bigbench what_is_the_tao
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]
2023-12-01 17:22:51 - INFO :       Use random pruner...
2023-12-01 17:22:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:22:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:22:51 - INFO :       Start Pruning
2023-12-01 17:22:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:22:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:22:53 - INFO :       what_is_the_tao: Total Sparsity 1.3621306055515601e-06
2023-12-01 17:22:53 - INFO :       
==================Finish================

2023-12-01 17:22:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:22:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:22:53 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]
2023-12-01 17:23:03 - INFO :       Use random pruner...
2023-12-01 17:23:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:23:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:23:03 - INFO :       Start Pruning
2023-12-01 17:23:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:23:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:23:05 - INFO :       which_wiki_edit: Total Sparsity 1.3556081735073764e-06
2023-12-01 17:23:05 - INFO :       
==================Finish================

2023-12-01 17:23:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:23:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:23:05 - INFO :       DATASET: tasksource/bigbench winowhy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]
2023-12-01 17:23:14 - INFO :       Use random pruner...
2023-12-01 17:23:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:23:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:23:14 - INFO :       Start Pruning
2023-12-01 17:23:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:23:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:23:16 - INFO :       winowhy: Total Sparsity 1.3601915041330191e-06
2023-12-01 17:23:16 - INFO :       
==================Finish================

2023-12-01 17:23:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:23:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:23:16 - INFO :       DATASET: tasksource/mmlu abstract_algebra
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.98s/it]
2023-12-01 17:23:26 - INFO :       Use random pruner...
2023-12-01 17:23:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:23:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:23:26 - INFO :       Start Pruning
2023-12-01 17:23:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:23:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:23:28 - INFO :       abstract_algebra: Total Sparsity 1.3578998388201979e-06
2023-12-01 17:23:28 - INFO :       
==================Finish================

2023-12-01 17:23:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:23:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:23:28 - INFO :       DATASET: tasksource/mmlu anatomy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2023-12-01 17:23:37 - INFO :       Use random pruner...
2023-12-01 17:23:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:23:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:23:37 - INFO :       Start Pruning
2023-12-01 17:23:38 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:23:38 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:23:39 - INFO :       anatomy: Total Sparsity 1.3656562444943623e-06
2023-12-01 17:23:39 - INFO :       
==================Finish================

2023-12-01 17:23:39 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:23:39 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:23:39 - INFO :       DATASET: tasksource/mmlu astronomy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
2023-12-01 17:23:47 - INFO :       Use random pruner...
2023-12-01 17:23:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:23:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:23:47 - INFO :       Start Pruning
2023-12-01 17:23:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:23:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:23:49 - INFO :       astronomy: Total Sparsity 1.3624831694458404e-06
2023-12-01 17:23:49 - INFO :       
==================Finish================

2023-12-01 17:23:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:23:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:23:49 - INFO :       DATASET: tasksource/mmlu business_ethics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]
2023-12-01 17:23:58 - INFO :       Use random pruner...
2023-12-01 17:23:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:23:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:23:59 - INFO :       Start Pruning
2023-12-01 17:23:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:23:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:24:00 - INFO :       business_ethics: Total Sparsity 1.3691818834371643e-06
2023-12-01 17:24:00 - INFO :       
==================Finish================

2023-12-01 17:24:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:24:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:24:00 - INFO :       DATASET: tasksource/mmlu clinical_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]
2023-12-01 17:24:09 - INFO :       Use random pruner...
2023-12-01 17:24:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:24:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:24:10 - INFO :       Start Pruning
2023-12-01 17:24:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:24:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:24:11 - INFO :       clinical_knowledge: Total Sparsity 1.370415857067145e-06
2023-12-01 17:24:11 - INFO :       
==================Finish================

2023-12-01 17:24:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:24:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:24:11 - INFO :       DATASET: tasksource/mmlu college_biology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 17:24:21 - INFO :       Use random pruner...
2023-12-01 17:24:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:24:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:24:22 - INFO :       Start Pruning
2023-12-01 17:24:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:24:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:24:24 - INFO :       college_biology: Total Sparsity 1.353140226247415e-06
2023-12-01 17:24:24 - INFO :       
==================Finish================

2023-12-01 17:24:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:24:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:24:24 - INFO :       DATASET: tasksource/mmlu college_chemistry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2023-12-01 17:24:33 - INFO :       Use random pruner...
2023-12-01 17:24:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:24:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:24:33 - INFO :       Start Pruning
2023-12-01 17:24:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:24:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:24:35 - INFO :       college_chemistry: Total Sparsity 1.3675953459129033e-06
2023-12-01 17:24:35 - INFO :       
==================Finish================

2023-12-01 17:24:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:24:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:24:35 - INFO :       DATASET: tasksource/mmlu college_computer_science
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]
2023-12-01 17:24:45 - INFO :       Use random pruner...
2023-12-01 17:24:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:24:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:24:45 - INFO :       Start Pruning
2023-12-01 17:24:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:24:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:24:47 - INFO :       college_computer_science: Total Sparsity 1.3619543236044201e-06
2023-12-01 17:24:47 - INFO :       
==================Finish================

2023-12-01 17:24:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:24:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:24:47 - INFO :       DATASET: tasksource/mmlu college_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 17:24:56 - INFO :       Use random pruner...
2023-12-01 17:24:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:24:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:24:56 - INFO :       Start Pruning
2023-12-01 17:24:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:24:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:24:58 - INFO :       college_mathematics: Total Sparsity 1.3649511167058018e-06
2023-12-01 17:24:58 - INFO :       
==================Finish================

2023-12-01 17:24:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:24:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:24:58 - INFO :       DATASET: tasksource/mmlu college_medicine
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]
2023-12-01 17:25:07 - INFO :       Use random pruner...
2023-12-01 17:25:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:25:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:25:08 - INFO :       Start Pruning
2023-12-01 17:25:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:25:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:25:10 - INFO :       college_medicine: Total Sparsity 1.3695344473314445e-06
2023-12-01 17:25:10 - INFO :       
==================Finish================

2023-12-01 17:25:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:25:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:25:10 - INFO :       DATASET: tasksource/mmlu college_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2023-12-01 17:25:19 - INFO :       Use random pruner...
2023-12-01 17:25:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:25:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:25:19 - INFO :       Start Pruning
2023-12-01 17:25:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:25:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:25:21 - INFO :       college_physics: Total Sparsity 1.3707684209614252e-06
2023-12-01 17:25:21 - INFO :       
==================Finish================

2023-12-01 17:25:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:25:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:25:21 - INFO :       DATASET: tasksource/mmlu computer_security
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 17:25:31 - INFO :       Use random pruner...
2023-12-01 17:25:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:25:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:25:32 - INFO :       Start Pruning
2023-12-01 17:25:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:25:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:25:34 - INFO :       computer_security: Total Sparsity 1.3575472749259176e-06
2023-12-01 17:25:34 - INFO :       
==================Finish================

2023-12-01 17:25:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:25:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:25:34 - INFO :       DATASET: tasksource/mmlu conceptual_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 17:25:43 - INFO :       Use random pruner...
2023-12-01 17:25:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:25:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:25:43 - INFO :       Start Pruning
2023-12-01 17:25:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:25:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:25:45 - INFO :       conceptual_physics: Total Sparsity 1.360015222185879e-06
2023-12-01 17:25:45 - INFO :       
==================Finish================

2023-12-01 17:25:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:25:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:25:45 - INFO :       DATASET: tasksource/mmlu econometrics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
2023-12-01 17:25:54 - INFO :       Use random pruner...
2023-12-01 17:25:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:25:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:25:55 - INFO :       Start Pruning
2023-12-01 17:25:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:25:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:25:56 - INFO :       econometrics: Total Sparsity 1.3647748347586618e-06
2023-12-01 17:25:56 - INFO :       
==================Finish================

2023-12-01 17:25:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:25:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:25:56 - INFO :       DATASET: tasksource/mmlu electrical_engineering
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]
2023-12-01 17:26:04 - INFO :       Use random pruner...
2023-12-01 17:26:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:26:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:26:04 - INFO :       Start Pruning
2023-12-01 17:26:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:26:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:26:06 - INFO :       electrical_engineering: Total Sparsity 1.3638934250229613e-06
2023-12-01 17:26:06 - INFO :       
==================Finish================

2023-12-01 17:26:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:26:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:26:06 - INFO :       DATASET: tasksource/mmlu elementary_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]
2023-12-01 17:26:15 - INFO :       Use random pruner...
2023-12-01 17:26:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:26:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:26:15 - INFO :       Start Pruning
2023-12-01 17:26:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:26:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:26:17 - INFO :       elementary_mathematics: Total Sparsity 1.3663613722829226e-06
2023-12-01 17:26:17 - INFO :       
==================Finish================

2023-12-01 17:26:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:26:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:26:17 - INFO :       DATASET: tasksource/mmlu formal_logic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]
2023-12-01 17:26:26 - INFO :       Use random pruner...
2023-12-01 17:26:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:26:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:26:26 - INFO :       Start Pruning
2023-12-01 17:26:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:26:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:26:28 - INFO :       formal_logic: Total Sparsity 1.3714735487499855e-06
2023-12-01 17:26:28 - INFO :       
==================Finish================

2023-12-01 17:26:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:26:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:26:28 - INFO :       DATASET: tasksource/mmlu global_facts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2023-12-01 17:26:37 - INFO :       Use random pruner...
2023-12-01 17:26:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:26:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:26:38 - INFO :       Start Pruning
2023-12-01 17:26:38 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:26:38 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:26:39 - INFO :       global_facts: Total Sparsity 1.3720023945914058e-06
2023-12-01 17:26:39 - INFO :       
==================Finish================

2023-12-01 17:26:39 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:26:39 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:26:39 - INFO :       DATASET: tasksource/mmlu high_school_biology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]
2023-12-01 17:26:47 - INFO :       Use random pruner...
2023-12-01 17:26:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:26:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:26:48 - INFO :       Start Pruning
2023-12-01 17:26:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:26:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:26:49 - INFO :       high_school_biology: Total Sparsity 1.3605440680272994e-06
2023-12-01 17:26:49 - INFO :       
==================Finish================

2023-12-01 17:26:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:26:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:26:49 - INFO :       DATASET: tasksource/mmlu high_school_chemistry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
2023-12-01 17:26:58 - INFO :       Use random pruner...
2023-12-01 17:26:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:26:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:26:58 - INFO :       Start Pruning
2023-12-01 17:26:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:26:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:27:00 - INFO :       high_school_chemistry: Total Sparsity 1.3603677860801591e-06
2023-12-01 17:27:00 - INFO :       
==================Finish================

2023-12-01 17:27:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:27:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:27:00 - INFO :       DATASET: tasksource/mmlu high_school_computer_science
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.31s/it]
2023-12-01 17:27:12 - INFO :       Use random pruner...
2023-12-01 17:27:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:27:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:27:12 - INFO :       Start Pruning
2023-12-01 17:27:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:27:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:27:14 - INFO :       high_school_computer_science: Total Sparsity 1.363540861128681e-06
2023-12-01 17:27:14 - INFO :       
==================Finish================

2023-12-01 17:27:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:27:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:27:14 - INFO :       DATASET: tasksource/mmlu high_school_european_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.42s/it]
2023-12-01 17:27:26 - INFO :       Use random pruner...
2023-12-01 17:27:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:27:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:27:27 - INFO :       Start Pruning
2023-12-01 17:27:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:27:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:27:29 - INFO :       high_school_european_history: Total Sparsity 1.3591338124501784e-06
2023-12-01 17:27:29 - INFO :       
==================Finish================

2023-12-01 17:27:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:27:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:27:29 - INFO :       DATASET: tasksource/mmlu high_school_geography
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]
2023-12-01 17:27:41 - INFO :       Use random pruner...
2023-12-01 17:27:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:27:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:27:41 - INFO :       Start Pruning
2023-12-01 17:27:42 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:27:42 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:27:43 - INFO :       high_school_geography: Total Sparsity 1.3679479098071835e-06
2023-12-01 17:27:43 - INFO :       
==================Finish================

2023-12-01 17:27:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:27:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:27:43 - INFO :       DATASET: tasksource/mmlu high_school_government_and_politics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]
2023-12-01 17:27:54 - INFO :       Use random pruner...
2023-12-01 17:27:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:27:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:27:55 - INFO :       Start Pruning
2023-12-01 17:27:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:27:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:27:56 - INFO :       high_school_government_and_politics: Total Sparsity 1.3626594513929806e-06
2023-12-01 17:27:56 - INFO :       
==================Finish================

2023-12-01 17:27:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:27:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:27:56 - INFO :       DATASET: tasksource/mmlu high_school_macroeconomics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]
2023-12-01 17:28:08 - INFO :       Use random pruner...
2023-12-01 17:28:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:28:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:28:08 - INFO :       Start Pruning
2023-12-01 17:28:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:28:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:28:10 - INFO :       high_school_macroeconomics: Total Sparsity 1.3684767556486038e-06
2023-12-01 17:28:10 - INFO :       
==================Finish================

2023-12-01 17:28:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:28:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:28:10 - INFO :       DATASET: tasksource/mmlu high_school_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 17:28:21 - INFO :       Use random pruner...
2023-12-01 17:28:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:28:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:28:22 - INFO :       Start Pruning
2023-12-01 17:28:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:28:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:28:24 - INFO :       high_school_mathematics: Total Sparsity 1.3667139361772028e-06
2023-12-01 17:28:24 - INFO :       
==================Finish================

2023-12-01 17:28:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:28:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:28:24 - INFO :       DATASET: tasksource/mmlu high_school_microeconomics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.32s/it]
2023-12-01 17:28:35 - INFO :       Use random pruner...
2023-12-01 17:28:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:28:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:28:36 - INFO :       Start Pruning
2023-12-01 17:28:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:28:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:28:37 - INFO :       high_school_microeconomics: Total Sparsity 1.3711209848557053e-06
2023-12-01 17:28:37 - INFO :       
==================Finish================

2023-12-01 17:28:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:28:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:28:37 - INFO :       DATASET: tasksource/mmlu high_school_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2023-12-01 17:28:47 - INFO :       Use random pruner...
2023-12-01 17:28:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:28:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:28:47 - INFO :       Start Pruning
2023-12-01 17:28:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:28:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:28:49 - INFO :       high_school_physics: Total Sparsity 1.3619543236044201e-06
2023-12-01 17:28:49 - INFO :       
==================Finish================

2023-12-01 17:28:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:28:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:28:49 - INFO :       DATASET: tasksource/mmlu high_school_psychology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]
2023-12-01 17:29:01 - INFO :       Use random pruner...
2023-12-01 17:29:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:29:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:29:01 - INFO :       Start Pruning
2023-12-01 17:29:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:29:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:29:03 - INFO :       high_school_psychology: Total Sparsity 1.3727075223799662e-06
2023-12-01 17:29:03 - INFO :       
==================Finish================

2023-12-01 17:29:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:29:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:29:03 - INFO :       DATASET: tasksource/mmlu high_school_statistics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2023-12-01 17:29:13 - INFO :       Use random pruner...
2023-12-01 17:29:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:29:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:29:13 - INFO :       Start Pruning
2023-12-01 17:29:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:29:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:29:15 - INFO :       high_school_statistics: Total Sparsity 1.3684767556486038e-06
2023-12-01 17:29:15 - INFO :       
==================Finish================

2023-12-01 17:29:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:29:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:29:15 - INFO :       DATASET: tasksource/mmlu high_school_us_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 17:29:21 - INFO :       Use random pruner...
2023-12-01 17:29:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:29:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:29:22 - INFO :       Start Pruning
2023-12-01 17:29:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:29:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:29:23 - INFO :       high_school_us_history: Total Sparsity 1.363717143075821e-06
2023-12-01 17:29:23 - INFO :       
==================Finish================

2023-12-01 17:29:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:29:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:29:23 - INFO :       DATASET: tasksource/mmlu high_school_world_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 17:29:30 - INFO :       Use random pruner...
2023-12-01 17:29:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:29:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:29:31 - INFO :       Start Pruning
2023-12-01 17:29:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:29:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:29:32 - INFO :       high_school_world_history: Total Sparsity 1.3559607374016567e-06
2023-12-01 17:29:32 - INFO :       
==================Finish================

2023-12-01 17:29:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:29:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:29:32 - INFO :       DATASET: tasksource/mmlu human_aging
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]
2023-12-01 17:29:39 - INFO :       Use random pruner...
2023-12-01 17:29:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:29:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:29:39 - INFO :       Start Pruning
2023-12-01 17:29:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:29:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:29:41 - INFO :       human_aging: Total Sparsity 1.3702395751200048e-06
2023-12-01 17:29:41 - INFO :       
==================Finish================

2023-12-01 17:29:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:29:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:29:41 - INFO :       DATASET: tasksource/mmlu human_sexuality
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 17:29:48 - INFO :       Use random pruner...
2023-12-01 17:29:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:29:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:29:48 - INFO :       Start Pruning
2023-12-01 17:29:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:29:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:29:50 - INFO :       human_sexuality: Total Sparsity 1.365479962547222e-06
2023-12-01 17:29:50 - INFO :       
==================Finish================

2023-12-01 17:29:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:29:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:29:50 - INFO :       DATASET: tasksource/mmlu international_law
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 17:29:57 - INFO :       Use random pruner...
2023-12-01 17:29:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:29:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:29:57 - INFO :       Start Pruning
2023-12-01 17:29:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:29:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:29:59 - INFO :       international_law: Total Sparsity 1.3674190639657633e-06
2023-12-01 17:29:59 - INFO :       
==================Finish================

2023-12-01 17:29:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:29:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:29:59 - INFO :       DATASET: tasksource/mmlu jurisprudence
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 17:30:08 - INFO :       Use random pruner...
2023-12-01 17:30:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:30:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:30:08 - INFO :       Start Pruning
2023-12-01 17:30:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:30:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:30:10 - INFO :       jurisprudence: Total Sparsity 1.3575472749259176e-06
2023-12-01 17:30:10 - INFO :       
==================Finish================

2023-12-01 17:30:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:30:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:30:10 - INFO :       DATASET: tasksource/mmlu logical_fallacies
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]
2023-12-01 17:30:21 - INFO :       Use random pruner...
2023-12-01 17:30:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:30:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:30:21 - INFO :       Start Pruning
2023-12-01 17:30:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:30:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:30:23 - INFO :       logical_fallacies: Total Sparsity 1.3610729138687196e-06
2023-12-01 17:30:23 - INFO :       
==================Finish================

2023-12-01 17:30:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:30:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:30:23 - INFO :       DATASET: tasksource/mmlu machine_learning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2023-12-01 17:30:33 - INFO :       Use random pruner...
2023-12-01 17:30:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:30:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:30:34 - INFO :       Start Pruning
2023-12-01 17:30:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:30:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:30:35 - INFO :       machine_learning: Total Sparsity 1.3596626582915989e-06
2023-12-01 17:30:35 - INFO :       
==================Finish================

2023-12-01 17:30:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:30:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:30:35 - INFO :       DATASET: tasksource/mmlu management
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]
2023-12-01 17:30:44 - INFO :       Use random pruner...
2023-12-01 17:30:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:30:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:30:44 - INFO :       Start Pruning
2023-12-01 17:30:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:30:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:30:46 - INFO :       management: Total Sparsity 1.3584286846616181e-06
2023-12-01 17:30:46 - INFO :       
==================Finish================

2023-12-01 17:30:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:30:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:30:46 - INFO :       DATASET: tasksource/mmlu marketing
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2023-12-01 17:30:56 - INFO :       Use random pruner...
2023-12-01 17:30:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:30:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:30:56 - INFO :       Start Pruning
2023-12-01 17:30:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:30:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:30:58 - INFO :       marketing: Total Sparsity 1.3601915041330191e-06
2023-12-01 17:30:58 - INFO :       
==================Finish================

2023-12-01 17:30:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:30:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:30:58 - INFO :       DATASET: tasksource/mmlu medical_genetics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 17:31:07 - INFO :       Use random pruner...
2023-12-01 17:31:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:31:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:31:07 - INFO :       Start Pruning
2023-12-01 17:31:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:31:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:31:09 - INFO :       medical_genetics: Total Sparsity 1.3661850903357826e-06
2023-12-01 17:31:09 - INFO :       
==================Finish================

2023-12-01 17:31:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:31:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:31:09 - INFO :       DATASET: tasksource/mmlu miscellaneous
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
2023-12-01 17:31:18 - INFO :       Use random pruner...
2023-12-01 17:31:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:31:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:31:18 - INFO :       Start Pruning
2023-12-01 17:31:19 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:31:19 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:31:20 - INFO :       miscellaneous: Total Sparsity 1.3607203499744394e-06
2023-12-01 17:31:20 - INFO :       
==================Finish================

2023-12-01 17:31:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:31:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:31:20 - INFO :       DATASET: tasksource/mmlu moral_disputes
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.91s/it]
2023-12-01 17:31:29 - INFO :       Use random pruner...
2023-12-01 17:31:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:31:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:31:29 - INFO :       Start Pruning
2023-12-01 17:31:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:31:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:31:31 - INFO :       moral_disputes: Total Sparsity 1.3584286846616181e-06
2023-12-01 17:31:31 - INFO :       
==================Finish================

2023-12-01 17:31:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:31:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:31:31 - INFO :       DATASET: tasksource/mmlu moral_scenarios
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 17:31:40 - INFO :       Use random pruner...
2023-12-01 17:31:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:31:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:31:41 - INFO :       Start Pruning
2023-12-01 17:31:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:31:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:31:42 - INFO :       moral_scenarios: Total Sparsity 1.3651273986529418e-06
2023-12-01 17:31:42 - INFO :       
==================Finish================

2023-12-01 17:31:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:31:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:31:42 - INFO :       DATASET: tasksource/mmlu nutrition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.23s/it]
2023-12-01 17:31:54 - INFO :       Use random pruner...
2023-12-01 17:31:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:31:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:31:54 - INFO :       Start Pruning
2023-12-01 17:31:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:31:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:31:56 - INFO :       nutrition: Total Sparsity 1.3556081735073764e-06
2023-12-01 17:31:56 - INFO :       
==================Finish================

2023-12-01 17:31:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:31:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:31:56 - INFO :       DATASET: tasksource/mmlu philosophy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 17:32:05 - INFO :       Use random pruner...
2023-12-01 17:32:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:32:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:32:05 - INFO :       Start Pruning
2023-12-01 17:32:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:32:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:32:07 - INFO :       philosophy: Total Sparsity 1.370592139014285e-06
2023-12-01 17:32:07 - INFO :       
==================Finish================

2023-12-01 17:32:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:32:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:32:07 - INFO :       DATASET: tasksource/mmlu prehistory
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]
2023-12-01 17:32:16 - INFO :       Use random pruner...
2023-12-01 17:32:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:32:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:32:17 - INFO :       Start Pruning
2023-12-01 17:32:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:32:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:32:19 - INFO :       prehistory: Total Sparsity 1.3628357333401206e-06
2023-12-01 17:32:19 - INFO :       
==================Finish================

2023-12-01 17:32:19 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:32:19 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:32:19 - INFO :       DATASET: tasksource/mmlu professional_accounting
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2023-12-01 17:32:28 - INFO :       Use random pruner...
2023-12-01 17:32:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:32:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:32:29 - INFO :       Start Pruning
2023-12-01 17:32:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:32:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:32:30 - INFO :       professional_accounting: Total Sparsity 1.3621306055515601e-06
2023-12-01 17:32:30 - INFO :       
==================Finish================

2023-12-01 17:32:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:32:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:32:30 - INFO :       DATASET: tasksource/mmlu professional_law
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2023-12-01 17:32:40 - INFO :       Use random pruner...
2023-12-01 17:32:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:32:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:32:40 - INFO :       Start Pruning
2023-12-01 17:32:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:32:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:32:42 - INFO :       professional_law: Total Sparsity 1.3626594513929806e-06
2023-12-01 17:32:42 - INFO :       
==================Finish================

2023-12-01 17:32:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:32:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:32:42 - INFO :       DATASET: tasksource/mmlu professional_medicine
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.47s/it]
2023-12-01 17:32:54 - INFO :       Use random pruner...
2023-12-01 17:32:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:32:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:32:55 - INFO :       Start Pruning
2023-12-01 17:32:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:32:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:32:56 - INFO :       professional_medicine: Total Sparsity 1.3681241917543236e-06
2023-12-01 17:32:56 - INFO :       
==================Finish================

2023-12-01 17:32:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:32:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:32:56 - INFO :       DATASET: tasksource/mmlu professional_psychology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.43s/it]
2023-12-01 17:33:10 - INFO :       Use random pruner...
2023-12-01 17:33:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:33:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:33:10 - INFO :       Start Pruning
2023-12-01 17:33:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:33:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:33:12 - INFO :       professional_psychology: Total Sparsity 1.3651273986529418e-06
2023-12-01 17:33:12 - INFO :       
==================Finish================

2023-12-01 17:33:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:33:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:33:12 - INFO :       DATASET: tasksource/mmlu public_relations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.28s/it]
2023-12-01 17:33:24 - INFO :       Use random pruner...
2023-12-01 17:33:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:33:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:33:24 - INFO :       Start Pruning
2023-12-01 17:33:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:33:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:33:26 - INFO :       public_relations: Total Sparsity 1.3683004737014638e-06
2023-12-01 17:33:26 - INFO :       
==================Finish================

2023-12-01 17:33:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:33:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:33:26 - INFO :       DATASET: tasksource/mmlu security_studies
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2023-12-01 17:33:35 - INFO :       Use random pruner...
2023-12-01 17:33:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:33:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:33:35 - INFO :       Start Pruning
2023-12-01 17:33:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:33:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:33:37 - INFO :       security_studies: Total Sparsity 1.3575472749259176e-06
2023-12-01 17:33:37 - INFO :       
==================Finish================

2023-12-01 17:33:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:33:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:33:37 - INFO :       DATASET: tasksource/mmlu sociology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]
2023-12-01 17:33:44 - INFO :       Use random pruner...
2023-12-01 17:33:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:33:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:33:45 - INFO :       Start Pruning
2023-12-01 17:33:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:33:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:33:46 - INFO :       sociology: Total Sparsity 1.363717143075821e-06
2023-12-01 17:33:46 - INFO :       
==================Finish================

2023-12-01 17:33:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:33:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:33:46 - INFO :       DATASET: tasksource/mmlu us_foreign_policy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2023-12-01 17:33:56 - INFO :       Use random pruner...
2023-12-01 17:33:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:33:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:33:57 - INFO :       Start Pruning
2023-12-01 17:33:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:33:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:33:58 - INFO :       us_foreign_policy: Total Sparsity 1.3598389402387389e-06
2023-12-01 17:33:58 - INFO :       
==================Finish================

2023-12-01 17:33:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:33:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:33:58 - INFO :       DATASET: tasksource/mmlu virology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]
2023-12-01 17:34:08 - INFO :       Use random pruner...
2023-12-01 17:34:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:34:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:34:08 - INFO :       Start Pruning
2023-12-01 17:34:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:34:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:34:10 - INFO :       virology: Total Sparsity 1.3658325264415023e-06
2023-12-01 17:34:10 - INFO :       
==================Finish================

2023-12-01 17:34:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:34:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:34:10 - INFO :       DATASET: tasksource/mmlu world_religions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.22s/it]
2023-12-01 17:34:20 - INFO :       Use random pruner...
2023-12-01 17:34:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:34:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:34:21 - INFO :       Start Pruning
2023-12-01 17:34:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:34:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:34:22 - INFO :       world_religions: Total Sparsity 1.3561370193487967e-06
2023-12-01 17:34:22 - INFO :       
==================Finish================

2023-12-01 17:34:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:34:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:34:22 - INFO :       DATASET: math_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
2023-12-01 17:34:31 - INFO :       Use random pruner...
2023-12-01 17:34:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:34:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:34:31 - INFO :       Start Pruning
2023-12-01 17:34:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:34:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:34:33 - INFO :       math_qa: Total Sparsity 1.3571947110316374e-06
2023-12-01 17:34:33 - INFO :       
==================Finish================

2023-12-01 17:34:33 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:34:33 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:34:33 - INFO :       DATASET: EleutherAI/truthful_qa_mc
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 17:34:43 - INFO :       Use random pruner...
2023-12-01 17:34:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:34:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:34:43 - INFO :       Start Pruning
2023-12-01 17:34:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:34:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:34:45 - INFO :       truthful_qa_mc: Total Sparsity 1.3550793276659562e-06
2023-12-01 17:34:45 - INFO :       
==================Finish================

2023-12-01 17:34:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:34:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:34:45 - INFO :       DATASET: derek-thomas/ScienceQA
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 17:34:55 - INFO :       Use random pruner...
2023-12-01 17:34:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:34:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:34:55 - INFO :       Start Pruning
2023-12-01 17:34:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:34:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:34:57 - INFO :       ScienceQA: Total Sparsity 1.3533165081945552e-06
2023-12-01 17:34:57 - INFO :       
==================Finish================

2023-12-01 17:34:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:34:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:34:57 - INFO :       DATASET: commonsense_qa
Index 3
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2023-12-01 17:35:08 - INFO :       Use random pruner...
2023-12-01 17:35:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:35:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:35:09 - INFO :       Start Pruning
2023-12-01 17:35:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:35:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:35:11 - INFO :       commonsense_qa: Total Sparsity 1.3667139361772028e-06
2023-12-01 17:35:11 - INFO :       
==================Finish================

2023-12-01 17:35:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:35:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:35:11 - INFO :       DATASET: tasksource/bigbench abstract_narrative_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2023-12-01 17:35:21 - INFO :       Use random pruner...
2023-12-01 17:35:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:35:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:35:21 - INFO :       Start Pruning
2023-12-01 17:35:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:35:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:35:23 - INFO :       abstract_narrative_understanding: Total Sparsity 1.3674190639657633e-06
2023-12-01 17:35:23 - INFO :       
==================Finish================

2023-12-01 17:35:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:35:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:35:23 - INFO :       DATASET: tasksource/bigbench anachronisms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]
2023-12-01 17:35:34 - INFO :       Use random pruner...
2023-12-01 17:35:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:35:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:35:34 - INFO :       Start Pruning
2023-12-01 17:35:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:35:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:35:36 - INFO :       anachronisms: Total Sparsity 1.352787662353135e-06
2023-12-01 17:35:36 - INFO :       
==================Finish================

2023-12-01 17:35:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:35:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:35:36 - INFO :       DATASET: tasksource/bigbench analogical_similarity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2023-12-01 17:35:45 - INFO :       Use random pruner...
2023-12-01 17:35:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:35:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:35:45 - INFO :       Start Pruning
2023-12-01 17:35:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:35:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:35:47 - INFO :       analogical_similarity: Total Sparsity 1.3612491958158596e-06
2023-12-01 17:35:47 - INFO :       
==================Finish================

2023-12-01 17:35:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:35:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:35:47 - INFO :       DATASET: tasksource/bigbench analytic_entailment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 17:35:56 - INFO :       Use random pruner...
2023-12-01 17:35:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:35:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:35:56 - INFO :       Start Pruning
2023-12-01 17:35:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:35:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:35:58 - INFO :       analytic_entailment: Total Sparsity 1.3603677860801591e-06
2023-12-01 17:35:58 - INFO :       
==================Finish================

2023-12-01 17:35:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:35:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:35:58 - INFO :       DATASET: tasksource/bigbench arithmetic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 17:36:06 - INFO :       Use random pruner...
2023-12-01 17:36:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:36:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:36:06 - INFO :       Start Pruning
2023-12-01 17:36:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:36:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:36:08 - INFO :       arithmetic: Total Sparsity 1.3594863763444586e-06
2023-12-01 17:36:08 - INFO :       
==================Finish================

2023-12-01 17:36:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:36:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:36:08 - INFO :       DATASET: tasksource/bigbench authorship_verification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 17:36:17 - INFO :       Use random pruner...
2023-12-01 17:36:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:36:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:36:17 - INFO :       Start Pruning
2023-12-01 17:36:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:36:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:36:19 - INFO :       authorship_verification: Total Sparsity 1.363540861128681e-06
2023-12-01 17:36:19 - INFO :       
==================Finish================

2023-12-01 17:36:19 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:36:19 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:36:19 - INFO :       DATASET: tasksource/bigbench bbq_lite_json
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 17:36:29 - INFO :       Use random pruner...
2023-12-01 17:36:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:36:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:36:30 - INFO :       Start Pruning
2023-12-01 17:36:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:36:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:36:31 - INFO :       bbq_lite_json: Total Sparsity 1.3700632931728648e-06
2023-12-01 17:36:31 - INFO :       
==================Finish================

2023-12-01 17:36:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:36:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:36:31 - INFO :       DATASET: tasksource/bigbench causal_judgment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]
2023-12-01 17:36:40 - INFO :       Use random pruner...
2023-12-01 17:36:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:36:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:36:40 - INFO :       Start Pruning
2023-12-01 17:36:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:36:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:36:42 - INFO :       causal_judgment: Total Sparsity 1.3612491958158596e-06
2023-12-01 17:36:42 - INFO :       
==================Finish================

2023-12-01 17:36:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:36:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:36:42 - INFO :       DATASET: tasksource/bigbench cause_and_effect
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.46s/it]
2023-12-01 17:36:51 - INFO :       Use random pruner...
2023-12-01 17:36:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:36:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:36:52 - INFO :       Start Pruning
2023-12-01 17:36:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:36:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:36:53 - INFO :       cause_and_effect: Total Sparsity 1.3571947110316374e-06
2023-12-01 17:36:53 - INFO :       
==================Finish================

2023-12-01 17:36:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:36:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:36:53 - INFO :       DATASET: tasksource/bigbench checkmate_in_one
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]
2023-12-01 17:37:00 - INFO :       Use random pruner...
2023-12-01 17:37:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:37:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:37:00 - INFO :       Start Pruning
2023-12-01 17:37:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:37:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:37:02 - INFO :       checkmate_in_one: Total Sparsity 1.3663613722829226e-06
2023-12-01 17:37:02 - INFO :       
==================Finish================

2023-12-01 17:37:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:37:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:37:02 - INFO :       DATASET: tasksource/bigbench cifar10_classification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2023-12-01 17:37:12 - INFO :       Use random pruner...
2023-12-01 17:37:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:37:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:37:12 - INFO :       Start Pruning
2023-12-01 17:37:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:37:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:37:14 - INFO :       cifar10_classification: Total Sparsity 1.3647748347586618e-06
2023-12-01 17:37:14 - INFO :       
==================Finish================

2023-12-01 17:37:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:37:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:37:14 - INFO :       DATASET: tasksource/bigbench code_line_description
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
2023-12-01 17:37:23 - INFO :       Use random pruner...
2023-12-01 17:37:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:37:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:37:23 - INFO :       Start Pruning
2023-12-01 17:37:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:37:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:37:25 - INFO :       code_line_description: Total Sparsity 1.3506722789874537e-06
2023-12-01 17:37:25 - INFO :       
==================Finish================

2023-12-01 17:37:25 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:37:25 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:37:25 - INFO :       DATASET: tasksource/bigbench color
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 17:37:33 - INFO :       Use random pruner...
2023-12-01 17:37:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:37:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:37:34 - INFO :       Start Pruning
2023-12-01 17:37:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:37:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:37:36 - INFO :       color: Total Sparsity 1.3538453540359754e-06
2023-12-01 17:37:36 - INFO :       
==================Finish================

2023-12-01 17:37:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:37:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:37:36 - INFO :       DATASET: tasksource/bigbench common_morpheme
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 17:37:43 - INFO :       Use random pruner...
2023-12-01 17:37:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:37:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:37:43 - INFO :       Start Pruning
2023-12-01 17:37:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:37:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:37:45 - INFO :       common_morpheme: Total Sparsity 1.3598389402387389e-06
2023-12-01 17:37:45 - INFO :       
==================Finish================

2023-12-01 17:37:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:37:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:37:45 - INFO :       DATASET: tasksource/bigbench conceptual_combinations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 17:37:53 - INFO :       Use random pruner...
2023-12-01 17:37:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:37:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:37:53 - INFO :       Start Pruning
2023-12-01 17:37:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:37:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:37:55 - INFO :       conceptual_combinations: Total Sparsity 1.3623068874987003e-06
2023-12-01 17:37:55 - INFO :       
==================Finish================

2023-12-01 17:37:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:37:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:37:55 - INFO :       DATASET: tasksource/bigbench crash_blossom
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
2023-12-01 17:38:04 - INFO :       Use random pruner...
2023-12-01 17:38:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:38:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:38:04 - INFO :       Start Pruning
2023-12-01 17:38:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:38:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:38:06 - INFO :       crash_blossom: Total Sparsity 1.3550793276659562e-06
2023-12-01 17:38:06 - INFO :       
==================Finish================

2023-12-01 17:38:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:38:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:38:06 - INFO :       DATASET: tasksource/bigbench crass_ai
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 17:38:15 - INFO :       Use random pruner...
2023-12-01 17:38:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:38:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:38:16 - INFO :       Start Pruning
2023-12-01 17:38:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:38:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:38:18 - INFO :       crass_ai: Total Sparsity 1.36177804165728e-06
2023-12-01 17:38:18 - INFO :       
==================Finish================

2023-12-01 17:38:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:38:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:38:18 - INFO :       DATASET: tasksource/bigbench cryobiology_spanish
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]
2023-12-01 17:38:28 - INFO :       Use random pruner...
2023-12-01 17:38:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:38:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:38:28 - INFO :       Start Pruning
2023-12-01 17:38:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:38:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:38:30 - INFO :       cryobiology_spanish: Total Sparsity 1.3695344473314445e-06
2023-12-01 17:38:30 - INFO :       
==================Finish================

2023-12-01 17:38:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:38:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:38:30 - INFO :       DATASET: tasksource/bigbench cs_algorithms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 17:38:40 - INFO :       Use random pruner...
2023-12-01 17:38:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:38:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:38:40 - INFO :       Start Pruning
2023-12-01 17:38:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:38:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:38:42 - INFO :       cs_algorithms: Total Sparsity 1.3663613722829226e-06
2023-12-01 17:38:42 - INFO :       
==================Finish================

2023-12-01 17:38:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:38:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:38:42 - INFO :       DATASET: tasksource/bigbench dark_humor_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]
2023-12-01 17:38:51 - INFO :       Use random pruner...
2023-12-01 17:38:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:38:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:38:52 - INFO :       Start Pruning
2023-12-01 17:38:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:38:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:38:53 - INFO :       dark_humor_detection: Total Sparsity 1.354550481824536e-06
2023-12-01 17:38:53 - INFO :       
==================Finish================

2023-12-01 17:38:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:38:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:38:53 - INFO :       DATASET: tasksource/bigbench date_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]
2023-12-01 17:39:03 - INFO :       Use random pruner...
2023-12-01 17:39:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:39:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:39:03 - INFO :       Start Pruning
2023-12-01 17:39:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:39:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:39:05 - INFO :       date_understanding: Total Sparsity 1.3603677860801591e-06
2023-12-01 17:39:05 - INFO :       
==================Finish================

2023-12-01 17:39:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:39:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:39:05 - INFO :       DATASET: tasksource/bigbench disambiguation_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]
2023-12-01 17:39:14 - INFO :       Use random pruner...
2023-12-01 17:39:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:39:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:39:15 - INFO :       Start Pruning
2023-12-01 17:39:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:39:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:39:16 - INFO :       disambiguation_qa: Total Sparsity 1.3608966319215796e-06
2023-12-01 17:39:16 - INFO :       
==================Finish================

2023-12-01 17:39:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:39:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:39:16 - INFO :       DATASET: tasksource/bigbench discourse_marker_prediction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2023-12-01 17:39:25 - INFO :       Use random pruner...
2023-12-01 17:39:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:39:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:39:25 - INFO :       Start Pruning
2023-12-01 17:39:26 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:39:26 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:39:27 - INFO :       discourse_marker_prediction: Total Sparsity 1.3610729138687196e-06
2023-12-01 17:39:27 - INFO :       
==================Finish================

2023-12-01 17:39:27 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:39:27 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:39:27 - INFO :       DATASET: tasksource/bigbench dyck_languages
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]
2023-12-01 17:39:37 - INFO :       Use random pruner...
2023-12-01 17:39:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:39:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:39:38 - INFO :       Start Pruning
2023-12-01 17:39:38 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:39:38 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:39:39 - INFO :       dyck_languages: Total Sparsity 1.3647748347586618e-06
2023-12-01 17:39:39 - INFO :       
==================Finish================

2023-12-01 17:39:39 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:39:39 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:39:39 - INFO :       DATASET: tasksource/bigbench elementary_math_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]
2023-12-01 17:39:47 - INFO :       Use random pruner...
2023-12-01 17:39:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:39:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:39:47 - INFO :       Start Pruning
2023-12-01 17:39:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:39:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:39:49 - INFO :       elementary_math_qa: Total Sparsity 1.3619543236044201e-06
2023-12-01 17:39:49 - INFO :       
==================Finish================

2023-12-01 17:39:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:39:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:39:49 - INFO :       DATASET: tasksource/bigbench emoji_movie
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2023-12-01 17:39:58 - INFO :       Use random pruner...
2023-12-01 17:39:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:39:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:39:58 - INFO :       Start Pruning
2023-12-01 17:39:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:39:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:40:00 - INFO :       emoji_movie: Total Sparsity 1.3533165081945552e-06
2023-12-01 17:40:00 - INFO :       
==================Finish================

2023-12-01 17:40:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:40:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:40:00 - INFO :       DATASET: tasksource/bigbench empirical_judgments
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.98s/it]
2023-12-01 17:40:10 - INFO :       Use random pruner...
2023-12-01 17:40:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:40:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:40:10 - INFO :       Start Pruning
2023-12-01 17:40:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:40:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:40:12 - INFO :       empirical_judgments: Total Sparsity 1.3674190639657633e-06
2023-12-01 17:40:12 - INFO :       
==================Finish================

2023-12-01 17:40:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:40:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:40:12 - INFO :       DATASET: tasksource/bigbench english_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]
2023-12-01 17:40:21 - INFO :       Use random pruner...
2023-12-01 17:40:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:40:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:40:21 - INFO :       Start Pruning
2023-12-01 17:40:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:40:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:40:23 - INFO :       english_proverbs: Total Sparsity 1.3559607374016567e-06
2023-12-01 17:40:23 - INFO :       
==================Finish================

2023-12-01 17:40:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:40:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:40:23 - INFO :       DATASET: tasksource/bigbench english_russian_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2023-12-01 17:40:32 - INFO :       Use random pruner...
2023-12-01 17:40:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:40:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:40:32 - INFO :       Start Pruning
2023-12-01 17:40:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:40:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:40:34 - INFO :       english_russian_proverbs: Total Sparsity 1.356489583243077e-06
2023-12-01 17:40:34 - INFO :       
==================Finish================

2023-12-01 17:40:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:40:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:40:34 - INFO :       DATASET: tasksource/bigbench entailed_polarity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2023-12-01 17:40:43 - INFO :       Use random pruner...
2023-12-01 17:40:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:40:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:40:44 - INFO :       Start Pruning
2023-12-01 17:40:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:40:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:40:45 - INFO :       entailed_polarity: Total Sparsity 1.367066500071483e-06
2023-12-01 17:40:45 - INFO :       
==================Finish================

2023-12-01 17:40:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:40:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:40:45 - INFO :       DATASET: tasksource/bigbench entailed_polarity_hindi
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2023-12-01 17:40:55 - INFO :       Use random pruner...
2023-12-01 17:40:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:40:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:40:56 - INFO :       Start Pruning
2023-12-01 17:40:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:40:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:40:57 - INFO :       entailed_polarity_hindi: Total Sparsity 1.356313301295937e-06
2023-12-01 17:40:57 - INFO :       
==================Finish================

2023-12-01 17:40:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:40:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:40:57 - INFO :       DATASET: tasksource/bigbench epistemic_reasoning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 17:41:06 - INFO :       Use random pruner...
2023-12-01 17:41:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:41:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:41:07 - INFO :       Start Pruning
2023-12-01 17:41:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:41:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:41:08 - INFO :       epistemic_reasoning: Total Sparsity 1.3645985528115216e-06
2023-12-01 17:41:08 - INFO :       
==================Finish================

2023-12-01 17:41:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:41:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:41:08 - INFO :       DATASET: tasksource/bigbench evaluating_information_essentiality
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]
2023-12-01 17:41:18 - INFO :       Use random pruner...
2023-12-01 17:41:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:41:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:41:19 - INFO :       Start Pruning
2023-12-01 17:41:19 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:41:19 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:41:20 - INFO :       evaluating_information_essentiality: Total Sparsity 1.3586049666087581e-06
2023-12-01 17:41:20 - INFO :       
==================Finish================

2023-12-01 17:41:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:41:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:41:20 - INFO :       DATASET: tasksource/bigbench fact_checker
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2023-12-01 17:41:29 - INFO :       Use random pruner...
2023-12-01 17:41:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:41:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:41:30 - INFO :       Start Pruning
2023-12-01 17:41:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:41:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:41:31 - INFO :       fact_checker: Total Sparsity 1.363540861128681e-06
2023-12-01 17:41:31 - INFO :       
==================Finish================

2023-12-01 17:41:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:41:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:41:31 - INFO :       DATASET: tasksource/bigbench fantasy_reasoning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]
2023-12-01 17:41:39 - INFO :       Use random pruner...
2023-12-01 17:41:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:41:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:41:39 - INFO :       Start Pruning
2023-12-01 17:41:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:41:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:41:41 - INFO :       fantasy_reasoning: Total Sparsity 1.374117777957087e-06
2023-12-01 17:41:41 - INFO :       
==================Finish================

2023-12-01 17:41:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:41:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:41:41 - INFO :       DATASET: tasksource/bigbench figure_of_speech_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]
2023-12-01 17:41:49 - INFO :       Use random pruner...
2023-12-01 17:41:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:41:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:41:50 - INFO :       Start Pruning
2023-12-01 17:41:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:41:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:41:51 - INFO :       figure_of_speech_detection: Total Sparsity 1.3616017597101399e-06
2023-12-01 17:41:51 - INFO :       
==================Finish================

2023-12-01 17:41:51 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:41:51 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:41:51 - INFO :       DATASET: tasksource/bigbench formal_fallacies_syllogisms_negation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2023-12-01 17:42:01 - INFO :       Use random pruner...
2023-12-01 17:42:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:42:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:42:02 - INFO :       Start Pruning
2023-12-01 17:42:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:42:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:42:04 - INFO :       formal_fallacies_syllogisms_negation: Total Sparsity 1.3660088083886423e-06
2023-12-01 17:42:04 - INFO :       
==================Finish================

2023-12-01 17:42:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:42:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:42:04 - INFO :       DATASET: tasksource/bigbench general_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
2023-12-01 17:42:13 - INFO :       Use random pruner...
2023-12-01 17:42:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:42:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:42:13 - INFO :       Start Pruning
2023-12-01 17:42:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:42:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:42:15 - INFO :       general_knowledge: Total Sparsity 1.3607203499744394e-06
2023-12-01 17:42:15 - INFO :       
==================Finish================

2023-12-01 17:42:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:42:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:42:15 - INFO :       DATASET: tasksource/bigbench geometric_shapes
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 17:42:25 - INFO :       Use random pruner...
2023-12-01 17:42:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:42:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:42:25 - INFO :       Start Pruning
2023-12-01 17:42:26 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:42:26 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:42:27 - INFO :       geometric_shapes: Total Sparsity 1.3647748347586618e-06
2023-12-01 17:42:27 - INFO :       
==================Finish================

2023-12-01 17:42:27 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:42:27 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:42:27 - INFO :       DATASET: tasksource/bigbench goal_step_wikihow
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2023-12-01 17:42:36 - INFO :       Use random pruner...
2023-12-01 17:42:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:42:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:42:36 - INFO :       Start Pruning
2023-12-01 17:42:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:42:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:42:38 - INFO :       goal_step_wikihow: Total Sparsity 1.36177804165728e-06
2023-12-01 17:42:38 - INFO :       
==================Finish================

2023-12-01 17:42:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:42:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:42:38 - INFO :       DATASET: tasksource/bigbench gre_reading_comprehension
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]
2023-12-01 17:42:45 - INFO :       Use random pruner...
2023-12-01 17:42:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:42:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:42:46 - INFO :       Start Pruning
2023-12-01 17:42:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:42:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:42:48 - INFO :       gre_reading_comprehension: Total Sparsity 1.3570184290844972e-06
2023-12-01 17:42:48 - INFO :       
==================Finish================

2023-12-01 17:42:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:42:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:42:48 - INFO :       DATASET: tasksource/bigbench hhh_alignment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 17:42:57 - INFO :       Use random pruner...
2023-12-01 17:42:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:42:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:42:58 - INFO :       Start Pruning
2023-12-01 17:42:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:42:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:42:59 - INFO :       hhh_alignment: Total Sparsity 1.3594863763444586e-06
2023-12-01 17:42:59 - INFO :       
==================Finish================

2023-12-01 17:42:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:42:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:42:59 - INFO :       DATASET: tasksource/bigbench hindu_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2023-12-01 17:43:09 - INFO :       Use random pruner...
2023-12-01 17:43:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:43:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:43:09 - INFO :       Start Pruning
2023-12-01 17:43:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:43:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:43:11 - INFO :       hindu_knowledge: Total Sparsity 1.363717143075821e-06
2023-12-01 17:43:11 - INFO :       
==================Finish================

2023-12-01 17:43:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:43:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:43:11 - INFO :       DATASET: tasksource/bigbench hinglish_toxicity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]
2023-12-01 17:43:18 - INFO :       Use random pruner...
2023-12-01 17:43:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:43:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:43:18 - INFO :       Start Pruning
2023-12-01 17:43:19 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:43:19 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:43:20 - INFO :       hinglish_toxicity: Total Sparsity 1.3683004737014638e-06
2023-12-01 17:43:20 - INFO :       
==================Finish================

2023-12-01 17:43:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:43:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:43:20 - INFO :       DATASET: tasksource/bigbench human_organs_senses
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]
2023-12-01 17:43:31 - INFO :       Use random pruner...
2023-12-01 17:43:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:43:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:43:31 - INFO :       Start Pruning
2023-12-01 17:43:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:43:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:43:33 - INFO :       human_organs_senses: Total Sparsity 1.3626594513929806e-06
2023-12-01 17:43:33 - INFO :       
==================Finish================

2023-12-01 17:43:33 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:43:33 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:43:33 - INFO :       DATASET: tasksource/bigbench hyperbaton
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
2023-12-01 17:43:43 - INFO :       Use random pruner...
2023-12-01 17:43:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:43:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:43:44 - INFO :       Start Pruning
2023-12-01 17:43:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:43:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:43:45 - INFO :       hyperbaton: Total Sparsity 1.3628357333401206e-06
2023-12-01 17:43:45 - INFO :       
==================Finish================

2023-12-01 17:43:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:43:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:43:45 - INFO :       DATASET: tasksource/bigbench identify_math_theorems
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2023-12-01 17:43:55 - INFO :       Use random pruner...
2023-12-01 17:43:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:43:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:43:55 - INFO :       Start Pruning
2023-12-01 17:43:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:43:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:43:57 - INFO :       identify_math_theorems: Total Sparsity 1.3601915041330191e-06
2023-12-01 17:43:57 - INFO :       
==================Finish================

2023-12-01 17:43:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:43:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:43:57 - INFO :       DATASET: tasksource/bigbench identify_odd_metaphor
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]
2023-12-01 17:44:06 - INFO :       Use random pruner...
2023-12-01 17:44:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:44:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:44:07 - INFO :       Start Pruning
2023-12-01 17:44:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:44:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:44:09 - INFO :       identify_odd_metaphor: Total Sparsity 1.3593100943973186e-06
2023-12-01 17:44:09 - INFO :       
==================Finish================

2023-12-01 17:44:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:44:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:44:09 - INFO :       DATASET: tasksource/bigbench implicatures
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2023-12-01 17:44:18 - INFO :       Use random pruner...
2023-12-01 17:44:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:44:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:44:19 - INFO :       Start Pruning
2023-12-01 17:44:19 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:44:19 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:44:20 - INFO :       implicatures: Total Sparsity 1.3624831694458404e-06
2023-12-01 17:44:20 - INFO :       
==================Finish================

2023-12-01 17:44:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:44:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:44:20 - INFO :       DATASET: tasksource/bigbench implicit_relations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]
2023-12-01 17:44:30 - INFO :       Use random pruner...
2023-12-01 17:44:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:44:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:44:31 - INFO :       Start Pruning
2023-12-01 17:44:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:44:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:44:32 - INFO :       implicit_relations: Total Sparsity 1.3573709929787774e-06
2023-12-01 17:44:32 - INFO :       
==================Finish================

2023-12-01 17:44:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:44:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:44:32 - INFO :       DATASET: tasksource/bigbench indic_cause_and_effect
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2023-12-01 17:44:43 - INFO :       Use random pruner...
2023-12-01 17:44:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:44:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:44:43 - INFO :       Start Pruning
2023-12-01 17:44:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:44:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:44:45 - INFO :       indic_cause_and_effect: Total Sparsity 1.360015222185879e-06
2023-12-01 17:44:45 - INFO :       
==================Finish================

2023-12-01 17:44:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:44:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:44:45 - INFO :       DATASET: tasksource/bigbench intent_recognition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
2023-12-01 17:44:54 - INFO :       Use random pruner...
2023-12-01 17:44:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:44:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:44:54 - INFO :       Start Pruning
2023-12-01 17:44:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:44:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:44:56 - INFO :       intent_recognition: Total Sparsity 1.3628357333401206e-06
2023-12-01 17:44:56 - INFO :       
==================Finish================

2023-12-01 17:44:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:44:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:44:56 - INFO :       DATASET: tasksource/bigbench international_phonetic_alphabet_nli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2023-12-01 17:45:05 - INFO :       Use random pruner...
2023-12-01 17:45:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:45:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:45:05 - INFO :       Start Pruning
2023-12-01 17:45:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:45:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:45:07 - INFO :       international_phonetic_alphabet_nli: Total Sparsity 1.365303680600082e-06
2023-12-01 17:45:07 - INFO :       
==================Finish================

2023-12-01 17:45:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:45:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:45:07 - INFO :       DATASET: tasksource/bigbench intersect_geometry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2023-12-01 17:45:15 - INFO :       Use random pruner...
2023-12-01 17:45:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:45:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:45:15 - INFO :       Start Pruning
2023-12-01 17:45:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:45:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:45:17 - INFO :       intersect_geometry: Total Sparsity 1.3601915041330191e-06
2023-12-01 17:45:17 - INFO :       
==================Finish================

2023-12-01 17:45:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:45:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:45:17 - INFO :       DATASET: tasksource/bigbench irony_identification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 17:45:25 - INFO :       Use random pruner...
2023-12-01 17:45:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:45:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:45:26 - INFO :       Start Pruning
2023-12-01 17:45:26 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:45:26 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:45:27 - INFO :       irony_identification: Total Sparsity 1.353140226247415e-06
2023-12-01 17:45:27 - INFO :       
==================Finish================

2023-12-01 17:45:27 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:45:27 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:45:27 - INFO :       DATASET: tasksource/bigbench kannada
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2023-12-01 17:45:39 - INFO :       Use random pruner...
2023-12-01 17:45:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:45:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:45:40 - INFO :       Start Pruning
2023-12-01 17:45:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:45:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:45:41 - INFO :       kannada: Total Sparsity 1.3665376542300628e-06
2023-12-01 17:45:41 - INFO :       
==================Finish================

2023-12-01 17:45:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:45:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:45:41 - INFO :       DATASET: tasksource/bigbench key_value_maps
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2023-12-01 17:45:53 - INFO :       Use random pruner...
2023-12-01 17:45:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:45:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:45:53 - INFO :       Start Pruning
2023-12-01 17:45:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:45:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:45:55 - INFO :       key_value_maps: Total Sparsity 1.358252402714478e-06
2023-12-01 17:45:55 - INFO :       
==================Finish================

2023-12-01 17:45:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:45:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:45:55 - INFO :       DATASET: tasksource/bigbench known_unknowns
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]
2023-12-01 17:46:06 - INFO :       Use random pruner...
2023-12-01 17:46:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:46:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:46:07 - INFO :       Start Pruning
2023-12-01 17:46:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:46:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:46:08 - INFO :       known_unknowns: Total Sparsity 1.3605440680272994e-06
2023-12-01 17:46:08 - INFO :       
==================Finish================

2023-12-01 17:46:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:46:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:46:08 - INFO :       DATASET: tasksource/bigbench language_identification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2023-12-01 17:46:18 - INFO :       Use random pruner...
2023-12-01 17:46:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:46:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:46:18 - INFO :       Start Pruning
2023-12-01 17:46:19 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:46:19 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:46:20 - INFO :       language_identification: Total Sparsity 1.3626594513929806e-06
2023-12-01 17:46:20 - INFO :       
==================Finish================

2023-12-01 17:46:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:46:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:46:20 - INFO :       DATASET: tasksource/bigbench logic_grid_puzzle
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]
2023-12-01 17:46:28 - INFO :       Use random pruner...
2023-12-01 17:46:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:46:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:46:29 - INFO :       Start Pruning
2023-12-01 17:46:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:46:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:46:31 - INFO :       logic_grid_puzzle: Total Sparsity 1.3571947110316374e-06
2023-12-01 17:46:31 - INFO :       
==================Finish================

2023-12-01 17:46:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:46:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:46:31 - INFO :       DATASET: tasksource/bigbench logical_args
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]
2023-12-01 17:46:38 - INFO :       Use random pruner...
2023-12-01 17:46:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:46:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:46:39 - INFO :       Start Pruning
2023-12-01 17:46:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:46:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:46:41 - INFO :       logical_args: Total Sparsity 1.3598389402387389e-06
2023-12-01 17:46:41 - INFO :       
==================Finish================

2023-12-01 17:46:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:46:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:46:41 - INFO :       DATASET: tasksource/bigbench logical_deduction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]
2023-12-01 17:46:50 - INFO :       Use random pruner...
2023-12-01 17:46:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:46:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:46:51 - INFO :       Start Pruning
2023-12-01 17:46:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:46:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:46:52 - INFO :       logical_deduction: Total Sparsity 1.363717143075821e-06
2023-12-01 17:46:52 - INFO :       
==================Finish================

2023-12-01 17:46:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:46:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:46:52 - INFO :       DATASET: tasksource/bigbench logical_fallacy_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2023-12-01 17:47:02 - INFO :       Use random pruner...
2023-12-01 17:47:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:47:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:47:03 - INFO :       Start Pruning
2023-12-01 17:47:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:47:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:47:04 - INFO :       logical_fallacy_detection: Total Sparsity 1.3644222708643816e-06
2023-12-01 17:47:04 - INFO :       
==================Finish================

2023-12-01 17:47:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:47:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:47:04 - INFO :       DATASET: tasksource/bigbench logical_sequence
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
2023-12-01 17:47:14 - INFO :       Use random pruner...
2023-12-01 17:47:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:47:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:47:14 - INFO :       Start Pruning
2023-12-01 17:47:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:47:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:47:16 - INFO :       logical_sequence: Total Sparsity 1.3598389402387389e-06
2023-12-01 17:47:16 - INFO :       
==================Finish================

2023-12-01 17:47:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:47:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:47:16 - INFO :       DATASET: tasksource/bigbench mathematical_induction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
2023-12-01 17:47:24 - INFO :       Use random pruner...
2023-12-01 17:47:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:47:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:47:24 - INFO :       Start Pruning
2023-12-01 17:47:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:47:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:47:26 - INFO :       mathematical_induction: Total Sparsity 1.3536690720888354e-06
2023-12-01 17:47:26 - INFO :       
==================Finish================

2023-12-01 17:47:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:47:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:47:26 - INFO :       DATASET: tasksource/bigbench medical_questions_russian
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2023-12-01 17:47:35 - INFO :       Use random pruner...
2023-12-01 17:47:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:47:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:47:35 - INFO :       Start Pruning
2023-12-01 17:47:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:47:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:47:37 - INFO :       medical_questions_russian: Total Sparsity 1.3593100943973186e-06
2023-12-01 17:47:37 - INFO :       
==================Finish================

2023-12-01 17:47:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:47:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:47:37 - INFO :       DATASET: tasksource/bigbench metaphor_boolean
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2023-12-01 17:47:47 - INFO :       Use random pruner...
2023-12-01 17:47:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:47:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:47:48 - INFO :       Start Pruning
2023-12-01 17:47:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:47:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:47:49 - INFO :       metaphor_boolean: Total Sparsity 1.3577235568730577e-06
2023-12-01 17:47:49 - INFO :       
==================Finish================

2023-12-01 17:47:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:47:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:47:49 - INFO :       DATASET: tasksource/bigbench metaphor_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2023-12-01 17:47:59 - INFO :       Use random pruner...
2023-12-01 17:47:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:47:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:47:59 - INFO :       Start Pruning
2023-12-01 17:48:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:48:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:48:01 - INFO :       metaphor_understanding: Total Sparsity 1.3712972668028455e-06
2023-12-01 17:48:01 - INFO :       
==================Finish================

2023-12-01 17:48:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:48:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:48:01 - INFO :       DATASET: tasksource/bigbench misconceptions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 17:48:11 - INFO :       Use random pruner...
2023-12-01 17:48:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:48:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:48:11 - INFO :       Start Pruning
2023-12-01 17:48:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:48:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:48:13 - INFO :       misconceptions: Total Sparsity 1.3730600862742465e-06
2023-12-01 17:48:13 - INFO :       
==================Finish================

2023-12-01 17:48:13 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:48:13 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:48:13 - INFO :       DATASET: tasksource/bigbench misconceptions_russian
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2023-12-01 17:48:23 - INFO :       Use random pruner...
2023-12-01 17:48:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:48:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:48:24 - INFO :       Start Pruning
2023-12-01 17:48:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:48:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:48:25 - INFO :       misconceptions_russian: Total Sparsity 1.363540861128681e-06
2023-12-01 17:48:25 - INFO :       
==================Finish================

2023-12-01 17:48:25 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:48:25 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:48:25 - INFO :       DATASET: tasksource/bigbench mnist_ascii
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2023-12-01 17:48:35 - INFO :       Use random pruner...
2023-12-01 17:48:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:48:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:48:36 - INFO :       Start Pruning
2023-12-01 17:48:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:48:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:48:38 - INFO :       mnist_ascii: Total Sparsity 1.3679479098071835e-06
2023-12-01 17:48:38 - INFO :       
==================Finish================

2023-12-01 17:48:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:48:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:48:38 - INFO :       DATASET: tasksource/bigbench moral_permissibility
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 17:48:47 - INFO :       Use random pruner...
2023-12-01 17:48:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:48:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:48:48 - INFO :       Start Pruning
2023-12-01 17:48:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:48:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:48:50 - INFO :       moral_permissibility: Total Sparsity 1.3642459889172413e-06
2023-12-01 17:48:50 - INFO :       
==================Finish================

2023-12-01 17:48:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:48:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:48:50 - INFO :       DATASET: tasksource/bigbench movie_dialog_same_or_different
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]
2023-12-01 17:48:57 - INFO :       Use random pruner...
2023-12-01 17:48:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:48:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:48:57 - INFO :       Start Pruning
2023-12-01 17:48:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:48:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:48:59 - INFO :       movie_dialog_same_or_different: Total Sparsity 1.372354958485686e-06
2023-12-01 17:48:59 - INFO :       
==================Finish================

2023-12-01 17:48:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:48:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:48:59 - INFO :       DATASET: tasksource/bigbench movie_recommendation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]
2023-12-01 17:49:09 - INFO :       Use random pruner...
2023-12-01 17:49:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:49:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:49:09 - INFO :       Start Pruning
2023-12-01 17:49:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:49:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:49:11 - INFO :       movie_recommendation: Total Sparsity 1.3616017597101399e-06
2023-12-01 17:49:11 - INFO :       
==================Finish================

2023-12-01 17:49:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:49:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:49:11 - INFO :       DATASET: tasksource/bigbench navigate
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]
2023-12-01 17:49:20 - INFO :       Use random pruner...
2023-12-01 17:49:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:49:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:49:20 - INFO :       Start Pruning
2023-12-01 17:49:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:49:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:49:22 - INFO :       navigate: Total Sparsity 1.3552556096130962e-06
2023-12-01 17:49:22 - INFO :       
==================Finish================

2023-12-01 17:49:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:49:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:49:22 - INFO :       DATASET: tasksource/bigbench nonsense_words_grammar
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 17:49:28 - INFO :       Use random pruner...
2023-12-01 17:49:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:49:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:49:29 - INFO :       Start Pruning
2023-12-01 17:49:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:49:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:49:30 - INFO :       nonsense_words_grammar: Total Sparsity 1.356489583243077e-06
2023-12-01 17:49:30 - INFO :       
==================Finish================

2023-12-01 17:49:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:49:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:49:30 - INFO :       DATASET: tasksource/bigbench novel_concepts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.04it/s]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.04s/it]
2023-12-01 17:49:36 - INFO :       Use random pruner...
2023-12-01 17:49:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:49:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:49:37 - INFO :       Start Pruning
2023-12-01 17:49:38 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:49:38 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:49:39 - INFO :       novel_concepts: Total Sparsity 1.3610729138687196e-06
2023-12-01 17:49:39 - INFO :       
==================Finish================

2023-12-01 17:49:39 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:49:39 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:49:39 - INFO :       DATASET: tasksource/bigbench odd_one_out
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2023-12-01 17:49:47 - INFO :       Use random pruner...
2023-12-01 17:49:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:49:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:49:47 - INFO :       Start Pruning
2023-12-01 17:49:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:49:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:49:49 - INFO :       odd_one_out: Total Sparsity 1.363717143075821e-06
2023-12-01 17:49:49 - INFO :       
==================Finish================

2023-12-01 17:49:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:49:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:49:49 - INFO :       DATASET: tasksource/bigbench parsinlu_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]
2023-12-01 17:50:00 - INFO :       Use random pruner...
2023-12-01 17:50:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:50:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:50:00 - INFO :       Start Pruning
2023-12-01 17:50:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:50:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:50:02 - INFO :       parsinlu_qa: Total Sparsity 1.3549030457188162e-06
2023-12-01 17:50:02 - INFO :       
==================Finish================

2023-12-01 17:50:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:50:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:50:02 - INFO :       DATASET: tasksource/bigbench penguins_in_a_table
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]
2023-12-01 17:50:11 - INFO :       Use random pruner...
2023-12-01 17:50:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:50:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:50:11 - INFO :       Start Pruning
2023-12-01 17:50:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:50:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:50:13 - INFO :       penguins_in_a_table: Total Sparsity 1.3608966319215796e-06
2023-12-01 17:50:13 - INFO :       
==================Finish================

2023-12-01 17:50:13 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:50:13 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:50:13 - INFO :       DATASET: tasksource/bigbench persian_idioms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 17:50:23 - INFO :       Use random pruner...
2023-12-01 17:50:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:50:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:50:23 - INFO :       Start Pruning
2023-12-01 17:50:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:50:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:50:25 - INFO :       persian_idioms: Total Sparsity 1.3684767556486038e-06
2023-12-01 17:50:25 - INFO :       
==================Finish================

2023-12-01 17:50:25 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:50:25 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:50:25 - INFO :       DATASET: tasksource/bigbench phrase_relatedness
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 17:50:36 - INFO :       Use random pruner...
2023-12-01 17:50:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:50:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:50:36 - INFO :       Start Pruning
2023-12-01 17:50:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:50:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:50:38 - INFO :       phrase_relatedness: Total Sparsity 1.3700632931728648e-06
2023-12-01 17:50:38 - INFO :       
==================Finish================

2023-12-01 17:50:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:50:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:50:38 - INFO :       DATASET: tasksource/bigbench physical_intuition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]
2023-12-01 17:50:50 - INFO :       Use random pruner...
2023-12-01 17:50:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:50:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:50:50 - INFO :       Start Pruning
2023-12-01 17:50:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:50:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:50:52 - INFO :       physical_intuition: Total Sparsity 1.3612491958158596e-06
2023-12-01 17:50:52 - INFO :       
==================Finish================

2023-12-01 17:50:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:50:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:50:52 - INFO :       DATASET: tasksource/bigbench physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.98s/it]
2023-12-01 17:51:03 - INFO :       Use random pruner...
2023-12-01 17:51:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:51:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:51:04 - INFO :       Start Pruning
2023-12-01 17:51:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:51:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:51:05 - INFO :       physics: Total Sparsity 1.3623068874987003e-06
2023-12-01 17:51:05 - INFO :       
==================Finish================

2023-12-01 17:51:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:51:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:51:05 - INFO :       DATASET: tasksource/bigbench play_dialog_same_or_different
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]
2023-12-01 17:51:16 - INFO :       Use random pruner...
2023-12-01 17:51:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:51:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:51:17 - INFO :       Start Pruning
2023-12-01 17:51:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:51:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:51:18 - INFO :       play_dialog_same_or_different: Total Sparsity 1.3675953459129033e-06
2023-12-01 17:51:18 - INFO :       
==================Finish================

2023-12-01 17:51:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:51:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:51:18 - INFO :       DATASET: tasksource/bigbench presuppositions_as_nli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]
2023-12-01 17:51:29 - INFO :       Use random pruner...
2023-12-01 17:51:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:51:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:51:30 - INFO :       Start Pruning
2023-12-01 17:51:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:51:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:51:31 - INFO :       presuppositions_as_nli: Total Sparsity 1.3619543236044201e-06
2023-12-01 17:51:31 - INFO :       
==================Finish================

2023-12-01 17:51:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:51:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:51:31 - INFO :       DATASET: tasksource/bigbench question_selection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 17:51:40 - INFO :       Use random pruner...
2023-12-01 17:51:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:51:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:51:41 - INFO :       Start Pruning
2023-12-01 17:51:42 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:51:42 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:51:42 - INFO :       question_selection: Total Sparsity 1.3598389402387389e-06
2023-12-01 17:51:42 - INFO :       
==================Finish================

2023-12-01 17:51:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:51:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:51:42 - INFO :       DATASET: tasksource/bigbench reasoning_about_colored_objects
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2023-12-01 17:51:52 - INFO :       Use random pruner...
2023-12-01 17:51:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:51:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:51:52 - INFO :       Start Pruning
2023-12-01 17:51:53 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:51:53 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:51:54 - INFO :       reasoning_about_colored_objects: Total Sparsity 1.3526113804059947e-06
2023-12-01 17:51:54 - INFO :       
==================Finish================

2023-12-01 17:51:54 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:51:54 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:51:54 - INFO :       DATASET: tasksource/bigbench riddle_sense
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]
2023-12-01 17:52:04 - INFO :       Use random pruner...
2023-12-01 17:52:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:52:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:52:04 - INFO :       Start Pruning
2023-12-01 17:52:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:52:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:52:06 - INFO :       riddle_sense: Total Sparsity 1.3663613722829226e-06
2023-12-01 17:52:06 - INFO :       
==================Finish================

2023-12-01 17:52:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:52:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:52:06 - INFO :       DATASET: tasksource/bigbench ruin_names
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2023-12-01 17:52:16 - INFO :       Use random pruner...
2023-12-01 17:52:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:52:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:52:17 - INFO :       Start Pruning
2023-12-01 17:52:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:52:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:52:18 - INFO :       ruin_names: Total Sparsity 1.3575472749259176e-06
2023-12-01 17:52:18 - INFO :       
==================Finish================

2023-12-01 17:52:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:52:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:52:18 - INFO :       DATASET: tasksource/bigbench salient_translation_error_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
2023-12-01 17:52:30 - INFO :       Use random pruner...
2023-12-01 17:52:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:52:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:52:30 - INFO :       Start Pruning
2023-12-01 17:52:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:52:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:52:32 - INFO :       salient_translation_error_detection: Total Sparsity 1.3578998388201979e-06
2023-12-01 17:52:32 - INFO :       
==================Finish================

2023-12-01 17:52:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:52:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:52:32 - INFO :       DATASET: tasksource/bigbench sentence_ambiguity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2023-12-01 17:52:43 - INFO :       Use random pruner...
2023-12-01 17:52:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:52:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:52:43 - INFO :       Start Pruning
2023-12-01 17:52:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:52:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:52:45 - INFO :       sentence_ambiguity: Total Sparsity 1.3605440680272994e-06
2023-12-01 17:52:45 - INFO :       
==================Finish================

2023-12-01 17:52:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:52:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:52:45 - INFO :       DATASET: tasksource/bigbench similarities_abstraction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]
2023-12-01 17:52:56 - INFO :       Use random pruner...
2023-12-01 17:52:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:52:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:52:56 - INFO :       Start Pruning
2023-12-01 17:52:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:52:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:52:58 - INFO :       similarities_abstraction: Total Sparsity 1.3684767556486038e-06
2023-12-01 17:52:58 - INFO :       
==================Finish================

2023-12-01 17:52:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:52:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:52:58 - INFO :       DATASET: tasksource/bigbench simple_ethical_questions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
2023-12-01 17:53:08 - INFO :       Use random pruner...
2023-12-01 17:53:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:53:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:53:08 - INFO :       Start Pruning
2023-12-01 17:53:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:53:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:53:10 - INFO :       simple_ethical_questions: Total Sparsity 1.3619543236044201e-06
2023-12-01 17:53:10 - INFO :       
==================Finish================

2023-12-01 17:53:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:53:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:53:10 - INFO :       DATASET: tasksource/bigbench snarks
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.28s/it]
2023-12-01 17:53:21 - INFO :       Use random pruner...
2023-12-01 17:53:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:53:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:53:21 - INFO :       Start Pruning
2023-12-01 17:53:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:53:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:53:23 - INFO :       snarks: Total Sparsity 1.3683004737014638e-06
2023-12-01 17:53:23 - INFO :       
==================Finish================

2023-12-01 17:53:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:53:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:53:23 - INFO :       DATASET: tasksource/bigbench social_iqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2023-12-01 17:53:33 - INFO :       Use random pruner...
2023-12-01 17:53:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:53:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:53:33 - INFO :       Start Pruning
2023-12-01 17:53:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:53:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:53:35 - INFO :       social_iqa: Total Sparsity 1.3533165081945552e-06
2023-12-01 17:53:35 - INFO :       
==================Finish================

2023-12-01 17:53:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:53:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:53:35 - INFO :       DATASET: tasksource/bigbench social_support
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2023-12-01 17:53:45 - INFO :       Use random pruner...
2023-12-01 17:53:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:53:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:53:45 - INFO :       Start Pruning
2023-12-01 17:53:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:53:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:53:47 - INFO :       social_support: Total Sparsity 1.3681241917543236e-06
2023-12-01 17:53:47 - INFO :       
==================Finish================

2023-12-01 17:53:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:53:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:53:47 - INFO :       DATASET: tasksource/bigbench sports_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.28s/it]
2023-12-01 17:53:58 - INFO :       Use random pruner...
2023-12-01 17:53:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:53:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:53:58 - INFO :       Start Pruning
2023-12-01 17:53:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:53:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:54:00 - INFO :       sports_understanding: Total Sparsity 1.363717143075821e-06
2023-12-01 17:54:00 - INFO :       
==================Finish================

2023-12-01 17:54:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:54:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:54:00 - INFO :       DATASET: tasksource/bigbench strange_stories
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.32s/it]
2023-12-01 17:54:12 - INFO :       Use random pruner...
2023-12-01 17:54:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:54:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:54:12 - INFO :       Start Pruning
2023-12-01 17:54:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:54:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:54:14 - INFO :       strange_stories: Total Sparsity 1.3589575305030384e-06
2023-12-01 17:54:14 - INFO :       
==================Finish================

2023-12-01 17:54:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:54:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:54:14 - INFO :       DATASET: tasksource/bigbench strategyqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]
2023-12-01 17:54:25 - INFO :       Use random pruner...
2023-12-01 17:54:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:54:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:54:25 - INFO :       Start Pruning
2023-12-01 17:54:26 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:54:26 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:54:27 - INFO :       strategyqa: Total Sparsity 1.3732363682213865e-06
2023-12-01 17:54:27 - INFO :       
==================Finish================

2023-12-01 17:54:27 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:54:27 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:54:27 - INFO :       DATASET: tasksource/bigbench suicide_risk
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 17:54:38 - INFO :       Use random pruner...
2023-12-01 17:54:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:54:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:54:39 - INFO :       Start Pruning
2023-12-01 17:54:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:54:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:54:40 - INFO :       suicide_risk: Total Sparsity 1.3608966319215796e-06
2023-12-01 17:54:40 - INFO :       
==================Finish================

2023-12-01 17:54:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:54:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:54:40 - INFO :       DATASET: tasksource/bigbench swahili_english_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
2023-12-01 17:54:52 - INFO :       Use random pruner...
2023-12-01 17:54:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:54:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:54:52 - INFO :       Start Pruning
2023-12-01 17:54:53 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:54:53 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:54:54 - INFO :       swahili_english_proverbs: Total Sparsity 1.3645985528115216e-06
2023-12-01 17:54:54 - INFO :       
==================Finish================

2023-12-01 17:54:54 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:54:54 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:54:54 - INFO :       DATASET: tasksource/bigbench swedish_to_german_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]
2023-12-01 17:55:05 - INFO :       Use random pruner...
2023-12-01 17:55:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:55:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:55:06 - INFO :       Start Pruning
2023-12-01 17:55:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:55:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:55:07 - INFO :       swedish_to_german_proverbs: Total Sparsity 1.3584286846616181e-06
2023-12-01 17:55:07 - INFO :       
==================Finish================

2023-12-01 17:55:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:55:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:55:07 - INFO :       DATASET: tasksource/bigbench symbol_interpretation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.22s/it]
2023-12-01 17:55:19 - INFO :       Use random pruner...
2023-12-01 17:55:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:55:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:55:20 - INFO :       Start Pruning
2023-12-01 17:55:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:55:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:55:21 - INFO :       symbol_interpretation: Total Sparsity 1.370592139014285e-06
2023-12-01 17:55:21 - INFO :       
==================Finish================

2023-12-01 17:55:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:55:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:55:21 - INFO :       DATASET: tasksource/bigbench temporal_sequences
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 17:55:33 - INFO :       Use random pruner...
2023-12-01 17:55:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:55:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:55:33 - INFO :       Start Pruning
2023-12-01 17:55:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:55:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:55:35 - INFO :       temporal_sequences: Total Sparsity 1.358252402714478e-06
2023-12-01 17:55:35 - INFO :       
==================Finish================

2023-12-01 17:55:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:55:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:55:35 - INFO :       DATASET: tasksource/bigbench timedial
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.33s/it]
2023-12-01 17:55:47 - INFO :       Use random pruner...
2023-12-01 17:55:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:55:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:55:47 - INFO :       Start Pruning
2023-12-01 17:55:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:55:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:55:49 - INFO :       timedial: Total Sparsity 1.3601915041330191e-06
2023-12-01 17:55:49 - INFO :       
==================Finish================

2023-12-01 17:55:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:55:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:55:49 - INFO :       DATASET: tasksource/bigbench tracking_shuffled_objects
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.91s/it]
2023-12-01 17:56:00 - INFO :       Use random pruner...
2023-12-01 17:56:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:56:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:56:00 - INFO :       Start Pruning
2023-12-01 17:56:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:56:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:56:02 - INFO :       tracking_shuffled_objects: Total Sparsity 1.3534927901416952e-06
2023-12-01 17:56:02 - INFO :       
==================Finish================

2023-12-01 17:56:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:56:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:56:02 - INFO :       DATASET: tasksource/bigbench understanding_fables
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
2023-12-01 17:56:12 - INFO :       Use random pruner...
2023-12-01 17:56:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:56:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:56:13 - INFO :       Start Pruning
2023-12-01 17:56:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:56:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:56:14 - INFO :       understanding_fables: Total Sparsity 1.3709447029085653e-06
2023-12-01 17:56:14 - INFO :       
==================Finish================

2023-12-01 17:56:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:56:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:56:14 - INFO :       DATASET: tasksource/bigbench undo_permutation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.19s/it]
2023-12-01 17:56:27 - INFO :       Use random pruner...
2023-12-01 17:56:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:56:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:56:27 - INFO :       Start Pruning
2023-12-01 17:56:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:56:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:56:29 - INFO :       undo_permutation: Total Sparsity 1.3649511167058018e-06
2023-12-01 17:56:29 - INFO :       
==================Finish================

2023-12-01 17:56:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:56:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:56:29 - INFO :       DATASET: tasksource/bigbench unit_interpretation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2023-12-01 17:56:40 - INFO :       Use random pruner...
2023-12-01 17:56:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:56:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:56:40 - INFO :       Start Pruning
2023-12-01 17:56:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:56:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:56:42 - INFO :       unit_interpretation: Total Sparsity 1.3656562444943623e-06
2023-12-01 17:56:42 - INFO :       
==================Finish================

2023-12-01 17:56:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:56:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:56:42 - INFO :       DATASET: tasksource/bigbench vitaminc_fact_verification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.33s/it]
2023-12-01 17:56:54 - INFO :       Use random pruner...
2023-12-01 17:56:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:56:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:56:54 - INFO :       Start Pruning
2023-12-01 17:56:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:56:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:56:56 - INFO :       vitaminc_fact_verification: Total Sparsity 1.366890218124343e-06
2023-12-01 17:56:56 - INFO :       
==================Finish================

2023-12-01 17:56:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:56:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:56:56 - INFO :       DATASET: tasksource/bigbench what_is_the_tao
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]
2023-12-01 17:57:08 - INFO :       Use random pruner...
2023-12-01 17:57:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:57:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:57:08 - INFO :       Start Pruning
2023-12-01 17:57:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:57:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:57:10 - INFO :       what_is_the_tao: Total Sparsity 1.3577235568730577e-06
2023-12-01 17:57:10 - INFO :       
==================Finish================

2023-12-01 17:57:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:57:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:57:10 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.23s/it]
2023-12-01 17:57:21 - INFO :       Use random pruner...
2023-12-01 17:57:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:57:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:57:22 - INFO :       Start Pruning
2023-12-01 17:57:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:57:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:57:23 - INFO :       which_wiki_edit: Total Sparsity 1.3693581653843043e-06
2023-12-01 17:57:23 - INFO :       
==================Finish================

2023-12-01 17:57:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:57:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:57:23 - INFO :       DATASET: tasksource/bigbench winowhy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]
2023-12-01 17:57:35 - INFO :       Use random pruner...
2023-12-01 17:57:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:57:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:57:36 - INFO :       Start Pruning
2023-12-01 17:57:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:57:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:57:37 - INFO :       winowhy: Total Sparsity 1.3630120152872606e-06
2023-12-01 17:57:37 - INFO :       
==================Finish================

2023-12-01 17:57:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:57:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:57:37 - INFO :       DATASET: tasksource/mmlu abstract_algebra
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 17:57:49 - INFO :       Use random pruner...
2023-12-01 17:57:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:57:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:57:49 - INFO :       Start Pruning
2023-12-01 17:57:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:57:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:57:51 - INFO :       abstract_algebra: Total Sparsity 1.367242782018623e-06
2023-12-01 17:57:51 - INFO :       
==================Finish================

2023-12-01 17:57:51 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:57:51 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:57:51 - INFO :       DATASET: tasksource/mmlu anatomy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 17:58:03 - INFO :       Use random pruner...
2023-12-01 17:58:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:58:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:58:03 - INFO :       Start Pruning
2023-12-01 17:58:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:58:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:58:05 - INFO :       anatomy: Total Sparsity 1.3619543236044201e-06
2023-12-01 17:58:05 - INFO :       
==================Finish================

2023-12-01 17:58:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:58:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:58:05 - INFO :       DATASET: tasksource/mmlu astronomy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.29s/it]
2023-12-01 17:58:17 - INFO :       Use random pruner...
2023-12-01 17:58:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:58:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:58:17 - INFO :       Start Pruning
2023-12-01 17:58:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:58:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:58:19 - INFO :       astronomy: Total Sparsity 1.3517299706702942e-06
2023-12-01 17:58:19 - INFO :       
==================Finish================

2023-12-01 17:58:19 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:58:19 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:58:19 - INFO :       DATASET: tasksource/mmlu business_ethics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]
2023-12-01 17:58:31 - INFO :       Use random pruner...
2023-12-01 17:58:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:58:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:58:31 - INFO :       Start Pruning
2023-12-01 17:58:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:58:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:58:33 - INFO :       business_ethics: Total Sparsity 1.3624831694458404e-06
2023-12-01 17:58:33 - INFO :       
==================Finish================

2023-12-01 17:58:33 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:58:33 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:58:33 - INFO :       DATASET: tasksource/mmlu clinical_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 17:58:44 - INFO :       Use random pruner...
2023-12-01 17:58:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:58:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:58:44 - INFO :       Start Pruning
2023-12-01 17:58:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:58:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:58:46 - INFO :       clinical_knowledge: Total Sparsity 1.3534927901416952e-06
2023-12-01 17:58:46 - INFO :       
==================Finish================

2023-12-01 17:58:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:58:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:58:46 - INFO :       DATASET: tasksource/mmlu college_biology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.30s/it]
2023-12-01 17:58:57 - INFO :       Use random pruner...
2023-12-01 17:58:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:58:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:58:58 - INFO :       Start Pruning
2023-12-01 17:58:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:58:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:59:00 - INFO :       college_biology: Total Sparsity 1.3679479098071835e-06
2023-12-01 17:59:00 - INFO :       
==================Finish================

2023-12-01 17:59:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:59:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:59:00 - INFO :       DATASET: tasksource/mmlu college_chemistry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.39s/it]
2023-12-01 17:59:10 - INFO :       Use random pruner...
2023-12-01 17:59:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:59:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:59:11 - INFO :       Start Pruning
2023-12-01 17:59:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:59:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:59:13 - INFO :       college_chemistry: Total Sparsity 1.3720023945914058e-06
2023-12-01 17:59:13 - INFO :       
==================Finish================

2023-12-01 17:59:13 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:59:13 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:59:13 - INFO :       DATASET: tasksource/mmlu college_computer_science
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]
2023-12-01 17:59:19 - INFO :       Use random pruner...
2023-12-01 17:59:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:59:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:59:20 - INFO :       Start Pruning
2023-12-01 17:59:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:59:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:59:22 - INFO :       college_computer_science: Total Sparsity 1.3570184290844972e-06
2023-12-01 17:59:22 - INFO :       
==================Finish================

2023-12-01 17:59:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:59:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:59:22 - INFO :       DATASET: tasksource/mmlu college_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 17:59:28 - INFO :       Use random pruner...
2023-12-01 17:59:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:59:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:59:29 - INFO :       Start Pruning
2023-12-01 17:59:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:59:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:59:30 - INFO :       college_mathematics: Total Sparsity 1.3536690720888354e-06
2023-12-01 17:59:30 - INFO :       
==================Finish================

2023-12-01 17:59:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:59:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:59:30 - INFO :       DATASET: tasksource/mmlu college_medicine
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 17:59:37 - INFO :       Use random pruner...
2023-12-01 17:59:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:59:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:59:38 - INFO :       Start Pruning
2023-12-01 17:59:38 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:59:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:59:39 - INFO :       college_medicine: Total Sparsity 1.356313301295937e-06
2023-12-01 17:59:39 - INFO :       
==================Finish================

2023-12-01 17:59:39 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:59:39 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:59:39 - INFO :       DATASET: tasksource/mmlu college_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]
2023-12-01 17:59:46 - INFO :       Use random pruner...
2023-12-01 17:59:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:59:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:59:47 - INFO :       Start Pruning
2023-12-01 17:59:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:59:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:59:48 - INFO :       college_physics: Total Sparsity 1.3734126501685267e-06
2023-12-01 17:59:48 - INFO :       
==================Finish================

2023-12-01 17:59:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:59:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:59:48 - INFO :       DATASET: tasksource/mmlu computer_security
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]
2023-12-01 17:59:56 - INFO :       Use random pruner...
2023-12-01 17:59:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:59:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 17:59:57 - INFO :       Start Pruning
2023-12-01 17:59:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 17:59:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 17:59:59 - INFO :       computer_security: Total Sparsity 1.3700632931728648e-06
2023-12-01 17:59:59 - INFO :       
==================Finish================

2023-12-01 17:59:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 17:59:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 17:59:59 - INFO :       DATASET: tasksource/mmlu conceptual_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]
2023-12-01 18:00:06 - INFO :       Use random pruner...
2023-12-01 18:00:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:00:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:00:07 - INFO :       Start Pruning
2023-12-01 18:00:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:00:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:00:08 - INFO :       conceptual_physics: Total Sparsity 1.354550481824536e-06
2023-12-01 18:00:08 - INFO :       
==================Finish================

2023-12-01 18:00:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:00:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:00:08 - INFO :       DATASET: tasksource/mmlu econometrics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]
2023-12-01 18:00:16 - INFO :       Use random pruner...
2023-12-01 18:00:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:00:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:00:17 - INFO :       Start Pruning
2023-12-01 18:00:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:00:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:00:18 - INFO :       econometrics: Total Sparsity 1.3591338124501784e-06
2023-12-01 18:00:18 - INFO :       
==================Finish================

2023-12-01 18:00:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:00:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:00:18 - INFO :       DATASET: tasksource/mmlu electrical_engineering
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]
2023-12-01 18:00:26 - INFO :       Use random pruner...
2023-12-01 18:00:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:00:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:00:27 - INFO :       Start Pruning
2023-12-01 18:00:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:00:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:00:28 - INFO :       electrical_engineering: Total Sparsity 1.3566658651902172e-06
2023-12-01 18:00:28 - INFO :       
==================Finish================

2023-12-01 18:00:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:00:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:00:28 - INFO :       DATASET: tasksource/mmlu elementary_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]
2023-12-01 18:00:36 - INFO :       Use random pruner...
2023-12-01 18:00:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:00:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:00:36 - INFO :       Start Pruning
2023-12-01 18:00:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:00:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:00:38 - INFO :       elementary_mathematics: Total Sparsity 1.3591338124501784e-06
2023-12-01 18:00:38 - INFO :       
==================Finish================

2023-12-01 18:00:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:00:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:00:38 - INFO :       DATASET: tasksource/mmlu formal_logic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]
2023-12-01 18:00:46 - INFO :       Use random pruner...
2023-12-01 18:00:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:00:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:00:46 - INFO :       Start Pruning
2023-12-01 18:00:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:00:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:00:48 - INFO :       formal_logic: Total Sparsity 1.3608966319215796e-06
2023-12-01 18:00:48 - INFO :       
==================Finish================

2023-12-01 18:00:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:00:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:00:48 - INFO :       DATASET: tasksource/mmlu global_facts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]
2023-12-01 18:00:56 - INFO :       Use random pruner...
2023-12-01 18:00:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:00:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:00:56 - INFO :       Start Pruning
2023-12-01 18:00:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:00:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:00:58 - INFO :       global_facts: Total Sparsity 1.365479962547222e-06
2023-12-01 18:00:58 - INFO :       
==================Finish================

2023-12-01 18:00:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:00:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:00:58 - INFO :       DATASET: tasksource/mmlu high_school_biology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]
2023-12-01 18:01:05 - INFO :       Use random pruner...
2023-12-01 18:01:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:01:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:01:06 - INFO :       Start Pruning
2023-12-01 18:01:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:01:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:01:07 - INFO :       high_school_biology: Total Sparsity 1.3663613722829226e-06
2023-12-01 18:01:07 - INFO :       
==================Finish================

2023-12-01 18:01:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:01:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:01:07 - INFO :       DATASET: tasksource/mmlu high_school_chemistry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]
2023-12-01 18:01:15 - INFO :       Use random pruner...
2023-12-01 18:01:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:01:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:01:16 - INFO :       Start Pruning
2023-12-01 18:01:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:01:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:01:17 - INFO :       high_school_chemistry: Total Sparsity 1.3744703418513672e-06
2023-12-01 18:01:17 - INFO :       
==================Finish================

2023-12-01 18:01:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:01:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:01:17 - INFO :       DATASET: tasksource/mmlu high_school_computer_science
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]
2023-12-01 18:01:25 - INFO :       Use random pruner...
2023-12-01 18:01:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:01:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:01:26 - INFO :       Start Pruning
2023-12-01 18:01:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:01:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:01:28 - INFO :       high_school_computer_science: Total Sparsity 1.352963944300275e-06
2023-12-01 18:01:28 - INFO :       
==================Finish================

2023-12-01 18:01:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:01:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:01:28 - INFO :       DATASET: tasksource/mmlu high_school_european_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]
2023-12-01 18:01:35 - INFO :       Use random pruner...
2023-12-01 18:01:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:01:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:01:36 - INFO :       Start Pruning
2023-12-01 18:01:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:01:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:01:37 - INFO :       high_school_european_history: Total Sparsity 1.366890218124343e-06
2023-12-01 18:01:37 - INFO :       
==================Finish================

2023-12-01 18:01:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:01:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:01:37 - INFO :       DATASET: tasksource/mmlu high_school_geography
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 18:01:44 - INFO :       Use random pruner...
2023-12-01 18:01:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:01:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:01:45 - INFO :       Start Pruning
2023-12-01 18:01:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:01:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:01:46 - INFO :       high_school_geography: Total Sparsity 1.3640697069701013e-06
2023-12-01 18:01:46 - INFO :       
==================Finish================

2023-12-01 18:01:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:01:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:01:46 - INFO :       DATASET: tasksource/mmlu high_school_government_and_politics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.46s/it]
2023-12-01 18:01:53 - INFO :       Use random pruner...
2023-12-01 18:01:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:01:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:01:54 - INFO :       Start Pruning
2023-12-01 18:01:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:01:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:01:56 - INFO :       high_school_government_and_politics: Total Sparsity 1.3601915041330191e-06
2023-12-01 18:01:56 - INFO :       
==================Finish================

2023-12-01 18:01:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:01:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:01:56 - INFO :       DATASET: tasksource/mmlu high_school_macroeconomics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 18:02:03 - INFO :       Use random pruner...
2023-12-01 18:02:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:02:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:02:03 - INFO :       Start Pruning
2023-12-01 18:02:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:02:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:02:05 - INFO :       high_school_macroeconomics: Total Sparsity 1.3621306055515601e-06
2023-12-01 18:02:05 - INFO :       
==================Finish================

2023-12-01 18:02:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:02:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:02:05 - INFO :       DATASET: tasksource/mmlu high_school_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2023-12-01 18:02:12 - INFO :       Use random pruner...
2023-12-01 18:02:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:02:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:02:13 - INFO :       Start Pruning
2023-12-01 18:02:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:02:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:02:14 - INFO :       high_school_mathematics: Total Sparsity 1.354726763771676e-06
2023-12-01 18:02:14 - INFO :       
==================Finish================

2023-12-01 18:02:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:02:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:02:14 - INFO :       DATASET: tasksource/mmlu high_school_microeconomics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 18:02:22 - INFO :       Use random pruner...
2023-12-01 18:02:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:02:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:02:23 - INFO :       Start Pruning
2023-12-01 18:02:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:02:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:02:25 - INFO :       high_school_microeconomics: Total Sparsity 1.3658325264415023e-06
2023-12-01 18:02:25 - INFO :       
==================Finish================

2023-12-01 18:02:25 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:02:25 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:02:25 - INFO :       DATASET: tasksource/mmlu high_school_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]
2023-12-01 18:02:32 - INFO :       Use random pruner...
2023-12-01 18:02:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:02:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:02:33 - INFO :       Start Pruning
2023-12-01 18:02:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:02:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:02:34 - INFO :       high_school_physics: Total Sparsity 1.3633645791815409e-06
2023-12-01 18:02:34 - INFO :       
==================Finish================

2023-12-01 18:02:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:02:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:02:34 - INFO :       DATASET: tasksource/mmlu high_school_psychology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 18:02:42 - INFO :       Use random pruner...
2023-12-01 18:02:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:02:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:02:42 - INFO :       Start Pruning
2023-12-01 18:02:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:02:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:02:44 - INFO :       high_school_psychology: Total Sparsity 1.3631882972344008e-06
2023-12-01 18:02:44 - INFO :       
==================Finish================

2023-12-01 18:02:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:02:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:02:44 - INFO :       DATASET: tasksource/mmlu high_school_statistics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.46s/it]
2023-12-01 18:02:52 - INFO :       Use random pruner...
2023-12-01 18:02:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:02:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:02:53 - INFO :       Start Pruning
2023-12-01 18:02:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:02:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:02:55 - INFO :       high_school_statistics: Total Sparsity 1.3607203499744394e-06
2023-12-01 18:02:55 - INFO :       
==================Finish================

2023-12-01 18:02:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:02:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:02:55 - INFO :       DATASET: tasksource/mmlu high_school_us_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]
2023-12-01 18:03:03 - INFO :       Use random pruner...
2023-12-01 18:03:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:03:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:03:03 - INFO :       Start Pruning
2023-12-01 18:03:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:03:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:03:05 - INFO :       high_school_us_history: Total Sparsity 1.3612491958158596e-06
2023-12-01 18:03:05 - INFO :       
==================Finish================

2023-12-01 18:03:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:03:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:03:05 - INFO :       DATASET: tasksource/mmlu high_school_world_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]
2023-12-01 18:03:13 - INFO :       Use random pruner...
2023-12-01 18:03:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:03:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:03:13 - INFO :       Start Pruning
2023-12-01 18:03:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:03:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:03:15 - INFO :       high_school_world_history: Total Sparsity 1.363540861128681e-06
2023-12-01 18:03:15 - INFO :       
==================Finish================

2023-12-01 18:03:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:03:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:03:15 - INFO :       DATASET: tasksource/mmlu human_aging
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 18:03:23 - INFO :       Use random pruner...
2023-12-01 18:03:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:03:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:03:24 - INFO :       Start Pruning
2023-12-01 18:03:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:03:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:03:25 - INFO :       human_aging: Total Sparsity 1.3663613722829226e-06
2023-12-01 18:03:25 - INFO :       
==================Finish================

2023-12-01 18:03:25 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:03:25 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:03:25 - INFO :       DATASET: tasksource/mmlu human_sexuality
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
2023-12-01 18:03:33 - INFO :       Use random pruner...
2023-12-01 18:03:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:03:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:03:34 - INFO :       Start Pruning
2023-12-01 18:03:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:03:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:03:36 - INFO :       human_sexuality: Total Sparsity 1.372178676538546e-06
2023-12-01 18:03:36 - INFO :       
==================Finish================

2023-12-01 18:03:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:03:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:03:36 - INFO :       DATASET: tasksource/mmlu international_law
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2023-12-01 18:03:44 - INFO :       Use random pruner...
2023-12-01 18:03:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:03:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:03:44 - INFO :       Start Pruning
2023-12-01 18:03:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:03:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:03:46 - INFO :       international_law: Total Sparsity 1.3651273986529418e-06
2023-12-01 18:03:46 - INFO :       
==================Finish================

2023-12-01 18:03:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:03:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:03:46 - INFO :       DATASET: tasksource/mmlu jurisprudence
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2023-12-01 18:03:54 - INFO :       Use random pruner...
2023-12-01 18:03:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:03:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:03:55 - INFO :       Start Pruning
2023-12-01 18:03:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:03:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:03:56 - INFO :       jurisprudence: Total Sparsity 1.363540861128681e-06
2023-12-01 18:03:56 - INFO :       
==================Finish================

2023-12-01 18:03:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:03:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:03:56 - INFO :       DATASET: tasksource/mmlu logical_fallacies
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]
2023-12-01 18:04:05 - INFO :       Use random pruner...
2023-12-01 18:04:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:04:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:04:05 - INFO :       Start Pruning
2023-12-01 18:04:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:04:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:04:07 - INFO :       logical_fallacies: Total Sparsity 1.363717143075821e-06
2023-12-01 18:04:07 - INFO :       
==================Finish================

2023-12-01 18:04:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:04:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:04:07 - INFO :       DATASET: tasksource/mmlu machine_learning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2023-12-01 18:04:17 - INFO :       Use random pruner...
2023-12-01 18:04:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:04:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:04:18 - INFO :       Start Pruning
2023-12-01 18:04:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:04:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:04:19 - INFO :       machine_learning: Total Sparsity 1.3712972668028455e-06
2023-12-01 18:04:19 - INFO :       
==================Finish================

2023-12-01 18:04:19 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:04:19 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:04:19 - INFO :       DATASET: tasksource/mmlu management
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 18:04:29 - INFO :       Use random pruner...
2023-12-01 18:04:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:04:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:04:29 - INFO :       Start Pruning
2023-12-01 18:04:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:04:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:04:31 - INFO :       management: Total Sparsity 1.3607203499744394e-06
2023-12-01 18:04:31 - INFO :       
==================Finish================

2023-12-01 18:04:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:04:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:04:31 - INFO :       DATASET: tasksource/mmlu marketing
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]
2023-12-01 18:04:41 - INFO :       Use random pruner...
2023-12-01 18:04:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:04:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:04:41 - INFO :       Start Pruning
2023-12-01 18:04:42 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:04:42 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:04:43 - INFO :       marketing: Total Sparsity 1.367242782018623e-06
2023-12-01 18:04:43 - INFO :       
==================Finish================

2023-12-01 18:04:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:04:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:04:43 - INFO :       DATASET: tasksource/mmlu medical_genetics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2023-12-01 18:04:52 - INFO :       Use random pruner...
2023-12-01 18:04:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:04:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:04:53 - INFO :       Start Pruning
2023-12-01 18:04:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:04:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:04:55 - INFO :       medical_genetics: Total Sparsity 1.365479962547222e-06
2023-12-01 18:04:55 - INFO :       
==================Finish================

2023-12-01 18:04:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:04:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:04:55 - INFO :       DATASET: tasksource/mmlu miscellaneous
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]
2023-12-01 18:05:04 - INFO :       Use random pruner...
2023-12-01 18:05:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:05:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:05:04 - INFO :       Start Pruning
2023-12-01 18:05:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:05:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:05:06 - INFO :       miscellaneous: Total Sparsity 1.36177804165728e-06
2023-12-01 18:05:06 - INFO :       
==================Finish================

2023-12-01 18:05:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:05:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:05:06 - INFO :       DATASET: tasksource/mmlu moral_disputes
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2023-12-01 18:05:16 - INFO :       Use random pruner...
2023-12-01 18:05:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:05:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:05:17 - INFO :       Start Pruning
2023-12-01 18:05:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:05:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:05:18 - INFO :       moral_disputes: Total Sparsity 1.3612491958158596e-06
2023-12-01 18:05:18 - INFO :       
==================Finish================

2023-12-01 18:05:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:05:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:05:18 - INFO :       DATASET: tasksource/mmlu moral_scenarios
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]
2023-12-01 18:05:29 - INFO :       Use random pruner...
2023-12-01 18:05:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:05:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:05:29 - INFO :       Start Pruning
2023-12-01 18:05:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:05:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:05:31 - INFO :       moral_scenarios: Total Sparsity 1.3534927901416952e-06
2023-12-01 18:05:31 - INFO :       
==================Finish================

2023-12-01 18:05:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:05:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:05:31 - INFO :       DATASET: tasksource/mmlu nutrition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]
2023-12-01 18:05:38 - INFO :       Use random pruner...
2023-12-01 18:05:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:05:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:05:39 - INFO :       Start Pruning
2023-12-01 18:05:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:05:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:05:40 - INFO :       nutrition: Total Sparsity 1.3467940761503715e-06
2023-12-01 18:05:40 - INFO :       
==================Finish================

2023-12-01 18:05:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:05:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:05:40 - INFO :       DATASET: tasksource/mmlu philosophy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.46s/it]
2023-12-01 18:05:49 - INFO :       Use random pruner...
2023-12-01 18:05:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:05:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:05:49 - INFO :       Start Pruning
2023-12-01 18:05:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:05:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:05:51 - INFO :       philosophy: Total Sparsity 1.3645985528115216e-06
2023-12-01 18:05:51 - INFO :       
==================Finish================

2023-12-01 18:05:51 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:05:51 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:05:51 - INFO :       DATASET: tasksource/mmlu prehistory
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 18:05:58 - INFO :       Use random pruner...
2023-12-01 18:05:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:05:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:05:59 - INFO :       Start Pruning
2023-12-01 18:06:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:06:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:06:00 - INFO :       prehistory: Total Sparsity 1.3628357333401206e-06
2023-12-01 18:06:00 - INFO :       
==================Finish================

2023-12-01 18:06:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:06:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:06:00 - INFO :       DATASET: tasksource/mmlu professional_accounting
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]
2023-12-01 18:06:08 - INFO :       Use random pruner...
2023-12-01 18:06:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:06:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:06:09 - INFO :       Start Pruning
2023-12-01 18:06:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:06:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:06:10 - INFO :       professional_accounting: Total Sparsity 1.3658325264415023e-06
2023-12-01 18:06:10 - INFO :       
==================Finish================

2023-12-01 18:06:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:06:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:06:10 - INFO :       DATASET: tasksource/mmlu professional_law
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]
2023-12-01 18:06:18 - INFO :       Use random pruner...
2023-12-01 18:06:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:06:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:06:19 - INFO :       Start Pruning
2023-12-01 18:06:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:06:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:06:20 - INFO :       professional_law: Total Sparsity 1.3508485609345937e-06
2023-12-01 18:06:21 - INFO :       
==================Finish================

2023-12-01 18:06:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:06:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:06:21 - INFO :       DATASET: tasksource/mmlu professional_medicine
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]
2023-12-01 18:06:28 - INFO :       Use random pruner...
2023-12-01 18:06:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:06:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:06:29 - INFO :       Start Pruning
2023-12-01 18:06:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:06:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:06:31 - INFO :       professional_medicine: Total Sparsity 1.3656562444943623e-06
2023-12-01 18:06:31 - INFO :       
==================Finish================

2023-12-01 18:06:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:06:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:06:31 - INFO :       DATASET: tasksource/mmlu professional_psychology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]
2023-12-01 18:06:39 - INFO :       Use random pruner...
2023-12-01 18:06:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:06:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:06:39 - INFO :       Start Pruning
2023-12-01 18:06:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:06:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:06:41 - INFO :       professional_psychology: Total Sparsity 1.3631882972344008e-06
2023-12-01 18:06:41 - INFO :       
==================Finish================

2023-12-01 18:06:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:06:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:06:41 - INFO :       DATASET: tasksource/mmlu public_relations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 18:06:49 - INFO :       Use random pruner...
2023-12-01 18:06:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:06:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:06:49 - INFO :       Start Pruning
2023-12-01 18:06:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:06:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:06:51 - INFO :       public_relations: Total Sparsity 1.3716498306971257e-06
2023-12-01 18:06:51 - INFO :       
==================Finish================

2023-12-01 18:06:51 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:06:51 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:06:51 - INFO :       DATASET: tasksource/mmlu security_studies
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 18:06:58 - INFO :       Use random pruner...
2023-12-01 18:06:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:06:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:06:59 - INFO :       Start Pruning
2023-12-01 18:06:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:06:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:07:00 - INFO :       security_studies: Total Sparsity 1.3645985528115216e-06
2023-12-01 18:07:00 - INFO :       
==================Finish================

2023-12-01 18:07:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:07:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:07:00 - INFO :       DATASET: tasksource/mmlu sociology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 18:07:08 - INFO :       Use random pruner...
2023-12-01 18:07:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:07:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:07:08 - INFO :       Start Pruning
2023-12-01 18:07:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:07:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:07:10 - INFO :       sociology: Total Sparsity 1.3679479098071835e-06
2023-12-01 18:07:10 - INFO :       
==================Finish================

2023-12-01 18:07:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:07:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:07:10 - INFO :       DATASET: tasksource/mmlu us_foreign_policy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]
2023-12-01 18:07:18 - INFO :       Use random pruner...
2023-12-01 18:07:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:07:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:07:18 - INFO :       Start Pruning
2023-12-01 18:07:19 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:07:19 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:07:20 - INFO :       us_foreign_policy: Total Sparsity 1.3607203499744394e-06
2023-12-01 18:07:20 - INFO :       
==================Finish================

2023-12-01 18:07:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:07:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:07:20 - INFO :       DATASET: tasksource/mmlu virology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]
2023-12-01 18:07:28 - INFO :       Use random pruner...
2023-12-01 18:07:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:07:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:07:28 - INFO :       Start Pruning
2023-12-01 18:07:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:07:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:07:30 - INFO :       virology: Total Sparsity 1.3614254777629999e-06
2023-12-01 18:07:30 - INFO :       
==================Finish================

2023-12-01 18:07:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:07:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:07:30 - INFO :       DATASET: tasksource/mmlu world_religions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2023-12-01 18:07:38 - INFO :       Use random pruner...
2023-12-01 18:07:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:07:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:07:38 - INFO :       Start Pruning
2023-12-01 18:07:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:07:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:07:40 - INFO :       world_religions: Total Sparsity 1.3665376542300628e-06
2023-12-01 18:07:40 - INFO :       
==================Finish================

2023-12-01 18:07:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:07:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:07:40 - INFO :       DATASET: math_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]
2023-12-01 18:07:47 - INFO :       Use random pruner...
2023-12-01 18:07:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:07:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:07:48 - INFO :       Start Pruning
2023-12-01 18:07:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:07:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:07:50 - INFO :       math_qa: Total Sparsity 1.3675953459129033e-06
2023-12-01 18:07:50 - INFO :       
==================Finish================

2023-12-01 18:07:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:07:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:07:50 - INFO :       DATASET: EleutherAI/truthful_qa_mc
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]
2023-12-01 18:07:57 - INFO :       Use random pruner...
2023-12-01 18:07:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:07:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:07:57 - INFO :       Start Pruning
2023-12-01 18:07:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:07:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:07:59 - INFO :       truthful_qa_mc: Total Sparsity 1.3663613722829226e-06
2023-12-01 18:07:59 - INFO :       
==================Finish================

2023-12-01 18:07:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:07:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:07:59 - INFO :       DATASET: derek-thomas/ScienceQA
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]
2023-12-01 18:08:08 - INFO :       Use random pruner...
2023-12-01 18:08:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:08:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:08:09 - INFO :       Start Pruning
2023-12-01 18:08:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:08:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:08:10 - INFO :       ScienceQA: Total Sparsity 1.36177804165728e-06
2023-12-01 18:08:10 - INFO :       
==================Finish================

2023-12-01 18:08:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:08:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:08:10 - INFO :       DATASET: commonsense_qa
Index 4
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 18:08:21 - INFO :       Use random pruner...
2023-12-01 18:08:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:08:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:08:22 - INFO :       Start Pruning
2023-12-01 18:08:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:08:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:08:24 - INFO :       commonsense_qa: Total Sparsity 1.3649511167058018e-06
2023-12-01 18:08:24 - INFO :       
==================Finish================

2023-12-01 18:08:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:08:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:08:24 - INFO :       DATASET: tasksource/bigbench abstract_narrative_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.98s/it]
2023-12-01 18:08:33 - INFO :       Use random pruner...
2023-12-01 18:08:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:08:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:08:34 - INFO :       Start Pruning
2023-12-01 18:08:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:08:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:08:36 - INFO :       abstract_narrative_understanding: Total Sparsity 1.3536690720888354e-06
2023-12-01 18:08:36 - INFO :       
==================Finish================

2023-12-01 18:08:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:08:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:08:36 - INFO :       DATASET: tasksource/bigbench anachronisms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]
2023-12-01 18:08:44 - INFO :       Use random pruner...
2023-12-01 18:08:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:08:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:08:44 - INFO :       Start Pruning
2023-12-01 18:08:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:08:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:08:46 - INFO :       anachronisms: Total Sparsity 1.3605440680272994e-06
2023-12-01 18:08:46 - INFO :       
==================Finish================

2023-12-01 18:08:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:08:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:08:46 - INFO :       DATASET: tasksource/bigbench analogical_similarity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.50s/it]
2023-12-01 18:08:53 - INFO :       Use random pruner...
2023-12-01 18:08:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:08:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:08:54 - INFO :       Start Pruning
2023-12-01 18:08:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:08:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:08:56 - INFO :       analogical_similarity: Total Sparsity 1.3598389402387389e-06
2023-12-01 18:08:56 - INFO :       
==================Finish================

2023-12-01 18:08:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:08:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:08:56 - INFO :       DATASET: tasksource/bigbench analytic_entailment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]
2023-12-01 18:09:03 - INFO :       Use random pruner...
2023-12-01 18:09:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:09:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:09:04 - INFO :       Start Pruning
2023-12-01 18:09:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:09:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:09:05 - INFO :       analytic_entailment: Total Sparsity 1.367242782018623e-06
2023-12-01 18:09:05 - INFO :       
==================Finish================

2023-12-01 18:09:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:09:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:09:05 - INFO :       DATASET: tasksource/bigbench arithmetic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]
2023-12-01 18:09:13 - INFO :       Use random pruner...
2023-12-01 18:09:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:09:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:09:14 - INFO :       Start Pruning
2023-12-01 18:09:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:09:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:09:16 - INFO :       arithmetic: Total Sparsity 1.369005601490024e-06
2023-12-01 18:09:16 - INFO :       
==================Finish================

2023-12-01 18:09:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:09:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:09:16 - INFO :       DATASET: tasksource/bigbench authorship_verification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2023-12-01 18:09:24 - INFO :       Use random pruner...
2023-12-01 18:09:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:09:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:09:24 - INFO :       Start Pruning
2023-12-01 18:09:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:09:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:09:26 - INFO :       authorship_verification: Total Sparsity 1.3660088083886423e-06
2023-12-01 18:09:26 - INFO :       
==================Finish================

2023-12-01 18:09:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:09:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:09:26 - INFO :       DATASET: tasksource/bigbench bbq_lite_json
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]
2023-12-01 18:09:34 - INFO :       Use random pruner...
2023-12-01 18:09:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:09:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:09:34 - INFO :       Start Pruning
2023-12-01 18:09:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:09:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:09:36 - INFO :       bbq_lite_json: Total Sparsity 1.3638934250229613e-06
2023-12-01 18:09:36 - INFO :       
==================Finish================

2023-12-01 18:09:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:09:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:09:36 - INFO :       DATASET: tasksource/bigbench causal_judgment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.46s/it]
2023-12-01 18:09:44 - INFO :       Use random pruner...
2023-12-01 18:09:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:09:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:09:44 - INFO :       Start Pruning
2023-12-01 18:09:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:09:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:09:46 - INFO :       causal_judgment: Total Sparsity 1.3541979179302557e-06
2023-12-01 18:09:46 - INFO :       
==================Finish================

2023-12-01 18:09:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:09:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:09:46 - INFO :       DATASET: tasksource/bigbench cause_and_effect
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]
2023-12-01 18:09:54 - INFO :       Use random pruner...
2023-12-01 18:09:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:09:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:09:54 - INFO :       Start Pruning
2023-12-01 18:09:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:09:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:09:56 - INFO :       cause_and_effect: Total Sparsity 1.3616017597101399e-06
2023-12-01 18:09:56 - INFO :       
==================Finish================

2023-12-01 18:09:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:09:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:09:56 - INFO :       DATASET: tasksource/bigbench checkmate_in_one
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]
2023-12-01 18:10:04 - INFO :       Use random pruner...
2023-12-01 18:10:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:10:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:10:04 - INFO :       Start Pruning
2023-12-01 18:10:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:10:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:10:06 - INFO :       checkmate_in_one: Total Sparsity 1.3628357333401206e-06
2023-12-01 18:10:06 - INFO :       
==================Finish================

2023-12-01 18:10:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:10:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:10:06 - INFO :       DATASET: tasksource/bigbench cifar10_classification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]
2023-12-01 18:10:13 - INFO :       Use random pruner...
2023-12-01 18:10:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:10:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:10:13 - INFO :       Start Pruning
2023-12-01 18:10:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:10:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:10:15 - INFO :       cifar10_classification: Total Sparsity 1.3589575305030384e-06
2023-12-01 18:10:15 - INFO :       
==================Finish================

2023-12-01 18:10:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:10:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:10:15 - INFO :       DATASET: tasksource/bigbench code_line_description
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]
2023-12-01 18:10:23 - INFO :       Use random pruner...
2023-12-01 18:10:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:10:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:10:23 - INFO :       Start Pruning
2023-12-01 18:10:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:10:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:10:25 - INFO :       code_line_description: Total Sparsity 1.3631882972344008e-06
2023-12-01 18:10:25 - INFO :       
==================Finish================

2023-12-01 18:10:25 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:10:25 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:10:25 - INFO :       DATASET: tasksource/bigbench color
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.50s/it]
2023-12-01 18:10:33 - INFO :       Use random pruner...
2023-12-01 18:10:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:10:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:10:33 - INFO :       Start Pruning
2023-12-01 18:10:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:10:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:10:35 - INFO :       color: Total Sparsity 1.372178676538546e-06
2023-12-01 18:10:35 - INFO :       
==================Finish================

2023-12-01 18:10:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:10:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:10:35 - INFO :       DATASET: tasksource/bigbench common_morpheme
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2023-12-01 18:10:43 - INFO :       Use random pruner...
2023-12-01 18:10:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:10:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:10:44 - INFO :       Start Pruning
2023-12-01 18:10:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:10:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:10:45 - INFO :       common_morpheme: Total Sparsity 1.3533165081945552e-06
2023-12-01 18:10:45 - INFO :       
==================Finish================

2023-12-01 18:10:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:10:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:10:45 - INFO :       DATASET: tasksource/bigbench conceptual_combinations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2023-12-01 18:10:53 - INFO :       Use random pruner...
2023-12-01 18:10:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:10:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:10:54 - INFO :       Start Pruning
2023-12-01 18:10:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:10:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:10:55 - INFO :       conceptual_combinations: Total Sparsity 1.3667139361772028e-06
2023-12-01 18:10:55 - INFO :       
==================Finish================

2023-12-01 18:10:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:10:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:10:55 - INFO :       DATASET: tasksource/bigbench crash_blossom
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 18:11:02 - INFO :       Use random pruner...
2023-12-01 18:11:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:11:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:11:02 - INFO :       Start Pruning
2023-12-01 18:11:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:11:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:11:04 - INFO :       crash_blossom: Total Sparsity 1.3631882972344008e-06
2023-12-01 18:11:04 - INFO :       
==================Finish================

2023-12-01 18:11:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:11:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:11:04 - INFO :       DATASET: tasksource/bigbench crass_ai
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 18:11:11 - INFO :       Use random pruner...
2023-12-01 18:11:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:11:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:11:12 - INFO :       Start Pruning
2023-12-01 18:11:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:11:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:11:14 - INFO :       crass_ai: Total Sparsity 1.3601915041330191e-06
2023-12-01 18:11:14 - INFO :       
==================Finish================

2023-12-01 18:11:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:11:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:11:14 - INFO :       DATASET: tasksource/bigbench cryobiology_spanish
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2023-12-01 18:11:24 - INFO :       Use random pruner...
2023-12-01 18:11:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:11:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:11:24 - INFO :       Start Pruning
2023-12-01 18:11:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:11:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:11:26 - INFO :       cryobiology_spanish: Total Sparsity 1.3578998388201979e-06
2023-12-01 18:11:26 - INFO :       
==================Finish================

2023-12-01 18:11:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:11:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:11:26 - INFO :       DATASET: tasksource/bigbench cs_algorithms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]
2023-12-01 18:11:35 - INFO :       Use random pruner...
2023-12-01 18:11:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:11:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:11:35 - INFO :       Start Pruning
2023-12-01 18:11:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:11:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:11:37 - INFO :       cs_algorithms: Total Sparsity 1.3640697069701013e-06
2023-12-01 18:11:37 - INFO :       
==================Finish================

2023-12-01 18:11:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:11:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:11:37 - INFO :       DATASET: tasksource/bigbench dark_humor_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 18:11:47 - INFO :       Use random pruner...
2023-12-01 18:11:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:11:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:11:47 - INFO :       Start Pruning
2023-12-01 18:11:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:11:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:11:49 - INFO :       dark_humor_detection: Total Sparsity 1.3570184290844972e-06
2023-12-01 18:11:49 - INFO :       
==================Finish================

2023-12-01 18:11:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:11:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:11:49 - INFO :       DATASET: tasksource/bigbench date_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2023-12-01 18:11:58 - INFO :       Use random pruner...
2023-12-01 18:11:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:11:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:11:58 - INFO :       Start Pruning
2023-12-01 18:11:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:11:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:12:00 - INFO :       date_understanding: Total Sparsity 1.358076120767338e-06
2023-12-01 18:12:00 - INFO :       
==================Finish================

2023-12-01 18:12:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:12:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:12:00 - INFO :       DATASET: tasksource/bigbench disambiguation_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2023-12-01 18:12:10 - INFO :       Use random pruner...
2023-12-01 18:12:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:12:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:12:10 - INFO :       Start Pruning
2023-12-01 18:12:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:12:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:12:12 - INFO :       disambiguation_qa: Total Sparsity 1.3695344473314445e-06
2023-12-01 18:12:12 - INFO :       
==================Finish================

2023-12-01 18:12:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:12:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:12:12 - INFO :       DATASET: tasksource/bigbench discourse_marker_prediction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]
2023-12-01 18:12:21 - INFO :       Use random pruner...
2023-12-01 18:12:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:12:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:12:21 - INFO :       Start Pruning
2023-12-01 18:12:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:12:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:12:23 - INFO :       discourse_marker_prediction: Total Sparsity 1.3612491958158596e-06
2023-12-01 18:12:23 - INFO :       
==================Finish================

2023-12-01 18:12:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:12:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:12:23 - INFO :       DATASET: tasksource/bigbench dyck_languages
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2023-12-01 18:12:34 - INFO :       Use random pruner...
2023-12-01 18:12:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:12:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:12:35 - INFO :       Start Pruning
2023-12-01 18:12:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:12:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:12:37 - INFO :       dyck_languages: Total Sparsity 1.354726763771676e-06
2023-12-01 18:12:37 - INFO :       
==================Finish================

2023-12-01 18:12:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:12:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:12:37 - INFO :       DATASET: tasksource/bigbench elementary_math_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.33s/it]
2023-12-01 18:12:48 - INFO :       Use random pruner...
2023-12-01 18:12:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:12:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:12:48 - INFO :       Start Pruning
2023-12-01 18:12:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:12:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:12:50 - INFO :       elementary_math_qa: Total Sparsity 1.3649511167058018e-06
2023-12-01 18:12:50 - INFO :       
==================Finish================

2023-12-01 18:12:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:12:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:12:50 - INFO :       DATASET: tasksource/bigbench emoji_movie
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.35s/it]
2023-12-01 18:13:01 - INFO :       Use random pruner...
2023-12-01 18:13:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:13:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:13:01 - INFO :       Start Pruning
2023-12-01 18:13:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:13:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:13:03 - INFO :       emoji_movie: Total Sparsity 1.3621306055515601e-06
2023-12-01 18:13:03 - INFO :       
==================Finish================

2023-12-01 18:13:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:13:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:13:03 - INFO :       DATASET: tasksource/bigbench empirical_judgments
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]
2023-12-01 18:13:15 - INFO :       Use random pruner...
2023-12-01 18:13:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:13:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:13:15 - INFO :       Start Pruning
2023-12-01 18:13:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:13:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:13:17 - INFO :       empirical_judgments: Total Sparsity 1.3485568956217725e-06
2023-12-01 18:13:17 - INFO :       
==================Finish================

2023-12-01 18:13:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:13:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:13:17 - INFO :       DATASET: tasksource/bigbench english_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 18:13:28 - INFO :       Use random pruner...
2023-12-01 18:13:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:13:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:13:28 - INFO :       Start Pruning
2023-12-01 18:13:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:13:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:13:30 - INFO :       english_proverbs: Total Sparsity 1.3601915041330191e-06
2023-12-01 18:13:30 - INFO :       
==================Finish================

2023-12-01 18:13:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:13:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:13:30 - INFO :       DATASET: tasksource/bigbench english_russian_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 18:13:41 - INFO :       Use random pruner...
2023-12-01 18:13:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:13:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:13:42 - INFO :       Start Pruning
2023-12-01 18:13:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:13:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:13:44 - INFO :       english_russian_proverbs: Total Sparsity 1.3623068874987003e-06
2023-12-01 18:13:44 - INFO :       
==================Finish================

2023-12-01 18:13:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:13:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:13:44 - INFO :       DATASET: tasksource/bigbench entailed_polarity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 18:13:55 - INFO :       Use random pruner...
2023-12-01 18:13:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:13:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:13:56 - INFO :       Start Pruning
2023-12-01 18:13:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:13:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:13:57 - INFO :       entailed_polarity: Total Sparsity 1.3549030457188162e-06
2023-12-01 18:13:57 - INFO :       
==================Finish================

2023-12-01 18:13:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:13:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:13:57 - INFO :       DATASET: tasksource/bigbench entailed_polarity_hindi
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]
2023-12-01 18:14:09 - INFO :       Use random pruner...
2023-12-01 18:14:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:14:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:14:09 - INFO :       Start Pruning
2023-12-01 18:14:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:14:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:14:11 - INFO :       entailed_polarity_hindi: Total Sparsity 1.3667139361772028e-06
2023-12-01 18:14:11 - INFO :       
==================Finish================

2023-12-01 18:14:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:14:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:14:11 - INFO :       DATASET: tasksource/bigbench epistemic_reasoning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]
2023-12-01 18:14:22 - INFO :       Use random pruner...
2023-12-01 18:14:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:14:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:14:22 - INFO :       Start Pruning
2023-12-01 18:14:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:14:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:14:24 - INFO :       epistemic_reasoning: Total Sparsity 1.3566658651902172e-06
2023-12-01 18:14:24 - INFO :       
==================Finish================

2023-12-01 18:14:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:14:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:14:24 - INFO :       DATASET: tasksource/bigbench evaluating_information_essentiality
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.29s/it]
2023-12-01 18:14:35 - INFO :       Use random pruner...
2023-12-01 18:14:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:14:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:14:36 - INFO :       Start Pruning
2023-12-01 18:14:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:14:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:14:38 - INFO :       evaluating_information_essentiality: Total Sparsity 1.3578998388201979e-06
2023-12-01 18:14:38 - INFO :       
==================Finish================

2023-12-01 18:14:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:14:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:14:38 - INFO :       DATASET: tasksource/bigbench fact_checker
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]
2023-12-01 18:14:49 - INFO :       Use random pruner...
2023-12-01 18:14:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:14:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:14:49 - INFO :       Start Pruning
2023-12-01 18:14:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:14:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:14:51 - INFO :       fact_checker: Total Sparsity 1.3538453540359754e-06
2023-12-01 18:14:51 - INFO :       
==================Finish================

2023-12-01 18:14:51 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:14:51 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:14:51 - INFO :       DATASET: tasksource/bigbench fantasy_reasoning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]
2023-12-01 18:15:02 - INFO :       Use random pruner...
2023-12-01 18:15:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:15:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:15:03 - INFO :       Start Pruning
2023-12-01 18:15:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:15:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:15:05 - INFO :       fantasy_reasoning: Total Sparsity 1.3645985528115216e-06
2023-12-01 18:15:05 - INFO :       
==================Finish================

2023-12-01 18:15:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:15:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:15:05 - INFO :       DATASET: tasksource/bigbench figure_of_speech_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.35s/it]
2023-12-01 18:15:16 - INFO :       Use random pruner...
2023-12-01 18:15:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:15:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:15:16 - INFO :       Start Pruning
2023-12-01 18:15:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:15:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:15:18 - INFO :       figure_of_speech_detection: Total Sparsity 1.3621306055515601e-06
2023-12-01 18:15:18 - INFO :       
==================Finish================

2023-12-01 18:15:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:15:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:15:18 - INFO :       DATASET: tasksource/bigbench formal_fallacies_syllogisms_negation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 18:15:29 - INFO :       Use random pruner...
2023-12-01 18:15:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:15:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:15:30 - INFO :       Start Pruning
2023-12-01 18:15:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:15:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:15:32 - INFO :       formal_fallacies_syllogisms_negation: Total Sparsity 1.3638934250229613e-06
2023-12-01 18:15:32 - INFO :       
==================Finish================

2023-12-01 18:15:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:15:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:15:32 - INFO :       DATASET: tasksource/bigbench general_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.29s/it]
2023-12-01 18:15:43 - INFO :       Use random pruner...
2023-12-01 18:15:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:15:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:15:43 - INFO :       Start Pruning
2023-12-01 18:15:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:15:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:15:45 - INFO :       general_knowledge: Total Sparsity 1.3623068874987003e-06
2023-12-01 18:15:45 - INFO :       
==================Finish================

2023-12-01 18:15:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:15:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:15:45 - INFO :       DATASET: tasksource/bigbench geometric_shapes
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 18:15:57 - INFO :       Use random pruner...
2023-12-01 18:15:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:15:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:15:58 - INFO :       Start Pruning
2023-12-01 18:15:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:15:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:15:59 - INFO :       geometric_shapes: Total Sparsity 1.3748229057456475e-06
2023-12-01 18:15:59 - INFO :       
==================Finish================

2023-12-01 18:15:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:15:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:15:59 - INFO :       DATASET: tasksource/bigbench goal_step_wikihow
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.23s/it]
2023-12-01 18:16:10 - INFO :       Use random pruner...
2023-12-01 18:16:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:16:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:16:11 - INFO :       Start Pruning
2023-12-01 18:16:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:16:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:16:12 - INFO :       goal_step_wikihow: Total Sparsity 1.3612491958158596e-06
2023-12-01 18:16:12 - INFO :       
==================Finish================

2023-12-01 18:16:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:16:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:16:12 - INFO :       DATASET: tasksource/bigbench gre_reading_comprehension
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 18:16:24 - INFO :       Use random pruner...
2023-12-01 18:16:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:16:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:16:24 - INFO :       Start Pruning
2023-12-01 18:16:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:16:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:16:26 - INFO :       gre_reading_comprehension: Total Sparsity 1.358252402714478e-06
2023-12-01 18:16:26 - INFO :       
==================Finish================

2023-12-01 18:16:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:16:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:16:26 - INFO :       DATASET: tasksource/bigbench hhh_alignment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.19s/it]
2023-12-01 18:16:37 - INFO :       Use random pruner...
2023-12-01 18:16:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:16:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:16:38 - INFO :       Start Pruning
2023-12-01 18:16:38 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:16:38 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:16:39 - INFO :       hhh_alignment: Total Sparsity 1.3578998388201979e-06
2023-12-01 18:16:39 - INFO :       
==================Finish================

2023-12-01 18:16:39 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:16:39 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:16:39 - INFO :       DATASET: tasksource/bigbench hindu_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]
2023-12-01 18:16:51 - INFO :       Use random pruner...
2023-12-01 18:16:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:16:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:16:51 - INFO :       Start Pruning
2023-12-01 18:16:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:16:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:16:53 - INFO :       hindu_knowledge: Total Sparsity 1.3561370193487967e-06
2023-12-01 18:16:53 - INFO :       
==================Finish================

2023-12-01 18:16:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:16:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:16:53 - INFO :       DATASET: tasksource/bigbench hinglish_toxicity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]
2023-12-01 18:17:03 - INFO :       Use random pruner...
2023-12-01 18:17:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:17:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:17:04 - INFO :       Start Pruning
2023-12-01 18:17:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:17:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:17:06 - INFO :       hinglish_toxicity: Total Sparsity 1.3691818834371643e-06
2023-12-01 18:17:06 - INFO :       
==================Finish================

2023-12-01 18:17:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:17:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:17:06 - INFO :       DATASET: tasksource/bigbench human_organs_senses
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]
2023-12-01 18:17:16 - INFO :       Use random pruner...
2023-12-01 18:17:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:17:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:17:16 - INFO :       Start Pruning
2023-12-01 18:17:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:17:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:17:18 - INFO :       human_organs_senses: Total Sparsity 1.3605440680272994e-06
2023-12-01 18:17:18 - INFO :       
==================Finish================

2023-12-01 18:17:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:17:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:17:18 - INFO :       DATASET: tasksource/bigbench hyperbaton
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2023-12-01 18:17:27 - INFO :       Use random pruner...
2023-12-01 18:17:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:17:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:17:27 - INFO :       Start Pruning
2023-12-01 18:17:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:17:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:17:29 - INFO :       hyperbaton: Total Sparsity 1.3561370193487967e-06
2023-12-01 18:17:29 - INFO :       
==================Finish================

2023-12-01 18:17:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:17:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:17:29 - INFO :       DATASET: tasksource/bigbench identify_math_theorems
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]
2023-12-01 18:17:40 - INFO :       Use random pruner...
2023-12-01 18:17:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:17:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:17:41 - INFO :       Start Pruning
2023-12-01 18:17:42 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:17:42 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:17:43 - INFO :       identify_math_theorems: Total Sparsity 1.3612491958158596e-06
2023-12-01 18:17:43 - INFO :       
==================Finish================

2023-12-01 18:17:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:17:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:17:43 - INFO :       DATASET: tasksource/bigbench identify_odd_metaphor
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
2023-12-01 18:17:54 - INFO :       Use random pruner...
2023-12-01 18:17:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:17:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:17:54 - INFO :       Start Pruning
2023-12-01 18:17:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:17:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:17:56 - INFO :       identify_odd_metaphor: Total Sparsity 1.3614254777629999e-06
2023-12-01 18:17:56 - INFO :       
==================Finish================

2023-12-01 18:17:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:17:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:17:56 - INFO :       DATASET: tasksource/bigbench implicatures
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]
2023-12-01 18:18:06 - INFO :       Use random pruner...
2023-12-01 18:18:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:18:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:18:06 - INFO :       Start Pruning
2023-12-01 18:18:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:18:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:18:08 - INFO :       implicatures: Total Sparsity 1.363717143075821e-06
2023-12-01 18:18:08 - INFO :       
==================Finish================

2023-12-01 18:18:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:18:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:18:08 - INFO :       DATASET: tasksource/bigbench implicit_relations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]
2023-12-01 18:18:17 - INFO :       Use random pruner...
2023-12-01 18:18:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:18:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:18:18 - INFO :       Start Pruning
2023-12-01 18:18:19 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:18:19 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:18:20 - INFO :       implicit_relations: Total Sparsity 1.3610729138687196e-06
2023-12-01 18:18:20 - INFO :       
==================Finish================

2023-12-01 18:18:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:18:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:18:20 - INFO :       DATASET: tasksource/bigbench indic_cause_and_effect
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.46s/it]
2023-12-01 18:18:29 - INFO :       Use random pruner...
2023-12-01 18:18:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:18:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:18:29 - INFO :       Start Pruning
2023-12-01 18:18:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:18:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:18:31 - INFO :       indic_cause_and_effect: Total Sparsity 1.3619543236044201e-06
2023-12-01 18:18:31 - INFO :       
==================Finish================

2023-12-01 18:18:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:18:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:18:31 - INFO :       DATASET: tasksource/bigbench intent_recognition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]
2023-12-01 18:18:41 - INFO :       Use random pruner...
2023-12-01 18:18:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:18:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:18:42 - INFO :       Start Pruning
2023-12-01 18:18:42 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:18:42 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:18:43 - INFO :       intent_recognition: Total Sparsity 1.3608966319215796e-06
2023-12-01 18:18:43 - INFO :       
==================Finish================

2023-12-01 18:18:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:18:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:18:43 - INFO :       DATASET: tasksource/bigbench international_phonetic_alphabet_nli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]
2023-12-01 18:18:53 - INFO :       Use random pruner...
2023-12-01 18:18:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:18:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:18:53 - INFO :       Start Pruning
2023-12-01 18:18:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:18:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:18:55 - INFO :       international_phonetic_alphabet_nli: Total Sparsity 1.3570184290844972e-06
2023-12-01 18:18:55 - INFO :       
==================Finish================

2023-12-01 18:18:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:18:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:18:55 - INFO :       DATASET: tasksource/bigbench intersect_geometry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2023-12-01 18:19:03 - INFO :       Use random pruner...
2023-12-01 18:19:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:19:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:19:03 - INFO :       Start Pruning
2023-12-01 18:19:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:19:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:19:05 - INFO :       intersect_geometry: Total Sparsity 1.3661850903357826e-06
2023-12-01 18:19:05 - INFO :       
==================Finish================

2023-12-01 18:19:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:19:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:19:05 - INFO :       DATASET: tasksource/bigbench irony_identification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2023-12-01 18:19:14 - INFO :       Use random pruner...
2023-12-01 18:19:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:19:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:19:15 - INFO :       Start Pruning
2023-12-01 18:19:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:19:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:19:16 - INFO :       irony_identification: Total Sparsity 1.3566658651902172e-06
2023-12-01 18:19:16 - INFO :       
==================Finish================

2023-12-01 18:19:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:19:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:19:16 - INFO :       DATASET: tasksource/bigbench kannada
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 18:19:24 - INFO :       Use random pruner...
2023-12-01 18:19:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:19:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:19:24 - INFO :       Start Pruning
2023-12-01 18:19:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:19:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:19:26 - INFO :       kannada: Total Sparsity 1.3594863763444586e-06
2023-12-01 18:19:26 - INFO :       
==================Finish================

2023-12-01 18:19:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:19:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:19:26 - INFO :       DATASET: tasksource/bigbench key_value_maps
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 18:19:35 - INFO :       Use random pruner...
2023-12-01 18:19:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:19:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:19:35 - INFO :       Start Pruning
2023-12-01 18:19:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:19:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:19:37 - INFO :       key_value_maps: Total Sparsity 1.3522588165117145e-06
2023-12-01 18:19:37 - INFO :       
==================Finish================

2023-12-01 18:19:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:19:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:19:37 - INFO :       DATASET: tasksource/bigbench known_unknowns
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]
2023-12-01 18:19:44 - INFO :       Use random pruner...
2023-12-01 18:19:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:19:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:19:45 - INFO :       Start Pruning
2023-12-01 18:19:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:19:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:19:47 - INFO :       known_unknowns: Total Sparsity 1.3566658651902172e-06
2023-12-01 18:19:47 - INFO :       
==================Finish================

2023-12-01 18:19:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:19:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:19:47 - INFO :       DATASET: tasksource/bigbench language_identification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2023-12-01 18:19:55 - INFO :       Use random pruner...
2023-12-01 18:19:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:19:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:19:55 - INFO :       Start Pruning
2023-12-01 18:19:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:19:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:19:57 - INFO :       language_identification: Total Sparsity 1.3515536887231542e-06
2023-12-01 18:19:57 - INFO :       
==================Finish================

2023-12-01 18:19:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:19:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:19:57 - INFO :       DATASET: tasksource/bigbench logic_grid_puzzle
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2023-12-01 18:20:05 - INFO :       Use random pruner...
2023-12-01 18:20:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:20:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:20:06 - INFO :       Start Pruning
2023-12-01 18:20:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:20:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:20:08 - INFO :       logic_grid_puzzle: Total Sparsity 1.3607203499744394e-06
2023-12-01 18:20:08 - INFO :       
==================Finish================

2023-12-01 18:20:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:20:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:20:08 - INFO :       DATASET: tasksource/bigbench logical_args
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2023-12-01 18:20:17 - INFO :       Use random pruner...
2023-12-01 18:20:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:20:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:20:17 - INFO :       Start Pruning
2023-12-01 18:20:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:20:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:20:19 - INFO :       logical_args: Total Sparsity 1.3684767556486038e-06
2023-12-01 18:20:19 - INFO :       
==================Finish================

2023-12-01 18:20:19 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:20:19 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:20:19 - INFO :       DATASET: tasksource/bigbench logical_deduction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 18:20:28 - INFO :       Use random pruner...
2023-12-01 18:20:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:20:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:20:28 - INFO :       Start Pruning
2023-12-01 18:20:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:20:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:20:30 - INFO :       logical_deduction: Total Sparsity 1.3584286846616181e-06
2023-12-01 18:20:30 - INFO :       
==================Finish================

2023-12-01 18:20:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:20:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:20:30 - INFO :       DATASET: tasksource/bigbench logical_fallacy_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2023-12-01 18:20:40 - INFO :       Use random pruner...
2023-12-01 18:20:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:20:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:20:40 - INFO :       Start Pruning
2023-12-01 18:20:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:20:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:20:42 - INFO :       logical_fallacy_detection: Total Sparsity 1.3681241917543236e-06
2023-12-01 18:20:42 - INFO :       
==================Finish================

2023-12-01 18:20:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:20:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:20:42 - INFO :       DATASET: tasksource/bigbench logical_sequence
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2023-12-01 18:20:51 - INFO :       Use random pruner...
2023-12-01 18:20:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:20:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:20:52 - INFO :       Start Pruning
2023-12-01 18:20:53 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:20:53 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:20:53 - INFO :       logical_sequence: Total Sparsity 1.3656562444943623e-06
2023-12-01 18:20:53 - INFO :       
==================Finish================

2023-12-01 18:20:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:20:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:20:53 - INFO :       DATASET: tasksource/bigbench mathematical_induction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]
2023-12-01 18:21:02 - INFO :       Use random pruner...
2023-12-01 18:21:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:21:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:21:03 - INFO :       Start Pruning
2023-12-01 18:21:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:21:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:21:04 - INFO :       mathematical_induction: Total Sparsity 1.3660088083886423e-06
2023-12-01 18:21:04 - INFO :       
==================Finish================

2023-12-01 18:21:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:21:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:21:04 - INFO :       DATASET: tasksource/bigbench medical_questions_russian
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]
2023-12-01 18:21:14 - INFO :       Use random pruner...
2023-12-01 18:21:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:21:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:21:14 - INFO :       Start Pruning
2023-12-01 18:21:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:21:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:21:16 - INFO :       medical_questions_russian: Total Sparsity 1.3587812485558984e-06
2023-12-01 18:21:16 - INFO :       
==================Finish================

2023-12-01 18:21:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:21:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:21:16 - INFO :       DATASET: tasksource/bigbench metaphor_boolean
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 18:21:24 - INFO :       Use random pruner...
2023-12-01 18:21:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:21:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:21:24 - INFO :       Start Pruning
2023-12-01 18:21:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:21:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:21:26 - INFO :       metaphor_boolean: Total Sparsity 1.3593100943973186e-06
2023-12-01 18:21:26 - INFO :       
==================Finish================

2023-12-01 18:21:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:21:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:21:26 - INFO :       DATASET: tasksource/bigbench metaphor_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 18:21:35 - INFO :       Use random pruner...
2023-12-01 18:21:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:21:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:21:36 - INFO :       Start Pruning
2023-12-01 18:21:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:21:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:21:37 - INFO :       metaphor_understanding: Total Sparsity 1.363540861128681e-06
2023-12-01 18:21:37 - INFO :       
==================Finish================

2023-12-01 18:21:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:21:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:21:37 - INFO :       DATASET: tasksource/bigbench misconceptions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]
2023-12-01 18:21:47 - INFO :       Use random pruner...
2023-12-01 18:21:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:21:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:21:48 - INFO :       Start Pruning
2023-12-01 18:21:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:21:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:21:49 - INFO :       misconceptions: Total Sparsity 1.3707684209614252e-06
2023-12-01 18:21:49 - INFO :       
==================Finish================

2023-12-01 18:21:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:21:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:21:49 - INFO :       DATASET: tasksource/bigbench misconceptions_russian
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]
2023-12-01 18:22:00 - INFO :       Use random pruner...
2023-12-01 18:22:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:22:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:22:00 - INFO :       Start Pruning
2023-12-01 18:22:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:22:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:22:02 - INFO :       misconceptions_russian: Total Sparsity 1.3640697069701013e-06
2023-12-01 18:22:02 - INFO :       
==================Finish================

2023-12-01 18:22:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:22:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:22:02 - INFO :       DATASET: tasksource/bigbench mnist_ascii
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]
2023-12-01 18:22:12 - INFO :       Use random pruner...
2023-12-01 18:22:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:22:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:22:12 - INFO :       Start Pruning
2023-12-01 18:22:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:22:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:22:14 - INFO :       mnist_ascii: Total Sparsity 1.3587812485558984e-06
2023-12-01 18:22:14 - INFO :       
==================Finish================

2023-12-01 18:22:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:22:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:22:14 - INFO :       DATASET: tasksource/bigbench moral_permissibility
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]
2023-12-01 18:22:23 - INFO :       Use random pruner...
2023-12-01 18:22:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:22:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:22:24 - INFO :       Start Pruning
2023-12-01 18:22:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:22:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:22:26 - INFO :       moral_permissibility: Total Sparsity 1.3631882972344008e-06
2023-12-01 18:22:26 - INFO :       
==================Finish================

2023-12-01 18:22:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:22:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:22:26 - INFO :       DATASET: tasksource/bigbench movie_dialog_same_or_different
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]
2023-12-01 18:22:36 - INFO :       Use random pruner...
2023-12-01 18:22:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:22:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:22:36 - INFO :       Start Pruning
2023-12-01 18:22:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:22:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:22:38 - INFO :       movie_dialog_same_or_different: Total Sparsity 1.3570184290844972e-06
2023-12-01 18:22:38 - INFO :       
==================Finish================

2023-12-01 18:22:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:22:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:22:38 - INFO :       DATASET: tasksource/bigbench movie_recommendation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]
2023-12-01 18:22:47 - INFO :       Use random pruner...
2023-12-01 18:22:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:22:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:22:47 - INFO :       Start Pruning
2023-12-01 18:22:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:22:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:22:49 - INFO :       movie_recommendation: Total Sparsity 1.368653037595744e-06
2023-12-01 18:22:49 - INFO :       
==================Finish================

2023-12-01 18:22:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:22:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:22:49 - INFO :       DATASET: tasksource/bigbench navigate
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]
2023-12-01 18:22:58 - INFO :       Use random pruner...
2023-12-01 18:22:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:22:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:22:59 - INFO :       Start Pruning
2023-12-01 18:22:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:22:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:23:00 - INFO :       navigate: Total Sparsity 1.3598389402387389e-06
2023-12-01 18:23:00 - INFO :       
==================Finish================

2023-12-01 18:23:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:23:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:23:00 - INFO :       DATASET: tasksource/bigbench nonsense_words_grammar
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 18:23:10 - INFO :       Use random pruner...
2023-12-01 18:23:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:23:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:23:10 - INFO :       Start Pruning
2023-12-01 18:23:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:23:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:23:12 - INFO :       nonsense_words_grammar: Total Sparsity 1.3644222708643816e-06
2023-12-01 18:23:12 - INFO :       
==================Finish================

2023-12-01 18:23:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:23:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:23:12 - INFO :       DATASET: tasksource/bigbench novel_concepts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
2023-12-01 18:23:20 - INFO :       Use random pruner...
2023-12-01 18:23:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:23:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:23:21 - INFO :       Start Pruning
2023-12-01 18:23:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:23:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:23:23 - INFO :       novel_concepts: Total Sparsity 1.36177804165728e-06
2023-12-01 18:23:23 - INFO :       
==================Finish================

2023-12-01 18:23:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:23:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:23:23 - INFO :       DATASET: tasksource/bigbench odd_one_out
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2023-12-01 18:23:32 - INFO :       Use random pruner...
2023-12-01 18:23:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:23:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:23:32 - INFO :       Start Pruning
2023-12-01 18:23:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:23:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:23:34 - INFO :       odd_one_out: Total Sparsity 1.3658325264415023e-06
2023-12-01 18:23:34 - INFO :       
==================Finish================

2023-12-01 18:23:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:23:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:23:34 - INFO :       DATASET: tasksource/bigbench parsinlu_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2023-12-01 18:23:44 - INFO :       Use random pruner...
2023-12-01 18:23:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:23:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:23:44 - INFO :       Start Pruning
2023-12-01 18:23:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:23:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:23:46 - INFO :       parsinlu_qa: Total Sparsity 1.3658325264415023e-06
2023-12-01 18:23:46 - INFO :       
==================Finish================

2023-12-01 18:23:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:23:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:23:46 - INFO :       DATASET: tasksource/bigbench penguins_in_a_table
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.91s/it]
2023-12-01 18:23:56 - INFO :       Use random pruner...
2023-12-01 18:23:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:23:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:23:56 - INFO :       Start Pruning
2023-12-01 18:23:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:23:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:23:58 - INFO :       penguins_in_a_table: Total Sparsity 1.3623068874987003e-06
2023-12-01 18:23:58 - INFO :       
==================Finish================

2023-12-01 18:23:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:23:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:23:58 - INFO :       DATASET: tasksource/bigbench persian_idioms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
2023-12-01 18:24:07 - INFO :       Use random pruner...
2023-12-01 18:24:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:24:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:24:07 - INFO :       Start Pruning
2023-12-01 18:24:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:24:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:24:09 - INFO :       persian_idioms: Total Sparsity 1.3674190639657633e-06
2023-12-01 18:24:09 - INFO :       
==================Finish================

2023-12-01 18:24:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:24:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:24:09 - INFO :       DATASET: tasksource/bigbench phrase_relatedness
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
2023-12-01 18:24:19 - INFO :       Use random pruner...
2023-12-01 18:24:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:24:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:24:19 - INFO :       Start Pruning
2023-12-01 18:24:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:24:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:24:21 - INFO :       phrase_relatedness: Total Sparsity 1.3651273986529418e-06
2023-12-01 18:24:21 - INFO :       
==================Finish================

2023-12-01 18:24:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:24:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:24:21 - INFO :       DATASET: tasksource/bigbench physical_intuition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2023-12-01 18:24:29 - INFO :       Use random pruner...
2023-12-01 18:24:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:24:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:24:30 - INFO :       Start Pruning
2023-12-01 18:24:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:24:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:24:32 - INFO :       physical_intuition: Total Sparsity 1.3575472749259176e-06
2023-12-01 18:24:32 - INFO :       
==================Finish================

2023-12-01 18:24:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:24:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:24:32 - INFO :       DATASET: tasksource/bigbench physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]
2023-12-01 18:24:40 - INFO :       Use random pruner...
2023-12-01 18:24:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:24:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:24:40 - INFO :       Start Pruning
2023-12-01 18:24:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:24:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:24:42 - INFO :       physics: Total Sparsity 1.3554318915602364e-06
2023-12-01 18:24:42 - INFO :       
==================Finish================

2023-12-01 18:24:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:24:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:24:42 - INFO :       DATASET: tasksource/bigbench play_dialog_same_or_different
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]
2023-12-01 18:24:50 - INFO :       Use random pruner...
2023-12-01 18:24:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:24:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:24:51 - INFO :       Start Pruning
2023-12-01 18:24:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:24:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:24:52 - INFO :       play_dialog_same_or_different: Total Sparsity 1.356313301295937e-06
2023-12-01 18:24:52 - INFO :       
==================Finish================

2023-12-01 18:24:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:24:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:24:52 - INFO :       DATASET: tasksource/bigbench presuppositions_as_nli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]
2023-12-01 18:25:02 - INFO :       Use random pruner...
2023-12-01 18:25:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:25:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:25:02 - INFO :       Start Pruning
2023-12-01 18:25:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:25:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:25:04 - INFO :       presuppositions_as_nli: Total Sparsity 1.3570184290844972e-06
2023-12-01 18:25:04 - INFO :       
==================Finish================

2023-12-01 18:25:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:25:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:25:04 - INFO :       DATASET: tasksource/bigbench question_selection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 18:25:12 - INFO :       Use random pruner...
2023-12-01 18:25:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:25:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:25:13 - INFO :       Start Pruning
2023-12-01 18:25:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:25:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:25:14 - INFO :       question_selection: Total Sparsity 1.369005601490024e-06
2023-12-01 18:25:14 - INFO :       
==================Finish================

2023-12-01 18:25:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:25:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:25:14 - INFO :       DATASET: tasksource/bigbench reasoning_about_colored_objects
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2023-12-01 18:25:23 - INFO :       Use random pruner...
2023-12-01 18:25:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:25:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:25:24 - INFO :       Start Pruning
2023-12-01 18:25:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:25:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:25:26 - INFO :       reasoning_about_colored_objects: Total Sparsity 1.3716498306971257e-06
2023-12-01 18:25:26 - INFO :       
==================Finish================

2023-12-01 18:25:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:25:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:25:26 - INFO :       DATASET: tasksource/bigbench riddle_sense
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 18:25:35 - INFO :       Use random pruner...
2023-12-01 18:25:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:25:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:25:35 - INFO :       Start Pruning
2023-12-01 18:25:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:25:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:25:37 - INFO :       riddle_sense: Total Sparsity 1.3630120152872606e-06
2023-12-01 18:25:37 - INFO :       
==================Finish================

2023-12-01 18:25:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:25:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:25:37 - INFO :       DATASET: tasksource/bigbench ruin_names
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2023-12-01 18:25:46 - INFO :       Use random pruner...
2023-12-01 18:25:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:25:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:25:46 - INFO :       Start Pruning
2023-12-01 18:25:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:25:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:25:48 - INFO :       ruin_names: Total Sparsity 1.352787662353135e-06
2023-12-01 18:25:48 - INFO :       
==================Finish================

2023-12-01 18:25:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:25:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:25:48 - INFO :       DATASET: tasksource/bigbench salient_translation_error_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]
2023-12-01 18:25:56 - INFO :       Use random pruner...
2023-12-01 18:25:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:25:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:25:56 - INFO :       Start Pruning
2023-12-01 18:25:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:25:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:25:58 - INFO :       salient_translation_error_detection: Total Sparsity 1.3533165081945552e-06
2023-12-01 18:25:58 - INFO :       
==================Finish================

2023-12-01 18:25:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:25:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:25:58 - INFO :       DATASET: tasksource/bigbench sentence_ambiguity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
2023-12-01 18:26:08 - INFO :       Use random pruner...
2023-12-01 18:26:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:26:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:26:09 - INFO :       Start Pruning
2023-12-01 18:26:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:26:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:26:10 - INFO :       sentence_ambiguity: Total Sparsity 1.3631882972344008e-06
2023-12-01 18:26:10 - INFO :       
==================Finish================

2023-12-01 18:26:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:26:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:26:10 - INFO :       DATASET: tasksource/bigbench similarities_abstraction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]
2023-12-01 18:26:20 - INFO :       Use random pruner...
2023-12-01 18:26:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:26:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:26:21 - INFO :       Start Pruning
2023-12-01 18:26:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:26:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:26:23 - INFO :       similarities_abstraction: Total Sparsity 1.3614254777629999e-06
2023-12-01 18:26:23 - INFO :       
==================Finish================

2023-12-01 18:26:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:26:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:26:23 - INFO :       DATASET: tasksource/bigbench simple_ethical_questions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2023-12-01 18:26:32 - INFO :       Use random pruner...
2023-12-01 18:26:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:26:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:26:32 - INFO :       Start Pruning
2023-12-01 18:26:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:26:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:26:34 - INFO :       simple_ethical_questions: Total Sparsity 1.3734126501685267e-06
2023-12-01 18:26:34 - INFO :       
==================Finish================

2023-12-01 18:26:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:26:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:26:34 - INFO :       DATASET: tasksource/bigbench snarks
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 18:26:44 - INFO :       Use random pruner...
2023-12-01 18:26:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:26:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:26:44 - INFO :       Start Pruning
2023-12-01 18:26:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:26:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:26:46 - INFO :       snarks: Total Sparsity 1.3693581653843043e-06
2023-12-01 18:26:46 - INFO :       
==================Finish================

2023-12-01 18:26:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:26:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:26:46 - INFO :       DATASET: tasksource/bigbench social_iqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.91s/it]
2023-12-01 18:26:56 - INFO :       Use random pruner...
2023-12-01 18:26:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:26:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:26:56 - INFO :       Start Pruning
2023-12-01 18:26:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:26:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:26:58 - INFO :       social_iqa: Total Sparsity 1.3614254777629999e-06
2023-12-01 18:26:58 - INFO :       
==================Finish================

2023-12-01 18:26:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:26:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:26:58 - INFO :       DATASET: tasksource/bigbench social_support
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]
2023-12-01 18:27:06 - INFO :       Use random pruner...
2023-12-01 18:27:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:27:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:27:07 - INFO :       Start Pruning
2023-12-01 18:27:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:27:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:27:08 - INFO :       social_support: Total Sparsity 1.347851767833212e-06
2023-12-01 18:27:08 - INFO :       
==================Finish================

2023-12-01 18:27:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:27:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:27:08 - INFO :       DATASET: tasksource/bigbench sports_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 18:27:17 - INFO :       Use random pruner...
2023-12-01 18:27:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:27:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:27:18 - INFO :       Start Pruning
2023-12-01 18:27:19 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:27:19 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:27:20 - INFO :       sports_understanding: Total Sparsity 1.3626594513929806e-06
2023-12-01 18:27:20 - INFO :       
==================Finish================

2023-12-01 18:27:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:27:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:27:20 - INFO :       DATASET: tasksource/bigbench strange_stories
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.91s/it]
2023-12-01 18:27:29 - INFO :       Use random pruner...
2023-12-01 18:27:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:27:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:27:30 - INFO :       Start Pruning
2023-12-01 18:27:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:27:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:27:31 - INFO :       strange_stories: Total Sparsity 1.3651273986529418e-06
2023-12-01 18:27:31 - INFO :       
==================Finish================

2023-12-01 18:27:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:27:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:27:31 - INFO :       DATASET: tasksource/bigbench strategyqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.91s/it]
2023-12-01 18:27:41 - INFO :       Use random pruner...
2023-12-01 18:27:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:27:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:27:42 - INFO :       Start Pruning
2023-12-01 18:27:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:27:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:27:44 - INFO :       strategyqa: Total Sparsity 1.3624831694458404e-06
2023-12-01 18:27:44 - INFO :       
==================Finish================

2023-12-01 18:27:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:27:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:27:44 - INFO :       DATASET: tasksource/bigbench suicide_risk
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]
2023-12-01 18:27:51 - INFO :       Use random pruner...
2023-12-01 18:27:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:27:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:27:51 - INFO :       Start Pruning
2023-12-01 18:27:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:27:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:27:53 - INFO :       suicide_risk: Total Sparsity 1.3630120152872606e-06
2023-12-01 18:27:53 - INFO :       
==================Finish================

2023-12-01 18:27:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:27:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:27:53 - INFO :       DATASET: tasksource/bigbench swahili_english_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2023-12-01 18:28:01 - INFO :       Use random pruner...
2023-12-01 18:28:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:28:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:28:02 - INFO :       Start Pruning
2023-12-01 18:28:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:28:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:28:03 - INFO :       swahili_english_proverbs: Total Sparsity 1.3566658651902172e-06
2023-12-01 18:28:03 - INFO :       
==================Finish================

2023-12-01 18:28:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:28:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:28:03 - INFO :       DATASET: tasksource/bigbench swedish_to_german_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]
2023-12-01 18:28:13 - INFO :       Use random pruner...
2023-12-01 18:28:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:28:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:28:14 - INFO :       Start Pruning
2023-12-01 18:28:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:28:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:28:16 - INFO :       swedish_to_german_proverbs: Total Sparsity 1.369005601490024e-06
2023-12-01 18:28:16 - INFO :       
==================Finish================

2023-12-01 18:28:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:28:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:28:16 - INFO :       DATASET: tasksource/bigbench symbol_interpretation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2023-12-01 18:28:25 - INFO :       Use random pruner...
2023-12-01 18:28:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:28:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:28:25 - INFO :       Start Pruning
2023-12-01 18:28:26 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:28:26 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:28:27 - INFO :       symbol_interpretation: Total Sparsity 1.3607203499744394e-06
2023-12-01 18:28:27 - INFO :       
==================Finish================

2023-12-01 18:28:27 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:28:27 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:28:27 - INFO :       DATASET: tasksource/bigbench temporal_sequences
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.21s/it]
2023-12-01 18:28:37 - INFO :       Use random pruner...
2023-12-01 18:28:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:28:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:28:38 - INFO :       Start Pruning
2023-12-01 18:28:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:28:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:28:39 - INFO :       temporal_sequences: Total Sparsity 1.363717143075821e-06
2023-12-01 18:28:39 - INFO :       
==================Finish================

2023-12-01 18:28:39 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:28:39 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:28:39 - INFO :       DATASET: tasksource/bigbench timedial
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2023-12-01 18:28:49 - INFO :       Use random pruner...
2023-12-01 18:28:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:28:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:28:49 - INFO :       Start Pruning
2023-12-01 18:28:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:28:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:28:51 - INFO :       timedial: Total Sparsity 1.3631882972344008e-06
2023-12-01 18:28:51 - INFO :       
==================Finish================

2023-12-01 18:28:51 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:28:51 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:28:51 - INFO :       DATASET: tasksource/bigbench tracking_shuffled_objects
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]
2023-12-01 18:28:59 - INFO :       Use random pruner...
2023-12-01 18:28:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:28:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:28:59 - INFO :       Start Pruning
2023-12-01 18:29:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:29:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:29:01 - INFO :       tracking_shuffled_objects: Total Sparsity 1.3623068874987003e-06
2023-12-01 18:29:01 - INFO :       
==================Finish================

2023-12-01 18:29:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:29:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:29:01 - INFO :       DATASET: tasksource/bigbench understanding_fables
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]
2023-12-01 18:29:10 - INFO :       Use random pruner...
2023-12-01 18:29:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:29:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:29:11 - INFO :       Start Pruning
2023-12-01 18:29:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:29:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:29:12 - INFO :       understanding_fables: Total Sparsity 1.3626594513929806e-06
2023-12-01 18:29:12 - INFO :       
==================Finish================

2023-12-01 18:29:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:29:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:29:12 - INFO :       DATASET: tasksource/bigbench undo_permutation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 18:29:19 - INFO :       Use random pruner...
2023-12-01 18:29:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:29:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:29:20 - INFO :       Start Pruning
2023-12-01 18:29:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:29:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:29:22 - INFO :       undo_permutation: Total Sparsity 1.3735889321156667e-06
2023-12-01 18:29:22 - INFO :       
==================Finish================

2023-12-01 18:29:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:29:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:29:22 - INFO :       DATASET: tasksource/bigbench unit_interpretation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]
2023-12-01 18:29:29 - INFO :       Use random pruner...
2023-12-01 18:29:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:29:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:29:30 - INFO :       Start Pruning
2023-12-01 18:29:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:29:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:29:32 - INFO :       unit_interpretation: Total Sparsity 1.3725312404328262e-06
2023-12-01 18:29:32 - INFO :       
==================Finish================

2023-12-01 18:29:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:29:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:29:32 - INFO :       DATASET: tasksource/bigbench vitaminc_fact_verification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]
2023-12-01 18:29:40 - INFO :       Use random pruner...
2023-12-01 18:29:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:29:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:29:40 - INFO :       Start Pruning
2023-12-01 18:29:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:29:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:29:42 - INFO :       vitaminc_fact_verification: Total Sparsity 1.3584286846616181e-06
2023-12-01 18:29:42 - INFO :       
==================Finish================

2023-12-01 18:29:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:29:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:29:42 - INFO :       DATASET: tasksource/bigbench what_is_the_tao
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2023-12-01 18:29:50 - INFO :       Use random pruner...
2023-12-01 18:29:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:29:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:29:50 - INFO :       Start Pruning
2023-12-01 18:29:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:29:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:29:52 - INFO :       what_is_the_tao: Total Sparsity 1.3630120152872606e-06
2023-12-01 18:29:52 - INFO :       
==================Finish================

2023-12-01 18:29:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:29:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:29:52 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
2023-12-01 18:30:00 - INFO :       Use random pruner...
2023-12-01 18:30:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:30:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:30:01 - INFO :       Start Pruning
2023-12-01 18:30:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:30:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:30:02 - INFO :       which_wiki_edit: Total Sparsity 1.3633645791815409e-06
2023-12-01 18:30:02 - INFO :       
==================Finish================

2023-12-01 18:30:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:30:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:30:02 - INFO :       DATASET: tasksource/bigbench winowhy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2023-12-01 18:30:10 - INFO :       Use random pruner...
2023-12-01 18:30:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:30:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:30:11 - INFO :       Start Pruning
2023-12-01 18:30:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:30:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:30:12 - INFO :       winowhy: Total Sparsity 1.3607203499744394e-06
2023-12-01 18:30:12 - INFO :       
==================Finish================

2023-12-01 18:30:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:30:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:30:12 - INFO :       DATASET: tasksource/mmlu abstract_algebra
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]
2023-12-01 18:30:21 - INFO :       Use random pruner...
2023-12-01 18:30:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:30:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:30:21 - INFO :       Start Pruning
2023-12-01 18:30:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:30:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:30:23 - INFO :       abstract_algebra: Total Sparsity 1.3578998388201979e-06
2023-12-01 18:30:23 - INFO :       
==================Finish================

2023-12-01 18:30:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:30:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:30:23 - INFO :       DATASET: tasksource/mmlu anatomy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
2023-12-01 18:30:30 - INFO :       Use random pruner...
2023-12-01 18:30:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:30:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:30:31 - INFO :       Start Pruning
2023-12-01 18:30:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:30:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:30:32 - INFO :       anatomy: Total Sparsity 1.3608966319215796e-06
2023-12-01 18:30:32 - INFO :       
==================Finish================

2023-12-01 18:30:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:30:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:30:32 - INFO :       DATASET: tasksource/mmlu astronomy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]
2023-12-01 18:30:41 - INFO :       Use random pruner...
2023-12-01 18:30:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:30:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:30:41 - INFO :       Start Pruning
2023-12-01 18:30:42 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:30:42 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:30:43 - INFO :       astronomy: Total Sparsity 1.365303680600082e-06
2023-12-01 18:30:43 - INFO :       
==================Finish================

2023-12-01 18:30:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:30:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:30:43 - INFO :       DATASET: tasksource/mmlu business_ethics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]
2023-12-01 18:30:50 - INFO :       Use random pruner...
2023-12-01 18:30:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:30:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:30:51 - INFO :       Start Pruning
2023-12-01 18:30:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:30:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:30:53 - INFO :       business_ethics: Total Sparsity 1.3610729138687196e-06
2023-12-01 18:30:53 - INFO :       
==================Finish================

2023-12-01 18:30:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:30:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:30:53 - INFO :       DATASET: tasksource/mmlu clinical_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]
2023-12-01 18:31:00 - INFO :       Use random pruner...
2023-12-01 18:31:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:31:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:31:01 - INFO :       Start Pruning
2023-12-01 18:31:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:31:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:31:03 - INFO :       clinical_knowledge: Total Sparsity 1.354550481824536e-06
2023-12-01 18:31:03 - INFO :       
==================Finish================

2023-12-01 18:31:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:31:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:31:03 - INFO :       DATASET: tasksource/mmlu college_biology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
2023-12-01 18:31:10 - INFO :       Use random pruner...
2023-12-01 18:31:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:31:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:31:11 - INFO :       Start Pruning
2023-12-01 18:31:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:31:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:31:13 - INFO :       college_biology: Total Sparsity 1.3658325264415023e-06
2023-12-01 18:31:13 - INFO :       
==================Finish================

2023-12-01 18:31:13 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:31:13 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:31:13 - INFO :       DATASET: tasksource/mmlu college_chemistry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2023-12-01 18:31:21 - INFO :       Use random pruner...
2023-12-01 18:31:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:31:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:31:21 - INFO :       Start Pruning
2023-12-01 18:31:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:31:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:31:23 - INFO :       college_chemistry: Total Sparsity 1.3628357333401206e-06
2023-12-01 18:31:23 - INFO :       
==================Finish================

2023-12-01 18:31:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:31:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:31:23 - INFO :       DATASET: tasksource/mmlu college_computer_science
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]
2023-12-01 18:31:31 - INFO :       Use random pruner...
2023-12-01 18:31:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:31:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:31:31 - INFO :       Start Pruning
2023-12-01 18:31:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:31:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:31:33 - INFO :       college_computer_science: Total Sparsity 1.367066500071483e-06
2023-12-01 18:31:33 - INFO :       
==================Finish================

2023-12-01 18:31:33 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:31:33 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:31:33 - INFO :       DATASET: tasksource/mmlu college_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]
2023-12-01 18:31:41 - INFO :       Use random pruner...
2023-12-01 18:31:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:31:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:31:41 - INFO :       Start Pruning
2023-12-01 18:31:42 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:31:42 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:31:43 - INFO :       college_mathematics: Total Sparsity 1.3601915041330191e-06
2023-12-01 18:31:43 - INFO :       
==================Finish================

2023-12-01 18:31:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:31:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:31:43 - INFO :       DATASET: tasksource/mmlu college_medicine
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]
2023-12-01 18:31:51 - INFO :       Use random pruner...
2023-12-01 18:31:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:31:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:31:51 - INFO :       Start Pruning
2023-12-01 18:31:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:31:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:31:53 - INFO :       college_medicine: Total Sparsity 1.3524350984588547e-06
2023-12-01 18:31:53 - INFO :       
==================Finish================

2023-12-01 18:31:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:31:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:31:53 - INFO :       DATASET: tasksource/mmlu college_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]
2023-12-01 18:32:01 - INFO :       Use random pruner...
2023-12-01 18:32:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:32:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:32:01 - INFO :       Start Pruning
2023-12-01 18:32:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:32:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:32:03 - INFO :       college_physics: Total Sparsity 1.3647748347586618e-06
2023-12-01 18:32:03 - INFO :       
==================Finish================

2023-12-01 18:32:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:32:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:32:03 - INFO :       DATASET: tasksource/mmlu computer_security
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2023-12-01 18:32:11 - INFO :       Use random pruner...
2023-12-01 18:32:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:32:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:32:12 - INFO :       Start Pruning
2023-12-01 18:32:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:32:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:32:14 - INFO :       computer_security: Total Sparsity 1.3573709929787774e-06
2023-12-01 18:32:14 - INFO :       
==================Finish================

2023-12-01 18:32:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:32:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:32:14 - INFO :       DATASET: tasksource/mmlu conceptual_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2023-12-01 18:32:22 - INFO :       Use random pruner...
2023-12-01 18:32:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:32:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:32:22 - INFO :       Start Pruning
2023-12-01 18:32:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:32:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:32:24 - INFO :       conceptual_physics: Total Sparsity 1.3487331775689125e-06
2023-12-01 18:32:24 - INFO :       
==================Finish================

2023-12-01 18:32:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:32:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:32:24 - INFO :       DATASET: tasksource/mmlu econometrics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2023-12-01 18:32:32 - INFO :       Use random pruner...
2023-12-01 18:32:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:32:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:32:32 - INFO :       Start Pruning
2023-12-01 18:32:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:32:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:32:34 - INFO :       econometrics: Total Sparsity 1.354726763771676e-06
2023-12-01 18:32:34 - INFO :       
==================Finish================

2023-12-01 18:32:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:32:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:32:34 - INFO :       DATASET: tasksource/mmlu electrical_engineering
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2023-12-01 18:32:42 - INFO :       Use random pruner...
2023-12-01 18:32:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:32:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:32:42 - INFO :       Start Pruning
2023-12-01 18:32:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:32:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:32:44 - INFO :       electrical_engineering: Total Sparsity 1.370592139014285e-06
2023-12-01 18:32:44 - INFO :       
==================Finish================

2023-12-01 18:32:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:32:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:32:44 - INFO :       DATASET: tasksource/mmlu elementary_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 18:32:51 - INFO :       Use random pruner...
2023-12-01 18:32:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:32:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:32:51 - INFO :       Start Pruning
2023-12-01 18:32:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:32:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:32:53 - INFO :       elementary_mathematics: Total Sparsity 1.3614254777629999e-06
2023-12-01 18:32:53 - INFO :       
==================Finish================

2023-12-01 18:32:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:32:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:32:53 - INFO :       DATASET: tasksource/mmlu formal_logic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 18:33:01 - INFO :       Use random pruner...
2023-12-01 18:33:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:33:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:33:01 - INFO :       Start Pruning
2023-12-01 18:33:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:33:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:33:03 - INFO :       formal_logic: Total Sparsity 1.3644222708643816e-06
2023-12-01 18:33:03 - INFO :       
==================Finish================

2023-12-01 18:33:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:33:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:33:03 - INFO :       DATASET: tasksource/mmlu global_facts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2023-12-01 18:33:13 - INFO :       Use random pruner...
2023-12-01 18:33:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:33:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:33:13 - INFO :       Start Pruning
2023-12-01 18:33:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:33:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:33:15 - INFO :       global_facts: Total Sparsity 1.3619543236044201e-06
2023-12-01 18:33:15 - INFO :       
==================Finish================

2023-12-01 18:33:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:33:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:33:15 - INFO :       DATASET: tasksource/mmlu high_school_biology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
2023-12-01 18:33:25 - INFO :       Use random pruner...
2023-12-01 18:33:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:33:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:33:25 - INFO :       Start Pruning
2023-12-01 18:33:26 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:33:26 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:33:27 - INFO :       high_school_biology: Total Sparsity 1.3677716278600435e-06
2023-12-01 18:33:27 - INFO :       
==================Finish================

2023-12-01 18:33:27 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:33:27 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:33:27 - INFO :       DATASET: tasksource/mmlu high_school_chemistry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 18:33:35 - INFO :       Use random pruner...
2023-12-01 18:33:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:33:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:33:35 - INFO :       Start Pruning
2023-12-01 18:33:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:33:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:33:37 - INFO :       high_school_chemistry: Total Sparsity 1.3644222708643816e-06
2023-12-01 18:33:37 - INFO :       
==================Finish================

2023-12-01 18:33:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:33:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:33:37 - INFO :       DATASET: tasksource/mmlu high_school_computer_science
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]
2023-12-01 18:33:45 - INFO :       Use random pruner...
2023-12-01 18:33:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:33:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:33:46 - INFO :       Start Pruning
2023-12-01 18:33:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:33:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:33:48 - INFO :       high_school_computer_science: Total Sparsity 1.3640697069701013e-06
2023-12-01 18:33:48 - INFO :       
==================Finish================

2023-12-01 18:33:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:33:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:33:48 - INFO :       DATASET: tasksource/mmlu high_school_european_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]
2023-12-01 18:33:56 - INFO :       Use random pruner...
2023-12-01 18:33:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:33:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:33:56 - INFO :       Start Pruning
2023-12-01 18:33:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:33:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:33:58 - INFO :       high_school_european_history: Total Sparsity 1.3549030457188162e-06
2023-12-01 18:33:58 - INFO :       
==================Finish================

2023-12-01 18:33:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:33:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:33:58 - INFO :       DATASET: tasksource/mmlu high_school_geography
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]
2023-12-01 18:34:07 - INFO :       Use random pruner...
2023-12-01 18:34:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:34:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:34:08 - INFO :       Start Pruning
2023-12-01 18:34:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:34:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:34:09 - INFO :       high_school_geography: Total Sparsity 1.3520825345645745e-06
2023-12-01 18:34:09 - INFO :       
==================Finish================

2023-12-01 18:34:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:34:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:34:09 - INFO :       DATASET: tasksource/mmlu high_school_government_and_politics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]
2023-12-01 18:34:19 - INFO :       Use random pruner...
2023-12-01 18:34:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:34:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:34:20 - INFO :       Start Pruning
2023-12-01 18:34:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:34:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:34:21 - INFO :       high_school_government_and_politics: Total Sparsity 1.3584286846616181e-06
2023-12-01 18:34:21 - INFO :       
==================Finish================

2023-12-01 18:34:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:34:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:34:21 - INFO :       DATASET: tasksource/mmlu high_school_macroeconomics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2023-12-01 18:34:31 - INFO :       Use random pruner...
2023-12-01 18:34:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:34:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:34:32 - INFO :       Start Pruning
2023-12-01 18:34:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:34:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:34:34 - INFO :       high_school_macroeconomics: Total Sparsity 1.3677716278600435e-06
2023-12-01 18:34:34 - INFO :       
==================Finish================

2023-12-01 18:34:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:34:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:34:34 - INFO :       DATASET: tasksource/mmlu high_school_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]
2023-12-01 18:34:43 - INFO :       Use random pruner...
2023-12-01 18:34:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:34:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:34:43 - INFO :       Start Pruning
2023-12-01 18:34:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:34:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:34:45 - INFO :       high_school_mathematics: Total Sparsity 1.3656562444943623e-06
2023-12-01 18:34:45 - INFO :       
==================Finish================

2023-12-01 18:34:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:34:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:34:45 - INFO :       DATASET: tasksource/mmlu high_school_microeconomics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2023-12-01 18:34:53 - INFO :       Use random pruner...
2023-12-01 18:34:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:34:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:34:53 - INFO :       Start Pruning
2023-12-01 18:34:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:34:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:34:55 - INFO :       high_school_microeconomics: Total Sparsity 1.3697107292785845e-06
2023-12-01 18:34:55 - INFO :       
==================Finish================

2023-12-01 18:34:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:34:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:34:55 - INFO :       DATASET: tasksource/mmlu high_school_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2023-12-01 18:35:05 - INFO :       Use random pruner...
2023-12-01 18:35:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:35:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:35:05 - INFO :       Start Pruning
2023-12-01 18:35:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:35:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:35:07 - INFO :       high_school_physics: Total Sparsity 1.3610729138687196e-06
2023-12-01 18:35:07 - INFO :       
==================Finish================

2023-12-01 18:35:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:35:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:35:07 - INFO :       DATASET: tasksource/mmlu high_school_psychology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 18:35:17 - INFO :       Use random pruner...
2023-12-01 18:35:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:35:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:35:18 - INFO :       Start Pruning
2023-12-01 18:35:19 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:35:19 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:35:19 - INFO :       high_school_psychology: Total Sparsity 1.3633645791815409e-06
2023-12-01 18:35:19 - INFO :       
==================Finish================

2023-12-01 18:35:19 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:35:19 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:35:19 - INFO :       DATASET: tasksource/mmlu high_school_statistics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2023-12-01 18:35:29 - INFO :       Use random pruner...
2023-12-01 18:35:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:35:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:35:30 - INFO :       Start Pruning
2023-12-01 18:35:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:35:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:35:31 - INFO :       high_school_statistics: Total Sparsity 1.3577235568730577e-06
2023-12-01 18:35:31 - INFO :       
==================Finish================

2023-12-01 18:35:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:35:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:35:31 - INFO :       DATASET: tasksource/mmlu high_school_us_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2023-12-01 18:35:41 - INFO :       Use random pruner...
2023-12-01 18:35:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:35:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:35:41 - INFO :       Start Pruning
2023-12-01 18:35:42 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:35:42 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:35:43 - INFO :       high_school_us_history: Total Sparsity 1.3667139361772028e-06
2023-12-01 18:35:43 - INFO :       
==================Finish================

2023-12-01 18:35:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:35:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:35:43 - INFO :       DATASET: tasksource/mmlu high_school_world_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 18:35:53 - INFO :       Use random pruner...
2023-12-01 18:35:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:35:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:35:53 - INFO :       Start Pruning
2023-12-01 18:35:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:35:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:35:55 - INFO :       high_school_world_history: Total Sparsity 1.3628357333401206e-06
2023-12-01 18:35:55 - INFO :       
==================Finish================

2023-12-01 18:35:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:35:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:35:55 - INFO :       DATASET: tasksource/mmlu human_aging
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.98s/it]
2023-12-01 18:36:05 - INFO :       Use random pruner...
2023-12-01 18:36:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:36:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:36:05 - INFO :       Start Pruning
2023-12-01 18:36:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:36:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:36:07 - INFO :       human_aging: Total Sparsity 1.3612491958158596e-06
2023-12-01 18:36:07 - INFO :       
==================Finish================

2023-12-01 18:36:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:36:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:36:07 - INFO :       DATASET: tasksource/mmlu human_sexuality
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.46s/it]
2023-12-01 18:36:16 - INFO :       Use random pruner...
2023-12-01 18:36:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:36:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:36:17 - INFO :       Start Pruning
2023-12-01 18:36:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:36:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:36:18 - INFO :       human_sexuality: Total Sparsity 1.3683004737014638e-06
2023-12-01 18:36:18 - INFO :       
==================Finish================

2023-12-01 18:36:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:36:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:36:18 - INFO :       DATASET: tasksource/mmlu international_law
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2023-12-01 18:36:29 - INFO :       Use random pruner...
2023-12-01 18:36:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:36:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:36:29 - INFO :       Start Pruning
2023-12-01 18:36:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:36:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:36:31 - INFO :       international_law: Total Sparsity 1.366890218124343e-06
2023-12-01 18:36:31 - INFO :       
==================Finish================

2023-12-01 18:36:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:36:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:36:31 - INFO :       DATASET: tasksource/mmlu jurisprudence
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]
2023-12-01 18:36:40 - INFO :       Use random pruner...
2023-12-01 18:36:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:36:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:36:40 - INFO :       Start Pruning
2023-12-01 18:36:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:36:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:36:42 - INFO :       jurisprudence: Total Sparsity 1.3651273986529418e-06
2023-12-01 18:36:42 - INFO :       
==================Finish================

2023-12-01 18:36:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:36:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:36:42 - INFO :       DATASET: tasksource/mmlu logical_fallacies
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.91s/it]
2023-12-01 18:36:51 - INFO :       Use random pruner...
2023-12-01 18:36:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:36:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:36:52 - INFO :       Start Pruning
2023-12-01 18:36:53 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:36:53 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:36:54 - INFO :       logical_fallacies: Total Sparsity 1.3586049666087581e-06
2023-12-01 18:36:54 - INFO :       
==================Finish================

2023-12-01 18:36:54 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:36:54 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:36:54 - INFO :       DATASET: tasksource/mmlu machine_learning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]
2023-12-01 18:37:03 - INFO :       Use random pruner...
2023-12-01 18:37:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:37:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:37:03 - INFO :       Start Pruning
2023-12-01 18:37:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:37:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:37:05 - INFO :       machine_learning: Total Sparsity 1.3616017597101399e-06
2023-12-01 18:37:05 - INFO :       
==================Finish================

2023-12-01 18:37:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:37:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:37:05 - INFO :       DATASET: tasksource/mmlu management
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 18:37:11 - INFO :       Use random pruner...
2023-12-01 18:37:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:37:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:37:12 - INFO :       Start Pruning
2023-12-01 18:37:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:37:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:37:14 - INFO :       management: Total Sparsity 1.3608966319215796e-06
2023-12-01 18:37:14 - INFO :       
==================Finish================

2023-12-01 18:37:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:37:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:37:14 - INFO :       DATASET: tasksource/mmlu marketing
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2023-12-01 18:37:24 - INFO :       Use random pruner...
2023-12-01 18:37:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:37:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:37:24 - INFO :       Start Pruning
2023-12-01 18:37:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:37:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:37:26 - INFO :       marketing: Total Sparsity 1.3630120152872606e-06
2023-12-01 18:37:26 - INFO :       
==================Finish================

2023-12-01 18:37:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:37:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:37:26 - INFO :       DATASET: tasksource/mmlu medical_genetics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2023-12-01 18:37:35 - INFO :       Use random pruner...
2023-12-01 18:37:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:37:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:37:36 - INFO :       Start Pruning
2023-12-01 18:37:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:37:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:37:37 - INFO :       medical_genetics: Total Sparsity 1.366890218124343e-06
2023-12-01 18:37:37 - INFO :       
==================Finish================

2023-12-01 18:37:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:37:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:37:37 - INFO :       DATASET: tasksource/mmlu miscellaneous
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]
2023-12-01 18:37:48 - INFO :       Use random pruner...
2023-12-01 18:37:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:37:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:37:48 - INFO :       Start Pruning
2023-12-01 18:37:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:37:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:37:50 - INFO :       miscellaneous: Total Sparsity 1.370592139014285e-06
2023-12-01 18:37:50 - INFO :       
==================Finish================

2023-12-01 18:37:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:37:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:37:50 - INFO :       DATASET: tasksource/mmlu moral_disputes
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 18:37:56 - INFO :       Use random pruner...
2023-12-01 18:37:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:37:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:37:57 - INFO :       Start Pruning
2023-12-01 18:37:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:37:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:37:59 - INFO :       moral_disputes: Total Sparsity 1.3571947110316374e-06
2023-12-01 18:37:59 - INFO :       
==================Finish================

2023-12-01 18:37:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:37:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:37:59 - INFO :       DATASET: tasksource/mmlu moral_scenarios
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 18:38:08 - INFO :       Use random pruner...
2023-12-01 18:38:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:38:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:38:08 - INFO :       Start Pruning
2023-12-01 18:38:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:38:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:38:10 - INFO :       moral_scenarios: Total Sparsity 1.352963944300275e-06
2023-12-01 18:38:10 - INFO :       
==================Finish================

2023-12-01 18:38:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:38:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:38:10 - INFO :       DATASET: tasksource/mmlu nutrition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]
2023-12-01 18:38:21 - INFO :       Use random pruner...
2023-12-01 18:38:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:38:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:38:21 - INFO :       Start Pruning
2023-12-01 18:38:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:38:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:38:23 - INFO :       nutrition: Total Sparsity 1.3799350822127104e-06
2023-12-01 18:38:23 - INFO :       
==================Finish================

2023-12-01 18:38:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:38:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:38:23 - INFO :       DATASET: tasksource/mmlu philosophy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 18:38:33 - INFO :       Use random pruner...
2023-12-01 18:38:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:38:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:38:33 - INFO :       Start Pruning
2023-12-01 18:38:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:38:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:38:35 - INFO :       philosophy: Total Sparsity 1.3589575305030384e-06
2023-12-01 18:38:35 - INFO :       
==================Finish================

2023-12-01 18:38:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:38:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:38:35 - INFO :       DATASET: tasksource/mmlu prehistory
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]
2023-12-01 18:38:44 - INFO :       Use random pruner...
2023-12-01 18:38:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:38:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:38:45 - INFO :       Start Pruning
2023-12-01 18:38:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:38:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:38:47 - INFO :       prehistory: Total Sparsity 1.3612491958158596e-06
2023-12-01 18:38:47 - INFO :       
==================Finish================

2023-12-01 18:38:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:38:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:38:47 - INFO :       DATASET: tasksource/mmlu professional_accounting
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2023-12-01 18:38:57 - INFO :       Use random pruner...
2023-12-01 18:38:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:38:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:38:57 - INFO :       Start Pruning
2023-12-01 18:38:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:38:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:38:59 - INFO :       professional_accounting: Total Sparsity 1.3554318915602364e-06
2023-12-01 18:38:59 - INFO :       
==================Finish================

2023-12-01 18:38:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:38:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:38:59 - INFO :       DATASET: tasksource/mmlu professional_law
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2023-12-01 18:39:08 - INFO :       Use random pruner...
2023-12-01 18:39:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:39:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:39:08 - INFO :       Start Pruning
2023-12-01 18:39:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:39:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:39:10 - INFO :       professional_law: Total Sparsity 1.3623068874987003e-06
2023-12-01 18:39:10 - INFO :       
==================Finish================

2023-12-01 18:39:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:39:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:39:10 - INFO :       DATASET: tasksource/mmlu professional_medicine
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2023-12-01 18:39:19 - INFO :       Use random pruner...
2023-12-01 18:39:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:39:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:39:20 - INFO :       Start Pruning
2023-12-01 18:39:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:39:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:39:21 - INFO :       professional_medicine: Total Sparsity 1.3656562444943623e-06
2023-12-01 18:39:21 - INFO :       
==================Finish================

2023-12-01 18:39:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:39:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:39:21 - INFO :       DATASET: tasksource/mmlu professional_psychology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]
2023-12-01 18:39:30 - INFO :       Use random pruner...
2023-12-01 18:39:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:39:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:39:31 - INFO :       Start Pruning
2023-12-01 18:39:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:39:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:39:32 - INFO :       professional_psychology: Total Sparsity 1.3559607374016567e-06
2023-12-01 18:39:32 - INFO :       
==================Finish================

2023-12-01 18:39:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:39:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:39:32 - INFO :       DATASET: tasksource/mmlu public_relations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2023-12-01 18:39:42 - INFO :       Use random pruner...
2023-12-01 18:39:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:39:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:39:42 - INFO :       Start Pruning
2023-12-01 18:39:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:39:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:39:44 - INFO :       public_relations: Total Sparsity 1.3566658651902172e-06
2023-12-01 18:39:44 - INFO :       
==================Finish================

2023-12-01 18:39:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:39:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:39:44 - INFO :       DATASET: tasksource/mmlu security_studies
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2023-12-01 18:39:53 - INFO :       Use random pruner...
2023-12-01 18:39:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:39:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:39:53 - INFO :       Start Pruning
2023-12-01 18:39:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:39:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:39:55 - INFO :       security_studies: Total Sparsity 1.3598389402387389e-06
2023-12-01 18:39:55 - INFO :       
==================Finish================

2023-12-01 18:39:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:39:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:39:55 - INFO :       DATASET: tasksource/mmlu sociology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 18:40:04 - INFO :       Use random pruner...
2023-12-01 18:40:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:40:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:40:05 - INFO :       Start Pruning
2023-12-01 18:40:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:40:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:40:07 - INFO :       sociology: Total Sparsity 1.3510248428817337e-06
2023-12-01 18:40:07 - INFO :       
==================Finish================

2023-12-01 18:40:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:40:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:40:07 - INFO :       DATASET: tasksource/mmlu us_foreign_policy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]
2023-12-01 18:40:17 - INFO :       Use random pruner...
2023-12-01 18:40:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:40:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:40:17 - INFO :       Start Pruning
2023-12-01 18:40:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:40:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:40:19 - INFO :       us_foreign_policy: Total Sparsity 1.36177804165728e-06
2023-12-01 18:40:19 - INFO :       
==================Finish================

2023-12-01 18:40:19 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:40:19 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:40:19 - INFO :       DATASET: tasksource/mmlu virology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 18:40:28 - INFO :       Use random pruner...
2023-12-01 18:40:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:40:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:40:28 - INFO :       Start Pruning
2023-12-01 18:40:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:40:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:40:30 - INFO :       virology: Total Sparsity 1.365303680600082e-06
2023-12-01 18:40:30 - INFO :       
==================Finish================

2023-12-01 18:40:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:40:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:40:30 - INFO :       DATASET: tasksource/mmlu world_religions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.91s/it]
2023-12-01 18:40:40 - INFO :       Use random pruner...
2023-12-01 18:40:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:40:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:40:40 - INFO :       Start Pruning
2023-12-01 18:40:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:40:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:40:42 - INFO :       world_religions: Total Sparsity 1.3628357333401206e-06
2023-12-01 18:40:42 - INFO :       
==================Finish================

2023-12-01 18:40:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:40:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:40:42 - INFO :       DATASET: math_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]
2023-12-01 18:40:51 - INFO :       Use random pruner...
2023-12-01 18:40:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:40:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:40:51 - INFO :       Start Pruning
2023-12-01 18:40:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:40:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:40:53 - INFO :       math_qa: Total Sparsity 1.3601915041330191e-06
2023-12-01 18:40:53 - INFO :       
==================Finish================

2023-12-01 18:40:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:40:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:40:53 - INFO :       DATASET: EleutherAI/truthful_qa_mc
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]
2023-12-01 18:41:02 - INFO :       Use random pruner...
2023-12-01 18:41:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:41:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:41:03 - INFO :       Start Pruning
2023-12-01 18:41:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:41:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:41:05 - INFO :       truthful_qa_mc: Total Sparsity 1.3642459889172413e-06
2023-12-01 18:41:05 - INFO :       
==================Finish================

2023-12-01 18:41:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:41:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:41:05 - INFO :       DATASET: derek-thomas/ScienceQA
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]
2023-12-01 18:41:13 - INFO :       Use random pruner...
2023-12-01 18:41:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:41:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:41:13 - INFO :       Start Pruning
2023-12-01 18:41:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:41:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:41:15 - INFO :       ScienceQA: Total Sparsity 1.3586049666087581e-06
2023-12-01 18:41:15 - INFO :       
==================Finish================

2023-12-01 18:41:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:41:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:41:15 - INFO :       DATASET: commonsense_qa
Index 5
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2023-12-01 18:41:24 - INFO :       Use random pruner...
2023-12-01 18:41:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:41:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:41:25 - INFO :       Start Pruning
2023-12-01 18:41:26 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:41:26 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:41:27 - INFO :       commonsense_qa: Total Sparsity 1.3663613722829226e-06
2023-12-01 18:41:27 - INFO :       
==================Finish================

2023-12-01 18:41:27 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:41:27 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:41:27 - INFO :       DATASET: tasksource/bigbench abstract_narrative_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 18:41:36 - INFO :       Use random pruner...
2023-12-01 18:41:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:41:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:41:37 - INFO :       Start Pruning
2023-12-01 18:41:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:41:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:41:38 - INFO :       abstract_narrative_understanding: Total Sparsity 1.3712972668028455e-06
2023-12-01 18:41:38 - INFO :       
==================Finish================

2023-12-01 18:41:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:41:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:41:38 - INFO :       DATASET: tasksource/bigbench anachronisms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2023-12-01 18:41:47 - INFO :       Use random pruner...
2023-12-01 18:41:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:41:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:41:48 - INFO :       Start Pruning
2023-12-01 18:41:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:41:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:41:49 - INFO :       anachronisms: Total Sparsity 1.3656562444943623e-06
2023-12-01 18:41:49 - INFO :       
==================Finish================

2023-12-01 18:41:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:41:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:41:49 - INFO :       DATASET: tasksource/bigbench analogical_similarity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]
2023-12-01 18:41:57 - INFO :       Use random pruner...
2023-12-01 18:41:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:41:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:41:57 - INFO :       Start Pruning
2023-12-01 18:41:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:41:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:41:59 - INFO :       analogical_similarity: Total Sparsity 1.3638934250229613e-06
2023-12-01 18:41:59 - INFO :       
==================Finish================

2023-12-01 18:41:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:41:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:41:59 - INFO :       DATASET: tasksource/bigbench analytic_entailment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2023-12-01 18:42:09 - INFO :       Use random pruner...
2023-12-01 18:42:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:42:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:42:09 - INFO :       Start Pruning
2023-12-01 18:42:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:42:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:42:11 - INFO :       analytic_entailment: Total Sparsity 1.3769382891113287e-06
2023-12-01 18:42:11 - INFO :       
==================Finish================

2023-12-01 18:42:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:42:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:42:11 - INFO :       DATASET: tasksource/bigbench arithmetic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]
2023-12-01 18:42:20 - INFO :       Use random pruner...
2023-12-01 18:42:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:42:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:42:21 - INFO :       Start Pruning
2023-12-01 18:42:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:42:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:42:22 - INFO :       arithmetic: Total Sparsity 1.3584286846616181e-06
2023-12-01 18:42:22 - INFO :       
==================Finish================

2023-12-01 18:42:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:42:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:42:22 - INFO :       DATASET: tasksource/bigbench authorship_verification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2023-12-01 18:42:31 - INFO :       Use random pruner...
2023-12-01 18:42:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:42:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:42:32 - INFO :       Start Pruning
2023-12-01 18:42:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:42:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:42:34 - INFO :       authorship_verification: Total Sparsity 1.3638934250229613e-06
2023-12-01 18:42:34 - INFO :       
==================Finish================

2023-12-01 18:42:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:42:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:42:34 - INFO :       DATASET: tasksource/bigbench bbq_lite_json
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]
2023-12-01 18:42:43 - INFO :       Use random pruner...
2023-12-01 18:42:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:42:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:42:44 - INFO :       Start Pruning
2023-12-01 18:42:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:42:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:42:45 - INFO :       bbq_lite_json: Total Sparsity 1.36177804165728e-06
2023-12-01 18:42:45 - INFO :       
==================Finish================

2023-12-01 18:42:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:42:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:42:45 - INFO :       DATASET: tasksource/bigbench causal_judgment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]
2023-12-01 18:42:55 - INFO :       Use random pruner...
2023-12-01 18:42:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:42:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:42:56 - INFO :       Start Pruning
2023-12-01 18:42:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:42:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:42:58 - INFO :       causal_judgment: Total Sparsity 1.372178676538546e-06
2023-12-01 18:42:58 - INFO :       
==================Finish================

2023-12-01 18:42:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:42:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:42:58 - INFO :       DATASET: tasksource/bigbench cause_and_effect
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]
2023-12-01 18:43:06 - INFO :       Use random pruner...
2023-12-01 18:43:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:43:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:43:07 - INFO :       Start Pruning
2023-12-01 18:43:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:43:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:43:09 - INFO :       cause_and_effect: Total Sparsity 1.356489583243077e-06
2023-12-01 18:43:09 - INFO :       
==================Finish================

2023-12-01 18:43:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:43:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:43:09 - INFO :       DATASET: tasksource/bigbench checkmate_in_one
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 18:43:18 - INFO :       Use random pruner...
2023-12-01 18:43:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:43:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:43:19 - INFO :       Start Pruning
2023-12-01 18:43:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:43:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:43:21 - INFO :       checkmate_in_one: Total Sparsity 1.368829319542884e-06
2023-12-01 18:43:21 - INFO :       
==================Finish================

2023-12-01 18:43:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:43:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:43:21 - INFO :       DATASET: tasksource/bigbench cifar10_classification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]
2023-12-01 18:43:30 - INFO :       Use random pruner...
2023-12-01 18:43:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:43:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:43:30 - INFO :       Start Pruning
2023-12-01 18:43:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:43:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:43:32 - INFO :       cifar10_classification: Total Sparsity 1.3644222708643816e-06
2023-12-01 18:43:32 - INFO :       
==================Finish================

2023-12-01 18:43:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:43:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:43:32 - INFO :       DATASET: tasksource/bigbench code_line_description
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 18:43:42 - INFO :       Use random pruner...
2023-12-01 18:43:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:43:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:43:42 - INFO :       Start Pruning
2023-12-01 18:43:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:43:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:43:44 - INFO :       code_line_description: Total Sparsity 1.3593100943973186e-06
2023-12-01 18:43:44 - INFO :       
==================Finish================

2023-12-01 18:43:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:43:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:43:44 - INFO :       DATASET: tasksource/bigbench color
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2023-12-01 18:43:53 - INFO :       Use random pruner...
2023-12-01 18:43:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:43:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:43:54 - INFO :       Start Pruning
2023-12-01 18:43:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:43:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:43:55 - INFO :       color: Total Sparsity 1.3593100943973186e-06
2023-12-01 18:43:55 - INFO :       
==================Finish================

2023-12-01 18:43:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:43:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:43:55 - INFO :       DATASET: tasksource/bigbench common_morpheme
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2023-12-01 18:44:05 - INFO :       Use random pruner...
2023-12-01 18:44:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:44:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:44:05 - INFO :       Start Pruning
2023-12-01 18:44:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:44:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:44:07 - INFO :       common_morpheme: Total Sparsity 1.3561370193487967e-06
2023-12-01 18:44:07 - INFO :       
==================Finish================

2023-12-01 18:44:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:44:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:44:07 - INFO :       DATASET: tasksource/bigbench conceptual_combinations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]
2023-12-01 18:44:16 - INFO :       Use random pruner...
2023-12-01 18:44:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:44:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:44:16 - INFO :       Start Pruning
2023-12-01 18:44:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:44:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:44:18 - INFO :       conceptual_combinations: Total Sparsity 1.367242782018623e-06
2023-12-01 18:44:18 - INFO :       
==================Finish================

2023-12-01 18:44:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:44:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:44:18 - INFO :       DATASET: tasksource/bigbench crash_blossom
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 18:44:27 - INFO :       Use random pruner...
2023-12-01 18:44:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:44:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:44:27 - INFO :       Start Pruning
2023-12-01 18:44:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:44:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:44:29 - INFO :       crash_blossom: Total Sparsity 1.3605440680272994e-06
2023-12-01 18:44:29 - INFO :       
==================Finish================

2023-12-01 18:44:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:44:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:44:29 - INFO :       DATASET: tasksource/bigbench crass_ai
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 18:44:39 - INFO :       Use random pruner...
2023-12-01 18:44:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:44:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:44:40 - INFO :       Start Pruning
2023-12-01 18:44:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:44:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:44:41 - INFO :       crass_ai: Total Sparsity 1.367066500071483e-06
2023-12-01 18:44:41 - INFO :       
==================Finish================

2023-12-01 18:44:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:44:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:44:41 - INFO :       DATASET: tasksource/bigbench cryobiology_spanish
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2023-12-01 18:44:52 - INFO :       Use random pruner...
2023-12-01 18:44:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:44:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:44:52 - INFO :       Start Pruning
2023-12-01 18:44:53 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:44:53 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:44:54 - INFO :       cryobiology_spanish: Total Sparsity 1.3624831694458404e-06
2023-12-01 18:44:54 - INFO :       
==================Finish================

2023-12-01 18:44:54 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:44:54 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:44:54 - INFO :       DATASET: tasksource/bigbench cs_algorithms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2023-12-01 18:45:03 - INFO :       Use random pruner...
2023-12-01 18:45:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:45:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:45:04 - INFO :       Start Pruning
2023-12-01 18:45:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:45:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:45:05 - INFO :       cs_algorithms: Total Sparsity 1.3619543236044201e-06
2023-12-01 18:45:05 - INFO :       
==================Finish================

2023-12-01 18:45:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:45:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:45:05 - INFO :       DATASET: tasksource/bigbench dark_humor_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 18:45:14 - INFO :       Use random pruner...
2023-12-01 18:45:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:45:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:45:14 - INFO :       Start Pruning
2023-12-01 18:45:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:45:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:45:16 - INFO :       dark_humor_detection: Total Sparsity 1.3628357333401206e-06
2023-12-01 18:45:16 - INFO :       
==================Finish================

2023-12-01 18:45:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:45:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:45:16 - INFO :       DATASET: tasksource/bigbench date_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]
2023-12-01 18:45:26 - INFO :       Use random pruner...
2023-12-01 18:45:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:45:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:45:26 - INFO :       Start Pruning
2023-12-01 18:45:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:45:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:45:28 - INFO :       date_understanding: Total Sparsity 1.358252402714478e-06
2023-12-01 18:45:28 - INFO :       
==================Finish================

2023-12-01 18:45:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:45:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:45:28 - INFO :       DATASET: tasksource/bigbench disambiguation_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.46s/it]
2023-12-01 18:45:37 - INFO :       Use random pruner...
2023-12-01 18:45:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:45:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:45:38 - INFO :       Start Pruning
2023-12-01 18:45:38 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:45:38 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:45:39 - INFO :       disambiguation_qa: Total Sparsity 1.36177804165728e-06
2023-12-01 18:45:39 - INFO :       
==================Finish================

2023-12-01 18:45:39 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:45:39 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:45:39 - INFO :       DATASET: tasksource/bigbench discourse_marker_prediction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]
2023-12-01 18:45:49 - INFO :       Use random pruner...
2023-12-01 18:45:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:45:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:45:49 - INFO :       Start Pruning
2023-12-01 18:45:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:45:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:45:51 - INFO :       discourse_marker_prediction: Total Sparsity 1.3684767556486038e-06
2023-12-01 18:45:51 - INFO :       
==================Finish================

2023-12-01 18:45:51 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:45:51 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:45:51 - INFO :       DATASET: tasksource/bigbench dyck_languages
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]
2023-12-01 18:46:01 - INFO :       Use random pruner...
2023-12-01 18:46:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:46:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:46:01 - INFO :       Start Pruning
2023-12-01 18:46:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:46:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:46:03 - INFO :       dyck_languages: Total Sparsity 1.3594863763444586e-06
2023-12-01 18:46:03 - INFO :       
==================Finish================

2023-12-01 18:46:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:46:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:46:03 - INFO :       DATASET: tasksource/bigbench elementary_math_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]
2023-12-01 18:46:11 - INFO :       Use random pruner...
2023-12-01 18:46:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:46:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:46:11 - INFO :       Start Pruning
2023-12-01 18:46:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:46:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:46:13 - INFO :       elementary_math_qa: Total Sparsity 1.3573709929787774e-06
2023-12-01 18:46:13 - INFO :       
==================Finish================

2023-12-01 18:46:13 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:46:13 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:46:13 - INFO :       DATASET: tasksource/bigbench emoji_movie
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]
2023-12-01 18:46:23 - INFO :       Use random pruner...
2023-12-01 18:46:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:46:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:46:24 - INFO :       Start Pruning
2023-12-01 18:46:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:46:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:46:26 - INFO :       emoji_movie: Total Sparsity 1.3608966319215796e-06
2023-12-01 18:46:26 - INFO :       
==================Finish================

2023-12-01 18:46:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:46:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:46:26 - INFO :       DATASET: tasksource/bigbench empirical_judgments
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]
2023-12-01 18:46:35 - INFO :       Use random pruner...
2023-12-01 18:46:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:46:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:46:36 - INFO :       Start Pruning
2023-12-01 18:46:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:46:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:46:37 - INFO :       empirical_judgments: Total Sparsity 1.3683004737014638e-06
2023-12-01 18:46:37 - INFO :       
==================Finish================

2023-12-01 18:46:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:46:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:46:37 - INFO :       DATASET: tasksource/bigbench english_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]
2023-12-01 18:46:47 - INFO :       Use random pruner...
2023-12-01 18:46:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:46:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:46:47 - INFO :       Start Pruning
2023-12-01 18:46:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:46:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:46:49 - INFO :       english_proverbs: Total Sparsity 1.3628357333401206e-06
2023-12-01 18:46:49 - INFO :       
==================Finish================

2023-12-01 18:46:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:46:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:46:49 - INFO :       DATASET: tasksource/bigbench english_russian_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]
2023-12-01 18:46:58 - INFO :       Use random pruner...
2023-12-01 18:46:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:46:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:46:59 - INFO :       Start Pruning
2023-12-01 18:46:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:46:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:47:00 - INFO :       english_russian_proverbs: Total Sparsity 1.3616017597101399e-06
2023-12-01 18:47:00 - INFO :       
==================Finish================

2023-12-01 18:47:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:47:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:47:00 - INFO :       DATASET: tasksource/bigbench entailed_polarity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]
2023-12-01 18:47:10 - INFO :       Use random pruner...
2023-12-01 18:47:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:47:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:47:10 - INFO :       Start Pruning
2023-12-01 18:47:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:47:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:47:12 - INFO :       entailed_polarity: Total Sparsity 1.3589575305030384e-06
2023-12-01 18:47:12 - INFO :       
==================Finish================

2023-12-01 18:47:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:47:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:47:12 - INFO :       DATASET: tasksource/bigbench entailed_polarity_hindi
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]
2023-12-01 18:47:22 - INFO :       Use random pruner...
2023-12-01 18:47:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:47:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:47:22 - INFO :       Start Pruning
2023-12-01 18:47:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:47:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:47:24 - INFO :       entailed_polarity_hindi: Total Sparsity 1.3543741998773957e-06
2023-12-01 18:47:24 - INFO :       
==================Finish================

2023-12-01 18:47:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:47:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:47:24 - INFO :       DATASET: tasksource/bigbench epistemic_reasoning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2023-12-01 18:47:34 - INFO :       Use random pruner...
2023-12-01 18:47:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:47:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:47:35 - INFO :       Start Pruning
2023-12-01 18:47:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:47:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:47:37 - INFO :       epistemic_reasoning: Total Sparsity 1.3556081735073764e-06
2023-12-01 18:47:37 - INFO :       
==================Finish================

2023-12-01 18:47:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:47:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:47:37 - INFO :       DATASET: tasksource/bigbench evaluating_information_essentiality
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 18:47:45 - INFO :       Use random pruner...
2023-12-01 18:47:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:47:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:47:45 - INFO :       Start Pruning
2023-12-01 18:47:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:47:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:47:47 - INFO :       evaluating_information_essentiality: Total Sparsity 1.3718261126442658e-06
2023-12-01 18:47:47 - INFO :       
==================Finish================

2023-12-01 18:47:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:47:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:47:47 - INFO :       DATASET: tasksource/bigbench fact_checker
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.49s/it]
2023-12-01 18:47:56 - INFO :       Use random pruner...
2023-12-01 18:47:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:47:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:47:56 - INFO :       Start Pruning
2023-12-01 18:47:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:47:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:47:58 - INFO :       fact_checker: Total Sparsity 1.3630120152872606e-06
2023-12-01 18:47:58 - INFO :       
==================Finish================

2023-12-01 18:47:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:47:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:47:58 - INFO :       DATASET: tasksource/bigbench fantasy_reasoning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.21s/it]
2023-12-01 18:48:08 - INFO :       Use random pruner...
2023-12-01 18:48:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:48:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:48:08 - INFO :       Start Pruning
2023-12-01 18:48:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:48:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:48:10 - INFO :       fantasy_reasoning: Total Sparsity 1.3674190639657633e-06
2023-12-01 18:48:10 - INFO :       
==================Finish================

2023-12-01 18:48:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:48:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:48:10 - INFO :       DATASET: tasksource/bigbench figure_of_speech_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2023-12-01 18:48:20 - INFO :       Use random pruner...
2023-12-01 18:48:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:48:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:48:20 - INFO :       Start Pruning
2023-12-01 18:48:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:48:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:48:22 - INFO :       figure_of_speech_detection: Total Sparsity 1.3608966319215796e-06
2023-12-01 18:48:22 - INFO :       
==================Finish================

2023-12-01 18:48:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:48:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:48:22 - INFO :       DATASET: tasksource/bigbench formal_fallacies_syllogisms_negation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 18:48:30 - INFO :       Use random pruner...
2023-12-01 18:48:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:48:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:48:31 - INFO :       Start Pruning
2023-12-01 18:48:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:48:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:48:33 - INFO :       formal_fallacies_syllogisms_negation: Total Sparsity 1.3647748347586618e-06
2023-12-01 18:48:33 - INFO :       
==================Finish================

2023-12-01 18:48:33 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:48:33 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:48:33 - INFO :       DATASET: tasksource/bigbench general_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2023-12-01 18:48:42 - INFO :       Use random pruner...
2023-12-01 18:48:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:48:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:48:43 - INFO :       Start Pruning
2023-12-01 18:48:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:48:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:48:45 - INFO :       general_knowledge: Total Sparsity 1.3540216359831155e-06
2023-12-01 18:48:45 - INFO :       
==================Finish================

2023-12-01 18:48:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:48:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:48:45 - INFO :       DATASET: tasksource/bigbench geometric_shapes
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2023-12-01 18:48:54 - INFO :       Use random pruner...
2023-12-01 18:48:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:48:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:48:54 - INFO :       Start Pruning
2023-12-01 18:48:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:48:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:48:56 - INFO :       geometric_shapes: Total Sparsity 1.367242782018623e-06
2023-12-01 18:48:56 - INFO :       
==================Finish================

2023-12-01 18:48:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:48:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:48:56 - INFO :       DATASET: tasksource/bigbench goal_step_wikihow
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
2023-12-01 18:49:05 - INFO :       Use random pruner...
2023-12-01 18:49:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:49:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:49:05 - INFO :       Start Pruning
2023-12-01 18:49:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:49:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:49:07 - INFO :       goal_step_wikihow: Total Sparsity 1.3616017597101399e-06
2023-12-01 18:49:07 - INFO :       
==================Finish================

2023-12-01 18:49:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:49:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:49:07 - INFO :       DATASET: tasksource/bigbench gre_reading_comprehension
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2023-12-01 18:49:15 - INFO :       Use random pruner...
2023-12-01 18:49:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:49:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:49:16 - INFO :       Start Pruning
2023-12-01 18:49:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:49:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:49:18 - INFO :       gre_reading_comprehension: Total Sparsity 1.3675953459129033e-06
2023-12-01 18:49:18 - INFO :       
==================Finish================

2023-12-01 18:49:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:49:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:49:18 - INFO :       DATASET: tasksource/bigbench hhh_alignment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.50s/it]
2023-12-01 18:49:25 - INFO :       Use random pruner...
2023-12-01 18:49:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:49:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:49:26 - INFO :       Start Pruning
2023-12-01 18:49:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:49:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:49:27 - INFO :       hhh_alignment: Total Sparsity 1.3608966319215796e-06
2023-12-01 18:49:27 - INFO :       
==================Finish================

2023-12-01 18:49:27 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:49:27 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:49:27 - INFO :       DATASET: tasksource/bigbench hindu_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.50s/it]
2023-12-01 18:49:35 - INFO :       Use random pruner...
2023-12-01 18:49:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:49:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:49:36 - INFO :       Start Pruning
2023-12-01 18:49:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:49:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:49:38 - INFO :       hindu_knowledge: Total Sparsity 1.3631882972344008e-06
2023-12-01 18:49:38 - INFO :       
==================Finish================

2023-12-01 18:49:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:49:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:49:38 - INFO :       DATASET: tasksource/bigbench hinglish_toxicity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]
2023-12-01 18:49:45 - INFO :       Use random pruner...
2023-12-01 18:49:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:49:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:49:45 - INFO :       Start Pruning
2023-12-01 18:49:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:49:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:49:47 - INFO :       hinglish_toxicity: Total Sparsity 1.3679479098071835e-06
2023-12-01 18:49:47 - INFO :       
==================Finish================

2023-12-01 18:49:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:49:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:49:47 - INFO :       DATASET: tasksource/bigbench human_organs_senses
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]
2023-12-01 18:49:55 - INFO :       Use random pruner...
2023-12-01 18:49:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:49:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:49:55 - INFO :       Start Pruning
2023-12-01 18:49:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:49:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:49:57 - INFO :       human_organs_senses: Total Sparsity 1.3578998388201979e-06
2023-12-01 18:49:57 - INFO :       
==================Finish================

2023-12-01 18:49:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:49:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:49:57 - INFO :       DATASET: tasksource/bigbench hyperbaton
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]
2023-12-01 18:50:04 - INFO :       Use random pruner...
2023-12-01 18:50:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:50:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:50:04 - INFO :       Start Pruning
2023-12-01 18:50:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:50:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:50:06 - INFO :       hyperbaton: Total Sparsity 1.372354958485686e-06
2023-12-01 18:50:06 - INFO :       
==================Finish================

2023-12-01 18:50:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:50:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:50:06 - INFO :       DATASET: tasksource/bigbench identify_math_theorems
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 18:50:13 - INFO :       Use random pruner...
2023-12-01 18:50:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:50:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:50:14 - INFO :       Start Pruning
2023-12-01 18:50:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:50:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:50:15 - INFO :       identify_math_theorems: Total Sparsity 1.3556081735073764e-06
2023-12-01 18:50:15 - INFO :       
==================Finish================

2023-12-01 18:50:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:50:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:50:15 - INFO :       DATASET: tasksource/bigbench identify_odd_metaphor
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]
2023-12-01 18:50:24 - INFO :       Use random pruner...
2023-12-01 18:50:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:50:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:50:25 - INFO :       Start Pruning
2023-12-01 18:50:26 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:50:26 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:50:27 - INFO :       identify_odd_metaphor: Total Sparsity 1.3674190639657633e-06
2023-12-01 18:50:27 - INFO :       
==================Finish================

2023-12-01 18:50:27 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:50:27 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:50:27 - INFO :       DATASET: tasksource/bigbench implicatures
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]
2023-12-01 18:50:36 - INFO :       Use random pruner...
2023-12-01 18:50:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:50:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:50:36 - INFO :       Start Pruning
2023-12-01 18:50:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:50:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:50:38 - INFO :       implicatures: Total Sparsity 1.3605440680272994e-06
2023-12-01 18:50:38 - INFO :       
==================Finish================

2023-12-01 18:50:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:50:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:50:38 - INFO :       DATASET: tasksource/bigbench implicit_relations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]
2023-12-01 18:50:48 - INFO :       Use random pruner...
2023-12-01 18:50:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:50:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:50:48 - INFO :       Start Pruning
2023-12-01 18:50:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:50:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:50:50 - INFO :       implicit_relations: Total Sparsity 1.3640697069701013e-06
2023-12-01 18:50:50 - INFO :       
==================Finish================

2023-12-01 18:50:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:50:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:50:50 - INFO :       DATASET: tasksource/bigbench indic_cause_and_effect
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  3.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]
2023-12-01 18:50:59 - INFO :       Use random pruner...
2023-12-01 18:50:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:50:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:51:00 - INFO :       Start Pruning
2023-12-01 18:51:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:51:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:51:01 - INFO :       indic_cause_and_effect: Total Sparsity 1.3520825345645745e-06
2023-12-01 18:51:01 - INFO :       
==================Finish================

2023-12-01 18:51:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:51:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:51:01 - INFO :       DATASET: tasksource/bigbench intent_recognition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]
2023-12-01 18:51:10 - INFO :       Use random pruner...
2023-12-01 18:51:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:51:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:51:10 - INFO :       Start Pruning
2023-12-01 18:51:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:51:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:51:12 - INFO :       intent_recognition: Total Sparsity 1.3700632931728648e-06
2023-12-01 18:51:12 - INFO :       
==================Finish================

2023-12-01 18:51:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:51:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:51:12 - INFO :       DATASET: tasksource/bigbench international_phonetic_alphabet_nli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 18:51:21 - INFO :       Use random pruner...
2023-12-01 18:51:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:51:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:51:22 - INFO :       Start Pruning
2023-12-01 18:51:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:51:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:51:23 - INFO :       international_phonetic_alphabet_nli: Total Sparsity 1.3601915041330191e-06
2023-12-01 18:51:23 - INFO :       
==================Finish================

2023-12-01 18:51:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:51:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:51:23 - INFO :       DATASET: tasksource/bigbench intersect_geometry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2023-12-01 18:51:33 - INFO :       Use random pruner...
2023-12-01 18:51:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:51:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:51:34 - INFO :       Start Pruning
2023-12-01 18:51:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:51:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:51:36 - INFO :       intersect_geometry: Total Sparsity 1.3589575305030384e-06
2023-12-01 18:51:36 - INFO :       
==================Finish================

2023-12-01 18:51:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:51:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:51:36 - INFO :       DATASET: tasksource/bigbench irony_identification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2023-12-01 18:51:44 - INFO :       Use random pruner...
2023-12-01 18:51:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:51:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:51:44 - INFO :       Start Pruning
2023-12-01 18:51:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:51:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:51:46 - INFO :       irony_identification: Total Sparsity 1.3732363682213865e-06
2023-12-01 18:51:46 - INFO :       
==================Finish================

2023-12-01 18:51:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:51:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:51:46 - INFO :       DATASET: tasksource/bigbench kannada
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2023-12-01 18:51:58 - INFO :       Use random pruner...
2023-12-01 18:51:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:51:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:51:58 - INFO :       Start Pruning
2023-12-01 18:51:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:51:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:52:00 - INFO :       kannada: Total Sparsity 1.3681241917543236e-06
2023-12-01 18:52:00 - INFO :       
==================Finish================

2023-12-01 18:52:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:52:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:52:00 - INFO :       DATASET: tasksource/bigbench key_value_maps
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.44s/it]
2023-12-01 18:52:12 - INFO :       Use random pruner...
2023-12-01 18:52:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:52:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:52:13 - INFO :       Start Pruning
2023-12-01 18:52:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:52:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:52:14 - INFO :       key_value_maps: Total Sparsity 1.3711209848557053e-06
2023-12-01 18:52:14 - INFO :       
==================Finish================

2023-12-01 18:52:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:52:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:52:14 - INFO :       DATASET: tasksource/bigbench known_unknowns
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]
2023-12-01 18:52:26 - INFO :       Use random pruner...
2023-12-01 18:52:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:52:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:52:26 - INFO :       Start Pruning
2023-12-01 18:52:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:52:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:52:28 - INFO :       known_unknowns: Total Sparsity 1.3586049666087581e-06
2023-12-01 18:52:28 - INFO :       
==================Finish================

2023-12-01 18:52:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:52:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:52:28 - INFO :       DATASET: tasksource/bigbench language_identification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2023-12-01 18:52:38 - INFO :       Use random pruner...
2023-12-01 18:52:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:52:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:52:38 - INFO :       Start Pruning
2023-12-01 18:52:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:52:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:52:40 - INFO :       language_identification: Total Sparsity 1.3603677860801591e-06
2023-12-01 18:52:40 - INFO :       
==================Finish================

2023-12-01 18:52:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:52:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:52:40 - INFO :       DATASET: tasksource/bigbench logic_grid_puzzle
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2023-12-01 18:52:50 - INFO :       Use random pruner...
2023-12-01 18:52:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:52:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:52:50 - INFO :       Start Pruning
2023-12-01 18:52:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:52:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:52:52 - INFO :       logic_grid_puzzle: Total Sparsity 1.3626594513929806e-06
2023-12-01 18:52:52 - INFO :       
==================Finish================

2023-12-01 18:52:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:52:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:52:52 - INFO :       DATASET: tasksource/bigbench logical_args
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]
2023-12-01 18:53:01 - INFO :       Use random pruner...
2023-12-01 18:53:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:53:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:53:02 - INFO :       Start Pruning
2023-12-01 18:53:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:53:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:53:03 - INFO :       logical_args: Total Sparsity 1.36177804165728e-06
2023-12-01 18:53:03 - INFO :       
==================Finish================

2023-12-01 18:53:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:53:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:53:03 - INFO :       DATASET: tasksource/bigbench logical_deduction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 18:53:13 - INFO :       Use random pruner...
2023-12-01 18:53:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:53:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:53:14 - INFO :       Start Pruning
2023-12-01 18:53:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:53:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:53:15 - INFO :       logical_deduction: Total Sparsity 1.3633645791815409e-06
2023-12-01 18:53:15 - INFO :       
==================Finish================

2023-12-01 18:53:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:53:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:53:15 - INFO :       DATASET: tasksource/bigbench logical_fallacy_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]
2023-12-01 18:53:23 - INFO :       Use random pruner...
2023-12-01 18:53:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:53:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:53:23 - INFO :       Start Pruning
2023-12-01 18:53:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:53:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:53:25 - INFO :       logical_fallacy_detection: Total Sparsity 1.3693581653843043e-06
2023-12-01 18:53:25 - INFO :       
==================Finish================

2023-12-01 18:53:25 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:53:25 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:53:25 - INFO :       DATASET: tasksource/bigbench logical_sequence
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]
2023-12-01 18:53:36 - INFO :       Use random pruner...
2023-12-01 18:53:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:53:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:53:36 - INFO :       Start Pruning
2023-12-01 18:53:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:53:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:53:38 - INFO :       logical_sequence: Total Sparsity 1.3628357333401206e-06
2023-12-01 18:53:38 - INFO :       
==================Finish================

2023-12-01 18:53:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:53:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:53:38 - INFO :       DATASET: tasksource/bigbench mathematical_induction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2023-12-01 18:53:47 - INFO :       Use random pruner...
2023-12-01 18:53:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:53:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:53:48 - INFO :       Start Pruning
2023-12-01 18:53:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:53:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:53:50 - INFO :       mathematical_induction: Total Sparsity 1.3610729138687196e-06
2023-12-01 18:53:50 - INFO :       
==================Finish================

2023-12-01 18:53:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:53:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:53:50 - INFO :       DATASET: tasksource/bigbench medical_questions_russian
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2023-12-01 18:53:58 - INFO :       Use random pruner...
2023-12-01 18:53:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:53:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:53:59 - INFO :       Start Pruning
2023-12-01 18:54:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:54:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:54:01 - INFO :       medical_questions_russian: Total Sparsity 1.3674190639657633e-06
2023-12-01 18:54:01 - INFO :       
==================Finish================

2023-12-01 18:54:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:54:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:54:01 - INFO :       DATASET: tasksource/bigbench metaphor_boolean
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]
2023-12-01 18:54:09 - INFO :       Use random pruner...
2023-12-01 18:54:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:54:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:54:10 - INFO :       Start Pruning
2023-12-01 18:54:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:54:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:54:11 - INFO :       metaphor_boolean: Total Sparsity 1.3675953459129033e-06
2023-12-01 18:54:11 - INFO :       
==================Finish================

2023-12-01 18:54:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:54:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:54:11 - INFO :       DATASET: tasksource/bigbench metaphor_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]
2023-12-01 18:54:21 - INFO :       Use random pruner...
2023-12-01 18:54:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:54:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:54:21 - INFO :       Start Pruning
2023-12-01 18:54:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:54:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:54:23 - INFO :       metaphor_understanding: Total Sparsity 1.3520825345645745e-06
2023-12-01 18:54:23 - INFO :       
==================Finish================

2023-12-01 18:54:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:54:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:54:23 - INFO :       DATASET: tasksource/bigbench misconceptions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
2023-12-01 18:54:32 - INFO :       Use random pruner...
2023-12-01 18:54:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:54:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:54:33 - INFO :       Start Pruning
2023-12-01 18:54:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:54:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:54:35 - INFO :       misconceptions: Total Sparsity 1.3667139361772028e-06
2023-12-01 18:54:35 - INFO :       
==================Finish================

2023-12-01 18:54:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:54:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:54:35 - INFO :       DATASET: tasksource/bigbench misconceptions_russian
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2023-12-01 18:54:44 - INFO :       Use random pruner...
2023-12-01 18:54:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:54:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:54:44 - INFO :       Start Pruning
2023-12-01 18:54:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:54:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:54:46 - INFO :       misconceptions_russian: Total Sparsity 1.3631882972344008e-06
2023-12-01 18:54:46 - INFO :       
==================Finish================

2023-12-01 18:54:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:54:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:54:46 - INFO :       DATASET: tasksource/bigbench mnist_ascii
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2023-12-01 18:54:54 - INFO :       Use random pruner...
2023-12-01 18:54:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:54:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:54:55 - INFO :       Start Pruning
2023-12-01 18:54:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:54:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:54:56 - INFO :       mnist_ascii: Total Sparsity 1.3603677860801591e-06
2023-12-01 18:54:56 - INFO :       
==================Finish================

2023-12-01 18:54:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:54:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:54:56 - INFO :       DATASET: tasksource/bigbench moral_permissibility
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.35s/it]
2023-12-01 18:55:08 - INFO :       Use random pruner...
2023-12-01 18:55:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:55:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:55:09 - INFO :       Start Pruning
2023-12-01 18:55:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:55:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:55:10 - INFO :       moral_permissibility: Total Sparsity 1.3619543236044201e-06
2023-12-01 18:55:10 - INFO :       
==================Finish================

2023-12-01 18:55:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:55:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:55:10 - INFO :       DATASET: tasksource/bigbench movie_dialog_same_or_different
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
2023-12-01 18:55:19 - INFO :       Use random pruner...
2023-12-01 18:55:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:55:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:55:19 - INFO :       Start Pruning
2023-12-01 18:55:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:55:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:55:21 - INFO :       movie_dialog_same_or_different: Total Sparsity 1.3681241917543236e-06
2023-12-01 18:55:21 - INFO :       
==================Finish================

2023-12-01 18:55:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:55:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:55:21 - INFO :       DATASET: tasksource/bigbench movie_recommendation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]
2023-12-01 18:55:32 - INFO :       Use random pruner...
2023-12-01 18:55:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:55:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:55:32 - INFO :       Start Pruning
2023-12-01 18:55:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:55:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:55:34 - INFO :       movie_recommendation: Total Sparsity 1.3630120152872606e-06
2023-12-01 18:55:34 - INFO :       
==================Finish================

2023-12-01 18:55:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:55:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:55:34 - INFO :       DATASET: tasksource/bigbench navigate
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2023-12-01 18:55:42 - INFO :       Use random pruner...
2023-12-01 18:55:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:55:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:55:43 - INFO :       Start Pruning
2023-12-01 18:55:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:55:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:55:44 - INFO :       navigate: Total Sparsity 1.3603677860801591e-06
2023-12-01 18:55:44 - INFO :       
==================Finish================

2023-12-01 18:55:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:55:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:55:44 - INFO :       DATASET: tasksource/bigbench nonsense_words_grammar
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2023-12-01 18:55:53 - INFO :       Use random pruner...
2023-12-01 18:55:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:55:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:55:54 - INFO :       Start Pruning
2023-12-01 18:55:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:55:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:55:55 - INFO :       nonsense_words_grammar: Total Sparsity 1.3647748347586618e-06
2023-12-01 18:55:55 - INFO :       
==================Finish================

2023-12-01 18:55:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:55:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:55:55 - INFO :       DATASET: tasksource/bigbench novel_concepts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]
2023-12-01 18:56:04 - INFO :       Use random pruner...
2023-12-01 18:56:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:56:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:56:05 - INFO :       Start Pruning
2023-12-01 18:56:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:56:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:56:06 - INFO :       novel_concepts: Total Sparsity 1.3584286846616181e-06
2023-12-01 18:56:06 - INFO :       
==================Finish================

2023-12-01 18:56:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:56:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:56:06 - INFO :       DATASET: tasksource/bigbench odd_one_out
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]
2023-12-01 18:56:16 - INFO :       Use random pruner...
2023-12-01 18:56:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:56:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:56:17 - INFO :       Start Pruning
2023-12-01 18:56:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:56:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:56:18 - INFO :       odd_one_out: Total Sparsity 1.3584286846616181e-06
2023-12-01 18:56:18 - INFO :       
==================Finish================

2023-12-01 18:56:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:56:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:56:18 - INFO :       DATASET: tasksource/bigbench parsinlu_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2023-12-01 18:56:28 - INFO :       Use random pruner...
2023-12-01 18:56:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:56:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:56:29 - INFO :       Start Pruning
2023-12-01 18:56:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:56:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:56:30 - INFO :       parsinlu_qa: Total Sparsity 1.3593100943973186e-06
2023-12-01 18:56:30 - INFO :       
==================Finish================

2023-12-01 18:56:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:56:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:56:30 - INFO :       DATASET: tasksource/bigbench penguins_in_a_table
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2023-12-01 18:56:39 - INFO :       Use random pruner...
2023-12-01 18:56:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:56:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:56:40 - INFO :       Start Pruning
2023-12-01 18:56:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:56:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:56:41 - INFO :       penguins_in_a_table: Total Sparsity 1.3649511167058018e-06
2023-12-01 18:56:41 - INFO :       
==================Finish================

2023-12-01 18:56:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:56:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:56:41 - INFO :       DATASET: tasksource/bigbench persian_idioms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]
2023-12-01 18:56:51 - INFO :       Use random pruner...
2023-12-01 18:56:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:56:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:56:51 - INFO :       Start Pruning
2023-12-01 18:56:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:56:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:56:53 - INFO :       persian_idioms: Total Sparsity 1.3607203499744394e-06
2023-12-01 18:56:53 - INFO :       
==================Finish================

2023-12-01 18:56:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:56:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:56:53 - INFO :       DATASET: tasksource/bigbench phrase_relatedness
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2023-12-01 18:57:01 - INFO :       Use random pruner...
2023-12-01 18:57:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:57:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:57:02 - INFO :       Start Pruning
2023-12-01 18:57:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:57:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:57:04 - INFO :       phrase_relatedness: Total Sparsity 1.367242782018623e-06
2023-12-01 18:57:04 - INFO :       
==================Finish================

2023-12-01 18:57:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:57:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:57:04 - INFO :       DATASET: tasksource/bigbench physical_intuition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.22s/it]
2023-12-01 18:57:15 - INFO :       Use random pruner...
2023-12-01 18:57:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:57:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:57:15 - INFO :       Start Pruning
2023-12-01 18:57:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:57:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:57:17 - INFO :       physical_intuition: Total Sparsity 1.3619543236044201e-06
2023-12-01 18:57:17 - INFO :       
==================Finish================

2023-12-01 18:57:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:57:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:57:17 - INFO :       DATASET: tasksource/bigbench physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2023-12-01 18:57:26 - INFO :       Use random pruner...
2023-12-01 18:57:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:57:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:57:27 - INFO :       Start Pruning
2023-12-01 18:57:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:57:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:57:29 - INFO :       physics: Total Sparsity 1.3571947110316374e-06
2023-12-01 18:57:29 - INFO :       
==================Finish================

2023-12-01 18:57:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:57:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:57:29 - INFO :       DATASET: tasksource/bigbench play_dialog_same_or_different
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
2023-12-01 18:57:38 - INFO :       Use random pruner...
2023-12-01 18:57:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:57:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:57:39 - INFO :       Start Pruning
2023-12-01 18:57:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:57:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:57:41 - INFO :       play_dialog_same_or_different: Total Sparsity 1.3661850903357826e-06
2023-12-01 18:57:41 - INFO :       
==================Finish================

2023-12-01 18:57:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:57:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:57:41 - INFO :       DATASET: tasksource/bigbench presuppositions_as_nli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.23s/it]
2023-12-01 18:57:51 - INFO :       Use random pruner...
2023-12-01 18:57:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:57:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:57:51 - INFO :       Start Pruning
2023-12-01 18:57:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:57:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:57:53 - INFO :       presuppositions_as_nli: Total Sparsity 1.3586049666087581e-06
2023-12-01 18:57:53 - INFO :       
==================Finish================

2023-12-01 18:57:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:57:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:57:53 - INFO :       DATASET: tasksource/bigbench question_selection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 18:58:01 - INFO :       Use random pruner...
2023-12-01 18:58:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:58:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:58:02 - INFO :       Start Pruning
2023-12-01 18:58:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:58:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:58:03 - INFO :       question_selection: Total Sparsity 1.3645985528115216e-06
2023-12-01 18:58:03 - INFO :       
==================Finish================

2023-12-01 18:58:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:58:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:58:03 - INFO :       DATASET: tasksource/bigbench reasoning_about_colored_objects
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  3.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]
2023-12-01 18:58:13 - INFO :       Use random pruner...
2023-12-01 18:58:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:58:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:58:14 - INFO :       Start Pruning
2023-12-01 18:58:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:58:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:58:15 - INFO :       reasoning_about_colored_objects: Total Sparsity 1.369005601490024e-06
2023-12-01 18:58:15 - INFO :       
==================Finish================

2023-12-01 18:58:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:58:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:58:15 - INFO :       DATASET: tasksource/bigbench riddle_sense
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]
2023-12-01 18:58:24 - INFO :       Use random pruner...
2023-12-01 18:58:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:58:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:58:24 - INFO :       Start Pruning
2023-12-01 18:58:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:58:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:58:26 - INFO :       riddle_sense: Total Sparsity 1.3589575305030384e-06
2023-12-01 18:58:26 - INFO :       
==================Finish================

2023-12-01 18:58:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:58:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:58:26 - INFO :       DATASET: tasksource/bigbench ruin_names
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2023-12-01 18:58:35 - INFO :       Use random pruner...
2023-12-01 18:58:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:58:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:58:36 - INFO :       Start Pruning
2023-12-01 18:58:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:58:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:58:37 - INFO :       ruin_names: Total Sparsity 1.365303680600082e-06
2023-12-01 18:58:37 - INFO :       
==================Finish================

2023-12-01 18:58:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:58:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:58:37 - INFO :       DATASET: tasksource/bigbench salient_translation_error_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]
2023-12-01 18:58:47 - INFO :       Use random pruner...
2023-12-01 18:58:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:58:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:58:47 - INFO :       Start Pruning
2023-12-01 18:58:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:58:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:58:49 - INFO :       salient_translation_error_detection: Total Sparsity 1.356489583243077e-06
2023-12-01 18:58:49 - INFO :       
==================Finish================

2023-12-01 18:58:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:58:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:58:49 - INFO :       DATASET: tasksource/bigbench sentence_ambiguity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]
2023-12-01 18:58:58 - INFO :       Use random pruner...
2023-12-01 18:58:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:58:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:58:58 - INFO :       Start Pruning
2023-12-01 18:58:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:58:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:59:00 - INFO :       sentence_ambiguity: Total Sparsity 1.3575472749259176e-06
2023-12-01 18:59:00 - INFO :       
==================Finish================

2023-12-01 18:59:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:59:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:59:00 - INFO :       DATASET: tasksource/bigbench similarities_abstraction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]
2023-12-01 18:59:10 - INFO :       Use random pruner...
2023-12-01 18:59:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:59:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:59:10 - INFO :       Start Pruning
2023-12-01 18:59:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:59:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:59:12 - INFO :       similarities_abstraction: Total Sparsity 1.3644222708643816e-06
2023-12-01 18:59:12 - INFO :       
==================Finish================

2023-12-01 18:59:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:59:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:59:12 - INFO :       DATASET: tasksource/bigbench simple_ethical_questions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 18:59:19 - INFO :       Use random pruner...
2023-12-01 18:59:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:59:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:59:19 - INFO :       Start Pruning
2023-12-01 18:59:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:59:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:59:21 - INFO :       simple_ethical_questions: Total Sparsity 1.3677716278600435e-06
2023-12-01 18:59:21 - INFO :       
==================Finish================

2023-12-01 18:59:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:59:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:59:21 - INFO :       DATASET: tasksource/bigbench snarks
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2023-12-01 18:59:31 - INFO :       Use random pruner...
2023-12-01 18:59:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:59:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:59:31 - INFO :       Start Pruning
2023-12-01 18:59:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:59:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:59:33 - INFO :       snarks: Total Sparsity 1.3675953459129033e-06
2023-12-01 18:59:33 - INFO :       
==================Finish================

2023-12-01 18:59:33 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:59:33 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:59:33 - INFO :       DATASET: tasksource/bigbench social_iqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]
2023-12-01 18:59:42 - INFO :       Use random pruner...
2023-12-01 18:59:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:59:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:59:43 - INFO :       Start Pruning
2023-12-01 18:59:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:59:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:59:44 - INFO :       social_iqa: Total Sparsity 1.3651273986529418e-06
2023-12-01 18:59:44 - INFO :       
==================Finish================

2023-12-01 18:59:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:59:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:59:44 - INFO :       DATASET: tasksource/bigbench social_support
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2023-12-01 18:59:54 - INFO :       Use random pruner...
2023-12-01 18:59:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:59:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 18:59:54 - INFO :       Start Pruning
2023-12-01 18:59:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 18:59:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 18:59:56 - INFO :       social_support: Total Sparsity 1.3644222708643816e-06
2023-12-01 18:59:56 - INFO :       
==================Finish================

2023-12-01 18:59:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 18:59:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 18:59:56 - INFO :       DATASET: tasksource/bigbench sports_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 19:00:06 - INFO :       Use random pruner...
2023-12-01 19:00:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:00:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:00:06 - INFO :       Start Pruning
2023-12-01 19:00:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:00:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:00:08 - INFO :       sports_understanding: Total Sparsity 1.360015222185879e-06
2023-12-01 19:00:08 - INFO :       
==================Finish================

2023-12-01 19:00:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:00:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:00:08 - INFO :       DATASET: tasksource/bigbench strange_stories
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2023-12-01 19:00:18 - INFO :       Use random pruner...
2023-12-01 19:00:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:00:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:00:19 - INFO :       Start Pruning
2023-12-01 19:00:19 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:00:19 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:00:20 - INFO :       strange_stories: Total Sparsity 1.3593100943973186e-06
2023-12-01 19:00:20 - INFO :       
==================Finish================

2023-12-01 19:00:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:00:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:00:20 - INFO :       DATASET: tasksource/bigbench strategyqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2023-12-01 19:00:30 - INFO :       Use random pruner...
2023-12-01 19:00:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:00:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:00:30 - INFO :       Start Pruning
2023-12-01 19:00:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:00:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:00:32 - INFO :       strategyqa: Total Sparsity 1.3626594513929806e-06
2023-12-01 19:00:32 - INFO :       
==================Finish================

2023-12-01 19:00:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:00:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:00:32 - INFO :       DATASET: tasksource/bigbench suicide_risk
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2023-12-01 19:00:41 - INFO :       Use random pruner...
2023-12-01 19:00:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:00:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:00:41 - INFO :       Start Pruning
2023-12-01 19:00:42 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:00:42 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:00:43 - INFO :       suicide_risk: Total Sparsity 1.3667139361772028e-06
2023-12-01 19:00:43 - INFO :       
==================Finish================

2023-12-01 19:00:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:00:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:00:43 - INFO :       DATASET: tasksource/bigbench swahili_english_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 19:00:52 - INFO :       Use random pruner...
2023-12-01 19:00:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:00:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:00:53 - INFO :       Start Pruning
2023-12-01 19:00:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:00:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:00:54 - INFO :       swahili_english_proverbs: Total Sparsity 1.3568421471373572e-06
2023-12-01 19:00:54 - INFO :       
==================Finish================

2023-12-01 19:00:54 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:00:54 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:00:54 - INFO :       DATASET: tasksource/bigbench swedish_to_german_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 19:01:05 - INFO :       Use random pruner...
2023-12-01 19:01:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:01:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:01:05 - INFO :       Start Pruning
2023-12-01 19:01:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:01:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:01:07 - INFO :       swedish_to_german_proverbs: Total Sparsity 1.363540861128681e-06
2023-12-01 19:01:07 - INFO :       
==================Finish================

2023-12-01 19:01:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:01:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:01:07 - INFO :       DATASET: tasksource/bigbench symbol_interpretation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2023-12-01 19:01:17 - INFO :       Use random pruner...
2023-12-01 19:01:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:01:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:01:17 - INFO :       Start Pruning
2023-12-01 19:01:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:01:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:01:19 - INFO :       symbol_interpretation: Total Sparsity 1.3647748347586618e-06
2023-12-01 19:01:19 - INFO :       
==================Finish================

2023-12-01 19:01:19 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:01:19 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:01:19 - INFO :       DATASET: tasksource/bigbench temporal_sequences
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]
2023-12-01 19:01:28 - INFO :       Use random pruner...
2023-12-01 19:01:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:01:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:01:28 - INFO :       Start Pruning
2023-12-01 19:01:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:01:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:01:30 - INFO :       temporal_sequences: Total Sparsity 1.3675953459129033e-06
2023-12-01 19:01:30 - INFO :       
==================Finish================

2023-12-01 19:01:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:01:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:01:30 - INFO :       DATASET: tasksource/bigbench timedial
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.49s/it]
2023-12-01 19:01:39 - INFO :       Use random pruner...
2023-12-01 19:01:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:01:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:01:40 - INFO :       Start Pruning
2023-12-01 19:01:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:01:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:01:42 - INFO :       timedial: Total Sparsity 1.3593100943973186e-06
2023-12-01 19:01:42 - INFO :       
==================Finish================

2023-12-01 19:01:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:01:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:01:42 - INFO :       DATASET: tasksource/bigbench tracking_shuffled_objects
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  3.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 19:01:51 - INFO :       Use random pruner...
2023-12-01 19:01:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:01:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:01:52 - INFO :       Start Pruning
2023-12-01 19:01:53 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:01:53 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:01:54 - INFO :       tracking_shuffled_objects: Total Sparsity 1.3587812485558984e-06
2023-12-01 19:01:54 - INFO :       
==================Finish================

2023-12-01 19:01:54 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:01:54 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:01:54 - INFO :       DATASET: tasksource/bigbench understanding_fables
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]
2023-12-01 19:02:03 - INFO :       Use random pruner...
2023-12-01 19:02:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:02:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:02:04 - INFO :       Start Pruning
2023-12-01 19:02:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:02:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:02:05 - INFO :       understanding_fables: Total Sparsity 1.3591338124501784e-06
2023-12-01 19:02:05 - INFO :       
==================Finish================

2023-12-01 19:02:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:02:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:02:05 - INFO :       DATASET: tasksource/bigbench undo_permutation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]
2023-12-01 19:02:14 - INFO :       Use random pruner...
2023-12-01 19:02:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:02:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:02:15 - INFO :       Start Pruning
2023-12-01 19:02:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:02:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:02:16 - INFO :       undo_permutation: Total Sparsity 1.3614254777629999e-06
2023-12-01 19:02:16 - INFO :       
==================Finish================

2023-12-01 19:02:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:02:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:02:16 - INFO :       DATASET: tasksource/bigbench unit_interpretation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 19:02:26 - INFO :       Use random pruner...
2023-12-01 19:02:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:02:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:02:26 - INFO :       Start Pruning
2023-12-01 19:02:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:02:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:02:28 - INFO :       unit_interpretation: Total Sparsity 1.358076120767338e-06
2023-12-01 19:02:28 - INFO :       
==================Finish================

2023-12-01 19:02:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:02:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:02:28 - INFO :       DATASET: tasksource/bigbench vitaminc_fact_verification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2023-12-01 19:02:38 - INFO :       Use random pruner...
2023-12-01 19:02:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:02:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:02:38 - INFO :       Start Pruning
2023-12-01 19:02:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:02:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:02:40 - INFO :       vitaminc_fact_verification: Total Sparsity 1.3610729138687196e-06
2023-12-01 19:02:40 - INFO :       
==================Finish================

2023-12-01 19:02:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:02:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:02:40 - INFO :       DATASET: tasksource/bigbench what_is_the_tao
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]
2023-12-01 19:02:49 - INFO :       Use random pruner...
2023-12-01 19:02:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:02:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:02:50 - INFO :       Start Pruning
2023-12-01 19:02:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:02:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:02:52 - INFO :       what_is_the_tao: Total Sparsity 1.3683004737014638e-06
2023-12-01 19:02:52 - INFO :       
==================Finish================

2023-12-01 19:02:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:02:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:02:52 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2023-12-01 19:03:03 - INFO :       Use random pruner...
2023-12-01 19:03:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:03:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:03:03 - INFO :       Start Pruning
2023-12-01 19:03:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:03:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:03:05 - INFO :       which_wiki_edit: Total Sparsity 1.356313301295937e-06
2023-12-01 19:03:05 - INFO :       
==================Finish================

2023-12-01 19:03:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:03:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:03:05 - INFO :       DATASET: tasksource/bigbench winowhy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2023-12-01 19:03:13 - INFO :       Use random pruner...
2023-12-01 19:03:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:03:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:03:13 - INFO :       Start Pruning
2023-12-01 19:03:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:03:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:03:15 - INFO :       winowhy: Total Sparsity 1.3626594513929806e-06
2023-12-01 19:03:15 - INFO :       
==================Finish================

2023-12-01 19:03:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:03:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:03:15 - INFO :       DATASET: tasksource/mmlu abstract_algebra
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2023-12-01 19:03:23 - INFO :       Use random pruner...
2023-12-01 19:03:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:03:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:03:24 - INFO :       Start Pruning
2023-12-01 19:03:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:03:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:03:25 - INFO :       abstract_algebra: Total Sparsity 1.3660088083886423e-06
2023-12-01 19:03:25 - INFO :       
==================Finish================

2023-12-01 19:03:25 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:03:25 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:03:25 - INFO :       DATASET: tasksource/mmlu anatomy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]
2023-12-01 19:03:34 - INFO :       Use random pruner...
2023-12-01 19:03:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:03:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:03:34 - INFO :       Start Pruning
2023-12-01 19:03:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:03:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:03:36 - INFO :       anatomy: Total Sparsity 1.3644222708643816e-06
2023-12-01 19:03:36 - INFO :       
==================Finish================

2023-12-01 19:03:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:03:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:03:36 - INFO :       DATASET: tasksource/mmlu astronomy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
2023-12-01 19:03:44 - INFO :       Use random pruner...
2023-12-01 19:03:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:03:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:03:44 - INFO :       Start Pruning
2023-12-01 19:03:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:03:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:03:46 - INFO :       astronomy: Total Sparsity 1.354550481824536e-06
2023-12-01 19:03:46 - INFO :       
==================Finish================

2023-12-01 19:03:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:03:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:03:46 - INFO :       DATASET: tasksource/mmlu business_ethics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2023-12-01 19:03:54 - INFO :       Use random pruner...
2023-12-01 19:03:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:03:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:03:54 - INFO :       Start Pruning
2023-12-01 19:03:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:03:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:03:56 - INFO :       business_ethics: Total Sparsity 1.3601915041330191e-06
2023-12-01 19:03:56 - INFO :       
==================Finish================

2023-12-01 19:03:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:03:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:03:56 - INFO :       DATASET: tasksource/mmlu clinical_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2023-12-01 19:04:06 - INFO :       Use random pruner...
2023-12-01 19:04:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:04:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:04:07 - INFO :       Start Pruning
2023-12-01 19:04:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:04:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:04:09 - INFO :       clinical_knowledge: Total Sparsity 1.3702395751200048e-06
2023-12-01 19:04:09 - INFO :       
==================Finish================

2023-12-01 19:04:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:04:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:04:09 - INFO :       DATASET: tasksource/mmlu college_biology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 19:04:20 - INFO :       Use random pruner...
2023-12-01 19:04:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:04:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:04:20 - INFO :       Start Pruning
2023-12-01 19:04:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:04:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:04:22 - INFO :       college_biology: Total Sparsity 1.3586049666087581e-06
2023-12-01 19:04:22 - INFO :       
==================Finish================

2023-12-01 19:04:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:04:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:04:22 - INFO :       DATASET: tasksource/mmlu college_chemistry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]
2023-12-01 19:04:33 - INFO :       Use random pruner...
2023-12-01 19:04:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:04:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:04:34 - INFO :       Start Pruning
2023-12-01 19:04:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:04:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:04:35 - INFO :       college_chemistry: Total Sparsity 1.3631882972344008e-06
2023-12-01 19:04:35 - INFO :       
==================Finish================

2023-12-01 19:04:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:04:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:04:35 - INFO :       DATASET: tasksource/mmlu college_computer_science
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.44s/it]
2023-12-01 19:04:47 - INFO :       Use random pruner...
2023-12-01 19:04:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:04:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:04:48 - INFO :       Start Pruning
2023-12-01 19:04:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:04:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:04:50 - INFO :       college_computer_science: Total Sparsity 1.3584286846616181e-06
2023-12-01 19:04:50 - INFO :       
==================Finish================

2023-12-01 19:04:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:04:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:04:50 - INFO :       DATASET: tasksource/mmlu college_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]
2023-12-01 19:05:01 - INFO :       Use random pruner...
2023-12-01 19:05:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:05:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:05:01 - INFO :       Start Pruning
2023-12-01 19:05:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:05:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:05:03 - INFO :       college_mathematics: Total Sparsity 1.3716498306971257e-06
2023-12-01 19:05:03 - INFO :       
==================Finish================

2023-12-01 19:05:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:05:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:05:03 - INFO :       DATASET: tasksource/mmlu college_medicine
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.28s/it]
2023-12-01 19:05:15 - INFO :       Use random pruner...
2023-12-01 19:05:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:05:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:05:15 - INFO :       Start Pruning
2023-12-01 19:05:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:05:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:05:17 - INFO :       college_medicine: Total Sparsity 1.3589575305030384e-06
2023-12-01 19:05:17 - INFO :       
==================Finish================

2023-12-01 19:05:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:05:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:05:17 - INFO :       DATASET: tasksource/mmlu college_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.31s/it]
2023-12-01 19:05:29 - INFO :       Use random pruner...
2023-12-01 19:05:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:05:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:05:29 - INFO :       Start Pruning
2023-12-01 19:05:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:05:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:05:31 - INFO :       college_physics: Total Sparsity 1.3633645791815409e-06
2023-12-01 19:05:31 - INFO :       
==================Finish================

2023-12-01 19:05:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:05:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:05:31 - INFO :       DATASET: tasksource/mmlu computer_security
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.36s/it]
2023-12-01 19:05:42 - INFO :       Use random pruner...
2023-12-01 19:05:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:05:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:05:43 - INFO :       Start Pruning
2023-12-01 19:05:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:05:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:05:44 - INFO :       computer_security: Total Sparsity 1.3695344473314445e-06
2023-12-01 19:05:44 - INFO :       
==================Finish================

2023-12-01 19:05:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:05:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:05:44 - INFO :       DATASET: tasksource/mmlu conceptual_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 19:05:52 - INFO :       Use random pruner...
2023-12-01 19:05:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:05:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:05:53 - INFO :       Start Pruning
2023-12-01 19:05:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:05:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:05:55 - INFO :       conceptual_physics: Total Sparsity 1.3677716278600435e-06
2023-12-01 19:05:55 - INFO :       
==================Finish================

2023-12-01 19:05:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:05:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:05:55 - INFO :       DATASET: tasksource/mmlu econometrics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2023-12-01 19:06:04 - INFO :       Use random pruner...
2023-12-01 19:06:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:06:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:06:05 - INFO :       Start Pruning
2023-12-01 19:06:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:06:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:06:06 - INFO :       econometrics: Total Sparsity 1.356313301295937e-06
2023-12-01 19:06:06 - INFO :       
==================Finish================

2023-12-01 19:06:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:06:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:06:06 - INFO :       DATASET: tasksource/mmlu electrical_engineering
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]
2023-12-01 19:06:16 - INFO :       Use random pruner...
2023-12-01 19:06:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:06:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:06:16 - INFO :       Start Pruning
2023-12-01 19:06:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:06:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:06:18 - INFO :       electrical_engineering: Total Sparsity 1.3702395751200048e-06
2023-12-01 19:06:18 - INFO :       
==================Finish================

2023-12-01 19:06:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:06:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:06:18 - INFO :       DATASET: tasksource/mmlu elementary_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.29s/it]
2023-12-01 19:06:28 - INFO :       Use random pruner...
2023-12-01 19:06:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:06:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:06:28 - INFO :       Start Pruning
2023-12-01 19:06:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:06:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:06:30 - INFO :       elementary_mathematics: Total Sparsity 1.3593100943973186e-06
2023-12-01 19:06:30 - INFO :       
==================Finish================

2023-12-01 19:06:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:06:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:06:30 - INFO :       DATASET: tasksource/mmlu formal_logic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]
2023-12-01 19:06:39 - INFO :       Use random pruner...
2023-12-01 19:06:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:06:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:06:39 - INFO :       Start Pruning
2023-12-01 19:06:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:06:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:06:41 - INFO :       formal_logic: Total Sparsity 1.3598389402387389e-06
2023-12-01 19:06:41 - INFO :       
==================Finish================

2023-12-01 19:06:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:06:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:06:41 - INFO :       DATASET: tasksource/mmlu global_facts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]
2023-12-01 19:06:50 - INFO :       Use random pruner...
2023-12-01 19:06:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:06:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:06:50 - INFO :       Start Pruning
2023-12-01 19:06:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:06:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:06:52 - INFO :       global_facts: Total Sparsity 1.3492620234103328e-06
2023-12-01 19:06:52 - INFO :       
==================Finish================

2023-12-01 19:06:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:06:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:06:52 - INFO :       DATASET: tasksource/mmlu high_school_biology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]
2023-12-01 19:07:01 - INFO :       Use random pruner...
2023-12-01 19:07:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:07:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:07:01 - INFO :       Start Pruning
2023-12-01 19:07:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:07:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:07:03 - INFO :       high_school_biology: Total Sparsity 1.3571947110316374e-06
2023-12-01 19:07:03 - INFO :       
==================Finish================

2023-12-01 19:07:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:07:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:07:03 - INFO :       DATASET: tasksource/mmlu high_school_chemistry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.46s/it]
2023-12-01 19:07:13 - INFO :       Use random pruner...
2023-12-01 19:07:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:07:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:07:13 - INFO :       Start Pruning
2023-12-01 19:07:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:07:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:07:15 - INFO :       high_school_chemistry: Total Sparsity 1.3663613722829226e-06
2023-12-01 19:07:15 - INFO :       
==================Finish================

2023-12-01 19:07:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:07:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:07:15 - INFO :       DATASET: tasksource/mmlu high_school_computer_science
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.19s/it]
2023-12-01 19:07:25 - INFO :       Use random pruner...
2023-12-01 19:07:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:07:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:07:26 - INFO :       Start Pruning
2023-12-01 19:07:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:07:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:07:28 - INFO :       high_school_computer_science: Total Sparsity 1.3589575305030384e-06
2023-12-01 19:07:28 - INFO :       
==================Finish================

2023-12-01 19:07:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:07:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:07:28 - INFO :       DATASET: tasksource/mmlu high_school_european_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]
2023-12-01 19:07:36 - INFO :       Use random pruner...
2023-12-01 19:07:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:07:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:07:36 - INFO :       Start Pruning
2023-12-01 19:07:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:07:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:07:38 - INFO :       high_school_european_history: Total Sparsity 1.3667139361772028e-06
2023-12-01 19:07:38 - INFO :       
==================Finish================

2023-12-01 19:07:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:07:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:07:38 - INFO :       DATASET: tasksource/mmlu high_school_geography
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  2.00s/it]
2023-12-01 19:07:48 - INFO :       Use random pruner...
2023-12-01 19:07:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:07:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:07:48 - INFO :       Start Pruning
2023-12-01 19:07:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:07:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:07:50 - INFO :       high_school_geography: Total Sparsity 1.3619543236044201e-06
2023-12-01 19:07:50 - INFO :       
==================Finish================

2023-12-01 19:07:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:07:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:07:50 - INFO :       DATASET: tasksource/mmlu high_school_government_and_politics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]
2023-12-01 19:08:00 - INFO :       Use random pruner...
2023-12-01 19:08:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:08:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:08:00 - INFO :       Start Pruning
2023-12-01 19:08:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:08:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:08:02 - INFO :       high_school_government_and_politics: Total Sparsity 1.372354958485686e-06
2023-12-01 19:08:02 - INFO :       
==================Finish================

2023-12-01 19:08:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:08:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:08:02 - INFO :       DATASET: tasksource/mmlu high_school_macroeconomics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]
2023-12-01 19:08:12 - INFO :       Use random pruner...
2023-12-01 19:08:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:08:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:08:12 - INFO :       Start Pruning
2023-12-01 19:08:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:08:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:08:14 - INFO :       high_school_macroeconomics: Total Sparsity 1.3624831694458404e-06
2023-12-01 19:08:14 - INFO :       
==================Finish================

2023-12-01 19:08:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:08:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:08:14 - INFO :       DATASET: tasksource/mmlu high_school_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.19s/it]
2023-12-01 19:08:24 - INFO :       Use random pruner...
2023-12-01 19:08:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:08:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:08:25 - INFO :       Start Pruning
2023-12-01 19:08:26 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:08:26 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:08:27 - INFO :       high_school_mathematics: Total Sparsity 1.3616017597101399e-06
2023-12-01 19:08:27 - INFO :       
==================Finish================

2023-12-01 19:08:27 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:08:27 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:08:27 - INFO :       DATASET: tasksource/mmlu high_school_microeconomics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 19:08:36 - INFO :       Use random pruner...
2023-12-01 19:08:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:08:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:08:36 - INFO :       Start Pruning
2023-12-01 19:08:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:08:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:08:38 - INFO :       high_school_microeconomics: Total Sparsity 1.369005601490024e-06
2023-12-01 19:08:38 - INFO :       
==================Finish================

2023-12-01 19:08:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:08:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:08:38 - INFO :       DATASET: tasksource/mmlu high_school_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2023-12-01 19:08:48 - INFO :       Use random pruner...
2023-12-01 19:08:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:08:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:08:48 - INFO :       Start Pruning
2023-12-01 19:08:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:08:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:08:50 - INFO :       high_school_physics: Total Sparsity 1.3734126501685267e-06
2023-12-01 19:08:50 - INFO :       
==================Finish================

2023-12-01 19:08:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:08:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:08:50 - INFO :       DATASET: tasksource/mmlu high_school_psychology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]
2023-12-01 19:09:00 - INFO :       Use random pruner...
2023-12-01 19:09:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:09:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:09:01 - INFO :       Start Pruning
2023-12-01 19:09:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:09:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:09:03 - INFO :       high_school_psychology: Total Sparsity 1.353140226247415e-06
2023-12-01 19:09:03 - INFO :       
==================Finish================

2023-12-01 19:09:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:09:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:09:03 - INFO :       DATASET: tasksource/mmlu high_school_statistics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2023-12-01 19:09:12 - INFO :       Use random pruner...
2023-12-01 19:09:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:09:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:09:12 - INFO :       Start Pruning
2023-12-01 19:09:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:09:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:09:14 - INFO :       high_school_statistics: Total Sparsity 1.3631882972344008e-06
2023-12-01 19:09:14 - INFO :       
==================Finish================

2023-12-01 19:09:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:09:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:09:14 - INFO :       DATASET: tasksource/mmlu high_school_us_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]
2023-12-01 19:09:21 - INFO :       Use random pruner...
2023-12-01 19:09:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:09:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:09:22 - INFO :       Start Pruning
2023-12-01 19:09:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:09:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:09:23 - INFO :       high_school_us_history: Total Sparsity 1.3631882972344008e-06
2023-12-01 19:09:23 - INFO :       
==================Finish================

2023-12-01 19:09:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:09:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:09:23 - INFO :       DATASET: tasksource/mmlu high_school_world_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]
2023-12-01 19:09:32 - INFO :       Use random pruner...
2023-12-01 19:09:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:09:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:09:32 - INFO :       Start Pruning
2023-12-01 19:09:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:09:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:09:34 - INFO :       high_school_world_history: Total Sparsity 1.3707684209614252e-06
2023-12-01 19:09:34 - INFO :       
==================Finish================

2023-12-01 19:09:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:09:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:09:34 - INFO :       DATASET: tasksource/mmlu human_aging
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2023-12-01 19:09:46 - INFO :       Use random pruner...
2023-12-01 19:09:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:09:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:09:46 - INFO :       Start Pruning
2023-12-01 19:09:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:09:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:09:48 - INFO :       human_aging: Total Sparsity 1.3541979179302557e-06
2023-12-01 19:09:48 - INFO :       
==================Finish================

2023-12-01 19:09:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:09:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:09:48 - INFO :       DATASET: tasksource/mmlu human_sexuality
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]
2023-12-01 19:09:57 - INFO :       Use random pruner...
2023-12-01 19:09:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:09:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:09:57 - INFO :       Start Pruning
2023-12-01 19:09:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:09:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:09:59 - INFO :       human_sexuality: Total Sparsity 1.365479962547222e-06
2023-12-01 19:09:59 - INFO :       
==================Finish================

2023-12-01 19:09:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:09:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:09:59 - INFO :       DATASET: tasksource/mmlu international_law
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]
2023-12-01 19:10:10 - INFO :       Use random pruner...
2023-12-01 19:10:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:10:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:10:10 - INFO :       Start Pruning
2023-12-01 19:10:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:10:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:10:12 - INFO :       international_law: Total Sparsity 1.3601915041330191e-06
2023-12-01 19:10:12 - INFO :       
==================Finish================

2023-12-01 19:10:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:10:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:10:12 - INFO :       DATASET: tasksource/mmlu jurisprudence
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2023-12-01 19:10:22 - INFO :       Use random pruner...
2023-12-01 19:10:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:10:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:10:22 - INFO :       Start Pruning
2023-12-01 19:10:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:10:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:10:24 - INFO :       jurisprudence: Total Sparsity 1.3633645791815409e-06
2023-12-01 19:10:24 - INFO :       
==================Finish================

2023-12-01 19:10:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:10:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:10:24 - INFO :       DATASET: tasksource/mmlu logical_fallacies
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2023-12-01 19:10:34 - INFO :       Use random pruner...
2023-12-01 19:10:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:10:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:10:34 - INFO :       Start Pruning
2023-12-01 19:10:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:10:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:10:36 - INFO :       logical_fallacies: Total Sparsity 1.356313301295937e-06
2023-12-01 19:10:36 - INFO :       
==================Finish================

2023-12-01 19:10:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:10:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:10:36 - INFO :       DATASET: tasksource/mmlu machine_learning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2023-12-01 19:10:46 - INFO :       Use random pruner...
2023-12-01 19:10:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:10:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:10:46 - INFO :       Start Pruning
2023-12-01 19:10:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:10:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:10:48 - INFO :       machine_learning: Total Sparsity 1.3591338124501784e-06
2023-12-01 19:10:48 - INFO :       
==================Finish================

2023-12-01 19:10:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:10:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:10:48 - INFO :       DATASET: tasksource/mmlu management
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2023-12-01 19:10:58 - INFO :       Use random pruner...
2023-12-01 19:10:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:10:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:10:58 - INFO :       Start Pruning
2023-12-01 19:10:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:10:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:11:00 - INFO :       management: Total Sparsity 1.363717143075821e-06
2023-12-01 19:11:00 - INFO :       
==================Finish================

2023-12-01 19:11:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:11:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:11:00 - INFO :       DATASET: tasksource/mmlu marketing
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]
2023-12-01 19:11:06 - INFO :       Use random pruner...
2023-12-01 19:11:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:11:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:11:07 - INFO :       Start Pruning
2023-12-01 19:11:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:11:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:11:08 - INFO :       marketing: Total Sparsity 1.3674190639657633e-06
2023-12-01 19:11:08 - INFO :       
==================Finish================

2023-12-01 19:11:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:11:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:11:08 - INFO :       DATASET: tasksource/mmlu medical_genetics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2023-12-01 19:11:18 - INFO :       Use random pruner...
2023-12-01 19:11:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:11:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:11:18 - INFO :       Start Pruning
2023-12-01 19:11:19 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:11:19 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:11:20 - INFO :       medical_genetics: Total Sparsity 1.3607203499744394e-06
2023-12-01 19:11:20 - INFO :       
==================Finish================

2023-12-01 19:11:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:11:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:11:20 - INFO :       DATASET: tasksource/mmlu miscellaneous
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 19:11:28 - INFO :       Use random pruner...
2023-12-01 19:11:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:11:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:11:28 - INFO :       Start Pruning
2023-12-01 19:11:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:11:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:11:30 - INFO :       miscellaneous: Total Sparsity 1.3644222708643816e-06
2023-12-01 19:11:30 - INFO :       
==================Finish================

2023-12-01 19:11:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:11:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:11:30 - INFO :       DATASET: tasksource/mmlu moral_disputes
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 19:11:40 - INFO :       Use random pruner...
2023-12-01 19:11:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:11:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:11:40 - INFO :       Start Pruning
2023-12-01 19:11:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:11:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:11:42 - INFO :       moral_disputes: Total Sparsity 1.3490857414631927e-06
2023-12-01 19:11:42 - INFO :       
==================Finish================

2023-12-01 19:11:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:11:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:11:42 - INFO :       DATASET: tasksource/mmlu moral_scenarios
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]
2023-12-01 19:11:51 - INFO :       Use random pruner...
2023-12-01 19:11:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:11:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:11:52 - INFO :       Start Pruning
2023-12-01 19:11:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:11:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:11:53 - INFO :       moral_scenarios: Total Sparsity 1.3679479098071835e-06
2023-12-01 19:11:53 - INFO :       
==================Finish================

2023-12-01 19:11:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:11:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:11:53 - INFO :       DATASET: tasksource/mmlu nutrition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]
2023-12-01 19:12:03 - INFO :       Use random pruner...
2023-12-01 19:12:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:12:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:12:03 - INFO :       Start Pruning
2023-12-01 19:12:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:12:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:12:05 - INFO :       nutrition: Total Sparsity 1.3651273986529418e-06
2023-12-01 19:12:05 - INFO :       
==================Finish================

2023-12-01 19:12:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:12:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:12:05 - INFO :       DATASET: tasksource/mmlu philosophy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]
2023-12-01 19:12:14 - INFO :       Use random pruner...
2023-12-01 19:12:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:12:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:12:15 - INFO :       Start Pruning
2023-12-01 19:12:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:12:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:12:16 - INFO :       philosophy: Total Sparsity 1.3628357333401206e-06
2023-12-01 19:12:16 - INFO :       
==================Finish================

2023-12-01 19:12:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:12:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:12:16 - INFO :       DATASET: tasksource/mmlu prehistory
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2023-12-01 19:12:26 - INFO :       Use random pruner...
2023-12-01 19:12:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:12:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:12:26 - INFO :       Start Pruning
2023-12-01 19:12:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:12:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:12:28 - INFO :       prehistory: Total Sparsity 1.3591338124501784e-06
2023-12-01 19:12:28 - INFO :       
==================Finish================

2023-12-01 19:12:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:12:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:12:28 - INFO :       DATASET: tasksource/mmlu professional_accounting
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]
2023-12-01 19:12:42 - INFO :       Use random pruner...
2023-12-01 19:12:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:12:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:12:43 - INFO :       Start Pruning
2023-12-01 19:12:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:12:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:12:44 - INFO :       professional_accounting: Total Sparsity 1.3605440680272994e-06
2023-12-01 19:12:44 - INFO :       
==================Finish================

2023-12-01 19:12:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:12:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:12:44 - INFO :       DATASET: tasksource/mmlu professional_law
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]
2023-12-01 19:12:54 - INFO :       Use random pruner...
2023-12-01 19:12:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:12:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:12:54 - INFO :       Start Pruning
2023-12-01 19:12:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:12:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:12:56 - INFO :       professional_law: Total Sparsity 1.3633645791815409e-06
2023-12-01 19:12:56 - INFO :       
==================Finish================

2023-12-01 19:12:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:12:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:12:56 - INFO :       DATASET: tasksource/mmlu professional_medicine
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]
2023-12-01 19:13:03 - INFO :       Use random pruner...
2023-12-01 19:13:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:13:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:13:04 - INFO :       Start Pruning
2023-12-01 19:13:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:13:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:13:06 - INFO :       professional_medicine: Total Sparsity 1.3651273986529418e-06
2023-12-01 19:13:06 - INFO :       
==================Finish================

2023-12-01 19:13:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:13:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:13:06 - INFO :       DATASET: tasksource/mmlu professional_psychology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2023-12-01 19:13:14 - INFO :       Use random pruner...
2023-12-01 19:13:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:13:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:13:14 - INFO :       Start Pruning
2023-12-01 19:13:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:13:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:13:16 - INFO :       professional_psychology: Total Sparsity 1.3603677860801591e-06
2023-12-01 19:13:16 - INFO :       
==================Finish================

2023-12-01 19:13:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:13:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:13:16 - INFO :       DATASET: tasksource/mmlu public_relations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2023-12-01 19:13:27 - INFO :       Use random pruner...
2023-12-01 19:13:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:13:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:13:27 - INFO :       Start Pruning
2023-12-01 19:13:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:13:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:13:29 - INFO :       public_relations: Total Sparsity 1.3624831694458404e-06
2023-12-01 19:13:29 - INFO :       
==================Finish================

2023-12-01 19:13:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:13:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:13:29 - INFO :       DATASET: tasksource/mmlu security_studies
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2023-12-01 19:13:38 - INFO :       Use random pruner...
2023-12-01 19:13:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:13:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:13:39 - INFO :       Start Pruning
2023-12-01 19:13:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:13:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:13:40 - INFO :       security_studies: Total Sparsity 1.360015222185879e-06
2023-12-01 19:13:40 - INFO :       
==================Finish================

2023-12-01 19:13:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:13:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:13:40 - INFO :       DATASET: tasksource/mmlu sociology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2023-12-01 19:13:50 - INFO :       Use random pruner...
2023-12-01 19:13:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:13:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:13:50 - INFO :       Start Pruning
2023-12-01 19:13:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:13:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:13:52 - INFO :       sociology: Total Sparsity 1.3683004737014638e-06
2023-12-01 19:13:52 - INFO :       
==================Finish================

2023-12-01 19:13:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:13:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:13:52 - INFO :       DATASET: tasksource/mmlu us_foreign_policy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 19:14:01 - INFO :       Use random pruner...
2023-12-01 19:14:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:14:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:14:02 - INFO :       Start Pruning
2023-12-01 19:14:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:14:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:14:03 - INFO :       us_foreign_policy: Total Sparsity 1.3640697069701013e-06
2023-12-01 19:14:03 - INFO :       
==================Finish================

2023-12-01 19:14:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:14:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:14:03 - INFO :       DATASET: tasksource/mmlu virology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 19:14:12 - INFO :       Use random pruner...
2023-12-01 19:14:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:14:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:14:13 - INFO :       Start Pruning
2023-12-01 19:14:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:14:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:14:15 - INFO :       virology: Total Sparsity 1.3610729138687196e-06
2023-12-01 19:14:15 - INFO :       
==================Finish================

2023-12-01 19:14:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:14:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:14:15 - INFO :       DATASET: tasksource/mmlu world_religions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
2023-12-01 19:14:23 - INFO :       Use random pruner...
2023-12-01 19:14:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:14:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:14:24 - INFO :       Start Pruning
2023-12-01 19:14:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:14:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:14:25 - INFO :       world_religions: Total Sparsity 1.366890218124343e-06
2023-12-01 19:14:25 - INFO :       
==================Finish================

2023-12-01 19:14:25 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:14:25 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:14:25 - INFO :       DATASET: math_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2023-12-01 19:14:36 - INFO :       Use random pruner...
2023-12-01 19:14:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:14:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:14:36 - INFO :       Start Pruning
2023-12-01 19:14:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:14:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:14:38 - INFO :       math_qa: Total Sparsity 1.3728838043271063e-06
2023-12-01 19:14:38 - INFO :       
==================Finish================

2023-12-01 19:14:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:14:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:14:38 - INFO :       DATASET: EleutherAI/truthful_qa_mc
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]
2023-12-01 19:14:47 - INFO :       Use random pruner...
2023-12-01 19:14:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:14:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:14:47 - INFO :       Start Pruning
2023-12-01 19:14:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:14:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:14:49 - INFO :       truthful_qa_mc: Total Sparsity 1.352787662353135e-06
2023-12-01 19:14:49 - INFO :       
==================Finish================

2023-12-01 19:14:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:14:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:14:49 - INFO :       DATASET: derek-thomas/ScienceQA
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 19:14:58 - INFO :       Use random pruner...
2023-12-01 19:14:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:14:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:14:59 - INFO :       Start Pruning
2023-12-01 19:14:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:14:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:15:00 - INFO :       ScienceQA: Total Sparsity 1.3665376542300628e-06
2023-12-01 19:15:00 - INFO :       
==================Finish================

2023-12-01 19:15:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:15:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:15:00 - INFO :       DATASET: commonsense_qa
Index 6
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2023-12-01 19:15:10 - INFO :       Use random pruner...
2023-12-01 19:15:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:15:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:15:11 - INFO :       Start Pruning
2023-12-01 19:15:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:15:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:15:12 - INFO :       commonsense_qa: Total Sparsity 1.3665376542300628e-06
2023-12-01 19:15:12 - INFO :       
==================Finish================

2023-12-01 19:15:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:15:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:15:12 - INFO :       DATASET: tasksource/bigbench abstract_narrative_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2023-12-01 19:15:22 - INFO :       Use random pruner...
2023-12-01 19:15:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:15:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:15:23 - INFO :       Start Pruning
2023-12-01 19:15:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:15:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:15:24 - INFO :       abstract_narrative_understanding: Total Sparsity 1.3603677860801591e-06
2023-12-01 19:15:24 - INFO :       
==================Finish================

2023-12-01 19:15:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:15:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:15:24 - INFO :       DATASET: tasksource/bigbench anachronisms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 19:15:35 - INFO :       Use random pruner...
2023-12-01 19:15:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:15:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:15:35 - INFO :       Start Pruning
2023-12-01 19:15:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:15:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:15:37 - INFO :       anachronisms: Total Sparsity 1.3570184290844972e-06
2023-12-01 19:15:37 - INFO :       
==================Finish================

2023-12-01 19:15:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:15:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:15:37 - INFO :       DATASET: tasksource/bigbench analogical_similarity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
2023-12-01 19:15:47 - INFO :       Use random pruner...
2023-12-01 19:15:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:15:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:15:47 - INFO :       Start Pruning
2023-12-01 19:15:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:15:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:15:49 - INFO :       analogical_similarity: Total Sparsity 1.3593100943973186e-06
2023-12-01 19:15:49 - INFO :       
==================Finish================

2023-12-01 19:15:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:15:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:15:49 - INFO :       DATASET: tasksource/bigbench analytic_entailment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2023-12-01 19:15:58 - INFO :       Use random pruner...
2023-12-01 19:15:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:15:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:15:59 - INFO :       Start Pruning
2023-12-01 19:16:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:16:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:16:01 - INFO :       analytic_entailment: Total Sparsity 1.368653037595744e-06
2023-12-01 19:16:01 - INFO :       
==================Finish================

2023-12-01 19:16:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:16:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:16:01 - INFO :       DATASET: tasksource/bigbench arithmetic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]
2023-12-01 19:16:10 - INFO :       Use random pruner...
2023-12-01 19:16:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:16:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:16:10 - INFO :       Start Pruning
2023-12-01 19:16:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:16:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:16:12 - INFO :       arithmetic: Total Sparsity 1.3589575305030384e-06
2023-12-01 19:16:12 - INFO :       
==================Finish================

2023-12-01 19:16:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:16:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:16:12 - INFO :       DATASET: tasksource/bigbench authorship_verification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2023-12-01 19:16:21 - INFO :       Use random pruner...
2023-12-01 19:16:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:16:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:16:21 - INFO :       Start Pruning
2023-12-01 19:16:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:16:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:16:23 - INFO :       authorship_verification: Total Sparsity 1.3584286846616181e-06
2023-12-01 19:16:23 - INFO :       
==================Finish================

2023-12-01 19:16:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:16:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:16:23 - INFO :       DATASET: tasksource/bigbench bbq_lite_json
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2023-12-01 19:16:32 - INFO :       Use random pruner...
2023-12-01 19:16:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:16:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:16:32 - INFO :       Start Pruning
2023-12-01 19:16:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:16:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:16:34 - INFO :       bbq_lite_json: Total Sparsity 1.3578998388201979e-06
2023-12-01 19:16:34 - INFO :       
==================Finish================

2023-12-01 19:16:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:16:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:16:34 - INFO :       DATASET: tasksource/bigbench causal_judgment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2023-12-01 19:16:44 - INFO :       Use random pruner...
2023-12-01 19:16:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:16:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:16:44 - INFO :       Start Pruning
2023-12-01 19:16:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:16:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:16:46 - INFO :       causal_judgment: Total Sparsity 1.3616017597101399e-06
2023-12-01 19:16:46 - INFO :       
==================Finish================

2023-12-01 19:16:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:16:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:16:46 - INFO :       DATASET: tasksource/bigbench cause_and_effect
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2023-12-01 19:16:55 - INFO :       Use random pruner...
2023-12-01 19:16:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:16:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:16:56 - INFO :       Start Pruning
2023-12-01 19:16:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:16:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:16:57 - INFO :       cause_and_effect: Total Sparsity 1.3559607374016567e-06
2023-12-01 19:16:57 - INFO :       
==================Finish================

2023-12-01 19:16:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:16:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:16:57 - INFO :       DATASET: tasksource/bigbench checkmate_in_one
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2023-12-01 19:17:06 - INFO :       Use random pruner...
2023-12-01 19:17:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:17:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:17:06 - INFO :       Start Pruning
2023-12-01 19:17:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:17:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:17:08 - INFO :       checkmate_in_one: Total Sparsity 1.3584286846616181e-06
2023-12-01 19:17:08 - INFO :       
==================Finish================

2023-12-01 19:17:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:17:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:17:08 - INFO :       DATASET: tasksource/bigbench cifar10_classification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 19:17:15 - INFO :       Use random pruner...
2023-12-01 19:17:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:17:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:17:15 - INFO :       Start Pruning
2023-12-01 19:17:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:17:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:17:17 - INFO :       cifar10_classification: Total Sparsity 1.3593100943973186e-06
2023-12-01 19:17:17 - INFO :       
==================Finish================

2023-12-01 19:17:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:17:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:17:17 - INFO :       DATASET: tasksource/bigbench code_line_description
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 19:17:24 - INFO :       Use random pruner...
2023-12-01 19:17:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:17:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:17:24 - INFO :       Start Pruning
2023-12-01 19:17:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:17:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:17:26 - INFO :       code_line_description: Total Sparsity 1.3663613722829226e-06
2023-12-01 19:17:26 - INFO :       
==================Finish================

2023-12-01 19:17:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:17:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:17:26 - INFO :       DATASET: tasksource/bigbench color
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 19:17:32 - INFO :       Use random pruner...
2023-12-01 19:17:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:17:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:17:33 - INFO :       Start Pruning
2023-12-01 19:17:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:17:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:17:35 - INFO :       color: Total Sparsity 1.3674190639657633e-06
2023-12-01 19:17:35 - INFO :       
==================Finish================

2023-12-01 19:17:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:17:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:17:35 - INFO :       DATASET: tasksource/bigbench common_morpheme
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 19:17:41 - INFO :       Use random pruner...
2023-12-01 19:17:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:17:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:17:42 - INFO :       Start Pruning
2023-12-01 19:17:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:17:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:17:43 - INFO :       common_morpheme: Total Sparsity 1.3698870112257248e-06
2023-12-01 19:17:43 - INFO :       
==================Finish================

2023-12-01 19:17:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:17:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:17:43 - INFO :       DATASET: tasksource/bigbench conceptual_combinations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 19:17:50 - INFO :       Use random pruner...
2023-12-01 19:17:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:17:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:17:50 - INFO :       Start Pruning
2023-12-01 19:17:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:17:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:17:52 - INFO :       conceptual_combinations: Total Sparsity 1.3658325264415023e-06
2023-12-01 19:17:52 - INFO :       
==================Finish================

2023-12-01 19:17:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:17:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:17:52 - INFO :       DATASET: tasksource/bigbench crash_blossom
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 19:17:59 - INFO :       Use random pruner...
2023-12-01 19:17:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:17:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:17:59 - INFO :       Start Pruning
2023-12-01 19:18:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:18:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:18:01 - INFO :       crash_blossom: Total Sparsity 1.3707684209614252e-06
2023-12-01 19:18:01 - INFO :       
==================Finish================

2023-12-01 19:18:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:18:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:18:01 - INFO :       DATASET: tasksource/bigbench crass_ai
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 19:18:08 - INFO :       Use random pruner...
2023-12-01 19:18:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:18:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:18:08 - INFO :       Start Pruning
2023-12-01 19:18:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:18:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:18:10 - INFO :       crass_ai: Total Sparsity 1.3621306055515601e-06
2023-12-01 19:18:10 - INFO :       
==================Finish================

2023-12-01 19:18:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:18:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:18:10 - INFO :       DATASET: tasksource/bigbench cryobiology_spanish
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]
2023-12-01 19:18:17 - INFO :       Use random pruner...
2023-12-01 19:18:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:18:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:18:17 - INFO :       Start Pruning
2023-12-01 19:18:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:18:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:18:19 - INFO :       cryobiology_spanish: Total Sparsity 1.368829319542884e-06
2023-12-01 19:18:19 - INFO :       
==================Finish================

2023-12-01 19:18:19 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:18:19 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:18:19 - INFO :       DATASET: tasksource/bigbench cs_algorithms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2023-12-01 19:18:29 - INFO :       Use random pruner...
2023-12-01 19:18:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:18:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:18:29 - INFO :       Start Pruning
2023-12-01 19:18:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:18:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:18:31 - INFO :       cs_algorithms: Total Sparsity 1.3749991876927875e-06
2023-12-01 19:18:31 - INFO :       
==================Finish================

2023-12-01 19:18:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:18:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:18:31 - INFO :       DATASET: tasksource/bigbench dark_humor_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.46s/it]
2023-12-01 19:18:40 - INFO :       Use random pruner...
2023-12-01 19:18:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:18:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:18:40 - INFO :       Start Pruning
2023-12-01 19:18:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:18:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:18:42 - INFO :       dark_humor_detection: Total Sparsity 1.3591338124501784e-06
2023-12-01 19:18:42 - INFO :       
==================Finish================

2023-12-01 19:18:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:18:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:18:42 - INFO :       DATASET: tasksource/bigbench date_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 19:18:53 - INFO :       Use random pruner...
2023-12-01 19:18:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:18:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:18:54 - INFO :       Start Pruning
2023-12-01 19:18:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:18:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:18:55 - INFO :       date_understanding: Total Sparsity 1.3519062526174344e-06
2023-12-01 19:18:55 - INFO :       
==================Finish================

2023-12-01 19:18:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:18:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:18:55 - INFO :       DATASET: tasksource/bigbench disambiguation_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]
2023-12-01 19:19:03 - INFO :       Use random pruner...
2023-12-01 19:19:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:19:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:19:04 - INFO :       Start Pruning
2023-12-01 19:19:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:19:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:19:05 - INFO :       disambiguation_qa: Total Sparsity 1.3601915041330191e-06
2023-12-01 19:19:05 - INFO :       
==================Finish================

2023-12-01 19:19:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:19:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:19:05 - INFO :       DATASET: tasksource/bigbench discourse_marker_prediction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2023-12-01 19:19:15 - INFO :       Use random pruner...
2023-12-01 19:19:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:19:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:19:15 - INFO :       Start Pruning
2023-12-01 19:19:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:19:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:19:17 - INFO :       discourse_marker_prediction: Total Sparsity 1.3538453540359754e-06
2023-12-01 19:19:17 - INFO :       
==================Finish================

2023-12-01 19:19:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:19:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:19:17 - INFO :       DATASET: tasksource/bigbench dyck_languages
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2023-12-01 19:19:27 - INFO :       Use random pruner...
2023-12-01 19:19:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:19:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:19:28 - INFO :       Start Pruning
2023-12-01 19:19:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:19:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:19:29 - INFO :       dyck_languages: Total Sparsity 1.3644222708643816e-06
2023-12-01 19:19:29 - INFO :       
==================Finish================

2023-12-01 19:19:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:19:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:19:29 - INFO :       DATASET: tasksource/bigbench elementary_math_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.30s/it]
2023-12-01 19:19:39 - INFO :       Use random pruner...
2023-12-01 19:19:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:19:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:19:40 - INFO :       Start Pruning
2023-12-01 19:19:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:19:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:19:41 - INFO :       elementary_math_qa: Total Sparsity 1.3626594513929806e-06
2023-12-01 19:19:41 - INFO :       
==================Finish================

2023-12-01 19:19:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:19:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:19:41 - INFO :       DATASET: tasksource/bigbench emoji_movie
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2023-12-01 19:19:53 - INFO :       Use random pruner...
2023-12-01 19:19:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:19:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:19:53 - INFO :       Start Pruning
2023-12-01 19:19:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:19:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:19:55 - INFO :       emoji_movie: Total Sparsity 1.3663613722829226e-06
2023-12-01 19:19:55 - INFO :       
==================Finish================

2023-12-01 19:19:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:19:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:19:55 - INFO :       DATASET: tasksource/bigbench empirical_judgments
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]
2023-12-01 19:20:04 - INFO :       Use random pruner...
2023-12-01 19:20:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:20:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:20:05 - INFO :       Start Pruning
2023-12-01 19:20:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:20:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:20:06 - INFO :       empirical_judgments: Total Sparsity 1.3626594513929806e-06
2023-12-01 19:20:06 - INFO :       
==================Finish================

2023-12-01 19:20:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:20:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:20:06 - INFO :       DATASET: tasksource/bigbench english_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.19s/it]
2023-12-01 19:20:15 - INFO :       Use random pruner...
2023-12-01 19:20:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:20:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:20:16 - INFO :       Start Pruning
2023-12-01 19:20:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:20:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:20:17 - INFO :       english_proverbs: Total Sparsity 1.3506722789874537e-06
2023-12-01 19:20:17 - INFO :       
==================Finish================

2023-12-01 19:20:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:20:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:20:17 - INFO :       DATASET: tasksource/bigbench english_russian_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2023-12-01 19:20:26 - INFO :       Use random pruner...
2023-12-01 19:20:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:20:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:20:27 - INFO :       Start Pruning
2023-12-01 19:20:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:20:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:20:28 - INFO :       english_russian_proverbs: Total Sparsity 1.3675953459129033e-06
2023-12-01 19:20:28 - INFO :       
==================Finish================

2023-12-01 19:20:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:20:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:20:28 - INFO :       DATASET: tasksource/bigbench entailed_polarity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.50s/it]
2023-12-01 19:20:37 - INFO :       Use random pruner...
2023-12-01 19:20:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:20:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:20:37 - INFO :       Start Pruning
2023-12-01 19:20:38 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:20:38 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:20:39 - INFO :       entailed_polarity: Total Sparsity 1.368653037595744e-06
2023-12-01 19:20:39 - INFO :       
==================Finish================

2023-12-01 19:20:39 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:20:39 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:20:39 - INFO :       DATASET: tasksource/bigbench entailed_polarity_hindi
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]
2023-12-01 19:20:47 - INFO :       Use random pruner...
2023-12-01 19:20:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:20:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:20:47 - INFO :       Start Pruning
2023-12-01 19:20:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:20:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:20:49 - INFO :       entailed_polarity_hindi: Total Sparsity 1.3633645791815409e-06
2023-12-01 19:20:49 - INFO :       
==================Finish================

2023-12-01 19:20:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:20:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:20:49 - INFO :       DATASET: tasksource/bigbench epistemic_reasoning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2023-12-01 19:20:59 - INFO :       Use random pruner...
2023-12-01 19:20:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:20:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:20:59 - INFO :       Start Pruning
2023-12-01 19:21:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:21:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:21:01 - INFO :       epistemic_reasoning: Total Sparsity 1.367066500071483e-06
2023-12-01 19:21:01 - INFO :       
==================Finish================

2023-12-01 19:21:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:21:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:21:01 - INFO :       DATASET: tasksource/bigbench evaluating_information_essentiality
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]
2023-12-01 19:21:08 - INFO :       Use random pruner...
2023-12-01 19:21:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:21:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:21:09 - INFO :       Start Pruning
2023-12-01 19:21:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:21:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:21:11 - INFO :       evaluating_information_essentiality: Total Sparsity 1.3727075223799662e-06
2023-12-01 19:21:11 - INFO :       
==================Finish================

2023-12-01 19:21:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:21:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:21:11 - INFO :       DATASET: tasksource/bigbench fact_checker
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2023-12-01 19:21:20 - INFO :       Use random pruner...
2023-12-01 19:21:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:21:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:21:21 - INFO :       Start Pruning
2023-12-01 19:21:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:21:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:21:22 - INFO :       fact_checker: Total Sparsity 1.3665376542300628e-06
2023-12-01 19:21:22 - INFO :       
==================Finish================

2023-12-01 19:21:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:21:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:21:22 - INFO :       DATASET: tasksource/bigbench fantasy_reasoning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
2023-12-01 19:21:32 - INFO :       Use random pruner...
2023-12-01 19:21:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:21:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:21:33 - INFO :       Start Pruning
2023-12-01 19:21:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:21:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:21:35 - INFO :       fantasy_reasoning: Total Sparsity 1.3711209848557053e-06
2023-12-01 19:21:35 - INFO :       
==================Finish================

2023-12-01 19:21:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:21:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:21:35 - INFO :       DATASET: tasksource/bigbench figure_of_speech_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]
2023-12-01 19:21:43 - INFO :       Use random pruner...
2023-12-01 19:21:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:21:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:21:44 - INFO :       Start Pruning
2023-12-01 19:21:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:21:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:21:46 - INFO :       figure_of_speech_detection: Total Sparsity 1.356313301295937e-06
2023-12-01 19:21:46 - INFO :       
==================Finish================

2023-12-01 19:21:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:21:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:21:46 - INFO :       DATASET: tasksource/bigbench formal_fallacies_syllogisms_negation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.49s/it]
2023-12-01 19:21:55 - INFO :       Use random pruner...
2023-12-01 19:21:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:21:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:21:55 - INFO :       Start Pruning
2023-12-01 19:21:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:21:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:21:57 - INFO :       formal_fallacies_syllogisms_negation: Total Sparsity 1.354550481824536e-06
2023-12-01 19:21:57 - INFO :       
==================Finish================

2023-12-01 19:21:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:21:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:21:57 - INFO :       DATASET: tasksource/bigbench general_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]
2023-12-01 19:22:09 - INFO :       Use random pruner...
2023-12-01 19:22:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:22:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:22:10 - INFO :       Start Pruning
2023-12-01 19:22:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:22:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:22:11 - INFO :       general_knowledge: Total Sparsity 1.366890218124343e-06
2023-12-01 19:22:11 - INFO :       
==================Finish================

2023-12-01 19:22:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:22:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:22:11 - INFO :       DATASET: tasksource/bigbench geometric_shapes
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.30s/it]
2023-12-01 19:22:23 - INFO :       Use random pruner...
2023-12-01 19:22:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:22:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:22:24 - INFO :       Start Pruning
2023-12-01 19:22:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:22:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:22:25 - INFO :       geometric_shapes: Total Sparsity 1.3614254777629999e-06
2023-12-01 19:22:25 - INFO :       
==================Finish================

2023-12-01 19:22:25 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:22:25 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:22:25 - INFO :       DATASET: tasksource/bigbench goal_step_wikihow
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]
2023-12-01 19:22:34 - INFO :       Use random pruner...
2023-12-01 19:22:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:22:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:22:35 - INFO :       Start Pruning
2023-12-01 19:22:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:22:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:22:36 - INFO :       goal_step_wikihow: Total Sparsity 1.349438305357473e-06
2023-12-01 19:22:36 - INFO :       
==================Finish================

2023-12-01 19:22:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:22:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:22:36 - INFO :       DATASET: tasksource/bigbench gre_reading_comprehension
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]
2023-12-01 19:22:46 - INFO :       Use random pruner...
2023-12-01 19:22:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:22:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:22:46 - INFO :       Start Pruning
2023-12-01 19:22:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:22:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:22:48 - INFO :       gre_reading_comprehension: Total Sparsity 1.367242782018623e-06
2023-12-01 19:22:48 - INFO :       
==================Finish================

2023-12-01 19:22:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:22:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:22:48 - INFO :       DATASET: tasksource/bigbench hhh_alignment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]
2023-12-01 19:22:58 - INFO :       Use random pruner...
2023-12-01 19:22:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:22:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:22:58 - INFO :       Start Pruning
2023-12-01 19:22:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:22:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:23:00 - INFO :       hhh_alignment: Total Sparsity 1.3677716278600435e-06
2023-12-01 19:23:00 - INFO :       
==================Finish================

2023-12-01 19:23:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:23:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:23:00 - INFO :       DATASET: tasksource/bigbench hindu_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2023-12-01 19:23:08 - INFO :       Use random pruner...
2023-12-01 19:23:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:23:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:23:09 - INFO :       Start Pruning
2023-12-01 19:23:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:23:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:23:10 - INFO :       hindu_knowledge: Total Sparsity 1.3700632931728648e-06
2023-12-01 19:23:10 - INFO :       
==================Finish================

2023-12-01 19:23:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:23:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:23:10 - INFO :       DATASET: tasksource/bigbench hinglish_toxicity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2023-12-01 19:23:20 - INFO :       Use random pruner...
2023-12-01 19:23:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:23:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:23:21 - INFO :       Start Pruning
2023-12-01 19:23:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:23:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:23:22 - INFO :       hinglish_toxicity: Total Sparsity 1.3556081735073764e-06
2023-12-01 19:23:22 - INFO :       
==================Finish================

2023-12-01 19:23:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:23:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:23:22 - INFO :       DATASET: tasksource/bigbench human_organs_senses
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 19:23:30 - INFO :       Use random pruner...
2023-12-01 19:23:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:23:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:23:31 - INFO :       Start Pruning
2023-12-01 19:23:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:23:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:23:33 - INFO :       human_organs_senses: Total Sparsity 1.365479962547222e-06
2023-12-01 19:23:33 - INFO :       
==================Finish================

2023-12-01 19:23:33 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:23:33 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:23:33 - INFO :       DATASET: tasksource/bigbench hyperbaton
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2023-12-01 19:23:42 - INFO :       Use random pruner...
2023-12-01 19:23:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:23:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:23:42 - INFO :       Start Pruning
2023-12-01 19:23:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:23:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:23:44 - INFO :       hyperbaton: Total Sparsity 1.3679479098071835e-06
2023-12-01 19:23:44 - INFO :       
==================Finish================

2023-12-01 19:23:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:23:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:23:44 - INFO :       DATASET: tasksource/bigbench identify_math_theorems
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]
2023-12-01 19:23:54 - INFO :       Use random pruner...
2023-12-01 19:23:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:23:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:23:54 - INFO :       Start Pruning
2023-12-01 19:23:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:23:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:23:56 - INFO :       identify_math_theorems: Total Sparsity 1.3608966319215796e-06
2023-12-01 19:23:56 - INFO :       
==================Finish================

2023-12-01 19:23:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:23:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:23:56 - INFO :       DATASET: tasksource/bigbench identify_odd_metaphor
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2023-12-01 19:24:05 - INFO :       Use random pruner...
2023-12-01 19:24:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:24:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:24:05 - INFO :       Start Pruning
2023-12-01 19:24:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:24:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:24:07 - INFO :       identify_odd_metaphor: Total Sparsity 1.3573709929787774e-06
2023-12-01 19:24:07 - INFO :       
==================Finish================

2023-12-01 19:24:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:24:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:24:07 - INFO :       DATASET: tasksource/bigbench implicatures
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2023-12-01 19:24:16 - INFO :       Use random pruner...
2023-12-01 19:24:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:24:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:24:17 - INFO :       Start Pruning
2023-12-01 19:24:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:24:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:24:19 - INFO :       implicatures: Total Sparsity 1.3586049666087581e-06
2023-12-01 19:24:19 - INFO :       
==================Finish================

2023-12-01 19:24:19 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:24:19 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:24:19 - INFO :       DATASET: tasksource/bigbench implicit_relations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]
2023-12-01 19:24:28 - INFO :       Use random pruner...
2023-12-01 19:24:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:24:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:24:28 - INFO :       Start Pruning
2023-12-01 19:24:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:24:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:24:30 - INFO :       implicit_relations: Total Sparsity 1.3533165081945552e-06
2023-12-01 19:24:30 - INFO :       
==================Finish================

2023-12-01 19:24:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:24:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:24:30 - INFO :       DATASET: tasksource/bigbench indic_cause_and_effect
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]
2023-12-01 19:24:39 - INFO :       Use random pruner...
2023-12-01 19:24:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:24:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:24:40 - INFO :       Start Pruning
2023-12-01 19:24:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:24:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:24:41 - INFO :       indic_cause_and_effect: Total Sparsity 1.3695344473314445e-06
2023-12-01 19:24:41 - INFO :       
==================Finish================

2023-12-01 19:24:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:24:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:24:41 - INFO :       DATASET: tasksource/bigbench intent_recognition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.46s/it]
2023-12-01 19:24:50 - INFO :       Use random pruner...
2023-12-01 19:24:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:24:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:24:50 - INFO :       Start Pruning
2023-12-01 19:24:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:24:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:24:52 - INFO :       intent_recognition: Total Sparsity 1.3571947110316374e-06
2023-12-01 19:24:52 - INFO :       
==================Finish================

2023-12-01 19:24:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:24:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:24:52 - INFO :       DATASET: tasksource/bigbench international_phonetic_alphabet_nli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]
2023-12-01 19:25:01 - INFO :       Use random pruner...
2023-12-01 19:25:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:25:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:25:02 - INFO :       Start Pruning
2023-12-01 19:25:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:25:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:25:03 - INFO :       international_phonetic_alphabet_nli: Total Sparsity 1.3598389402387389e-06
2023-12-01 19:25:03 - INFO :       
==================Finish================

2023-12-01 19:25:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:25:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:25:03 - INFO :       DATASET: tasksource/bigbench intersect_geometry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 19:25:13 - INFO :       Use random pruner...
2023-12-01 19:25:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:25:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:25:13 - INFO :       Start Pruning
2023-12-01 19:25:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:25:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:25:15 - INFO :       intersect_geometry: Total Sparsity 1.3744703418513672e-06
2023-12-01 19:25:15 - INFO :       
==================Finish================

2023-12-01 19:25:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:25:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:25:15 - INFO :       DATASET: tasksource/bigbench irony_identification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]
2023-12-01 19:25:25 - INFO :       Use random pruner...
2023-12-01 19:25:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:25:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:25:25 - INFO :       Start Pruning
2023-12-01 19:25:26 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:25:26 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:25:27 - INFO :       irony_identification: Total Sparsity 1.3624831694458404e-06
2023-12-01 19:25:27 - INFO :       
==================Finish================

2023-12-01 19:25:27 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:25:27 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:25:27 - INFO :       DATASET: tasksource/bigbench kannada
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]
2023-12-01 19:25:39 - INFO :       Use random pruner...
2023-12-01 19:25:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:25:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:25:39 - INFO :       Start Pruning
2023-12-01 19:25:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:25:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:25:41 - INFO :       kannada: Total Sparsity 1.3557844554545167e-06
2023-12-01 19:25:41 - INFO :       
==================Finish================

2023-12-01 19:25:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:25:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:25:41 - INFO :       DATASET: tasksource/bigbench key_value_maps
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.49s/it]
2023-12-01 19:25:50 - INFO :       Use random pruner...
2023-12-01 19:25:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:25:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:25:51 - INFO :       Start Pruning
2023-12-01 19:25:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:25:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:25:53 - INFO :       key_value_maps: Total Sparsity 1.3661850903357826e-06
2023-12-01 19:25:53 - INFO :       
==================Finish================

2023-12-01 19:25:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:25:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:25:53 - INFO :       DATASET: tasksource/bigbench known_unknowns
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.43s/it]
2023-12-01 19:26:04 - INFO :       Use random pruner...
2023-12-01 19:26:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:26:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:26:05 - INFO :       Start Pruning
2023-12-01 19:26:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:26:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:26:06 - INFO :       known_unknowns: Total Sparsity 1.3601915041330191e-06
2023-12-01 19:26:06 - INFO :       
==================Finish================

2023-12-01 19:26:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:26:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:26:06 - INFO :       DATASET: tasksource/bigbench language_identification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
2023-12-01 19:26:15 - INFO :       Use random pruner...
2023-12-01 19:26:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:26:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:26:16 - INFO :       Start Pruning
2023-12-01 19:26:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:26:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:26:17 - INFO :       language_identification: Total Sparsity 1.3624831694458404e-06
2023-12-01 19:26:17 - INFO :       
==================Finish================

2023-12-01 19:26:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:26:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:26:17 - INFO :       DATASET: tasksource/bigbench logic_grid_puzzle
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2023-12-01 19:26:27 - INFO :       Use random pruner...
2023-12-01 19:26:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:26:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:26:28 - INFO :       Start Pruning
2023-12-01 19:26:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:26:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:26:29 - INFO :       logic_grid_puzzle: Total Sparsity 1.3663613722829226e-06
2023-12-01 19:26:29 - INFO :       
==================Finish================

2023-12-01 19:26:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:26:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:26:29 - INFO :       DATASET: tasksource/bigbench logical_args
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2023-12-01 19:26:39 - INFO :       Use random pruner...
2023-12-01 19:26:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:26:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:26:39 - INFO :       Start Pruning
2023-12-01 19:26:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:26:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:26:41 - INFO :       logical_args: Total Sparsity 1.3631882972344008e-06
2023-12-01 19:26:41 - INFO :       
==================Finish================

2023-12-01 19:26:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:26:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:26:41 - INFO :       DATASET: tasksource/bigbench logical_deduction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2023-12-01 19:26:50 - INFO :       Use random pruner...
2023-12-01 19:26:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:26:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:26:51 - INFO :       Start Pruning
2023-12-01 19:26:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:26:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:26:52 - INFO :       logical_deduction: Total Sparsity 1.3667139361772028e-06
2023-12-01 19:26:52 - INFO :       
==================Finish================

2023-12-01 19:26:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:26:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:26:52 - INFO :       DATASET: tasksource/bigbench logical_fallacy_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]
2023-12-01 19:27:01 - INFO :       Use random pruner...
2023-12-01 19:27:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:27:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:27:02 - INFO :       Start Pruning
2023-12-01 19:27:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:27:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:27:03 - INFO :       logical_fallacy_detection: Total Sparsity 1.363717143075821e-06
2023-12-01 19:27:03 - INFO :       
==================Finish================

2023-12-01 19:27:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:27:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:27:03 - INFO :       DATASET: tasksource/bigbench logical_sequence
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2023-12-01 19:27:13 - INFO :       Use random pruner...
2023-12-01 19:27:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:27:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:27:13 - INFO :       Start Pruning
2023-12-01 19:27:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:27:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:27:15 - INFO :       logical_sequence: Total Sparsity 1.3667139361772028e-06
2023-12-01 19:27:15 - INFO :       
==================Finish================

2023-12-01 19:27:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:27:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:27:15 - INFO :       DATASET: tasksource/bigbench mathematical_induction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]
2023-12-01 19:27:23 - INFO :       Use random pruner...
2023-12-01 19:27:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:27:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:27:24 - INFO :       Start Pruning
2023-12-01 19:27:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:27:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:27:25 - INFO :       mathematical_induction: Total Sparsity 1.3695344473314445e-06
2023-12-01 19:27:25 - INFO :       
==================Finish================

2023-12-01 19:27:25 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:27:25 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:27:25 - INFO :       DATASET: tasksource/bigbench medical_questions_russian
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 19:27:32 - INFO :       Use random pruner...
2023-12-01 19:27:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:27:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:27:32 - INFO :       Start Pruning
2023-12-01 19:27:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:27:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:27:34 - INFO :       medical_questions_russian: Total Sparsity 1.3647748347586618e-06
2023-12-01 19:27:34 - INFO :       
==================Finish================

2023-12-01 19:27:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:27:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:27:34 - INFO :       DATASET: tasksource/bigbench metaphor_boolean
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]
2023-12-01 19:27:43 - INFO :       Use random pruner...
2023-12-01 19:27:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:27:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:27:43 - INFO :       Start Pruning
2023-12-01 19:27:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:27:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:27:45 - INFO :       metaphor_boolean: Total Sparsity 1.3573709929787774e-06
2023-12-01 19:27:45 - INFO :       
==================Finish================

2023-12-01 19:27:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:27:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:27:45 - INFO :       DATASET: tasksource/bigbench metaphor_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2023-12-01 19:27:55 - INFO :       Use random pruner...
2023-12-01 19:27:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:27:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:27:56 - INFO :       Start Pruning
2023-12-01 19:27:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:27:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:27:57 - INFO :       metaphor_understanding: Total Sparsity 1.3725312404328262e-06
2023-12-01 19:27:57 - INFO :       
==================Finish================

2023-12-01 19:27:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:27:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:27:57 - INFO :       DATASET: tasksource/bigbench misconceptions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2023-12-01 19:28:07 - INFO :       Use random pruner...
2023-12-01 19:28:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:28:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:28:07 - INFO :       Start Pruning
2023-12-01 19:28:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:28:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:28:09 - INFO :       misconceptions: Total Sparsity 1.3656562444943623e-06
2023-12-01 19:28:09 - INFO :       
==================Finish================

2023-12-01 19:28:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:28:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:28:09 - INFO :       DATASET: tasksource/bigbench misconceptions_russian
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2023-12-01 19:28:18 - INFO :       Use random pruner...
2023-12-01 19:28:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:28:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:28:19 - INFO :       Start Pruning
2023-12-01 19:28:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:28:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:28:20 - INFO :       misconceptions_russian: Total Sparsity 1.3712972668028455e-06
2023-12-01 19:28:20 - INFO :       
==================Finish================

2023-12-01 19:28:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:28:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:28:20 - INFO :       DATASET: tasksource/bigbench mnist_ascii
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]
2023-12-01 19:28:30 - INFO :       Use random pruner...
2023-12-01 19:28:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:28:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:28:30 - INFO :       Start Pruning
2023-12-01 19:28:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:28:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:28:32 - INFO :       mnist_ascii: Total Sparsity 1.3665376542300628e-06
2023-12-01 19:28:32 - INFO :       
==================Finish================

2023-12-01 19:28:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:28:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:28:32 - INFO :       DATASET: tasksource/bigbench moral_permissibility
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]
2023-12-01 19:28:40 - INFO :       Use random pruner...
2023-12-01 19:28:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:28:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:28:40 - INFO :       Start Pruning
2023-12-01 19:28:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:28:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:28:42 - INFO :       moral_permissibility: Total Sparsity 1.3628357333401206e-06
2023-12-01 19:28:42 - INFO :       
==================Finish================

2023-12-01 19:28:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:28:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:28:42 - INFO :       DATASET: tasksource/bigbench movie_dialog_same_or_different
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]
2023-12-01 19:28:50 - INFO :       Use random pruner...
2023-12-01 19:28:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:28:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:28:51 - INFO :       Start Pruning
2023-12-01 19:28:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:28:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:28:53 - INFO :       movie_dialog_same_or_different: Total Sparsity 1.365303680600082e-06
2023-12-01 19:28:53 - INFO :       
==================Finish================

2023-12-01 19:28:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:28:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:28:53 - INFO :       DATASET: tasksource/bigbench movie_recommendation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]
2023-12-01 19:29:03 - INFO :       Use random pruner...
2023-12-01 19:29:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:29:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:29:03 - INFO :       Start Pruning
2023-12-01 19:29:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:29:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:29:05 - INFO :       movie_recommendation: Total Sparsity 1.369005601490024e-06
2023-12-01 19:29:05 - INFO :       
==================Finish================

2023-12-01 19:29:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:29:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:29:05 - INFO :       DATASET: tasksource/bigbench navigate
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2023-12-01 19:29:13 - INFO :       Use random pruner...
2023-12-01 19:29:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:29:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:29:14 - INFO :       Start Pruning
2023-12-01 19:29:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:29:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:29:15 - INFO :       navigate: Total Sparsity 1.3700632931728648e-06
2023-12-01 19:29:15 - INFO :       
==================Finish================

2023-12-01 19:29:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:29:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:29:15 - INFO :       DATASET: tasksource/bigbench nonsense_words_grammar
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 19:29:22 - INFO :       Use random pruner...
2023-12-01 19:29:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:29:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:29:23 - INFO :       Start Pruning
2023-12-01 19:29:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:29:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:29:24 - INFO :       nonsense_words_grammar: Total Sparsity 1.3624831694458404e-06
2023-12-01 19:29:24 - INFO :       
==================Finish================

2023-12-01 19:29:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:29:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:29:24 - INFO :       DATASET: tasksource/bigbench novel_concepts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 19:29:31 - INFO :       Use random pruner...
2023-12-01 19:29:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:29:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:29:31 - INFO :       Start Pruning
2023-12-01 19:29:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:29:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:29:33 - INFO :       novel_concepts: Total Sparsity 1.3663613722829226e-06
2023-12-01 19:29:33 - INFO :       
==================Finish================

2023-12-01 19:29:33 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:29:33 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:29:33 - INFO :       DATASET: tasksource/bigbench odd_one_out
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 19:29:40 - INFO :       Use random pruner...
2023-12-01 19:29:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:29:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:29:40 - INFO :       Start Pruning
2023-12-01 19:29:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:29:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:29:42 - INFO :       odd_one_out: Total Sparsity 1.3554318915602364e-06
2023-12-01 19:29:42 - INFO :       
==================Finish================

2023-12-01 19:29:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:29:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:29:42 - INFO :       DATASET: tasksource/bigbench parsinlu_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
2023-12-01 19:29:51 - INFO :       Use random pruner...
2023-12-01 19:29:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:29:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:29:51 - INFO :       Start Pruning
2023-12-01 19:29:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:29:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:29:53 - INFO :       parsinlu_qa: Total Sparsity 1.3552556096130962e-06
2023-12-01 19:29:53 - INFO :       
==================Finish================

2023-12-01 19:29:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:29:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:29:53 - INFO :       DATASET: tasksource/bigbench penguins_in_a_table
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 19:30:01 - INFO :       Use random pruner...
2023-12-01 19:30:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:30:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:30:02 - INFO :       Start Pruning
2023-12-01 19:30:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:30:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:30:04 - INFO :       penguins_in_a_table: Total Sparsity 1.3638934250229613e-06
2023-12-01 19:30:04 - INFO :       
==================Finish================

2023-12-01 19:30:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:30:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:30:04 - INFO :       DATASET: tasksource/bigbench persian_idioms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2023-12-01 19:30:12 - INFO :       Use random pruner...
2023-12-01 19:30:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:30:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:30:12 - INFO :       Start Pruning
2023-12-01 19:30:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:30:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:30:14 - INFO :       persian_idioms: Total Sparsity 1.3571947110316374e-06
2023-12-01 19:30:14 - INFO :       
==================Finish================

2023-12-01 19:30:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:30:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:30:14 - INFO :       DATASET: tasksource/bigbench phrase_relatedness
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]
2023-12-01 19:30:23 - INFO :       Use random pruner...
2023-12-01 19:30:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:30:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:30:23 - INFO :       Start Pruning
2023-12-01 19:30:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:30:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:30:25 - INFO :       phrase_relatedness: Total Sparsity 1.3556081735073764e-06
2023-12-01 19:30:25 - INFO :       
==================Finish================

2023-12-01 19:30:25 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:30:25 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:30:25 - INFO :       DATASET: tasksource/bigbench physical_intuition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2023-12-01 19:30:34 - INFO :       Use random pruner...
2023-12-01 19:30:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:30:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:30:34 - INFO :       Start Pruning
2023-12-01 19:30:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:30:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:30:36 - INFO :       physical_intuition: Total Sparsity 1.370415857067145e-06
2023-12-01 19:30:36 - INFO :       
==================Finish================

2023-12-01 19:30:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:30:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:30:36 - INFO :       DATASET: tasksource/bigbench physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 19:30:45 - INFO :       Use random pruner...
2023-12-01 19:30:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:30:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:30:46 - INFO :       Start Pruning
2023-12-01 19:30:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:30:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:30:48 - INFO :       physics: Total Sparsity 1.372178676538546e-06
2023-12-01 19:30:48 - INFO :       
==================Finish================

2023-12-01 19:30:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:30:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:30:48 - INFO :       DATASET: tasksource/bigbench play_dialog_same_or_different
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]
2023-12-01 19:30:57 - INFO :       Use random pruner...
2023-12-01 19:30:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:30:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:30:58 - INFO :       Start Pruning
2023-12-01 19:30:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:30:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:31:00 - INFO :       play_dialog_same_or_different: Total Sparsity 1.3742940599042272e-06
2023-12-01 19:31:00 - INFO :       
==================Finish================

2023-12-01 19:31:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:31:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:31:00 - INFO :       DATASET: tasksource/bigbench presuppositions_as_nli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]
2023-12-01 19:31:09 - INFO :       Use random pruner...
2023-12-01 19:31:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:31:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:31:09 - INFO :       Start Pruning
2023-12-01 19:31:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:31:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:31:11 - INFO :       presuppositions_as_nli: Total Sparsity 1.3638934250229613e-06
2023-12-01 19:31:11 - INFO :       
==================Finish================

2023-12-01 19:31:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:31:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:31:11 - INFO :       DATASET: tasksource/bigbench question_selection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]
2023-12-01 19:31:20 - INFO :       Use random pruner...
2023-12-01 19:31:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:31:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:31:21 - INFO :       Start Pruning
2023-12-01 19:31:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:31:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:31:23 - INFO :       question_selection: Total Sparsity 1.3556081735073764e-06
2023-12-01 19:31:23 - INFO :       
==================Finish================

2023-12-01 19:31:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:31:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:31:23 - INFO :       DATASET: tasksource/bigbench reasoning_about_colored_objects
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
2023-12-01 19:31:31 - INFO :       Use random pruner...
2023-12-01 19:31:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:31:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:31:32 - INFO :       Start Pruning
2023-12-01 19:31:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:31:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:31:34 - INFO :       reasoning_about_colored_objects: Total Sparsity 1.3566658651902172e-06
2023-12-01 19:31:34 - INFO :       
==================Finish================

2023-12-01 19:31:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:31:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:31:34 - INFO :       DATASET: tasksource/bigbench riddle_sense
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2023-12-01 19:31:43 - INFO :       Use random pruner...
2023-12-01 19:31:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:31:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:31:44 - INFO :       Start Pruning
2023-12-01 19:31:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:31:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:31:46 - INFO :       riddle_sense: Total Sparsity 1.3660088083886423e-06
2023-12-01 19:31:46 - INFO :       
==================Finish================

2023-12-01 19:31:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:31:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:31:46 - INFO :       DATASET: tasksource/bigbench ruin_names
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
2023-12-01 19:31:55 - INFO :       Use random pruner...
2023-12-01 19:31:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:31:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:31:55 - INFO :       Start Pruning
2023-12-01 19:31:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:31:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:31:57 - INFO :       ruin_names: Total Sparsity 1.3665376542300628e-06
2023-12-01 19:31:57 - INFO :       
==================Finish================

2023-12-01 19:31:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:31:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:31:57 - INFO :       DATASET: tasksource/bigbench salient_translation_error_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2023-12-01 19:32:06 - INFO :       Use random pruner...
2023-12-01 19:32:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:32:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:32:06 - INFO :       Start Pruning
2023-12-01 19:32:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:32:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:32:08 - INFO :       salient_translation_error_detection: Total Sparsity 1.3603677860801591e-06
2023-12-01 19:32:08 - INFO :       
==================Finish================

2023-12-01 19:32:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:32:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:32:08 - INFO :       DATASET: tasksource/bigbench sentence_ambiguity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2023-12-01 19:32:16 - INFO :       Use random pruner...
2023-12-01 19:32:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:32:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:32:17 - INFO :       Start Pruning
2023-12-01 19:32:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:32:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:32:18 - INFO :       sentence_ambiguity: Total Sparsity 1.3517299706702942e-06
2023-12-01 19:32:18 - INFO :       
==================Finish================

2023-12-01 19:32:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:32:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:32:18 - INFO :       DATASET: tasksource/bigbench similarities_abstraction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]
2023-12-01 19:32:28 - INFO :       Use random pruner...
2023-12-01 19:32:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:32:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:32:28 - INFO :       Start Pruning
2023-12-01 19:32:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:32:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:32:30 - INFO :       similarities_abstraction: Total Sparsity 1.3732363682213865e-06
2023-12-01 19:32:30 - INFO :       
==================Finish================

2023-12-01 19:32:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:32:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:32:30 - INFO :       DATASET: tasksource/bigbench simple_ethical_questions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2023-12-01 19:32:39 - INFO :       Use random pruner...
2023-12-01 19:32:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:32:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:32:40 - INFO :       Start Pruning
2023-12-01 19:32:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:32:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:32:41 - INFO :       simple_ethical_questions: Total Sparsity 1.363717143075821e-06
2023-12-01 19:32:41 - INFO :       
==================Finish================

2023-12-01 19:32:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:32:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:32:41 - INFO :       DATASET: tasksource/bigbench snarks
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]
2023-12-01 19:32:51 - INFO :       Use random pruner...
2023-12-01 19:32:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:32:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:32:51 - INFO :       Start Pruning
2023-12-01 19:32:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:32:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:32:53 - INFO :       snarks: Total Sparsity 1.3667139361772028e-06
2023-12-01 19:32:53 - INFO :       
==================Finish================

2023-12-01 19:32:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:32:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:32:53 - INFO :       DATASET: tasksource/bigbench social_iqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 19:33:01 - INFO :       Use random pruner...
2023-12-01 19:33:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:33:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:33:02 - INFO :       Start Pruning
2023-12-01 19:33:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:33:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:33:04 - INFO :       social_iqa: Total Sparsity 1.3684767556486038e-06
2023-12-01 19:33:04 - INFO :       
==================Finish================

2023-12-01 19:33:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:33:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:33:04 - INFO :       DATASET: tasksource/bigbench social_support
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2023-12-01 19:33:14 - INFO :       Use random pruner...
2023-12-01 19:33:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:33:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:33:14 - INFO :       Start Pruning
2023-12-01 19:33:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:33:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:33:16 - INFO :       social_support: Total Sparsity 1.3645985528115216e-06
2023-12-01 19:33:16 - INFO :       
==================Finish================

2023-12-01 19:33:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:33:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:33:16 - INFO :       DATASET: tasksource/bigbench sports_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 19:33:24 - INFO :       Use random pruner...
2023-12-01 19:33:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:33:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:33:25 - INFO :       Start Pruning
2023-12-01 19:33:26 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:33:26 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:33:26 - INFO :       sports_understanding: Total Sparsity 1.3621306055515601e-06
2023-12-01 19:33:26 - INFO :       
==================Finish================

2023-12-01 19:33:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:33:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:33:26 - INFO :       DATASET: tasksource/bigbench strange_stories
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]
2023-12-01 19:33:36 - INFO :       Use random pruner...
2023-12-01 19:33:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:33:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:33:37 - INFO :       Start Pruning
2023-12-01 19:33:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:33:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:33:38 - INFO :       strange_stories: Total Sparsity 1.3594863763444586e-06
2023-12-01 19:33:38 - INFO :       
==================Finish================

2023-12-01 19:33:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:33:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:33:38 - INFO :       DATASET: tasksource/bigbench strategyqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 19:33:47 - INFO :       Use random pruner...
2023-12-01 19:33:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:33:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:33:48 - INFO :       Start Pruning
2023-12-01 19:33:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:33:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:33:49 - INFO :       strategyqa: Total Sparsity 1.3598389402387389e-06
2023-12-01 19:33:49 - INFO :       
==================Finish================

2023-12-01 19:33:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:33:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:33:49 - INFO :       DATASET: tasksource/bigbench suicide_risk
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2023-12-01 19:33:58 - INFO :       Use random pruner...
2023-12-01 19:33:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:33:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:33:59 - INFO :       Start Pruning
2023-12-01 19:33:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:33:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:34:00 - INFO :       suicide_risk: Total Sparsity 1.3621306055515601e-06
2023-12-01 19:34:00 - INFO :       
==================Finish================

2023-12-01 19:34:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:34:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:34:00 - INFO :       DATASET: tasksource/bigbench swahili_english_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2023-12-01 19:34:10 - INFO :       Use random pruner...
2023-12-01 19:34:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:34:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:34:11 - INFO :       Start Pruning
2023-12-01 19:34:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:34:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:34:12 - INFO :       swahili_english_proverbs: Total Sparsity 1.3605440680272994e-06
2023-12-01 19:34:12 - INFO :       
==================Finish================

2023-12-01 19:34:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:34:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:34:12 - INFO :       DATASET: tasksource/bigbench swedish_to_german_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2023-12-01 19:34:22 - INFO :       Use random pruner...
2023-12-01 19:34:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:34:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:34:23 - INFO :       Start Pruning
2023-12-01 19:34:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:34:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:34:24 - INFO :       swedish_to_german_proverbs: Total Sparsity 1.3651273986529418e-06
2023-12-01 19:34:24 - INFO :       
==================Finish================

2023-12-01 19:34:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:34:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:34:24 - INFO :       DATASET: tasksource/bigbench symbol_interpretation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.19s/it]
2023-12-01 19:34:35 - INFO :       Use random pruner...
2023-12-01 19:34:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:34:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:34:35 - INFO :       Start Pruning
2023-12-01 19:34:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:34:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:34:37 - INFO :       symbol_interpretation: Total Sparsity 1.3640697069701013e-06
2023-12-01 19:34:37 - INFO :       
==================Finish================

2023-12-01 19:34:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:34:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:34:37 - INFO :       DATASET: tasksource/bigbench temporal_sequences
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2023-12-01 19:34:47 - INFO :       Use random pruner...
2023-12-01 19:34:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:34:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:34:47 - INFO :       Start Pruning
2023-12-01 19:34:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:34:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:34:49 - INFO :       temporal_sequences: Total Sparsity 1.3631882972344008e-06
2023-12-01 19:34:49 - INFO :       
==================Finish================

2023-12-01 19:34:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:34:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:34:49 - INFO :       DATASET: tasksource/bigbench timedial
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 19:34:58 - INFO :       Use random pruner...
2023-12-01 19:34:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:34:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:34:59 - INFO :       Start Pruning
2023-12-01 19:35:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:35:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:35:01 - INFO :       timedial: Total Sparsity 1.3552556096130962e-06
2023-12-01 19:35:01 - INFO :       
==================Finish================

2023-12-01 19:35:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:35:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:35:01 - INFO :       DATASET: tasksource/bigbench tracking_shuffled_objects
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
2023-12-01 19:35:10 - INFO :       Use random pruner...
2023-12-01 19:35:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:35:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:35:11 - INFO :       Start Pruning
2023-12-01 19:35:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:35:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:35:12 - INFO :       tracking_shuffled_objects: Total Sparsity 1.366890218124343e-06
2023-12-01 19:35:12 - INFO :       
==================Finish================

2023-12-01 19:35:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:35:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:35:12 - INFO :       DATASET: tasksource/bigbench understanding_fables
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
2023-12-01 19:35:21 - INFO :       Use random pruner...
2023-12-01 19:35:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:35:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:35:22 - INFO :       Start Pruning
2023-12-01 19:35:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:35:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:35:24 - INFO :       understanding_fables: Total Sparsity 1.363540861128681e-06
2023-12-01 19:35:24 - INFO :       
==================Finish================

2023-12-01 19:35:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:35:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:35:24 - INFO :       DATASET: tasksource/bigbench undo_permutation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]
2023-12-01 19:35:33 - INFO :       Use random pruner...
2023-12-01 19:35:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:35:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:35:33 - INFO :       Start Pruning
2023-12-01 19:35:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:35:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:35:35 - INFO :       undo_permutation: Total Sparsity 1.3645985528115216e-06
2023-12-01 19:35:35 - INFO :       
==================Finish================

2023-12-01 19:35:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:35:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:35:35 - INFO :       DATASET: tasksource/bigbench unit_interpretation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 19:35:45 - INFO :       Use random pruner...
2023-12-01 19:35:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:35:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:35:45 - INFO :       Start Pruning
2023-12-01 19:35:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:35:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:35:47 - INFO :       unit_interpretation: Total Sparsity 1.3674190639657633e-06
2023-12-01 19:35:47 - INFO :       
==================Finish================

2023-12-01 19:35:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:35:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:35:47 - INFO :       DATASET: tasksource/bigbench vitaminc_fact_verification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]
2023-12-01 19:35:55 - INFO :       Use random pruner...
2023-12-01 19:35:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:35:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:35:56 - INFO :       Start Pruning
2023-12-01 19:35:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:35:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:35:58 - INFO :       vitaminc_fact_verification: Total Sparsity 1.368829319542884e-06
2023-12-01 19:35:58 - INFO :       
==================Finish================

2023-12-01 19:35:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:35:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:35:58 - INFO :       DATASET: tasksource/bigbench what_is_the_tao
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2023-12-01 19:36:07 - INFO :       Use random pruner...
2023-12-01 19:36:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:36:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:36:08 - INFO :       Start Pruning
2023-12-01 19:36:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:36:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:36:09 - INFO :       what_is_the_tao: Total Sparsity 1.352787662353135e-06
2023-12-01 19:36:09 - INFO :       
==================Finish================

2023-12-01 19:36:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:36:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:36:09 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2023-12-01 19:36:19 - INFO :       Use random pruner...
2023-12-01 19:36:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:36:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:36:19 - INFO :       Start Pruning
2023-12-01 19:36:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:36:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:36:21 - INFO :       which_wiki_edit: Total Sparsity 1.372354958485686e-06
2023-12-01 19:36:21 - INFO :       
==================Finish================

2023-12-01 19:36:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:36:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:36:21 - INFO :       DATASET: tasksource/bigbench winowhy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]
2023-12-01 19:36:30 - INFO :       Use random pruner...
2023-12-01 19:36:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:36:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:36:31 - INFO :       Start Pruning
2023-12-01 19:36:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:36:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:36:32 - INFO :       winowhy: Total Sparsity 1.3661850903357826e-06
2023-12-01 19:36:32 - INFO :       
==================Finish================

2023-12-01 19:36:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:36:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:36:32 - INFO :       DATASET: tasksource/mmlu abstract_algebra
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 19:36:39 - INFO :       Use random pruner...
2023-12-01 19:36:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:36:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:36:40 - INFO :       Start Pruning
2023-12-01 19:36:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:36:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:36:42 - INFO :       abstract_algebra: Total Sparsity 1.3626594513929806e-06
2023-12-01 19:36:42 - INFO :       
==================Finish================

2023-12-01 19:36:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:36:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:36:42 - INFO :       DATASET: tasksource/mmlu anatomy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]
2023-12-01 19:36:50 - INFO :       Use random pruner...
2023-12-01 19:36:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:36:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:36:50 - INFO :       Start Pruning
2023-12-01 19:36:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:36:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:36:52 - INFO :       anatomy: Total Sparsity 1.363540861128681e-06
2023-12-01 19:36:52 - INFO :       
==================Finish================

2023-12-01 19:36:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:36:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:36:52 - INFO :       DATASET: tasksource/mmlu astronomy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
2023-12-01 19:37:02 - INFO :       Use random pruner...
2023-12-01 19:37:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:37:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:37:03 - INFO :       Start Pruning
2023-12-01 19:37:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:37:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:37:04 - INFO :       astronomy: Total Sparsity 1.3647748347586618e-06
2023-12-01 19:37:04 - INFO :       
==================Finish================

2023-12-01 19:37:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:37:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:37:04 - INFO :       DATASET: tasksource/mmlu business_ethics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 19:37:15 - INFO :       Use random pruner...
2023-12-01 19:37:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:37:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:37:15 - INFO :       Start Pruning
2023-12-01 19:37:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:37:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:37:17 - INFO :       business_ethics: Total Sparsity 1.3610729138687196e-06
2023-12-01 19:37:17 - INFO :       
==================Finish================

2023-12-01 19:37:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:37:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:37:17 - INFO :       DATASET: tasksource/mmlu clinical_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]
2023-12-01 19:37:27 - INFO :       Use random pruner...
2023-12-01 19:37:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:37:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:37:28 - INFO :       Start Pruning
2023-12-01 19:37:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:37:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:37:29 - INFO :       clinical_knowledge: Total Sparsity 1.353140226247415e-06
2023-12-01 19:37:29 - INFO :       
==================Finish================

2023-12-01 19:37:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:37:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:37:29 - INFO :       DATASET: tasksource/mmlu college_biology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 19:37:37 - INFO :       Use random pruner...
2023-12-01 19:37:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:37:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:37:38 - INFO :       Start Pruning
2023-12-01 19:37:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:37:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:37:40 - INFO :       college_biology: Total Sparsity 1.3735889321156667e-06
2023-12-01 19:37:40 - INFO :       
==================Finish================

2023-12-01 19:37:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:37:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:37:40 - INFO :       DATASET: tasksource/mmlu college_chemistry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]
2023-12-01 19:37:49 - INFO :       Use random pruner...
2023-12-01 19:37:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:37:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:37:49 - INFO :       Start Pruning
2023-12-01 19:37:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:37:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:37:51 - INFO :       college_chemistry: Total Sparsity 1.3573709929787774e-06
2023-12-01 19:37:51 - INFO :       
==================Finish================

2023-12-01 19:37:51 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:37:51 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:37:51 - INFO :       DATASET: tasksource/mmlu college_computer_science
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 19:38:01 - INFO :       Use random pruner...
2023-12-01 19:38:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:38:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:38:02 - INFO :       Start Pruning
2023-12-01 19:38:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:38:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:38:03 - INFO :       college_computer_science: Total Sparsity 1.3681241917543236e-06
2023-12-01 19:38:03 - INFO :       
==================Finish================

2023-12-01 19:38:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:38:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:38:03 - INFO :       DATASET: tasksource/mmlu college_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]
2023-12-01 19:38:12 - INFO :       Use random pruner...
2023-12-01 19:38:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:38:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:38:13 - INFO :       Start Pruning
2023-12-01 19:38:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:38:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:38:14 - INFO :       college_mathematics: Total Sparsity 1.3557844554545167e-06
2023-12-01 19:38:14 - INFO :       
==================Finish================

2023-12-01 19:38:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:38:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:38:14 - INFO :       DATASET: tasksource/mmlu college_medicine
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
2023-12-01 19:38:23 - INFO :       Use random pruner...
2023-12-01 19:38:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:38:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:38:23 - INFO :       Start Pruning
2023-12-01 19:38:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:38:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:38:25 - INFO :       college_medicine: Total Sparsity 1.3677716278600435e-06
2023-12-01 19:38:25 - INFO :       
==================Finish================

2023-12-01 19:38:25 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:38:25 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:38:25 - INFO :       DATASET: tasksource/mmlu college_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 19:38:36 - INFO :       Use random pruner...
2023-12-01 19:38:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:38:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:38:37 - INFO :       Start Pruning
2023-12-01 19:38:38 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:38:38 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:38:39 - INFO :       college_physics: Total Sparsity 1.3707684209614252e-06
2023-12-01 19:38:39 - INFO :       
==================Finish================

2023-12-01 19:38:39 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:38:39 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:38:39 - INFO :       DATASET: tasksource/mmlu computer_security
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
2023-12-01 19:38:49 - INFO :       Use random pruner...
2023-12-01 19:38:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:38:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:38:50 - INFO :       Start Pruning
2023-12-01 19:38:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:38:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:38:52 - INFO :       computer_security: Total Sparsity 1.3656562444943623e-06
2023-12-01 19:38:52 - INFO :       
==================Finish================

2023-12-01 19:38:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:38:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:38:52 - INFO :       DATASET: tasksource/mmlu conceptual_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2023-12-01 19:39:02 - INFO :       Use random pruner...
2023-12-01 19:39:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:39:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:39:02 - INFO :       Start Pruning
2023-12-01 19:39:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:39:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:39:04 - INFO :       conceptual_physics: Total Sparsity 1.3559607374016567e-06
2023-12-01 19:39:04 - INFO :       
==================Finish================

2023-12-01 19:39:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:39:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:39:04 - INFO :       DATASET: tasksource/mmlu econometrics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]
2023-12-01 19:39:13 - INFO :       Use random pruner...
2023-12-01 19:39:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:39:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:39:13 - INFO :       Start Pruning
2023-12-01 19:39:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:39:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:39:15 - INFO :       econometrics: Total Sparsity 1.3603677860801591e-06
2023-12-01 19:39:15 - INFO :       
==================Finish================

2023-12-01 19:39:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:39:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:39:15 - INFO :       DATASET: tasksource/mmlu electrical_engineering
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 19:39:22 - INFO :       Use random pruner...
2023-12-01 19:39:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:39:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:39:22 - INFO :       Start Pruning
2023-12-01 19:39:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:39:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:39:24 - INFO :       electrical_engineering: Total Sparsity 1.3601915041330191e-06
2023-12-01 19:39:24 - INFO :       
==================Finish================

2023-12-01 19:39:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:39:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:39:24 - INFO :       DATASET: tasksource/mmlu elementary_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 19:39:31 - INFO :       Use random pruner...
2023-12-01 19:39:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:39:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:39:31 - INFO :       Start Pruning
2023-12-01 19:39:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:39:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:39:33 - INFO :       elementary_mathematics: Total Sparsity 1.3631882972344008e-06
2023-12-01 19:39:33 - INFO :       
==================Finish================

2023-12-01 19:39:33 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:39:33 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:39:33 - INFO :       DATASET: tasksource/mmlu formal_logic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2023-12-01 19:39:43 - INFO :       Use random pruner...
2023-12-01 19:39:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:39:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:39:43 - INFO :       Start Pruning
2023-12-01 19:39:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:39:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:39:45 - INFO :       formal_logic: Total Sparsity 1.367066500071483e-06
2023-12-01 19:39:45 - INFO :       
==================Finish================

2023-12-01 19:39:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:39:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:39:45 - INFO :       DATASET: tasksource/mmlu global_facts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]
2023-12-01 19:39:55 - INFO :       Use random pruner...
2023-12-01 19:39:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:39:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:39:56 - INFO :       Start Pruning
2023-12-01 19:39:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:39:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:39:57 - INFO :       global_facts: Total Sparsity 1.3778196988470292e-06
2023-12-01 19:39:57 - INFO :       
==================Finish================

2023-12-01 19:39:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:39:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:39:57 - INFO :       DATASET: tasksource/mmlu high_school_biology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2023-12-01 19:40:08 - INFO :       Use random pruner...
2023-12-01 19:40:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:40:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:40:08 - INFO :       Start Pruning
2023-12-01 19:40:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:40:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:40:10 - INFO :       high_school_biology: Total Sparsity 1.3638934250229613e-06
2023-12-01 19:40:10 - INFO :       
==================Finish================

2023-12-01 19:40:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:40:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:40:10 - INFO :       DATASET: tasksource/mmlu high_school_chemistry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]
2023-12-01 19:40:18 - INFO :       Use random pruner...
2023-12-01 19:40:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:40:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:40:19 - INFO :       Start Pruning
2023-12-01 19:40:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:40:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:40:20 - INFO :       high_school_chemistry: Total Sparsity 1.3624831694458404e-06
2023-12-01 19:40:20 - INFO :       
==================Finish================

2023-12-01 19:40:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:40:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:40:20 - INFO :       DATASET: tasksource/mmlu high_school_computer_science
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]
2023-12-01 19:40:29 - INFO :       Use random pruner...
2023-12-01 19:40:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:40:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:40:30 - INFO :       Start Pruning
2023-12-01 19:40:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:40:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:40:31 - INFO :       high_school_computer_science: Total Sparsity 1.365479962547222e-06
2023-12-01 19:40:31 - INFO :       
==================Finish================

2023-12-01 19:40:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:40:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:40:31 - INFO :       DATASET: tasksource/mmlu high_school_european_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
2023-12-01 19:40:41 - INFO :       Use random pruner...
2023-12-01 19:40:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:40:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:40:42 - INFO :       Start Pruning
2023-12-01 19:40:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:40:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:40:43 - INFO :       high_school_european_history: Total Sparsity 1.3554318915602364e-06
2023-12-01 19:40:43 - INFO :       
==================Finish================

2023-12-01 19:40:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:40:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:40:43 - INFO :       DATASET: tasksource/mmlu high_school_geography
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]
2023-12-01 19:40:53 - INFO :       Use random pruner...
2023-12-01 19:40:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:40:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:40:53 - INFO :       Start Pruning
2023-12-01 19:40:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:40:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:40:55 - INFO :       high_school_geography: Total Sparsity 1.372354958485686e-06
2023-12-01 19:40:55 - INFO :       
==================Finish================

2023-12-01 19:40:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:40:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:40:55 - INFO :       DATASET: tasksource/mmlu high_school_government_and_politics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2023-12-01 19:41:04 - INFO :       Use random pruner...
2023-12-01 19:41:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:41:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:41:04 - INFO :       Start Pruning
2023-12-01 19:41:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:41:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:41:06 - INFO :       high_school_government_and_politics: Total Sparsity 1.3492620234103328e-06
2023-12-01 19:41:06 - INFO :       
==================Finish================

2023-12-01 19:41:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:41:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:41:06 - INFO :       DATASET: tasksource/mmlu high_school_macroeconomics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
2023-12-01 19:41:16 - INFO :       Use random pruner...
2023-12-01 19:41:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:41:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:41:16 - INFO :       Start Pruning
2023-12-01 19:41:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:41:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:41:18 - INFO :       high_school_macroeconomics: Total Sparsity 1.36177804165728e-06
2023-12-01 19:41:18 - INFO :       
==================Finish================

2023-12-01 19:41:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:41:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:41:18 - INFO :       DATASET: tasksource/mmlu high_school_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]
2023-12-01 19:41:28 - INFO :       Use random pruner...
2023-12-01 19:41:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:41:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:41:28 - INFO :       Start Pruning
2023-12-01 19:41:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:41:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:41:30 - INFO :       high_school_mathematics: Total Sparsity 1.3598389402387389e-06
2023-12-01 19:41:30 - INFO :       
==================Finish================

2023-12-01 19:41:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:41:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:41:30 - INFO :       DATASET: tasksource/mmlu high_school_microeconomics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 19:41:39 - INFO :       Use random pruner...
2023-12-01 19:41:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:41:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:41:40 - INFO :       Start Pruning
2023-12-01 19:41:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:41:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:41:41 - INFO :       high_school_microeconomics: Total Sparsity 1.3623068874987003e-06
2023-12-01 19:41:41 - INFO :       
==================Finish================

2023-12-01 19:41:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:41:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:41:41 - INFO :       DATASET: tasksource/mmlu high_school_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2023-12-01 19:41:51 - INFO :       Use random pruner...
2023-12-01 19:41:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:41:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:41:52 - INFO :       Start Pruning
2023-12-01 19:41:53 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:41:53 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:41:54 - INFO :       high_school_physics: Total Sparsity 1.3612491958158596e-06
2023-12-01 19:41:54 - INFO :       
==================Finish================

2023-12-01 19:41:54 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:41:54 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:41:54 - INFO :       DATASET: tasksource/mmlu high_school_psychology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 19:42:01 - INFO :       Use random pruner...
2023-12-01 19:42:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:42:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:42:02 - INFO :       Start Pruning
2023-12-01 19:42:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:42:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:42:04 - INFO :       high_school_psychology: Total Sparsity 1.3607203499744394e-06
2023-12-01 19:42:04 - INFO :       
==================Finish================

2023-12-01 19:42:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:42:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:42:04 - INFO :       DATASET: tasksource/mmlu high_school_statistics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]
2023-12-01 19:42:12 - INFO :       Use random pruner...
2023-12-01 19:42:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:42:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:42:12 - INFO :       Start Pruning
2023-12-01 19:42:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:42:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:42:14 - INFO :       high_school_statistics: Total Sparsity 1.3538453540359754e-06
2023-12-01 19:42:14 - INFO :       
==================Finish================

2023-12-01 19:42:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:42:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:42:14 - INFO :       DATASET: tasksource/mmlu high_school_us_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]
2023-12-01 19:42:24 - INFO :       Use random pruner...
2023-12-01 19:42:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:42:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:42:24 - INFO :       Start Pruning
2023-12-01 19:42:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:42:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:42:26 - INFO :       high_school_us_history: Total Sparsity 1.3658325264415023e-06
2023-12-01 19:42:26 - INFO :       
==================Finish================

2023-12-01 19:42:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:42:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:42:26 - INFO :       DATASET: tasksource/mmlu high_school_world_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2023-12-01 19:42:36 - INFO :       Use random pruner...
2023-12-01 19:42:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:42:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:42:36 - INFO :       Start Pruning
2023-12-01 19:42:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:42:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:42:38 - INFO :       high_school_world_history: Total Sparsity 1.3645985528115216e-06
2023-12-01 19:42:38 - INFO :       
==================Finish================

2023-12-01 19:42:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:42:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:42:38 - INFO :       DATASET: tasksource/mmlu human_aging
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]
2023-12-01 19:42:47 - INFO :       Use random pruner...
2023-12-01 19:42:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:42:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:42:48 - INFO :       Start Pruning
2023-12-01 19:42:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:42:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:42:49 - INFO :       human_aging: Total Sparsity 1.3566658651902172e-06
2023-12-01 19:42:49 - INFO :       
==================Finish================

2023-12-01 19:42:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:42:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:42:49 - INFO :       DATASET: tasksource/mmlu human_sexuality
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2023-12-01 19:42:59 - INFO :       Use random pruner...
2023-12-01 19:42:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:42:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:42:59 - INFO :       Start Pruning
2023-12-01 19:43:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:43:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:43:01 - INFO :       human_sexuality: Total Sparsity 1.3520825345645745e-06
2023-12-01 19:43:01 - INFO :       
==================Finish================

2023-12-01 19:43:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:43:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:43:01 - INFO :       DATASET: tasksource/mmlu international_law
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 19:43:12 - INFO :       Use random pruner...
2023-12-01 19:43:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:43:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:43:13 - INFO :       Start Pruning
2023-12-01 19:43:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:43:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:43:15 - INFO :       international_law: Total Sparsity 1.3612491958158596e-06
2023-12-01 19:43:15 - INFO :       
==================Finish================

2023-12-01 19:43:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:43:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:43:15 - INFO :       DATASET: tasksource/mmlu jurisprudence
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]
2023-12-01 19:43:27 - INFO :       Use random pruner...
2023-12-01 19:43:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:43:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:43:27 - INFO :       Start Pruning
2023-12-01 19:43:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:43:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:43:29 - INFO :       jurisprudence: Total Sparsity 1.3619543236044201e-06
2023-12-01 19:43:29 - INFO :       
==================Finish================

2023-12-01 19:43:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:43:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:43:29 - INFO :       DATASET: tasksource/mmlu logical_fallacies
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 19:43:40 - INFO :       Use random pruner...
2023-12-01 19:43:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:43:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:43:40 - INFO :       Start Pruning
2023-12-01 19:43:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:43:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:43:42 - INFO :       logical_fallacies: Total Sparsity 1.358076120767338e-06
2023-12-01 19:43:42 - INFO :       
==================Finish================

2023-12-01 19:43:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:43:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:43:42 - INFO :       DATASET: tasksource/mmlu machine_learning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
2023-12-01 19:43:52 - INFO :       Use random pruner...
2023-12-01 19:43:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:43:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:43:52 - INFO :       Start Pruning
2023-12-01 19:43:53 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:43:53 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:43:54 - INFO :       machine_learning: Total Sparsity 1.3561370193487967e-06
2023-12-01 19:43:54 - INFO :       
==================Finish================

2023-12-01 19:43:54 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:43:54 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:43:54 - INFO :       DATASET: tasksource/mmlu management
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2023-12-01 19:44:04 - INFO :       Use random pruner...
2023-12-01 19:44:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:44:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:44:04 - INFO :       Start Pruning
2023-12-01 19:44:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:44:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:44:06 - INFO :       management: Total Sparsity 1.365303680600082e-06
2023-12-01 19:44:06 - INFO :       
==================Finish================

2023-12-01 19:44:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:44:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:44:06 - INFO :       DATASET: tasksource/mmlu marketing
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]
2023-12-01 19:44:16 - INFO :       Use random pruner...
2023-12-01 19:44:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:44:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:44:16 - INFO :       Start Pruning
2023-12-01 19:44:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:44:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:44:18 - INFO :       marketing: Total Sparsity 1.3578998388201979e-06
2023-12-01 19:44:18 - INFO :       
==================Finish================

2023-12-01 19:44:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:44:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:44:18 - INFO :       DATASET: tasksource/mmlu medical_genetics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]
2023-12-01 19:44:28 - INFO :       Use random pruner...
2023-12-01 19:44:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:44:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:44:28 - INFO :       Start Pruning
2023-12-01 19:44:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:44:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:44:30 - INFO :       medical_genetics: Total Sparsity 1.3554318915602364e-06
2023-12-01 19:44:30 - INFO :       
==================Finish================

2023-12-01 19:44:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:44:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:44:30 - INFO :       DATASET: tasksource/mmlu miscellaneous
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]
2023-12-01 19:44:39 - INFO :       Use random pruner...
2023-12-01 19:44:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:44:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:44:39 - INFO :       Start Pruning
2023-12-01 19:44:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:44:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:44:41 - INFO :       miscellaneous: Total Sparsity 1.366890218124343e-06
2023-12-01 19:44:41 - INFO :       
==================Finish================

2023-12-01 19:44:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:44:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:44:41 - INFO :       DATASET: tasksource/mmlu moral_disputes
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 19:44:48 - INFO :       Use random pruner...
2023-12-01 19:44:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:44:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:44:49 - INFO :       Start Pruning
2023-12-01 19:44:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:44:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:44:50 - INFO :       moral_disputes: Total Sparsity 1.3681241917543236e-06
2023-12-01 19:44:50 - INFO :       
==================Finish================

2023-12-01 19:44:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:44:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:44:50 - INFO :       DATASET: tasksource/mmlu moral_scenarios
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]
2023-12-01 19:45:00 - INFO :       Use random pruner...
2023-12-01 19:45:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:45:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:45:00 - INFO :       Start Pruning
2023-12-01 19:45:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:45:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:45:02 - INFO :       moral_scenarios: Total Sparsity 1.3621306055515601e-06
2023-12-01 19:45:02 - INFO :       
==================Finish================

2023-12-01 19:45:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:45:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:45:02 - INFO :       DATASET: tasksource/mmlu nutrition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]
2023-12-01 19:45:11 - INFO :       Use random pruner...
2023-12-01 19:45:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:45:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:45:11 - INFO :       Start Pruning
2023-12-01 19:45:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:45:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:45:13 - INFO :       nutrition: Total Sparsity 1.3591338124501784e-06
2023-12-01 19:45:13 - INFO :       
==================Finish================

2023-12-01 19:45:13 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:45:13 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:45:13 - INFO :       DATASET: tasksource/mmlu philosophy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]
2023-12-01 19:45:22 - INFO :       Use random pruner...
2023-12-01 19:45:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:45:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:45:22 - INFO :       Start Pruning
2023-12-01 19:45:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:45:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:45:24 - INFO :       philosophy: Total Sparsity 1.3681241917543236e-06
2023-12-01 19:45:24 - INFO :       
==================Finish================

2023-12-01 19:45:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:45:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:45:24 - INFO :       DATASET: tasksource/mmlu prehistory
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 19:45:32 - INFO :       Use random pruner...
2023-12-01 19:45:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:45:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:45:33 - INFO :       Start Pruning
2023-12-01 19:45:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:45:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:45:34 - INFO :       prehistory: Total Sparsity 1.3623068874987003e-06
2023-12-01 19:45:34 - INFO :       
==================Finish================

2023-12-01 19:45:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:45:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:45:34 - INFO :       DATASET: tasksource/mmlu professional_accounting
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 19:45:44 - INFO :       Use random pruner...
2023-12-01 19:45:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:45:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:45:45 - INFO :       Start Pruning
2023-12-01 19:45:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:45:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:45:47 - INFO :       professional_accounting: Total Sparsity 1.3679479098071835e-06
2023-12-01 19:45:47 - INFO :       
==================Finish================

2023-12-01 19:45:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:45:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:45:47 - INFO :       DATASET: tasksource/mmlu professional_law
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 19:45:56 - INFO :       Use random pruner...
2023-12-01 19:45:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:45:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:45:56 - INFO :       Start Pruning
2023-12-01 19:45:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:45:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:45:58 - INFO :       professional_law: Total Sparsity 1.3684767556486038e-06
2023-12-01 19:45:58 - INFO :       
==================Finish================

2023-12-01 19:45:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:45:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:45:58 - INFO :       DATASET: tasksource/mmlu professional_medicine
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2023-12-01 19:46:08 - INFO :       Use random pruner...
2023-12-01 19:46:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:46:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:46:08 - INFO :       Start Pruning
2023-12-01 19:46:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:46:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:46:10 - INFO :       professional_medicine: Total Sparsity 1.3589575305030384e-06
2023-12-01 19:46:10 - INFO :       
==================Finish================

2023-12-01 19:46:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:46:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:46:10 - INFO :       DATASET: tasksource/mmlu professional_psychology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 19:46:19 - INFO :       Use random pruner...
2023-12-01 19:46:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:46:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:46:19 - INFO :       Start Pruning
2023-12-01 19:46:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:46:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:46:21 - INFO :       professional_psychology: Total Sparsity 1.3612491958158596e-06
2023-12-01 19:46:21 - INFO :       
==================Finish================

2023-12-01 19:46:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:46:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:46:21 - INFO :       DATASET: tasksource/mmlu public_relations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]
2023-12-01 19:46:30 - INFO :       Use random pruner...
2023-12-01 19:46:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:46:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:46:31 - INFO :       Start Pruning
2023-12-01 19:46:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:46:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:46:32 - INFO :       public_relations: Total Sparsity 1.3568421471373572e-06
2023-12-01 19:46:32 - INFO :       
==================Finish================

2023-12-01 19:46:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:46:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:46:32 - INFO :       DATASET: tasksource/mmlu security_studies
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 19:46:42 - INFO :       Use random pruner...
2023-12-01 19:46:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:46:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:46:43 - INFO :       Start Pruning
2023-12-01 19:46:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:46:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:46:44 - INFO :       security_studies: Total Sparsity 1.358076120767338e-06
2023-12-01 19:46:44 - INFO :       
==================Finish================

2023-12-01 19:46:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:46:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:46:44 - INFO :       DATASET: tasksource/mmlu sociology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2023-12-01 19:46:54 - INFO :       Use random pruner...
2023-12-01 19:46:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:46:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:46:54 - INFO :       Start Pruning
2023-12-01 19:46:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:46:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:46:56 - INFO :       sociology: Total Sparsity 1.3633645791815409e-06
2023-12-01 19:46:56 - INFO :       
==================Finish================

2023-12-01 19:46:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:46:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:46:56 - INFO :       DATASET: tasksource/mmlu us_foreign_policy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]
2023-12-01 19:47:05 - INFO :       Use random pruner...
2023-12-01 19:47:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:47:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:47:05 - INFO :       Start Pruning
2023-12-01 19:47:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:47:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:47:07 - INFO :       us_foreign_policy: Total Sparsity 1.3663613722829226e-06
2023-12-01 19:47:07 - INFO :       
==================Finish================

2023-12-01 19:47:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:47:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:47:07 - INFO :       DATASET: tasksource/mmlu virology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2023-12-01 19:47:17 - INFO :       Use random pruner...
2023-12-01 19:47:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:47:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:47:17 - INFO :       Start Pruning
2023-12-01 19:47:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:47:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:47:19 - INFO :       virology: Total Sparsity 1.3623068874987003e-06
2023-12-01 19:47:19 - INFO :       
==================Finish================

2023-12-01 19:47:19 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:47:19 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:47:19 - INFO :       DATASET: tasksource/mmlu world_religions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]
2023-12-01 19:47:28 - INFO :       Use random pruner...
2023-12-01 19:47:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:47:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:47:28 - INFO :       Start Pruning
2023-12-01 19:47:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:47:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:47:30 - INFO :       world_religions: Total Sparsity 1.3483806136746323e-06
2023-12-01 19:47:30 - INFO :       
==================Finish================

2023-12-01 19:47:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:47:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:47:30 - INFO :       DATASET: math_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2023-12-01 19:47:40 - INFO :       Use random pruner...
2023-12-01 19:47:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:47:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:47:40 - INFO :       Start Pruning
2023-12-01 19:47:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:47:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:47:42 - INFO :       math_qa: Total Sparsity 1.3658325264415023e-06
2023-12-01 19:47:42 - INFO :       
==================Finish================

2023-12-01 19:47:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:47:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:47:42 - INFO :       DATASET: EleutherAI/truthful_qa_mc
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]
2023-12-01 19:47:51 - INFO :       Use random pruner...
2023-12-01 19:47:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:47:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:47:52 - INFO :       Start Pruning
2023-12-01 19:47:53 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:47:53 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:47:53 - INFO :       truthful_qa_mc: Total Sparsity 1.3626594513929806e-06
2023-12-01 19:47:53 - INFO :       
==================Finish================

2023-12-01 19:47:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:47:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:47:53 - INFO :       DATASET: derek-thomas/ScienceQA
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2023-12-01 19:48:03 - INFO :       Use random pruner...
2023-12-01 19:48:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:48:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:48:04 - INFO :       Start Pruning
2023-12-01 19:48:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:48:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:48:05 - INFO :       ScienceQA: Total Sparsity 1.3612491958158596e-06
2023-12-01 19:48:05 - INFO :       
==================Finish================

2023-12-01 19:48:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:48:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:48:05 - INFO :       DATASET: commonsense_qa
Index 7
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]
2023-12-01 19:48:14 - INFO :       Use random pruner...
2023-12-01 19:48:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:48:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:48:15 - INFO :       Start Pruning
2023-12-01 19:48:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:48:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:48:16 - INFO :       commonsense_qa: Total Sparsity 1.370592139014285e-06
2023-12-01 19:48:16 - INFO :       
==================Finish================

2023-12-01 19:48:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:48:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:48:16 - INFO :       DATASET: tasksource/bigbench abstract_narrative_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2023-12-01 19:48:26 - INFO :       Use random pruner...
2023-12-01 19:48:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:48:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:48:26 - INFO :       Start Pruning
2023-12-01 19:48:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:48:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:48:28 - INFO :       abstract_narrative_understanding: Total Sparsity 1.3591338124501784e-06
2023-12-01 19:48:28 - INFO :       
==================Finish================

2023-12-01 19:48:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:48:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:48:28 - INFO :       DATASET: tasksource/bigbench anachronisms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]
2023-12-01 19:48:38 - INFO :       Use random pruner...
2023-12-01 19:48:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:48:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:48:38 - INFO :       Start Pruning
2023-12-01 19:48:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:48:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:48:40 - INFO :       anachronisms: Total Sparsity 1.366890218124343e-06
2023-12-01 19:48:40 - INFO :       
==================Finish================

2023-12-01 19:48:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:48:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:48:40 - INFO :       DATASET: tasksource/bigbench analogical_similarity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]
2023-12-01 19:48:49 - INFO :       Use random pruner...
2023-12-01 19:48:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:48:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:48:49 - INFO :       Start Pruning
2023-12-01 19:48:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:48:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:48:51 - INFO :       analogical_similarity: Total Sparsity 1.3661850903357826e-06
2023-12-01 19:48:51 - INFO :       
==================Finish================

2023-12-01 19:48:51 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:48:51 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:48:51 - INFO :       DATASET: tasksource/bigbench analytic_entailment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]
2023-12-01 19:49:02 - INFO :       Use random pruner...
2023-12-01 19:49:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:49:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:49:02 - INFO :       Start Pruning
2023-12-01 19:49:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:49:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:49:04 - INFO :       analytic_entailment: Total Sparsity 1.363717143075821e-06
2023-12-01 19:49:04 - INFO :       
==================Finish================

2023-12-01 19:49:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:49:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:49:04 - INFO :       DATASET: tasksource/bigbench arithmetic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]
2023-12-01 19:49:12 - INFO :       Use random pruner...
2023-12-01 19:49:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:49:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:49:12 - INFO :       Start Pruning
2023-12-01 19:49:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:49:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:49:14 - INFO :       arithmetic: Total Sparsity 1.3621306055515601e-06
2023-12-01 19:49:14 - INFO :       
==================Finish================

2023-12-01 19:49:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:49:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:49:14 - INFO :       DATASET: tasksource/bigbench authorship_verification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 19:49:22 - INFO :       Use random pruner...
2023-12-01 19:49:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:49:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:49:22 - INFO :       Start Pruning
2023-12-01 19:49:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:49:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:49:24 - INFO :       authorship_verification: Total Sparsity 1.360015222185879e-06
2023-12-01 19:49:24 - INFO :       
==================Finish================

2023-12-01 19:49:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:49:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:49:24 - INFO :       DATASET: tasksource/bigbench bbq_lite_json
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
2023-12-01 19:49:34 - INFO :       Use random pruner...
2023-12-01 19:49:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:49:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:49:35 - INFO :       Start Pruning
2023-12-01 19:49:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:49:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:49:37 - INFO :       bbq_lite_json: Total Sparsity 1.3679479098071835e-06
2023-12-01 19:49:37 - INFO :       
==================Finish================

2023-12-01 19:49:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:49:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:49:37 - INFO :       DATASET: tasksource/bigbench causal_judgment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 19:49:48 - INFO :       Use random pruner...
2023-12-01 19:49:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:49:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:49:49 - INFO :       Start Pruning
2023-12-01 19:49:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:49:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:49:50 - INFO :       causal_judgment: Total Sparsity 1.368829319542884e-06
2023-12-01 19:49:50 - INFO :       
==================Finish================

2023-12-01 19:49:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:49:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:49:50 - INFO :       DATASET: tasksource/bigbench cause_and_effect
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.27s/it]
2023-12-01 19:50:02 - INFO :       Use random pruner...
2023-12-01 19:50:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:50:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:50:02 - INFO :       Start Pruning
2023-12-01 19:50:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:50:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:50:04 - INFO :       cause_and_effect: Total Sparsity 1.3712972668028455e-06
2023-12-01 19:50:04 - INFO :       
==================Finish================

2023-12-01 19:50:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:50:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:50:04 - INFO :       DATASET: tasksource/bigbench checkmate_in_one
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 19:50:14 - INFO :       Use random pruner...
2023-12-01 19:50:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:50:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:50:15 - INFO :       Start Pruning
2023-12-01 19:50:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:50:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:50:17 - INFO :       checkmate_in_one: Total Sparsity 1.3608966319215796e-06
2023-12-01 19:50:17 - INFO :       
==================Finish================

2023-12-01 19:50:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:50:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:50:17 - INFO :       DATASET: tasksource/bigbench cifar10_classification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]
2023-12-01 19:50:28 - INFO :       Use random pruner...
2023-12-01 19:50:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:50:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:50:29 - INFO :       Start Pruning
2023-12-01 19:50:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:50:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:50:31 - INFO :       cifar10_classification: Total Sparsity 1.354550481824536e-06
2023-12-01 19:50:31 - INFO :       
==================Finish================

2023-12-01 19:50:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:50:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:50:31 - INFO :       DATASET: tasksource/bigbench code_line_description
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 19:50:42 - INFO :       Use random pruner...
2023-12-01 19:50:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:50:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:50:43 - INFO :       Start Pruning
2023-12-01 19:50:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:50:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:50:44 - INFO :       code_line_description: Total Sparsity 1.358076120767338e-06
2023-12-01 19:50:44 - INFO :       
==================Finish================

2023-12-01 19:50:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:50:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:50:44 - INFO :       DATASET: tasksource/bigbench color
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 19:50:56 - INFO :       Use random pruner...
2023-12-01 19:50:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:50:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:50:56 - INFO :       Start Pruning
2023-12-01 19:50:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:50:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:50:58 - INFO :       color: Total Sparsity 1.367066500071483e-06
2023-12-01 19:50:58 - INFO :       
==================Finish================

2023-12-01 19:50:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:50:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:50:58 - INFO :       DATASET: tasksource/bigbench common_morpheme
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.33s/it]
2023-12-01 19:51:10 - INFO :       Use random pruner...
2023-12-01 19:51:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:51:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:51:10 - INFO :       Start Pruning
2023-12-01 19:51:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:51:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:51:12 - INFO :       common_morpheme: Total Sparsity 1.3568421471373572e-06
2023-12-01 19:51:12 - INFO :       
==================Finish================

2023-12-01 19:51:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:51:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:51:12 - INFO :       DATASET: tasksource/bigbench conceptual_combinations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 19:51:24 - INFO :       Use random pruner...
2023-12-01 19:51:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:51:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:51:24 - INFO :       Start Pruning
2023-12-01 19:51:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:51:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:51:26 - INFO :       conceptual_combinations: Total Sparsity 1.356489583243077e-06
2023-12-01 19:51:26 - INFO :       
==================Finish================

2023-12-01 19:51:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:51:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:51:26 - INFO :       DATASET: tasksource/bigbench crash_blossom
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.29s/it]
2023-12-01 19:51:37 - INFO :       Use random pruner...
2023-12-01 19:51:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:51:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:51:38 - INFO :       Start Pruning
2023-12-01 19:51:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:51:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:51:40 - INFO :       crash_blossom: Total Sparsity 1.3559607374016567e-06
2023-12-01 19:51:40 - INFO :       
==================Finish================

2023-12-01 19:51:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:51:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:51:40 - INFO :       DATASET: tasksource/bigbench crass_ai
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]
2023-12-01 19:51:49 - INFO :       Use random pruner...
2023-12-01 19:51:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:51:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:51:50 - INFO :       Start Pruning
2023-12-01 19:51:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:51:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:51:51 - INFO :       crass_ai: Total Sparsity 1.3628357333401206e-06
2023-12-01 19:51:51 - INFO :       
==================Finish================

2023-12-01 19:51:51 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:51:51 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:51:51 - INFO :       DATASET: tasksource/bigbench cryobiology_spanish
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]
2023-12-01 19:52:00 - INFO :       Use random pruner...
2023-12-01 19:52:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:52:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:52:00 - INFO :       Start Pruning
2023-12-01 19:52:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:52:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:52:02 - INFO :       cryobiology_spanish: Total Sparsity 1.3593100943973186e-06
2023-12-01 19:52:02 - INFO :       
==================Finish================

2023-12-01 19:52:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:52:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:52:02 - INFO :       DATASET: tasksource/bigbench cs_algorithms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]
2023-12-01 19:52:10 - INFO :       Use random pruner...
2023-12-01 19:52:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:52:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:52:11 - INFO :       Start Pruning
2023-12-01 19:52:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:52:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:52:12 - INFO :       cs_algorithms: Total Sparsity 1.3607203499744394e-06
2023-12-01 19:52:13 - INFO :       
==================Finish================

2023-12-01 19:52:13 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:52:13 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:52:13 - INFO :       DATASET: tasksource/bigbench dark_humor_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  2.00s/it]
2023-12-01 19:52:23 - INFO :       Use random pruner...
2023-12-01 19:52:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:52:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:52:23 - INFO :       Start Pruning
2023-12-01 19:52:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:52:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:52:25 - INFO :       dark_humor_detection: Total Sparsity 1.3631882972344008e-06
2023-12-01 19:52:25 - INFO :       
==================Finish================

2023-12-01 19:52:25 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:52:25 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:52:25 - INFO :       DATASET: tasksource/bigbench date_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]
2023-12-01 19:52:34 - INFO :       Use random pruner...
2023-12-01 19:52:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:52:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:52:34 - INFO :       Start Pruning
2023-12-01 19:52:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:52:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:52:36 - INFO :       date_understanding: Total Sparsity 1.3716498306971257e-06
2023-12-01 19:52:36 - INFO :       
==================Finish================

2023-12-01 19:52:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:52:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:52:36 - INFO :       DATASET: tasksource/bigbench disambiguation_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2023-12-01 19:52:45 - INFO :       Use random pruner...
2023-12-01 19:52:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:52:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:52:46 - INFO :       Start Pruning
2023-12-01 19:52:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:52:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:52:47 - INFO :       disambiguation_qa: Total Sparsity 1.3594863763444586e-06
2023-12-01 19:52:47 - INFO :       
==================Finish================

2023-12-01 19:52:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:52:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:52:47 - INFO :       DATASET: tasksource/bigbench discourse_marker_prediction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]
2023-12-01 19:52:57 - INFO :       Use random pruner...
2023-12-01 19:52:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:52:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:52:58 - INFO :       Start Pruning
2023-12-01 19:52:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:52:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:53:00 - INFO :       discourse_marker_prediction: Total Sparsity 1.3645985528115216e-06
2023-12-01 19:53:00 - INFO :       
==================Finish================

2023-12-01 19:53:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:53:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:53:00 - INFO :       DATASET: tasksource/bigbench dyck_languages
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]
2023-12-01 19:53:10 - INFO :       Use random pruner...
2023-12-01 19:53:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:53:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:53:10 - INFO :       Start Pruning
2023-12-01 19:53:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:53:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:53:12 - INFO :       dyck_languages: Total Sparsity 1.3557844554545167e-06
2023-12-01 19:53:12 - INFO :       
==================Finish================

2023-12-01 19:53:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:53:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:53:12 - INFO :       DATASET: tasksource/bigbench elementary_math_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]
2023-12-01 19:53:22 - INFO :       Use random pruner...
2023-12-01 19:53:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:53:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:53:22 - INFO :       Start Pruning
2023-12-01 19:53:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:53:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:53:24 - INFO :       elementary_math_qa: Total Sparsity 1.3603677860801591e-06
2023-12-01 19:53:24 - INFO :       
==================Finish================

2023-12-01 19:53:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:53:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:53:24 - INFO :       DATASET: tasksource/bigbench emoji_movie
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.29s/it]
2023-12-01 19:53:35 - INFO :       Use random pruner...
2023-12-01 19:53:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:53:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:53:35 - INFO :       Start Pruning
2023-12-01 19:53:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:53:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:53:37 - INFO :       emoji_movie: Total Sparsity 1.3707684209614252e-06
2023-12-01 19:53:37 - INFO :       
==================Finish================

2023-12-01 19:53:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:53:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:53:37 - INFO :       DATASET: tasksource/bigbench empirical_judgments
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2023-12-01 19:53:48 - INFO :       Use random pruner...
2023-12-01 19:53:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:53:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:53:48 - INFO :       Start Pruning
2023-12-01 19:53:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:53:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:53:50 - INFO :       empirical_judgments: Total Sparsity 1.3626594513929806e-06
2023-12-01 19:53:50 - INFO :       
==================Finish================

2023-12-01 19:53:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:53:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:53:50 - INFO :       DATASET: tasksource/bigbench english_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
2023-12-01 19:54:00 - INFO :       Use random pruner...
2023-12-01 19:54:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:54:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:54:01 - INFO :       Start Pruning
2023-12-01 19:54:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:54:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:54:02 - INFO :       english_proverbs: Total Sparsity 1.3651273986529418e-06
2023-12-01 19:54:02 - INFO :       
==================Finish================

2023-12-01 19:54:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:54:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:54:02 - INFO :       DATASET: tasksource/bigbench english_russian_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2023-12-01 19:54:13 - INFO :       Use random pruner...
2023-12-01 19:54:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:54:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:54:13 - INFO :       Start Pruning
2023-12-01 19:54:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:54:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:54:15 - INFO :       english_russian_proverbs: Total Sparsity 1.369005601490024e-06
2023-12-01 19:54:15 - INFO :       
==================Finish================

2023-12-01 19:54:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:54:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:54:15 - INFO :       DATASET: tasksource/bigbench entailed_polarity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 19:54:23 - INFO :       Use random pruner...
2023-12-01 19:54:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:54:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:54:24 - INFO :       Start Pruning
2023-12-01 19:54:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:54:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:54:26 - INFO :       entailed_polarity: Total Sparsity 1.3605440680272994e-06
2023-12-01 19:54:26 - INFO :       
==================Finish================

2023-12-01 19:54:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:54:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:54:26 - INFO :       DATASET: tasksource/bigbench entailed_polarity_hindi
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.98s/it]
2023-12-01 19:54:35 - INFO :       Use random pruner...
2023-12-01 19:54:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:54:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:54:36 - INFO :       Start Pruning
2023-12-01 19:54:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:54:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:54:38 - INFO :       entailed_polarity_hindi: Total Sparsity 1.3571947110316374e-06
2023-12-01 19:54:38 - INFO :       
==================Finish================

2023-12-01 19:54:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:54:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:54:38 - INFO :       DATASET: tasksource/bigbench epistemic_reasoning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 19:54:47 - INFO :       Use random pruner...
2023-12-01 19:54:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:54:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:54:48 - INFO :       Start Pruning
2023-12-01 19:54:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:54:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:54:50 - INFO :       epistemic_reasoning: Total Sparsity 1.354726763771676e-06
2023-12-01 19:54:50 - INFO :       
==================Finish================

2023-12-01 19:54:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:54:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:54:50 - INFO :       DATASET: tasksource/bigbench evaluating_information_essentiality
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]
2023-12-01 19:54:57 - INFO :       Use random pruner...
2023-12-01 19:54:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:54:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:54:58 - INFO :       Start Pruning
2023-12-01 19:54:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:54:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:54:59 - INFO :       evaluating_information_essentiality: Total Sparsity 1.3638934250229613e-06
2023-12-01 19:54:59 - INFO :       
==================Finish================

2023-12-01 19:54:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:54:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:54:59 - INFO :       DATASET: tasksource/bigbench fact_checker
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2023-12-01 19:55:09 - INFO :       Use random pruner...
2023-12-01 19:55:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:55:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:55:09 - INFO :       Start Pruning
2023-12-01 19:55:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:55:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:55:11 - INFO :       fact_checker: Total Sparsity 1.3640697069701013e-06
2023-12-01 19:55:11 - INFO :       
==================Finish================

2023-12-01 19:55:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:55:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:55:11 - INFO :       DATASET: tasksource/bigbench fantasy_reasoning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2023-12-01 19:55:20 - INFO :       Use random pruner...
2023-12-01 19:55:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:55:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:55:21 - INFO :       Start Pruning
2023-12-01 19:55:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:55:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:55:23 - INFO :       fantasy_reasoning: Total Sparsity 1.3621306055515601e-06
2023-12-01 19:55:23 - INFO :       
==================Finish================

2023-12-01 19:55:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:55:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:55:23 - INFO :       DATASET: tasksource/bigbench figure_of_speech_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 19:55:30 - INFO :       Use random pruner...
2023-12-01 19:55:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:55:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:55:31 - INFO :       Start Pruning
2023-12-01 19:55:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:55:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:55:32 - INFO :       figure_of_speech_detection: Total Sparsity 1.3658325264415023e-06
2023-12-01 19:55:32 - INFO :       
==================Finish================

2023-12-01 19:55:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:55:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:55:32 - INFO :       DATASET: tasksource/bigbench formal_fallacies_syllogisms_negation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]
2023-12-01 19:55:43 - INFO :       Use random pruner...
2023-12-01 19:55:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:55:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:55:43 - INFO :       Start Pruning
2023-12-01 19:55:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:55:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:55:45 - INFO :       formal_fallacies_syllogisms_negation: Total Sparsity 1.3601915041330191e-06
2023-12-01 19:55:45 - INFO :       
==================Finish================

2023-12-01 19:55:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:55:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:55:45 - INFO :       DATASET: tasksource/bigbench general_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.30s/it]
2023-12-01 19:55:55 - INFO :       Use random pruner...
2023-12-01 19:55:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:55:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:55:56 - INFO :       Start Pruning
2023-12-01 19:55:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:55:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:55:57 - INFO :       general_knowledge: Total Sparsity 1.3522588165117145e-06
2023-12-01 19:55:57 - INFO :       
==================Finish================

2023-12-01 19:55:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:55:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:55:57 - INFO :       DATASET: tasksource/bigbench geometric_shapes
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 19:56:08 - INFO :       Use random pruner...
2023-12-01 19:56:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:56:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:56:09 - INFO :       Start Pruning
2023-12-01 19:56:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:56:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:56:11 - INFO :       geometric_shapes: Total Sparsity 1.3610729138687196e-06
2023-12-01 19:56:11 - INFO :       
==================Finish================

2023-12-01 19:56:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:56:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:56:11 - INFO :       DATASET: tasksource/bigbench goal_step_wikihow
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]
2023-12-01 19:56:19 - INFO :       Use random pruner...
2023-12-01 19:56:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:56:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:56:20 - INFO :       Start Pruning
2023-12-01 19:56:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:56:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:56:22 - INFO :       goal_step_wikihow: Total Sparsity 1.3693581653843043e-06
2023-12-01 19:56:22 - INFO :       
==================Finish================

2023-12-01 19:56:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:56:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:56:22 - INFO :       DATASET: tasksource/bigbench gre_reading_comprehension
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 19:56:31 - INFO :       Use random pruner...
2023-12-01 19:56:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:56:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:56:32 - INFO :       Start Pruning
2023-12-01 19:56:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:56:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:56:33 - INFO :       gre_reading_comprehension: Total Sparsity 1.3709447029085653e-06
2023-12-01 19:56:34 - INFO :       
==================Finish================

2023-12-01 19:56:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:56:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:56:34 - INFO :       DATASET: tasksource/bigbench hhh_alignment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.98s/it]
2023-12-01 19:56:43 - INFO :       Use random pruner...
2023-12-01 19:56:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:56:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:56:44 - INFO :       Start Pruning
2023-12-01 19:56:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:56:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:56:45 - INFO :       hhh_alignment: Total Sparsity 1.3656562444943623e-06
2023-12-01 19:56:45 - INFO :       
==================Finish================

2023-12-01 19:56:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:56:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:56:45 - INFO :       DATASET: tasksource/bigbench hindu_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]
2023-12-01 19:56:54 - INFO :       Use random pruner...
2023-12-01 19:56:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:56:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:56:55 - INFO :       Start Pruning
2023-12-01 19:56:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:56:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:56:57 - INFO :       hindu_knowledge: Total Sparsity 1.360015222185879e-06
2023-12-01 19:56:57 - INFO :       
==================Finish================

2023-12-01 19:56:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:56:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:56:57 - INFO :       DATASET: tasksource/bigbench hinglish_toxicity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.46s/it]
2023-12-01 19:57:06 - INFO :       Use random pruner...
2023-12-01 19:57:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:57:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:57:06 - INFO :       Start Pruning
2023-12-01 19:57:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:57:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:57:08 - INFO :       hinglish_toxicity: Total Sparsity 1.3616017597101399e-06
2023-12-01 19:57:08 - INFO :       
==================Finish================

2023-12-01 19:57:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:57:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:57:08 - INFO :       DATASET: tasksource/bigbench human_organs_senses
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.28s/it]
2023-12-01 19:57:19 - INFO :       Use random pruner...
2023-12-01 19:57:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:57:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:57:20 - INFO :       Start Pruning
2023-12-01 19:57:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:57:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:57:22 - INFO :       human_organs_senses: Total Sparsity 1.360015222185879e-06
2023-12-01 19:57:22 - INFO :       
==================Finish================

2023-12-01 19:57:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:57:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:57:22 - INFO :       DATASET: tasksource/bigbench hyperbaton
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]
2023-12-01 19:57:32 - INFO :       Use random pruner...
2023-12-01 19:57:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:57:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:57:32 - INFO :       Start Pruning
2023-12-01 19:57:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:57:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:57:34 - INFO :       hyperbaton: Total Sparsity 1.3697107292785845e-06
2023-12-01 19:57:34 - INFO :       
==================Finish================

2023-12-01 19:57:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:57:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:57:34 - INFO :       DATASET: tasksource/bigbench identify_math_theorems
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.27s/it]
2023-12-01 19:57:44 - INFO :       Use random pruner...
2023-12-01 19:57:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:57:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:57:44 - INFO :       Start Pruning
2023-12-01 19:57:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:57:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:57:46 - INFO :       identify_math_theorems: Total Sparsity 1.3577235568730577e-06
2023-12-01 19:57:46 - INFO :       
==================Finish================

2023-12-01 19:57:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:57:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:57:46 - INFO :       DATASET: tasksource/bigbench identify_odd_metaphor
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]
2023-12-01 19:57:55 - INFO :       Use random pruner...
2023-12-01 19:57:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:57:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:57:56 - INFO :       Start Pruning
2023-12-01 19:57:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:57:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:57:58 - INFO :       identify_odd_metaphor: Total Sparsity 1.354550481824536e-06
2023-12-01 19:57:58 - INFO :       
==================Finish================

2023-12-01 19:57:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:57:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:57:58 - INFO :       DATASET: tasksource/bigbench implicatures
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
2023-12-01 19:58:07 - INFO :       Use random pruner...
2023-12-01 19:58:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:58:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:58:08 - INFO :       Start Pruning
2023-12-01 19:58:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:58:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:58:09 - INFO :       implicatures: Total Sparsity 1.3614254777629999e-06
2023-12-01 19:58:09 - INFO :       
==================Finish================

2023-12-01 19:58:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:58:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:58:09 - INFO :       DATASET: tasksource/bigbench implicit_relations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]
2023-12-01 19:58:19 - INFO :       Use random pruner...
2023-12-01 19:58:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:58:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:58:19 - INFO :       Start Pruning
2023-12-01 19:58:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:58:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:58:21 - INFO :       implicit_relations: Total Sparsity 1.3619543236044201e-06
2023-12-01 19:58:21 - INFO :       
==================Finish================

2023-12-01 19:58:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:58:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:58:21 - INFO :       DATASET: tasksource/bigbench indic_cause_and_effect
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  2.00s/it]
2023-12-01 19:58:30 - INFO :       Use random pruner...
2023-12-01 19:58:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:58:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:58:31 - INFO :       Start Pruning
2023-12-01 19:58:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:58:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:58:32 - INFO :       indic_cause_and_effect: Total Sparsity 1.3584286846616181e-06
2023-12-01 19:58:32 - INFO :       
==================Finish================

2023-12-01 19:58:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:58:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:58:32 - INFO :       DATASET: tasksource/bigbench intent_recognition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]
2023-12-01 19:58:41 - INFO :       Use random pruner...
2023-12-01 19:58:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:58:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:58:42 - INFO :       Start Pruning
2023-12-01 19:58:42 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:58:42 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:58:43 - INFO :       intent_recognition: Total Sparsity 1.3707684209614252e-06
2023-12-01 19:58:43 - INFO :       
==================Finish================

2023-12-01 19:58:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:58:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:58:43 - INFO :       DATASET: tasksource/bigbench international_phonetic_alphabet_nli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 19:58:52 - INFO :       Use random pruner...
2023-12-01 19:58:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:58:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:58:52 - INFO :       Start Pruning
2023-12-01 19:58:53 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:58:53 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:58:54 - INFO :       international_phonetic_alphabet_nli: Total Sparsity 1.3649511167058018e-06
2023-12-01 19:58:54 - INFO :       
==================Finish================

2023-12-01 19:58:54 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:58:54 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:58:54 - INFO :       DATASET: tasksource/bigbench intersect_geometry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 19:59:03 - INFO :       Use random pruner...
2023-12-01 19:59:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:59:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:59:04 - INFO :       Start Pruning
2023-12-01 19:59:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:59:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:59:05 - INFO :       intersect_geometry: Total Sparsity 1.3593100943973186e-06
2023-12-01 19:59:05 - INFO :       
==================Finish================

2023-12-01 19:59:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:59:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:59:05 - INFO :       DATASET: tasksource/bigbench irony_identification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2023-12-01 19:59:14 - INFO :       Use random pruner...
2023-12-01 19:59:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:59:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:59:15 - INFO :       Start Pruning
2023-12-01 19:59:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:59:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:59:17 - INFO :       irony_identification: Total Sparsity 1.3642459889172413e-06
2023-12-01 19:59:17 - INFO :       
==================Finish================

2023-12-01 19:59:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:59:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:59:17 - INFO :       DATASET: tasksource/bigbench kannada
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]
2023-12-01 19:59:29 - INFO :       Use random pruner...
2023-12-01 19:59:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:59:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:59:29 - INFO :       Start Pruning
2023-12-01 19:59:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:59:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:59:31 - INFO :       kannada: Total Sparsity 1.3603677860801591e-06
2023-12-01 19:59:31 - INFO :       
==================Finish================

2023-12-01 19:59:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:59:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:59:31 - INFO :       DATASET: tasksource/bigbench key_value_maps
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]
2023-12-01 19:59:38 - INFO :       Use random pruner...
2023-12-01 19:59:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:59:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:59:38 - INFO :       Start Pruning
2023-12-01 19:59:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:59:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:59:40 - INFO :       key_value_maps: Total Sparsity 1.3677716278600435e-06
2023-12-01 19:59:40 - INFO :       
==================Finish================

2023-12-01 19:59:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:59:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:59:40 - INFO :       DATASET: tasksource/bigbench known_unknowns
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2023-12-01 19:59:51 - INFO :       Use random pruner...
2023-12-01 19:59:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:59:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 19:59:52 - INFO :       Start Pruning
2023-12-01 19:59:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 19:59:53 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 19:59:53 - INFO :       known_unknowns: Total Sparsity 1.354726763771676e-06
2023-12-01 19:59:53 - INFO :       
==================Finish================

2023-12-01 19:59:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 19:59:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 19:59:53 - INFO :       DATASET: tasksource/bigbench language_identification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2023-12-01 20:00:03 - INFO :       Use random pruner...
2023-12-01 20:00:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:00:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:00:04 - INFO :       Start Pruning
2023-12-01 20:00:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:00:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:00:05 - INFO :       language_identification: Total Sparsity 1.3647748347586618e-06
2023-12-01 20:00:05 - INFO :       
==================Finish================

2023-12-01 20:00:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:00:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:00:05 - INFO :       DATASET: tasksource/bigbench logic_grid_puzzle
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]
2023-12-01 20:00:16 - INFO :       Use random pruner...
2023-12-01 20:00:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:00:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:00:16 - INFO :       Start Pruning
2023-12-01 20:00:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:00:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:00:18 - INFO :       logic_grid_puzzle: Total Sparsity 1.3667139361772028e-06
2023-12-01 20:00:18 - INFO :       
==================Finish================

2023-12-01 20:00:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:00:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:00:18 - INFO :       DATASET: tasksource/bigbench logical_args
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 20:00:27 - INFO :       Use random pruner...
2023-12-01 20:00:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:00:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:00:28 - INFO :       Start Pruning
2023-12-01 20:00:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:00:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:00:29 - INFO :       logical_args: Total Sparsity 1.3624831694458404e-06
2023-12-01 20:00:29 - INFO :       
==================Finish================

2023-12-01 20:00:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:00:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:00:29 - INFO :       DATASET: tasksource/bigbench logical_deduction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2023-12-01 20:00:39 - INFO :       Use random pruner...
2023-12-01 20:00:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:00:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:00:40 - INFO :       Start Pruning
2023-12-01 20:00:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:00:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:00:41 - INFO :       logical_deduction: Total Sparsity 1.3656562444943623e-06
2023-12-01 20:00:41 - INFO :       
==================Finish================

2023-12-01 20:00:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:00:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:00:41 - INFO :       DATASET: tasksource/bigbench logical_fallacy_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2023-12-01 20:00:51 - INFO :       Use random pruner...
2023-12-01 20:00:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:00:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:00:51 - INFO :       Start Pruning
2023-12-01 20:00:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:00:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:00:53 - INFO :       logical_fallacy_detection: Total Sparsity 1.3660088083886423e-06
2023-12-01 20:00:53 - INFO :       
==================Finish================

2023-12-01 20:00:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:00:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:00:53 - INFO :       DATASET: tasksource/bigbench logical_sequence
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]
2023-12-01 20:01:03 - INFO :       Use random pruner...
2023-12-01 20:01:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:01:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:01:04 - INFO :       Start Pruning
2023-12-01 20:01:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:01:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:01:05 - INFO :       logical_sequence: Total Sparsity 1.3624831694458404e-06
2023-12-01 20:01:05 - INFO :       
==================Finish================

2023-12-01 20:01:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:01:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:01:05 - INFO :       DATASET: tasksource/bigbench mathematical_induction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 20:01:14 - INFO :       Use random pruner...
2023-12-01 20:01:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:01:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:01:15 - INFO :       Start Pruning
2023-12-01 20:01:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:01:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:01:16 - INFO :       mathematical_induction: Total Sparsity 1.3711209848557053e-06
2023-12-01 20:01:16 - INFO :       
==================Finish================

2023-12-01 20:01:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:01:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:01:16 - INFO :       DATASET: tasksource/bigbench medical_questions_russian
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2023-12-01 20:01:26 - INFO :       Use random pruner...
2023-12-01 20:01:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:01:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:01:27 - INFO :       Start Pruning
2023-12-01 20:01:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:01:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:01:29 - INFO :       medical_questions_russian: Total Sparsity 1.3656562444943623e-06
2023-12-01 20:01:29 - INFO :       
==================Finish================

2023-12-01 20:01:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:01:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:01:29 - INFO :       DATASET: tasksource/bigbench metaphor_boolean
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]
2023-12-01 20:01:35 - INFO :       Use random pruner...
2023-12-01 20:01:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:01:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:01:36 - INFO :       Start Pruning
2023-12-01 20:01:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:01:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:01:38 - INFO :       metaphor_boolean: Total Sparsity 1.374117777957087e-06
2023-12-01 20:01:38 - INFO :       
==================Finish================

2023-12-01 20:01:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:01:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:01:38 - INFO :       DATASET: tasksource/bigbench metaphor_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 20:01:44 - INFO :       Use random pruner...
2023-12-01 20:01:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:01:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:01:45 - INFO :       Start Pruning
2023-12-01 20:01:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:01:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:01:46 - INFO :       metaphor_understanding: Total Sparsity 1.354550481824536e-06
2023-12-01 20:01:46 - INFO :       
==================Finish================

2023-12-01 20:01:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:01:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:01:46 - INFO :       DATASET: tasksource/bigbench misconceptions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]
2023-12-01 20:01:52 - INFO :       Use random pruner...
2023-12-01 20:01:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:01:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:01:53 - INFO :       Start Pruning
2023-12-01 20:01:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:01:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:01:55 - INFO :       misconceptions: Total Sparsity 1.3675953459129033e-06
2023-12-01 20:01:55 - INFO :       
==================Finish================

2023-12-01 20:01:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:01:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:01:55 - INFO :       DATASET: tasksource/bigbench misconceptions_russian
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]
2023-12-01 20:02:03 - INFO :       Use random pruner...
2023-12-01 20:02:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:02:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:02:03 - INFO :       Start Pruning
2023-12-01 20:02:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:02:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:02:05 - INFO :       misconceptions_russian: Total Sparsity 1.3616017597101399e-06
2023-12-01 20:02:05 - INFO :       
==================Finish================

2023-12-01 20:02:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:02:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:02:05 - INFO :       DATASET: tasksource/bigbench mnist_ascii
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]
2023-12-01 20:02:14 - INFO :       Use random pruner...
2023-12-01 20:02:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:02:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:02:15 - INFO :       Start Pruning
2023-12-01 20:02:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:02:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:02:16 - INFO :       mnist_ascii: Total Sparsity 1.3647748347586618e-06
2023-12-01 20:02:16 - INFO :       
==================Finish================

2023-12-01 20:02:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:02:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:02:16 - INFO :       DATASET: tasksource/bigbench moral_permissibility
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2023-12-01 20:02:25 - INFO :       Use random pruner...
2023-12-01 20:02:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:02:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:02:26 - INFO :       Start Pruning
2023-12-01 20:02:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:02:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:02:28 - INFO :       moral_permissibility: Total Sparsity 1.351377406776014e-06
2023-12-01 20:02:28 - INFO :       
==================Finish================

2023-12-01 20:02:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:02:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:02:28 - INFO :       DATASET: tasksource/bigbench movie_dialog_same_or_different
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
2023-12-01 20:02:36 - INFO :       Use random pruner...
2023-12-01 20:02:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:02:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:02:36 - INFO :       Start Pruning
2023-12-01 20:02:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:02:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:02:38 - INFO :       movie_dialog_same_or_different: Total Sparsity 1.3570184290844972e-06
2023-12-01 20:02:38 - INFO :       
==================Finish================

2023-12-01 20:02:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:02:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:02:38 - INFO :       DATASET: tasksource/bigbench movie_recommendation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 20:02:47 - INFO :       Use random pruner...
2023-12-01 20:02:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:02:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:02:48 - INFO :       Start Pruning
2023-12-01 20:02:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:02:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:02:49 - INFO :       movie_recommendation: Total Sparsity 1.3695344473314445e-06
2023-12-01 20:02:49 - INFO :       
==================Finish================

2023-12-01 20:02:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:02:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:02:49 - INFO :       DATASET: tasksource/bigbench navigate
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2023-12-01 20:02:59 - INFO :       Use random pruner...
2023-12-01 20:02:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:02:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:03:00 - INFO :       Start Pruning
2023-12-01 20:03:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:03:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:03:01 - INFO :       navigate: Total Sparsity 1.3610729138687196e-06
2023-12-01 20:03:01 - INFO :       
==================Finish================

2023-12-01 20:03:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:03:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:03:01 - INFO :       DATASET: tasksource/bigbench nonsense_words_grammar
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]
2023-12-01 20:03:10 - INFO :       Use random pruner...
2023-12-01 20:03:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:03:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:03:10 - INFO :       Start Pruning
2023-12-01 20:03:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:03:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:03:12 - INFO :       nonsense_words_grammar: Total Sparsity 1.3571947110316374e-06
2023-12-01 20:03:12 - INFO :       
==================Finish================

2023-12-01 20:03:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:03:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:03:12 - INFO :       DATASET: tasksource/bigbench novel_concepts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2023-12-01 20:03:21 - INFO :       Use random pruner...
2023-12-01 20:03:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:03:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:03:21 - INFO :       Start Pruning
2023-12-01 20:03:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:03:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:03:23 - INFO :       novel_concepts: Total Sparsity 1.3663613722829226e-06
2023-12-01 20:03:23 - INFO :       
==================Finish================

2023-12-01 20:03:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:03:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:03:23 - INFO :       DATASET: tasksource/bigbench odd_one_out
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]
2023-12-01 20:03:32 - INFO :       Use random pruner...
2023-12-01 20:03:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:03:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:03:33 - INFO :       Start Pruning
2023-12-01 20:03:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:03:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:03:34 - INFO :       odd_one_out: Total Sparsity 1.363540861128681e-06
2023-12-01 20:03:34 - INFO :       
==================Finish================

2023-12-01 20:03:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:03:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:03:34 - INFO :       DATASET: tasksource/bigbench parsinlu_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2023-12-01 20:03:45 - INFO :       Use random pruner...
2023-12-01 20:03:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:03:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:03:46 - INFO :       Start Pruning
2023-12-01 20:03:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:03:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:03:48 - INFO :       parsinlu_qa: Total Sparsity 1.3626594513929806e-06
2023-12-01 20:03:48 - INFO :       
==================Finish================

2023-12-01 20:03:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:03:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:03:48 - INFO :       DATASET: tasksource/bigbench penguins_in_a_table
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2023-12-01 20:03:57 - INFO :       Use random pruner...
2023-12-01 20:03:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:03:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:03:57 - INFO :       Start Pruning
2023-12-01 20:03:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:03:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:03:59 - INFO :       penguins_in_a_table: Total Sparsity 1.3644222708643816e-06
2023-12-01 20:03:59 - INFO :       
==================Finish================

2023-12-01 20:03:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:03:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:03:59 - INFO :       DATASET: tasksource/bigbench persian_idioms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2023-12-01 20:04:09 - INFO :       Use random pruner...
2023-12-01 20:04:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:04:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:04:09 - INFO :       Start Pruning
2023-12-01 20:04:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:04:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:04:11 - INFO :       persian_idioms: Total Sparsity 1.3674190639657633e-06
2023-12-01 20:04:11 - INFO :       
==================Finish================

2023-12-01 20:04:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:04:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:04:11 - INFO :       DATASET: tasksource/bigbench phrase_relatedness
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 20:04:19 - INFO :       Use random pruner...
2023-12-01 20:04:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:04:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:04:20 - INFO :       Start Pruning
2023-12-01 20:04:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:04:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:04:22 - INFO :       phrase_relatedness: Total Sparsity 1.3681241917543236e-06
2023-12-01 20:04:22 - INFO :       
==================Finish================

2023-12-01 20:04:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:04:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:04:22 - INFO :       DATASET: tasksource/bigbench physical_intuition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]
2023-12-01 20:04:30 - INFO :       Use random pruner...
2023-12-01 20:04:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:04:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:04:30 - INFO :       Start Pruning
2023-12-01 20:04:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:04:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:04:32 - INFO :       physical_intuition: Total Sparsity 1.368653037595744e-06
2023-12-01 20:04:32 - INFO :       
==================Finish================

2023-12-01 20:04:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:04:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:04:32 - INFO :       DATASET: tasksource/bigbench physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2023-12-01 20:04:42 - INFO :       Use random pruner...
2023-12-01 20:04:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:04:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:04:42 - INFO :       Start Pruning
2023-12-01 20:04:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:04:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:04:44 - INFO :       physics: Total Sparsity 1.358076120767338e-06
2023-12-01 20:04:44 - INFO :       
==================Finish================

2023-12-01 20:04:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:04:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:04:44 - INFO :       DATASET: tasksource/bigbench play_dialog_same_or_different
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2023-12-01 20:04:54 - INFO :       Use random pruner...
2023-12-01 20:04:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:04:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:04:55 - INFO :       Start Pruning
2023-12-01 20:04:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:04:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:04:56 - INFO :       play_dialog_same_or_different: Total Sparsity 1.3665376542300628e-06
2023-12-01 20:04:56 - INFO :       
==================Finish================

2023-12-01 20:04:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:04:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:04:56 - INFO :       DATASET: tasksource/bigbench presuppositions_as_nli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]
2023-12-01 20:05:05 - INFO :       Use random pruner...
2023-12-01 20:05:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:05:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:05:05 - INFO :       Start Pruning
2023-12-01 20:05:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:05:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:05:07 - INFO :       presuppositions_as_nli: Total Sparsity 1.3570184290844972e-06
2023-12-01 20:05:07 - INFO :       
==================Finish================

2023-12-01 20:05:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:05:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:05:07 - INFO :       DATASET: tasksource/bigbench question_selection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2023-12-01 20:05:16 - INFO :       Use random pruner...
2023-12-01 20:05:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:05:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:05:17 - INFO :       Start Pruning
2023-12-01 20:05:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:05:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:05:19 - INFO :       question_selection: Total Sparsity 1.3571947110316374e-06
2023-12-01 20:05:19 - INFO :       
==================Finish================

2023-12-01 20:05:19 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:05:19 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:05:19 - INFO :       DATASET: tasksource/bigbench reasoning_about_colored_objects
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]
2023-12-01 20:05:26 - INFO :       Use random pruner...
2023-12-01 20:05:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:05:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:05:26 - INFO :       Start Pruning
2023-12-01 20:05:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:05:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:05:28 - INFO :       reasoning_about_colored_objects: Total Sparsity 1.3614254777629999e-06
2023-12-01 20:05:28 - INFO :       
==================Finish================

2023-12-01 20:05:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:05:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:05:28 - INFO :       DATASET: tasksource/bigbench riddle_sense
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 20:05:35 - INFO :       Use random pruner...
2023-12-01 20:05:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:05:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:05:35 - INFO :       Start Pruning
2023-12-01 20:05:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:05:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:05:37 - INFO :       riddle_sense: Total Sparsity 1.3621306055515601e-06
2023-12-01 20:05:37 - INFO :       
==================Finish================

2023-12-01 20:05:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:05:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:05:37 - INFO :       DATASET: tasksource/bigbench ruin_names
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]
2023-12-01 20:05:45 - INFO :       Use random pruner...
2023-12-01 20:05:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:05:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:05:46 - INFO :       Start Pruning
2023-12-01 20:05:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:05:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:05:47 - INFO :       ruin_names: Total Sparsity 1.3596626582915989e-06
2023-12-01 20:05:47 - INFO :       
==================Finish================

2023-12-01 20:05:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:05:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:05:47 - INFO :       DATASET: tasksource/bigbench salient_translation_error_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]
2023-12-01 20:05:56 - INFO :       Use random pruner...
2023-12-01 20:05:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:05:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:05:56 - INFO :       Start Pruning
2023-12-01 20:05:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:05:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:05:58 - INFO :       salient_translation_error_detection: Total Sparsity 1.3596626582915989e-06
2023-12-01 20:05:58 - INFO :       
==================Finish================

2023-12-01 20:05:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:05:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:05:58 - INFO :       DATASET: tasksource/bigbench sentence_ambiguity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 20:06:06 - INFO :       Use random pruner...
2023-12-01 20:06:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:06:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:06:06 - INFO :       Start Pruning
2023-12-01 20:06:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:06:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:06:08 - INFO :       sentence_ambiguity: Total Sparsity 1.3638934250229613e-06
2023-12-01 20:06:08 - INFO :       
==================Finish================

2023-12-01 20:06:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:06:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:06:08 - INFO :       DATASET: tasksource/bigbench similarities_abstraction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
2023-12-01 20:06:20 - INFO :       Use random pruner...
2023-12-01 20:06:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:06:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:06:20 - INFO :       Start Pruning
2023-12-01 20:06:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:06:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:06:22 - INFO :       similarities_abstraction: Total Sparsity 1.3624831694458404e-06
2023-12-01 20:06:22 - INFO :       
==================Finish================

2023-12-01 20:06:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:06:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:06:22 - INFO :       DATASET: tasksource/bigbench simple_ethical_questions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 20:06:34 - INFO :       Use random pruner...
2023-12-01 20:06:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:06:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:06:34 - INFO :       Start Pruning
2023-12-01 20:06:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:06:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:06:36 - INFO :       simple_ethical_questions: Total Sparsity 1.3681241917543236e-06
2023-12-01 20:06:36 - INFO :       
==================Finish================

2023-12-01 20:06:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:06:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:06:36 - INFO :       DATASET: tasksource/bigbench snarks
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.27s/it]
2023-12-01 20:06:48 - INFO :       Use random pruner...
2023-12-01 20:06:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:06:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:06:49 - INFO :       Start Pruning
2023-12-01 20:06:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:06:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:06:50 - INFO :       snarks: Total Sparsity 1.3640697069701013e-06
2023-12-01 20:06:50 - INFO :       
==================Finish================

2023-12-01 20:06:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:06:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:06:50 - INFO :       DATASET: tasksource/bigbench social_iqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
2023-12-01 20:07:03 - INFO :       Use random pruner...
2023-12-01 20:07:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:07:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:07:03 - INFO :       Start Pruning
2023-12-01 20:07:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:07:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:07:05 - INFO :       social_iqa: Total Sparsity 1.366890218124343e-06
2023-12-01 20:07:05 - INFO :       
==================Finish================

2023-12-01 20:07:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:07:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:07:05 - INFO :       DATASET: tasksource/bigbench social_support
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.38s/it]
2023-12-01 20:07:17 - INFO :       Use random pruner...
2023-12-01 20:07:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:07:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:07:18 - INFO :       Start Pruning
2023-12-01 20:07:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:07:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:07:19 - INFO :       social_support: Total Sparsity 1.3663613722829226e-06
2023-12-01 20:07:19 - INFO :       
==================Finish================

2023-12-01 20:07:19 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:07:19 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:07:19 - INFO :       DATASET: tasksource/bigbench sports_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.34s/it]
2023-12-01 20:07:31 - INFO :       Use random pruner...
2023-12-01 20:07:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:07:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:07:32 - INFO :       Start Pruning
2023-12-01 20:07:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:07:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:07:33 - INFO :       sports_understanding: Total Sparsity 1.3605440680272994e-06
2023-12-01 20:07:33 - INFO :       
==================Finish================

2023-12-01 20:07:33 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:07:33 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:07:33 - INFO :       DATASET: tasksource/bigbench strange_stories
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.34s/it]
2023-12-01 20:07:45 - INFO :       Use random pruner...
2023-12-01 20:07:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:07:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:07:45 - INFO :       Start Pruning
2023-12-01 20:07:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:07:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:07:47 - INFO :       strange_stories: Total Sparsity 1.3631882972344008e-06
2023-12-01 20:07:47 - INFO :       
==================Finish================

2023-12-01 20:07:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:07:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:07:47 - INFO :       DATASET: tasksource/bigbench strategyqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
2023-12-01 20:07:59 - INFO :       Use random pruner...
2023-12-01 20:07:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:07:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:07:59 - INFO :       Start Pruning
2023-12-01 20:08:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:08:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:08:01 - INFO :       strategyqa: Total Sparsity 1.3593100943973186e-06
2023-12-01 20:08:01 - INFO :       
==================Finish================

2023-12-01 20:08:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:08:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:08:01 - INFO :       DATASET: tasksource/bigbench suicide_risk
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.34s/it]
2023-12-01 20:08:13 - INFO :       Use random pruner...
2023-12-01 20:08:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:08:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:08:13 - INFO :       Start Pruning
2023-12-01 20:08:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:08:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:08:15 - INFO :       suicide_risk: Total Sparsity 1.3667139361772028e-06
2023-12-01 20:08:15 - INFO :       
==================Finish================

2023-12-01 20:08:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:08:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:08:15 - INFO :       DATASET: tasksource/bigbench swahili_english_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]
2023-12-01 20:08:27 - INFO :       Use random pruner...
2023-12-01 20:08:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:08:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:08:27 - INFO :       Start Pruning
2023-12-01 20:08:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:08:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:08:29 - INFO :       swahili_english_proverbs: Total Sparsity 1.3603677860801591e-06
2023-12-01 20:08:29 - INFO :       
==================Finish================

2023-12-01 20:08:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:08:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:08:29 - INFO :       DATASET: tasksource/bigbench swedish_to_german_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.42s/it]
2023-12-01 20:08:40 - INFO :       Use random pruner...
2023-12-01 20:08:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:08:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:08:40 - INFO :       Start Pruning
2023-12-01 20:08:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:08:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:08:42 - INFO :       swedish_to_german_proverbs: Total Sparsity 1.3621306055515601e-06
2023-12-01 20:08:42 - INFO :       
==================Finish================

2023-12-01 20:08:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:08:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:08:42 - INFO :       DATASET: tasksource/bigbench symbol_interpretation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]
2023-12-01 20:08:54 - INFO :       Use random pruner...
2023-12-01 20:08:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:08:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:08:54 - INFO :       Start Pruning
2023-12-01 20:08:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:08:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:08:56 - INFO :       symbol_interpretation: Total Sparsity 1.3554318915602364e-06
2023-12-01 20:08:56 - INFO :       
==================Finish================

2023-12-01 20:08:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:08:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:08:56 - INFO :       DATASET: tasksource/bigbench temporal_sequences
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.22s/it]
2023-12-01 20:09:08 - INFO :       Use random pruner...
2023-12-01 20:09:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:09:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:09:08 - INFO :       Start Pruning
2023-12-01 20:09:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:09:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:09:10 - INFO :       temporal_sequences: Total Sparsity 1.3702395751200048e-06
2023-12-01 20:09:10 - INFO :       
==================Finish================

2023-12-01 20:09:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:09:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:09:10 - INFO :       DATASET: tasksource/bigbench timedial
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.32s/it]
2023-12-01 20:09:22 - INFO :       Use random pruner...
2023-12-01 20:09:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:09:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:09:23 - INFO :       Start Pruning
2023-12-01 20:09:24 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:09:24 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:09:24 - INFO :       timedial: Total Sparsity 1.3554318915602364e-06
2023-12-01 20:09:24 - INFO :       
==================Finish================

2023-12-01 20:09:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:09:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:09:24 - INFO :       DATASET: tasksource/bigbench tracking_shuffled_objects
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 20:09:36 - INFO :       Use random pruner...
2023-12-01 20:09:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:09:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:09:36 - INFO :       Start Pruning
2023-12-01 20:09:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:09:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:09:38 - INFO :       tracking_shuffled_objects: Total Sparsity 1.372178676538546e-06
2023-12-01 20:09:38 - INFO :       
==================Finish================

2023-12-01 20:09:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:09:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:09:38 - INFO :       DATASET: tasksource/bigbench understanding_fables
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.41s/it]
2023-12-01 20:09:50 - INFO :       Use random pruner...
2023-12-01 20:09:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:09:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:09:50 - INFO :       Start Pruning
2023-12-01 20:09:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:09:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:09:52 - INFO :       understanding_fables: Total Sparsity 1.3601915041330191e-06
2023-12-01 20:09:52 - INFO :       
==================Finish================

2023-12-01 20:09:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:09:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:09:52 - INFO :       DATASET: tasksource/bigbench undo_permutation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.46s/it]
2023-12-01 20:10:03 - INFO :       Use random pruner...
2023-12-01 20:10:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:10:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:10:04 - INFO :       Start Pruning
2023-12-01 20:10:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:10:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:10:06 - INFO :       undo_permutation: Total Sparsity 1.3561370193487967e-06
2023-12-01 20:10:06 - INFO :       
==================Finish================

2023-12-01 20:10:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:10:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:10:06 - INFO :       DATASET: tasksource/bigbench unit_interpretation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.39s/it]
2023-12-01 20:10:17 - INFO :       Use random pruner...
2023-12-01 20:10:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:10:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:10:18 - INFO :       Start Pruning
2023-12-01 20:10:19 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:10:19 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:10:20 - INFO :       unit_interpretation: Total Sparsity 1.3656562444943623e-06
2023-12-01 20:10:20 - INFO :       
==================Finish================

2023-12-01 20:10:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:10:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:10:20 - INFO :       DATASET: tasksource/bigbench vitaminc_fact_verification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 20:10:32 - INFO :       Use random pruner...
2023-12-01 20:10:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:10:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:10:32 - INFO :       Start Pruning
2023-12-01 20:10:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:10:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:10:34 - INFO :       vitaminc_fact_verification: Total Sparsity 1.3677716278600435e-06
2023-12-01 20:10:34 - INFO :       
==================Finish================

2023-12-01 20:10:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:10:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:10:34 - INFO :       DATASET: tasksource/bigbench what_is_the_tao
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.28s/it]
2023-12-01 20:10:46 - INFO :       Use random pruner...
2023-12-01 20:10:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:10:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:10:46 - INFO :       Start Pruning
2023-12-01 20:10:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:10:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:10:48 - INFO :       what_is_the_tao: Total Sparsity 1.360015222185879e-06
2023-12-01 20:10:48 - INFO :       
==================Finish================

2023-12-01 20:10:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:10:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:10:48 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]
2023-12-01 20:11:00 - INFO :       Use random pruner...
2023-12-01 20:11:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:11:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:11:00 - INFO :       Start Pruning
2023-12-01 20:11:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:11:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:11:02 - INFO :       which_wiki_edit: Total Sparsity 1.3681241917543236e-06
2023-12-01 20:11:02 - INFO :       
==================Finish================

2023-12-01 20:11:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:11:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:11:02 - INFO :       DATASET: tasksource/bigbench winowhy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.40s/it]
2023-12-01 20:11:15 - INFO :       Use random pruner...
2023-12-01 20:11:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:11:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:11:15 - INFO :       Start Pruning
2023-12-01 20:11:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:11:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:11:17 - INFO :       winowhy: Total Sparsity 1.363540861128681e-06
2023-12-01 20:11:17 - INFO :       
==================Finish================

2023-12-01 20:11:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:11:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:11:17 - INFO :       DATASET: tasksource/mmlu abstract_algebra
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.43s/it]
2023-12-01 20:11:28 - INFO :       Use random pruner...
2023-12-01 20:11:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:11:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:11:29 - INFO :       Start Pruning
2023-12-01 20:11:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:11:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:11:30 - INFO :       abstract_algebra: Total Sparsity 1.365303680600082e-06
2023-12-01 20:11:30 - INFO :       
==================Finish================

2023-12-01 20:11:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:11:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:11:30 - INFO :       DATASET: tasksource/mmlu anatomy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.33s/it]
2023-12-01 20:11:42 - INFO :       Use random pruner...
2023-12-01 20:11:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:11:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:11:43 - INFO :       Start Pruning
2023-12-01 20:11:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:11:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:11:44 - INFO :       anatomy: Total Sparsity 1.3647748347586618e-06
2023-12-01 20:11:44 - INFO :       
==================Finish================

2023-12-01 20:11:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:11:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:11:44 - INFO :       DATASET: tasksource/mmlu astronomy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2023-12-01 20:11:55 - INFO :       Use random pruner...
2023-12-01 20:11:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:11:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:11:56 - INFO :       Start Pruning
2023-12-01 20:11:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:11:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:11:57 - INFO :       astronomy: Total Sparsity 1.3656562444943623e-06
2023-12-01 20:11:57 - INFO :       
==================Finish================

2023-12-01 20:11:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:11:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:11:57 - INFO :       DATASET: tasksource/mmlu business_ethics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.46s/it]
2023-12-01 20:12:10 - INFO :       Use random pruner...
2023-12-01 20:12:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:12:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:12:11 - INFO :       Start Pruning
2023-12-01 20:12:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:12:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:12:13 - INFO :       business_ethics: Total Sparsity 1.368653037595744e-06
2023-12-01 20:12:13 - INFO :       
==================Finish================

2023-12-01 20:12:13 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:12:13 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:12:13 - INFO :       DATASET: tasksource/mmlu clinical_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2023-12-01 20:12:24 - INFO :       Use random pruner...
2023-12-01 20:12:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:12:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:12:25 - INFO :       Start Pruning
2023-12-01 20:12:26 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:12:26 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:12:26 - INFO :       clinical_knowledge: Total Sparsity 1.3712972668028455e-06
2023-12-01 20:12:26 - INFO :       
==================Finish================

2023-12-01 20:12:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:12:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:12:26 - INFO :       DATASET: tasksource/mmlu college_biology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]
2023-12-01 20:12:38 - INFO :       Use random pruner...
2023-12-01 20:12:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:12:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:12:39 - INFO :       Start Pruning
2023-12-01 20:12:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:12:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:12:41 - INFO :       college_biology: Total Sparsity 1.3612491958158596e-06
2023-12-01 20:12:41 - INFO :       
==================Finish================

2023-12-01 20:12:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:12:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:12:41 - INFO :       DATASET: tasksource/mmlu college_chemistry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.32s/it]
2023-12-01 20:12:53 - INFO :       Use random pruner...
2023-12-01 20:12:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:12:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:12:53 - INFO :       Start Pruning
2023-12-01 20:12:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:12:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:12:55 - INFO :       college_chemistry: Total Sparsity 1.367242782018623e-06
2023-12-01 20:12:55 - INFO :       
==================Finish================

2023-12-01 20:12:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:12:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:12:55 - INFO :       DATASET: tasksource/mmlu college_computer_science
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]
2023-12-01 20:13:06 - INFO :       Use random pruner...
2023-12-01 20:13:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:13:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:13:06 - INFO :       Start Pruning
2023-12-01 20:13:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:13:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:13:08 - INFO :       college_computer_science: Total Sparsity 1.3663613722829226e-06
2023-12-01 20:13:08 - INFO :       
==================Finish================

2023-12-01 20:13:08 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:13:08 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:13:08 - INFO :       DATASET: tasksource/mmlu college_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.41s/it]
2023-12-01 20:13:20 - INFO :       Use random pruner...
2023-12-01 20:13:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:13:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:13:21 - INFO :       Start Pruning
2023-12-01 20:13:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:13:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:13:23 - INFO :       college_mathematics: Total Sparsity 1.3663613722829226e-06
2023-12-01 20:13:23 - INFO :       
==================Finish================

2023-12-01 20:13:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:13:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:13:23 - INFO :       DATASET: tasksource/mmlu college_medicine
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2023-12-01 20:13:34 - INFO :       Use random pruner...
2023-12-01 20:13:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:13:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:13:35 - INFO :       Start Pruning
2023-12-01 20:13:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:13:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:13:36 - INFO :       college_medicine: Total Sparsity 1.3633645791815409e-06
2023-12-01 20:13:37 - INFO :       
==================Finish================

2023-12-01 20:13:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:13:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:13:37 - INFO :       DATASET: tasksource/mmlu college_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.32s/it]
2023-12-01 20:13:49 - INFO :       Use random pruner...
2023-12-01 20:13:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:13:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:13:50 - INFO :       Start Pruning
2023-12-01 20:13:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:13:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:13:52 - INFO :       college_physics: Total Sparsity 1.3487331775689125e-06
2023-12-01 20:13:52 - INFO :       
==================Finish================

2023-12-01 20:13:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:13:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:13:52 - INFO :       DATASET: tasksource/mmlu computer_security
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.36s/it]
2023-12-01 20:14:04 - INFO :       Use random pruner...
2023-12-01 20:14:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:14:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:14:04 - INFO :       Start Pruning
2023-12-01 20:14:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:14:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:14:06 - INFO :       computer_security: Total Sparsity 1.3633645791815409e-06
2023-12-01 20:14:06 - INFO :       
==================Finish================

2023-12-01 20:14:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:14:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:14:06 - INFO :       DATASET: tasksource/mmlu conceptual_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 20:14:19 - INFO :       Use random pruner...
2023-12-01 20:14:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:14:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:14:19 - INFO :       Start Pruning
2023-12-01 20:14:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:14:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:14:21 - INFO :       conceptual_physics: Total Sparsity 1.3577235568730577e-06
2023-12-01 20:14:21 - INFO :       
==================Finish================

2023-12-01 20:14:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:14:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:14:21 - INFO :       DATASET: tasksource/mmlu econometrics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.48s/it]
2023-12-01 20:14:34 - INFO :       Use random pruner...
2023-12-01 20:14:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:14:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:14:34 - INFO :       Start Pruning
2023-12-01 20:14:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:14:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:14:36 - INFO :       econometrics: Total Sparsity 1.3681241917543236e-06
2023-12-01 20:14:36 - INFO :       
==================Finish================

2023-12-01 20:14:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:14:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:14:36 - INFO :       DATASET: tasksource/mmlu electrical_engineering
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
2023-12-01 20:14:47 - INFO :       Use random pruner...
2023-12-01 20:14:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:14:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:14:48 - INFO :       Start Pruning
2023-12-01 20:14:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:14:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:14:49 - INFO :       electrical_engineering: Total Sparsity 1.3575472749259176e-06
2023-12-01 20:14:49 - INFO :       
==================Finish================

2023-12-01 20:14:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:14:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:14:49 - INFO :       DATASET: tasksource/mmlu elementary_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2023-12-01 20:15:01 - INFO :       Use random pruner...
2023-12-01 20:15:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:15:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:15:01 - INFO :       Start Pruning
2023-12-01 20:15:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:15:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:15:03 - INFO :       elementary_mathematics: Total Sparsity 1.3700632931728648e-06
2023-12-01 20:15:03 - INFO :       
==================Finish================

2023-12-01 20:15:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:15:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:15:03 - INFO :       DATASET: tasksource/mmlu formal_logic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 20:15:15 - INFO :       Use random pruner...
2023-12-01 20:15:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:15:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:15:15 - INFO :       Start Pruning
2023-12-01 20:15:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:15:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:15:17 - INFO :       formal_logic: Total Sparsity 1.3630120152872606e-06
2023-12-01 20:15:17 - INFO :       
==================Finish================

2023-12-01 20:15:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:15:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:15:17 - INFO :       DATASET: tasksource/mmlu global_facts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.40s/it]
2023-12-01 20:15:29 - INFO :       Use random pruner...
2023-12-01 20:15:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:15:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:15:29 - INFO :       Start Pruning
2023-12-01 20:15:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:15:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:15:31 - INFO :       global_facts: Total Sparsity 1.366890218124343e-06
2023-12-01 20:15:31 - INFO :       
==================Finish================

2023-12-01 20:15:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:15:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:15:31 - INFO :       DATASET: tasksource/mmlu high_school_biology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.27s/it]
2023-12-01 20:15:43 - INFO :       Use random pruner...
2023-12-01 20:15:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:15:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:15:44 - INFO :       Start Pruning
2023-12-01 20:15:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:15:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:15:45 - INFO :       high_school_biology: Total Sparsity 1.3607203499744394e-06
2023-12-01 20:15:45 - INFO :       
==================Finish================

2023-12-01 20:15:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:15:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:15:45 - INFO :       DATASET: tasksource/mmlu high_school_chemistry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.35s/it]
2023-12-01 20:15:58 - INFO :       Use random pruner...
2023-12-01 20:15:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:15:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:15:58 - INFO :       Start Pruning
2023-12-01 20:15:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:15:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:16:00 - INFO :       high_school_chemistry: Total Sparsity 1.3621306055515601e-06
2023-12-01 20:16:00 - INFO :       
==================Finish================

2023-12-01 20:16:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:16:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:16:00 - INFO :       DATASET: tasksource/mmlu high_school_computer_science
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.21s/it]
2023-12-01 20:16:11 - INFO :       Use random pruner...
2023-12-01 20:16:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:16:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:16:12 - INFO :       Start Pruning
2023-12-01 20:16:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:16:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:16:13 - INFO :       high_school_computer_science: Total Sparsity 1.363717143075821e-06
2023-12-01 20:16:13 - INFO :       
==================Finish================

2023-12-01 20:16:13 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:16:13 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:16:13 - INFO :       DATASET: tasksource/mmlu high_school_european_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.45s/it]
2023-12-01 20:16:25 - INFO :       Use random pruner...
2023-12-01 20:16:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:16:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:16:25 - INFO :       Start Pruning
2023-12-01 20:16:26 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:16:26 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:16:27 - INFO :       high_school_european_history: Total Sparsity 1.3554318915602364e-06
2023-12-01 20:16:27 - INFO :       
==================Finish================

2023-12-01 20:16:27 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:16:27 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:16:27 - INFO :       DATASET: tasksource/mmlu high_school_geography
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]
2023-12-01 20:16:39 - INFO :       Use random pruner...
2023-12-01 20:16:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:16:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:16:39 - INFO :       Start Pruning
2023-12-01 20:16:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:16:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:16:41 - INFO :       high_school_geography: Total Sparsity 1.3566658651902172e-06
2023-12-01 20:16:41 - INFO :       
==================Finish================

2023-12-01 20:16:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:16:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:16:41 - INFO :       DATASET: tasksource/mmlu high_school_government_and_politics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.37s/it]
2023-12-01 20:16:53 - INFO :       Use random pruner...
2023-12-01 20:16:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:16:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:16:53 - INFO :       Start Pruning
2023-12-01 20:16:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:16:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:16:55 - INFO :       high_school_government_and_politics: Total Sparsity 1.3598389402387389e-06
2023-12-01 20:16:55 - INFO :       
==================Finish================

2023-12-01 20:16:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:16:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:16:55 - INFO :       DATASET: tasksource/mmlu high_school_macroeconomics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]
2023-12-01 20:17:04 - INFO :       Use random pruner...
2023-12-01 20:17:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:17:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:17:04 - INFO :       Start Pruning
2023-12-01 20:17:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:17:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:17:06 - INFO :       high_school_macroeconomics: Total Sparsity 1.3526113804059947e-06
2023-12-01 20:17:06 - INFO :       
==================Finish================

2023-12-01 20:17:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:17:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:17:06 - INFO :       DATASET: tasksource/mmlu high_school_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]
2023-12-01 20:17:13 - INFO :       Use random pruner...
2023-12-01 20:17:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:17:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:17:13 - INFO :       Start Pruning
2023-12-01 20:17:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:17:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:17:15 - INFO :       high_school_mathematics: Total Sparsity 1.3630120152872606e-06
2023-12-01 20:17:15 - INFO :       
==================Finish================

2023-12-01 20:17:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:17:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:17:15 - INFO :       DATASET: tasksource/mmlu high_school_microeconomics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 20:17:22 - INFO :       Use random pruner...
2023-12-01 20:17:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:17:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:17:22 - INFO :       Start Pruning
2023-12-01 20:17:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:17:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:17:24 - INFO :       high_school_microeconomics: Total Sparsity 1.3607203499744394e-06
2023-12-01 20:17:24 - INFO :       
==================Finish================

2023-12-01 20:17:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:17:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:17:24 - INFO :       DATASET: tasksource/mmlu high_school_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2023-12-01 20:17:32 - INFO :       Use random pruner...
2023-12-01 20:17:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:17:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:17:33 - INFO :       Start Pruning
2023-12-01 20:17:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:17:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:17:34 - INFO :       high_school_physics: Total Sparsity 1.3651273986529418e-06
2023-12-01 20:17:34 - INFO :       
==================Finish================

2023-12-01 20:17:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:17:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:17:34 - INFO :       DATASET: tasksource/mmlu high_school_psychology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]
2023-12-01 20:17:43 - INFO :       Use random pruner...
2023-12-01 20:17:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:17:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:17:44 - INFO :       Start Pruning
2023-12-01 20:17:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:17:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:17:45 - INFO :       high_school_psychology: Total Sparsity 1.3663613722829226e-06
2023-12-01 20:17:45 - INFO :       
==================Finish================

2023-12-01 20:17:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:17:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:17:45 - INFO :       DATASET: tasksource/mmlu high_school_statistics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 20:17:53 - INFO :       Use random pruner...
2023-12-01 20:17:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:17:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:17:54 - INFO :       Start Pruning
2023-12-01 20:17:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:17:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:17:55 - INFO :       high_school_statistics: Total Sparsity 1.3603677860801591e-06
2023-12-01 20:17:55 - INFO :       
==================Finish================

2023-12-01 20:17:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:17:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:17:55 - INFO :       DATASET: tasksource/mmlu high_school_us_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]
2023-12-01 20:18:05 - INFO :       Use random pruner...
2023-12-01 20:18:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:18:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:18:05 - INFO :       Start Pruning
2023-12-01 20:18:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:18:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:18:07 - INFO :       high_school_us_history: Total Sparsity 1.3603677860801591e-06
2023-12-01 20:18:07 - INFO :       
==================Finish================

2023-12-01 20:18:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:18:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:18:07 - INFO :       DATASET: tasksource/mmlu high_school_world_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2023-12-01 20:18:17 - INFO :       Use random pruner...
2023-12-01 20:18:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:18:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:18:17 - INFO :       Start Pruning
2023-12-01 20:18:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:18:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:18:19 - INFO :       high_school_world_history: Total Sparsity 1.3614254777629999e-06
2023-12-01 20:18:19 - INFO :       
==================Finish================

2023-12-01 20:18:19 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:18:19 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:18:19 - INFO :       DATASET: tasksource/mmlu human_aging
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.43s/it]
2023-12-01 20:18:30 - INFO :       Use random pruner...
2023-12-01 20:18:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:18:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:18:31 - INFO :       Start Pruning
2023-12-01 20:18:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:18:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:18:33 - INFO :       human_aging: Total Sparsity 1.3626594513929806e-06
2023-12-01 20:18:33 - INFO :       
==================Finish================

2023-12-01 20:18:33 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:18:33 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:18:33 - INFO :       DATASET: tasksource/mmlu human_sexuality
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.44s/it]
2023-12-01 20:18:44 - INFO :       Use random pruner...
2023-12-01 20:18:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:18:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:18:45 - INFO :       Start Pruning
2023-12-01 20:18:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:18:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:18:47 - INFO :       human_sexuality: Total Sparsity 1.3728838043271063e-06
2023-12-01 20:18:47 - INFO :       
==================Finish================

2023-12-01 20:18:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:18:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:18:47 - INFO :       DATASET: tasksource/mmlu international_law
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]
2023-12-01 20:18:56 - INFO :       Use random pruner...
2023-12-01 20:18:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:18:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:18:57 - INFO :       Start Pruning
2023-12-01 20:18:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:18:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:18:59 - INFO :       international_law: Total Sparsity 1.3649511167058018e-06
2023-12-01 20:18:59 - INFO :       
==================Finish================

2023-12-01 20:18:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:18:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:18:59 - INFO :       DATASET: tasksource/mmlu jurisprudence
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]
2023-12-01 20:19:09 - INFO :       Use random pruner...
2023-12-01 20:19:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:19:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:19:10 - INFO :       Start Pruning
2023-12-01 20:19:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:19:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:19:12 - INFO :       jurisprudence: Total Sparsity 1.3561370193487967e-06
2023-12-01 20:19:12 - INFO :       
==================Finish================

2023-12-01 20:19:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:19:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:19:12 - INFO :       DATASET: tasksource/mmlu logical_fallacies
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2023-12-01 20:19:21 - INFO :       Use random pruner...
2023-12-01 20:19:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:19:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:19:21 - INFO :       Start Pruning
2023-12-01 20:19:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:19:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:19:23 - INFO :       logical_fallacies: Total Sparsity 1.3614254777629999e-06
2023-12-01 20:19:23 - INFO :       
==================Finish================

2023-12-01 20:19:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:19:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:19:23 - INFO :       DATASET: tasksource/mmlu machine_learning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2023-12-01 20:19:31 - INFO :       Use random pruner...
2023-12-01 20:19:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:19:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:19:31 - INFO :       Start Pruning
2023-12-01 20:19:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:19:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:19:33 - INFO :       machine_learning: Total Sparsity 1.3624831694458404e-06
2023-12-01 20:19:33 - INFO :       
==================Finish================

2023-12-01 20:19:33 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:19:33 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:19:33 - INFO :       DATASET: tasksource/mmlu management
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2023-12-01 20:19:41 - INFO :       Use random pruner...
2023-12-01 20:19:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:19:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:19:42 - INFO :       Start Pruning
2023-12-01 20:19:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:19:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:19:44 - INFO :       management: Total Sparsity 1.3660088083886423e-06
2023-12-01 20:19:44 - INFO :       
==================Finish================

2023-12-01 20:19:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:19:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:19:44 - INFO :       DATASET: tasksource/mmlu marketing
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]
2023-12-01 20:19:53 - INFO :       Use random pruner...
2023-12-01 20:19:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:19:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:19:53 - INFO :       Start Pruning
2023-12-01 20:19:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:19:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:19:55 - INFO :       marketing: Total Sparsity 1.367066500071483e-06
2023-12-01 20:19:55 - INFO :       
==================Finish================

2023-12-01 20:19:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:19:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:19:55 - INFO :       DATASET: tasksource/mmlu medical_genetics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.32s/it]
2023-12-01 20:20:05 - INFO :       Use random pruner...
2023-12-01 20:20:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:20:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:20:05 - INFO :       Start Pruning
2023-12-01 20:20:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:20:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:20:07 - INFO :       medical_genetics: Total Sparsity 1.3679479098071835e-06
2023-12-01 20:20:07 - INFO :       
==================Finish================

2023-12-01 20:20:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:20:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:20:07 - INFO :       DATASET: tasksource/mmlu miscellaneous
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2023-12-01 20:20:19 - INFO :       Use random pruner...
2023-12-01 20:20:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:20:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:20:19 - INFO :       Start Pruning
2023-12-01 20:20:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:20:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:20:21 - INFO :       miscellaneous: Total Sparsity 1.370415857067145e-06
2023-12-01 20:20:21 - INFO :       
==================Finish================

2023-12-01 20:20:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:20:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:20:21 - INFO :       DATASET: tasksource/mmlu moral_disputes
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.30s/it]
2023-12-01 20:20:33 - INFO :       Use random pruner...
2023-12-01 20:20:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:20:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:20:33 - INFO :       Start Pruning
2023-12-01 20:20:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:20:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:20:35 - INFO :       moral_disputes: Total Sparsity 1.3711209848557053e-06
2023-12-01 20:20:35 - INFO :       
==================Finish================

2023-12-01 20:20:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:20:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:20:35 - INFO :       DATASET: tasksource/mmlu moral_scenarios
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.42s/it]
2023-12-01 20:20:46 - INFO :       Use random pruner...
2023-12-01 20:20:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:20:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:20:46 - INFO :       Start Pruning
2023-12-01 20:20:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:20:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:20:48 - INFO :       moral_scenarios: Total Sparsity 1.3709447029085653e-06
2023-12-01 20:20:48 - INFO :       
==================Finish================

2023-12-01 20:20:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:20:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:20:48 - INFO :       DATASET: tasksource/mmlu nutrition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2023-12-01 20:20:57 - INFO :       Use random pruner...
2023-12-01 20:20:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:20:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:20:58 - INFO :       Start Pruning
2023-12-01 20:20:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:20:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:20:59 - INFO :       nutrition: Total Sparsity 1.3651273986529418e-06
2023-12-01 20:20:59 - INFO :       
==================Finish================

2023-12-01 20:20:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:20:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:20:59 - INFO :       DATASET: tasksource/mmlu philosophy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2023-12-01 20:21:11 - INFO :       Use random pruner...
2023-12-01 20:21:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:21:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:21:12 - INFO :       Start Pruning
2023-12-01 20:21:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:21:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:21:13 - INFO :       philosophy: Total Sparsity 1.367242782018623e-06
2023-12-01 20:21:13 - INFO :       
==================Finish================

2023-12-01 20:21:13 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:21:13 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:21:13 - INFO :       DATASET: tasksource/mmlu prehistory
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 20:21:24 - INFO :       Use random pruner...
2023-12-01 20:21:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:21:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:21:24 - INFO :       Start Pruning
2023-12-01 20:21:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:21:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:21:26 - INFO :       prehistory: Total Sparsity 1.3584286846616181e-06
2023-12-01 20:21:26 - INFO :       
==================Finish================

2023-12-01 20:21:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:21:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:21:26 - INFO :       DATASET: tasksource/mmlu professional_accounting
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2023-12-01 20:21:37 - INFO :       Use random pruner...
2023-12-01 20:21:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:21:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:21:38 - INFO :       Start Pruning
2023-12-01 20:21:38 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:21:38 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:21:39 - INFO :       professional_accounting: Total Sparsity 1.3571947110316374e-06
2023-12-01 20:21:39 - INFO :       
==================Finish================

2023-12-01 20:21:39 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:21:39 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:21:39 - INFO :       DATASET: tasksource/mmlu professional_law
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]
2023-12-01 20:21:49 - INFO :       Use random pruner...
2023-12-01 20:21:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:21:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:21:49 - INFO :       Start Pruning
2023-12-01 20:21:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:21:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:21:51 - INFO :       professional_law: Total Sparsity 1.3490857414631927e-06
2023-12-01 20:21:51 - INFO :       
==================Finish================

2023-12-01 20:21:51 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:21:51 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:21:51 - INFO :       DATASET: tasksource/mmlu professional_medicine
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2023-12-01 20:22:00 - INFO :       Use random pruner...
2023-12-01 20:22:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:22:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:22:00 - INFO :       Start Pruning
2023-12-01 20:22:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:22:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:22:02 - INFO :       professional_medicine: Total Sparsity 1.3631882972344008e-06
2023-12-01 20:22:02 - INFO :       
==================Finish================

2023-12-01 20:22:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:22:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:22:02 - INFO :       DATASET: tasksource/mmlu professional_psychology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
2023-12-01 20:22:11 - INFO :       Use random pruner...
2023-12-01 20:22:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:22:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:22:12 - INFO :       Start Pruning
2023-12-01 20:22:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:22:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:22:14 - INFO :       professional_psychology: Total Sparsity 1.3614254777629999e-06
2023-12-01 20:22:14 - INFO :       
==================Finish================

2023-12-01 20:22:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:22:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:22:14 - INFO :       DATASET: tasksource/mmlu public_relations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]
2023-12-01 20:22:24 - INFO :       Use random pruner...
2023-12-01 20:22:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:22:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:22:24 - INFO :       Start Pruning
2023-12-01 20:22:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:22:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:22:26 - INFO :       public_relations: Total Sparsity 1.3561370193487967e-06
2023-12-01 20:22:26 - INFO :       
==================Finish================

2023-12-01 20:22:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:22:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:22:26 - INFO :       DATASET: tasksource/mmlu security_studies
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2023-12-01 20:22:34 - INFO :       Use random pruner...
2023-12-01 20:22:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:22:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:22:35 - INFO :       Start Pruning
2023-12-01 20:22:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:22:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:22:36 - INFO :       security_studies: Total Sparsity 1.36177804165728e-06
2023-12-01 20:22:36 - INFO :       
==================Finish================

2023-12-01 20:22:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:22:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:22:36 - INFO :       DATASET: tasksource/mmlu sociology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]
2023-12-01 20:22:46 - INFO :       Use random pruner...
2023-12-01 20:22:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:22:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:22:46 - INFO :       Start Pruning
2023-12-01 20:22:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:22:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:22:48 - INFO :       sociology: Total Sparsity 1.3561370193487967e-06
2023-12-01 20:22:48 - INFO :       
==================Finish================

2023-12-01 20:22:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:22:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:22:48 - INFO :       DATASET: tasksource/mmlu us_foreign_policy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]
2023-12-01 20:22:58 - INFO :       Use random pruner...
2023-12-01 20:22:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:22:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:22:59 - INFO :       Start Pruning
2023-12-01 20:23:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:23:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:23:01 - INFO :       us_foreign_policy: Total Sparsity 1.3626594513929806e-06
2023-12-01 20:23:01 - INFO :       
==================Finish================

2023-12-01 20:23:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:23:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:23:01 - INFO :       DATASET: tasksource/mmlu virology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 20:23:11 - INFO :       Use random pruner...
2023-12-01 20:23:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:23:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:23:11 - INFO :       Start Pruning
2023-12-01 20:23:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:23:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:23:13 - INFO :       virology: Total Sparsity 1.3698870112257248e-06
2023-12-01 20:23:13 - INFO :       
==================Finish================

2023-12-01 20:23:13 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:23:13 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:23:13 - INFO :       DATASET: tasksource/mmlu world_religions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 20:23:21 - INFO :       Use random pruner...
2023-12-01 20:23:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:23:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:23:22 - INFO :       Start Pruning
2023-12-01 20:23:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:23:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:23:23 - INFO :       world_religions: Total Sparsity 1.3621306055515601e-06
2023-12-01 20:23:23 - INFO :       
==================Finish================

2023-12-01 20:23:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:23:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:23:23 - INFO :       DATASET: math_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 20:23:33 - INFO :       Use random pruner...
2023-12-01 20:23:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:23:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:23:34 - INFO :       Start Pruning
2023-12-01 20:23:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:23:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:23:36 - INFO :       math_qa: Total Sparsity 1.36177804165728e-06
2023-12-01 20:23:36 - INFO :       
==================Finish================

2023-12-01 20:23:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:23:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:23:36 - INFO :       DATASET: EleutherAI/truthful_qa_mc
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
2023-12-01 20:23:45 - INFO :       Use random pruner...
2023-12-01 20:23:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:23:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:23:46 - INFO :       Start Pruning
2023-12-01 20:23:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:23:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:23:48 - INFO :       truthful_qa_mc: Total Sparsity 1.3651273986529418e-06
2023-12-01 20:23:48 - INFO :       
==================Finish================

2023-12-01 20:23:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:23:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:23:48 - INFO :       DATASET: derek-thomas/ScienceQA
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]
2023-12-01 20:23:56 - INFO :       Use random pruner...
2023-12-01 20:23:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:23:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:23:57 - INFO :       Start Pruning
2023-12-01 20:23:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:23:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:23:58 - INFO :       ScienceQA: Total Sparsity 1.36177804165728e-06
2023-12-01 20:23:58 - INFO :       
==================Finish================

2023-12-01 20:23:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:23:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:23:58 - INFO :       DATASET: commonsense_qa
Index 8
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]
2023-12-01 20:24:07 - INFO :       Use random pruner...
2023-12-01 20:24:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:24:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:24:07 - INFO :       Start Pruning
2023-12-01 20:24:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:24:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:24:09 - INFO :       commonsense_qa: Total Sparsity 1.372354958485686e-06
2023-12-01 20:24:09 - INFO :       
==================Finish================

2023-12-01 20:24:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:24:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:24:09 - INFO :       DATASET: tasksource/bigbench abstract_narrative_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
2023-12-01 20:24:19 - INFO :       Use random pruner...
2023-12-01 20:24:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:24:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:24:20 - INFO :       Start Pruning
2023-12-01 20:24:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:24:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:24:21 - INFO :       abstract_narrative_understanding: Total Sparsity 1.3631882972344008e-06
2023-12-01 20:24:21 - INFO :       
==================Finish================

2023-12-01 20:24:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:24:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:24:21 - INFO :       DATASET: tasksource/bigbench anachronisms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 20:24:31 - INFO :       Use random pruner...
2023-12-01 20:24:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:24:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:24:32 - INFO :       Start Pruning
2023-12-01 20:24:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:24:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:24:33 - INFO :       anachronisms: Total Sparsity 1.3633645791815409e-06
2023-12-01 20:24:33 - INFO :       
==================Finish================

2023-12-01 20:24:33 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:24:33 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:24:33 - INFO :       DATASET: tasksource/bigbench analogical_similarity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 20:24:43 - INFO :       Use random pruner...
2023-12-01 20:24:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:24:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:24:44 - INFO :       Start Pruning
2023-12-01 20:24:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:24:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:24:45 - INFO :       analogical_similarity: Total Sparsity 1.3552556096130962e-06
2023-12-01 20:24:45 - INFO :       
==================Finish================

2023-12-01 20:24:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:24:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:24:45 - INFO :       DATASET: tasksource/bigbench analytic_entailment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.50s/it]
2023-12-01 20:24:54 - INFO :       Use random pruner...
2023-12-01 20:24:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:24:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:24:55 - INFO :       Start Pruning
2023-12-01 20:24:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:24:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:24:56 - INFO :       analytic_entailment: Total Sparsity 1.356313301295937e-06
2023-12-01 20:24:56 - INFO :       
==================Finish================

2023-12-01 20:24:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:24:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:24:56 - INFO :       DATASET: tasksource/bigbench arithmetic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 20:25:03 - INFO :       Use random pruner...
2023-12-01 20:25:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:25:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:25:04 - INFO :       Start Pruning
2023-12-01 20:25:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:25:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:25:05 - INFO :       arithmetic: Total Sparsity 1.3610729138687196e-06
2023-12-01 20:25:05 - INFO :       
==================Finish================

2023-12-01 20:25:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:25:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:25:05 - INFO :       DATASET: tasksource/bigbench authorship_verification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 20:25:15 - INFO :       Use random pruner...
2023-12-01 20:25:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:25:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:25:16 - INFO :       Start Pruning
2023-12-01 20:25:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:25:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:25:17 - INFO :       authorship_verification: Total Sparsity 1.360015222185879e-06
2023-12-01 20:25:17 - INFO :       
==================Finish================

2023-12-01 20:25:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:25:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:25:17 - INFO :       DATASET: tasksource/bigbench bbq_lite_json
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2023-12-01 20:25:26 - INFO :       Use random pruner...
2023-12-01 20:25:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:25:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:25:27 - INFO :       Start Pruning
2023-12-01 20:25:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:25:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:25:28 - INFO :       bbq_lite_json: Total Sparsity 1.3598389402387389e-06
2023-12-01 20:25:28 - INFO :       
==================Finish================

2023-12-01 20:25:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:25:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:25:28 - INFO :       DATASET: tasksource/bigbench causal_judgment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]
2023-12-01 20:25:38 - INFO :       Use random pruner...
2023-12-01 20:25:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:25:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:25:38 - INFO :       Start Pruning
2023-12-01 20:25:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:25:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:25:40 - INFO :       causal_judgment: Total Sparsity 1.368653037595744e-06
2023-12-01 20:25:40 - INFO :       
==================Finish================

2023-12-01 20:25:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:25:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:25:40 - INFO :       DATASET: tasksource/bigbench cause_and_effect
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2023-12-01 20:25:50 - INFO :       Use random pruner...
2023-12-01 20:25:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:25:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:25:50 - INFO :       Start Pruning
2023-12-01 20:25:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:25:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:25:52 - INFO :       cause_and_effect: Total Sparsity 1.3645985528115216e-06
2023-12-01 20:25:52 - INFO :       
==================Finish================

2023-12-01 20:25:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:25:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:25:52 - INFO :       DATASET: tasksource/bigbench checkmate_in_one
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 20:26:02 - INFO :       Use random pruner...
2023-12-01 20:26:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:26:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:26:02 - INFO :       Start Pruning
2023-12-01 20:26:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:26:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:26:04 - INFO :       checkmate_in_one: Total Sparsity 1.3584286846616181e-06
2023-12-01 20:26:04 - INFO :       
==================Finish================

2023-12-01 20:26:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:26:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:26:04 - INFO :       DATASET: tasksource/bigbench cifar10_classification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2023-12-01 20:26:14 - INFO :       Use random pruner...
2023-12-01 20:26:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:26:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:26:15 - INFO :       Start Pruning
2023-12-01 20:26:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:26:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:26:16 - INFO :       cifar10_classification: Total Sparsity 1.3640697069701013e-06
2023-12-01 20:26:16 - INFO :       
==================Finish================

2023-12-01 20:26:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:26:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:26:16 - INFO :       DATASET: tasksource/bigbench code_line_description
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 20:26:26 - INFO :       Use random pruner...
2023-12-01 20:26:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:26:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:26:26 - INFO :       Start Pruning
2023-12-01 20:26:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:26:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:26:28 - INFO :       code_line_description: Total Sparsity 1.3674190639657633e-06
2023-12-01 20:26:28 - INFO :       
==================Finish================

2023-12-01 20:26:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:26:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:26:28 - INFO :       DATASET: tasksource/bigbench color
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2023-12-01 20:26:38 - INFO :       Use random pruner...
2023-12-01 20:26:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:26:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:26:38 - INFO :       Start Pruning
2023-12-01 20:26:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:26:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:26:40 - INFO :       color: Total Sparsity 1.3573709929787774e-06
2023-12-01 20:26:40 - INFO :       
==================Finish================

2023-12-01 20:26:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:26:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:26:40 - INFO :       DATASET: tasksource/bigbench common_morpheme
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2023-12-01 20:26:49 - INFO :       Use random pruner...
2023-12-01 20:26:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:26:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:26:50 - INFO :       Start Pruning
2023-12-01 20:26:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:26:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:26:51 - INFO :       common_morpheme: Total Sparsity 1.3566658651902172e-06
2023-12-01 20:26:51 - INFO :       
==================Finish================

2023-12-01 20:26:51 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:26:51 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:26:51 - INFO :       DATASET: tasksource/bigbench conceptual_combinations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]
2023-12-01 20:27:00 - INFO :       Use random pruner...
2023-12-01 20:27:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:27:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:27:00 - INFO :       Start Pruning
2023-12-01 20:27:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:27:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:27:02 - INFO :       conceptual_combinations: Total Sparsity 1.3587812485558984e-06
2023-12-01 20:27:02 - INFO :       
==================Finish================

2023-12-01 20:27:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:27:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:27:02 - INFO :       DATASET: tasksource/bigbench crash_blossom
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.34s/it]
2023-12-01 20:27:12 - INFO :       Use random pruner...
2023-12-01 20:27:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:27:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:27:13 - INFO :       Start Pruning
2023-12-01 20:27:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:27:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:27:14 - INFO :       crash_blossom: Total Sparsity 1.36177804165728e-06
2023-12-01 20:27:14 - INFO :       
==================Finish================

2023-12-01 20:27:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:27:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:27:14 - INFO :       DATASET: tasksource/bigbench crass_ai
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]
2023-12-01 20:27:22 - INFO :       Use random pruner...
2023-12-01 20:27:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:27:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:27:22 - INFO :       Start Pruning
2023-12-01 20:27:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:27:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:27:24 - INFO :       crass_ai: Total Sparsity 1.3623068874987003e-06
2023-12-01 20:27:24 - INFO :       
==================Finish================

2023-12-01 20:27:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:27:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:27:24 - INFO :       DATASET: tasksource/bigbench cryobiology_spanish
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2023-12-01 20:27:34 - INFO :       Use random pruner...
2023-12-01 20:27:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:27:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:27:35 - INFO :       Start Pruning
2023-12-01 20:27:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:27:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:27:36 - INFO :       cryobiology_spanish: Total Sparsity 1.3631882972344008e-06
2023-12-01 20:27:36 - INFO :       
==================Finish================

2023-12-01 20:27:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:27:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:27:36 - INFO :       DATASET: tasksource/bigbench cs_algorithms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]
2023-12-01 20:27:47 - INFO :       Use random pruner...
2023-12-01 20:27:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:27:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:27:47 - INFO :       Start Pruning
2023-12-01 20:27:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:27:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:27:49 - INFO :       cs_algorithms: Total Sparsity 1.368653037595744e-06
2023-12-01 20:27:49 - INFO :       
==================Finish================

2023-12-01 20:27:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:27:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:27:49 - INFO :       DATASET: tasksource/bigbench dark_humor_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2023-12-01 20:27:58 - INFO :       Use random pruner...
2023-12-01 20:27:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:27:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:27:59 - INFO :       Start Pruning
2023-12-01 20:28:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:28:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:28:01 - INFO :       dark_humor_detection: Total Sparsity 1.3776434168998892e-06
2023-12-01 20:28:01 - INFO :       
==================Finish================

2023-12-01 20:28:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:28:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:28:01 - INFO :       DATASET: tasksource/bigbench date_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]
2023-12-01 20:28:10 - INFO :       Use random pruner...
2023-12-01 20:28:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:28:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:28:10 - INFO :       Start Pruning
2023-12-01 20:28:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:28:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:28:12 - INFO :       date_understanding: Total Sparsity 1.3631882972344008e-06
2023-12-01 20:28:12 - INFO :       
==================Finish================

2023-12-01 20:28:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:28:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:28:12 - INFO :       DATASET: tasksource/bigbench disambiguation_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.49s/it]
2023-12-01 20:28:21 - INFO :       Use random pruner...
2023-12-01 20:28:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:28:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:28:21 - INFO :       Start Pruning
2023-12-01 20:28:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:28:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:28:23 - INFO :       disambiguation_qa: Total Sparsity 1.3720023945914058e-06
2023-12-01 20:28:23 - INFO :       
==================Finish================

2023-12-01 20:28:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:28:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:28:23 - INFO :       DATASET: tasksource/bigbench discourse_marker_prediction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]
2023-12-01 20:28:33 - INFO :       Use random pruner...
2023-12-01 20:28:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:28:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:28:33 - INFO :       Start Pruning
2023-12-01 20:28:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:28:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:28:35 - INFO :       discourse_marker_prediction: Total Sparsity 1.3575472749259176e-06
2023-12-01 20:28:35 - INFO :       
==================Finish================

2023-12-01 20:28:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:28:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:28:35 - INFO :       DATASET: tasksource/bigbench dyck_languages
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2023-12-01 20:28:44 - INFO :       Use random pruner...
2023-12-01 20:28:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:28:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:28:45 - INFO :       Start Pruning
2023-12-01 20:28:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:28:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:28:46 - INFO :       dyck_languages: Total Sparsity 1.360015222185879e-06
2023-12-01 20:28:46 - INFO :       
==================Finish================

2023-12-01 20:28:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:28:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:28:46 - INFO :       DATASET: tasksource/bigbench elementary_math_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]
2023-12-01 20:28:56 - INFO :       Use random pruner...
2023-12-01 20:28:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:28:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:28:56 - INFO :       Start Pruning
2023-12-01 20:28:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:28:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:28:58 - INFO :       elementary_math_qa: Total Sparsity 1.374117777957087e-06
2023-12-01 20:28:58 - INFO :       
==================Finish================

2023-12-01 20:28:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:28:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:28:58 - INFO :       DATASET: tasksource/bigbench emoji_movie
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
2023-12-01 20:29:08 - INFO :       Use random pruner...
2023-12-01 20:29:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:29:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:29:08 - INFO :       Start Pruning
2023-12-01 20:29:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:29:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:29:10 - INFO :       emoji_movie: Total Sparsity 1.3557844554545167e-06
2023-12-01 20:29:10 - INFO :       
==================Finish================

2023-12-01 20:29:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:29:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:29:10 - INFO :       DATASET: tasksource/bigbench empirical_judgments
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]
2023-12-01 20:29:20 - INFO :       Use random pruner...
2023-12-01 20:29:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:29:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:29:20 - INFO :       Start Pruning
2023-12-01 20:29:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:29:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:29:22 - INFO :       empirical_judgments: Total Sparsity 1.3697107292785845e-06
2023-12-01 20:29:22 - INFO :       
==================Finish================

2023-12-01 20:29:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:29:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:29:22 - INFO :       DATASET: tasksource/bigbench english_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 20:29:32 - INFO :       Use random pruner...
2023-12-01 20:29:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:29:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:29:32 - INFO :       Start Pruning
2023-12-01 20:29:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:29:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:29:34 - INFO :       english_proverbs: Total Sparsity 1.3661850903357826e-06
2023-12-01 20:29:34 - INFO :       
==================Finish================

2023-12-01 20:29:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:29:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:29:34 - INFO :       DATASET: tasksource/bigbench english_russian_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 20:29:41 - INFO :       Use random pruner...
2023-12-01 20:29:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:29:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:29:42 - INFO :       Start Pruning
2023-12-01 20:29:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:29:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:29:44 - INFO :       english_russian_proverbs: Total Sparsity 1.3767620071641887e-06
2023-12-01 20:29:44 - INFO :       
==================Finish================

2023-12-01 20:29:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:29:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:29:44 - INFO :       DATASET: tasksource/bigbench entailed_polarity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]
2023-12-01 20:29:53 - INFO :       Use random pruner...
2023-12-01 20:29:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:29:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:29:53 - INFO :       Start Pruning
2023-12-01 20:29:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:29:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:29:55 - INFO :       entailed_polarity: Total Sparsity 1.365479962547222e-06
2023-12-01 20:29:55 - INFO :       
==================Finish================

2023-12-01 20:29:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:29:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:29:55 - INFO :       DATASET: tasksource/bigbench entailed_polarity_hindi
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 20:30:05 - INFO :       Use random pruner...
2023-12-01 20:30:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:30:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:30:05 - INFO :       Start Pruning
2023-12-01 20:30:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:30:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:30:07 - INFO :       entailed_polarity_hindi: Total Sparsity 1.3616017597101399e-06
2023-12-01 20:30:07 - INFO :       
==================Finish================

2023-12-01 20:30:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:30:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:30:07 - INFO :       DATASET: tasksource/bigbench epistemic_reasoning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]
2023-12-01 20:30:16 - INFO :       Use random pruner...
2023-12-01 20:30:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:30:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:30:16 - INFO :       Start Pruning
2023-12-01 20:30:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:30:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:30:18 - INFO :       epistemic_reasoning: Total Sparsity 1.3661850903357826e-06
2023-12-01 20:30:18 - INFO :       
==================Finish================

2023-12-01 20:30:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:30:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:30:18 - INFO :       DATASET: tasksource/bigbench evaluating_information_essentiality
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2023-12-01 20:30:28 - INFO :       Use random pruner...
2023-12-01 20:30:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:30:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:30:29 - INFO :       Start Pruning
2023-12-01 20:30:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:30:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:30:31 - INFO :       evaluating_information_essentiality: Total Sparsity 1.3568421471373572e-06
2023-12-01 20:30:31 - INFO :       
==================Finish================

2023-12-01 20:30:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:30:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:30:31 - INFO :       DATASET: tasksource/bigbench fact_checker
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 20:30:41 - INFO :       Use random pruner...
2023-12-01 20:30:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:30:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:30:41 - INFO :       Start Pruning
2023-12-01 20:30:42 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:30:42 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:30:43 - INFO :       fact_checker: Total Sparsity 1.3649511167058018e-06
2023-12-01 20:30:43 - INFO :       
==================Finish================

2023-12-01 20:30:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:30:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:30:43 - INFO :       DATASET: tasksource/bigbench fantasy_reasoning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]
2023-12-01 20:30:51 - INFO :       Use random pruner...
2023-12-01 20:30:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:30:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:30:52 - INFO :       Start Pruning
2023-12-01 20:30:53 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:30:53 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:30:54 - INFO :       fantasy_reasoning: Total Sparsity 1.3596626582915989e-06
2023-12-01 20:30:54 - INFO :       
==================Finish================

2023-12-01 20:30:54 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:30:54 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:30:54 - INFO :       DATASET: tasksource/bigbench figure_of_speech_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]
2023-12-01 20:31:04 - INFO :       Use random pruner...
2023-12-01 20:31:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:31:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:31:04 - INFO :       Start Pruning
2023-12-01 20:31:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:31:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:31:06 - INFO :       figure_of_speech_detection: Total Sparsity 1.3718261126442658e-06
2023-12-01 20:31:06 - INFO :       
==================Finish================

2023-12-01 20:31:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:31:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:31:06 - INFO :       DATASET: tasksource/bigbench formal_fallacies_syllogisms_negation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]
2023-12-01 20:31:13 - INFO :       Use random pruner...
2023-12-01 20:31:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:31:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:31:14 - INFO :       Start Pruning
2023-12-01 20:31:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:31:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:31:16 - INFO :       formal_fallacies_syllogisms_negation: Total Sparsity 1.3633645791815409e-06
2023-12-01 20:31:16 - INFO :       
==================Finish================

2023-12-01 20:31:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:31:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:31:16 - INFO :       DATASET: tasksource/bigbench general_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]
2023-12-01 20:31:26 - INFO :       Use random pruner...
2023-12-01 20:31:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:31:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:31:26 - INFO :       Start Pruning
2023-12-01 20:31:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:31:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:31:28 - INFO :       general_knowledge: Total Sparsity 1.3566658651902172e-06
2023-12-01 20:31:28 - INFO :       
==================Finish================

2023-12-01 20:31:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:31:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:31:28 - INFO :       DATASET: tasksource/bigbench geometric_shapes
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]
2023-12-01 20:31:38 - INFO :       Use random pruner...
2023-12-01 20:31:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:31:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:31:39 - INFO :       Start Pruning
2023-12-01 20:31:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:31:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:31:40 - INFO :       geometric_shapes: Total Sparsity 1.3665376542300628e-06
2023-12-01 20:31:40 - INFO :       
==================Finish================

2023-12-01 20:31:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:31:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:31:40 - INFO :       DATASET: tasksource/bigbench goal_step_wikihow
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.22s/it]
2023-12-01 20:31:51 - INFO :       Use random pruner...
2023-12-01 20:31:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:31:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:31:51 - INFO :       Start Pruning
2023-12-01 20:31:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:31:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:31:53 - INFO :       goal_step_wikihow: Total Sparsity 1.356313301295937e-06
2023-12-01 20:31:53 - INFO :       
==================Finish================

2023-12-01 20:31:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:31:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:31:53 - INFO :       DATASET: tasksource/bigbench gre_reading_comprehension
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 20:32:02 - INFO :       Use random pruner...
2023-12-01 20:32:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:32:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:32:03 - INFO :       Start Pruning
2023-12-01 20:32:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:32:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:32:04 - INFO :       gre_reading_comprehension: Total Sparsity 1.3594863763444586e-06
2023-12-01 20:32:04 - INFO :       
==================Finish================

2023-12-01 20:32:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:32:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:32:04 - INFO :       DATASET: tasksource/bigbench hhh_alignment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]
2023-12-01 20:32:14 - INFO :       Use random pruner...
2023-12-01 20:32:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:32:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:32:14 - INFO :       Start Pruning
2023-12-01 20:32:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:32:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:32:16 - INFO :       hhh_alignment: Total Sparsity 1.3633645791815409e-06
2023-12-01 20:32:16 - INFO :       
==================Finish================

2023-12-01 20:32:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:32:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:32:16 - INFO :       DATASET: tasksource/bigbench hindu_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 20:32:26 - INFO :       Use random pruner...
2023-12-01 20:32:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:32:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:32:26 - INFO :       Start Pruning
2023-12-01 20:32:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:32:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:32:28 - INFO :       hindu_knowledge: Total Sparsity 1.3658325264415023e-06
2023-12-01 20:32:28 - INFO :       
==================Finish================

2023-12-01 20:32:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:32:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:32:28 - INFO :       DATASET: tasksource/bigbench hinglish_toxicity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]
2023-12-01 20:32:37 - INFO :       Use random pruner...
2023-12-01 20:32:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:32:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:32:38 - INFO :       Start Pruning
2023-12-01 20:32:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:32:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:32:40 - INFO :       hinglish_toxicity: Total Sparsity 1.3709447029085653e-06
2023-12-01 20:32:40 - INFO :       
==================Finish================

2023-12-01 20:32:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:32:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:32:40 - INFO :       DATASET: tasksource/bigbench human_organs_senses
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]
2023-12-01 20:32:50 - INFO :       Use random pruner...
2023-12-01 20:32:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:32:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:32:50 - INFO :       Start Pruning
2023-12-01 20:32:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:32:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:32:52 - INFO :       human_organs_senses: Total Sparsity 1.3647748347586618e-06
2023-12-01 20:32:52 - INFO :       
==================Finish================

2023-12-01 20:32:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:32:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:32:52 - INFO :       DATASET: tasksource/bigbench hyperbaton
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2023-12-01 20:33:01 - INFO :       Use random pruner...
2023-12-01 20:33:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:33:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:33:02 - INFO :       Start Pruning
2023-12-01 20:33:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:33:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:33:04 - INFO :       hyperbaton: Total Sparsity 1.3619543236044201e-06
2023-12-01 20:33:04 - INFO :       
==================Finish================

2023-12-01 20:33:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:33:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:33:04 - INFO :       DATASET: tasksource/bigbench identify_math_theorems
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]
2023-12-01 20:33:12 - INFO :       Use random pruner...
2023-12-01 20:33:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:33:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:33:12 - INFO :       Start Pruning
2023-12-01 20:33:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:33:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:33:14 - INFO :       identify_math_theorems: Total Sparsity 1.372178676538546e-06
2023-12-01 20:33:14 - INFO :       
==================Finish================

2023-12-01 20:33:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:33:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:33:14 - INFO :       DATASET: tasksource/bigbench identify_odd_metaphor
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]
2023-12-01 20:33:23 - INFO :       Use random pruner...
2023-12-01 20:33:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:33:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:33:24 - INFO :       Start Pruning
2023-12-01 20:33:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:33:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:33:26 - INFO :       identify_odd_metaphor: Total Sparsity 1.369005601490024e-06
2023-12-01 20:33:26 - INFO :       
==================Finish================

2023-12-01 20:33:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:33:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:33:26 - INFO :       DATASET: tasksource/bigbench implicatures
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 20:33:34 - INFO :       Use random pruner...
2023-12-01 20:33:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:33:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:33:35 - INFO :       Start Pruning
2023-12-01 20:33:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:33:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:33:37 - INFO :       implicatures: Total Sparsity 1.3647748347586618e-06
2023-12-01 20:33:37 - INFO :       
==================Finish================

2023-12-01 20:33:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:33:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:33:37 - INFO :       DATASET: tasksource/bigbench implicit_relations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]
2023-12-01 20:33:46 - INFO :       Use random pruner...
2023-12-01 20:33:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:33:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:33:47 - INFO :       Start Pruning
2023-12-01 20:33:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:33:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:33:49 - INFO :       implicit_relations: Total Sparsity 1.3601915041330191e-06
2023-12-01 20:33:49 - INFO :       
==================Finish================

2023-12-01 20:33:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:33:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:33:49 - INFO :       DATASET: tasksource/bigbench indic_cause_and_effect
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 20:33:58 - INFO :       Use random pruner...
2023-12-01 20:33:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:33:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:33:58 - INFO :       Start Pruning
2023-12-01 20:33:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:33:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:34:00 - INFO :       indic_cause_and_effect: Total Sparsity 1.3608966319215796e-06
2023-12-01 20:34:00 - INFO :       
==================Finish================

2023-12-01 20:34:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:34:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:34:00 - INFO :       DATASET: tasksource/bigbench intent_recognition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2023-12-01 20:34:10 - INFO :       Use random pruner...
2023-12-01 20:34:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:34:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:34:10 - INFO :       Start Pruning
2023-12-01 20:34:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:34:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:34:12 - INFO :       intent_recognition: Total Sparsity 1.3561370193487967e-06
2023-12-01 20:34:12 - INFO :       
==================Finish================

2023-12-01 20:34:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:34:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:34:12 - INFO :       DATASET: tasksource/bigbench international_phonetic_alphabet_nli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]
2023-12-01 20:34:21 - INFO :       Use random pruner...
2023-12-01 20:34:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:34:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:34:22 - INFO :       Start Pruning
2023-12-01 20:34:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:34:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:34:24 - INFO :       international_phonetic_alphabet_nli: Total Sparsity 1.3631882972344008e-06
2023-12-01 20:34:24 - INFO :       
==================Finish================

2023-12-01 20:34:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:34:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:34:24 - INFO :       DATASET: tasksource/bigbench intersect_geometry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]
2023-12-01 20:34:33 - INFO :       Use random pruner...
2023-12-01 20:34:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:34:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:34:34 - INFO :       Start Pruning
2023-12-01 20:34:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:34:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:34:36 - INFO :       intersect_geometry: Total Sparsity 1.367242782018623e-06
2023-12-01 20:34:36 - INFO :       
==================Finish================

2023-12-01 20:34:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:34:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:34:36 - INFO :       DATASET: tasksource/bigbench irony_identification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]
2023-12-01 20:34:45 - INFO :       Use random pruner...
2023-12-01 20:34:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:34:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:34:46 - INFO :       Start Pruning
2023-12-01 20:34:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:34:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:34:47 - INFO :       irony_identification: Total Sparsity 1.3630120152872606e-06
2023-12-01 20:34:47 - INFO :       
==================Finish================

2023-12-01 20:34:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:34:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:34:47 - INFO :       DATASET: tasksource/bigbench kannada
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]
2023-12-01 20:34:57 - INFO :       Use random pruner...
2023-12-01 20:34:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:34:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:34:57 - INFO :       Start Pruning
2023-12-01 20:34:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:34:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:34:59 - INFO :       kannada: Total Sparsity 1.3619543236044201e-06
2023-12-01 20:34:59 - INFO :       
==================Finish================

2023-12-01 20:34:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:34:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:34:59 - INFO :       DATASET: tasksource/bigbench key_value_maps
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2023-12-01 20:35:09 - INFO :       Use random pruner...
2023-12-01 20:35:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:35:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:35:09 - INFO :       Start Pruning
2023-12-01 20:35:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:35:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:35:11 - INFO :       key_value_maps: Total Sparsity 1.372178676538546e-06
2023-12-01 20:35:11 - INFO :       
==================Finish================

2023-12-01 20:35:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:35:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:35:11 - INFO :       DATASET: tasksource/bigbench known_unknowns
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2023-12-01 20:35:20 - INFO :       Use random pruner...
2023-12-01 20:35:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:35:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:35:21 - INFO :       Start Pruning
2023-12-01 20:35:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:35:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:35:23 - INFO :       known_unknowns: Total Sparsity 1.3675953459129033e-06
2023-12-01 20:35:23 - INFO :       
==================Finish================

2023-12-01 20:35:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:35:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:35:23 - INFO :       DATASET: tasksource/bigbench language_identification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 20:35:30 - INFO :       Use random pruner...
2023-12-01 20:35:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:35:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:35:31 - INFO :       Start Pruning
2023-12-01 20:35:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:35:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:35:32 - INFO :       language_identification: Total Sparsity 1.358076120767338e-06
2023-12-01 20:35:32 - INFO :       
==================Finish================

2023-12-01 20:35:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:35:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:35:32 - INFO :       DATASET: tasksource/bigbench logic_grid_puzzle
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
2023-12-01 20:35:42 - INFO :       Use random pruner...
2023-12-01 20:35:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:35:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:35:43 - INFO :       Start Pruning
2023-12-01 20:35:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:35:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:35:45 - INFO :       logic_grid_puzzle: Total Sparsity 1.3610729138687196e-06
2023-12-01 20:35:45 - INFO :       
==================Finish================

2023-12-01 20:35:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:35:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:35:45 - INFO :       DATASET: tasksource/bigbench logical_args
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 20:35:55 - INFO :       Use random pruner...
2023-12-01 20:35:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:35:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:35:55 - INFO :       Start Pruning
2023-12-01 20:35:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:35:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:35:57 - INFO :       logical_args: Total Sparsity 1.3645985528115216e-06
2023-12-01 20:35:57 - INFO :       
==================Finish================

2023-12-01 20:35:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:35:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:35:57 - INFO :       DATASET: tasksource/bigbench logical_deduction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]
2023-12-01 20:36:07 - INFO :       Use random pruner...
2023-12-01 20:36:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:36:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:36:07 - INFO :       Start Pruning
2023-12-01 20:36:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:36:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:36:09 - INFO :       logical_deduction: Total Sparsity 1.3660088083886423e-06
2023-12-01 20:36:09 - INFO :       
==================Finish================

2023-12-01 20:36:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:36:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:36:09 - INFO :       DATASET: tasksource/bigbench logical_fallacy_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 20:36:19 - INFO :       Use random pruner...
2023-12-01 20:36:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:36:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:36:19 - INFO :       Start Pruning
2023-12-01 20:36:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:36:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:36:21 - INFO :       logical_fallacy_detection: Total Sparsity 1.3570184290844972e-06
2023-12-01 20:36:21 - INFO :       
==================Finish================

2023-12-01 20:36:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:36:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:36:21 - INFO :       DATASET: tasksource/bigbench logical_sequence
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2023-12-01 20:36:31 - INFO :       Use random pruner...
2023-12-01 20:36:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:36:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:36:31 - INFO :       Start Pruning
2023-12-01 20:36:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:36:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:36:33 - INFO :       logical_sequence: Total Sparsity 1.351201124828874e-06
2023-12-01 20:36:33 - INFO :       
==================Finish================

2023-12-01 20:36:33 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:36:33 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:36:33 - INFO :       DATASET: tasksource/bigbench mathematical_induction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]
2023-12-01 20:36:42 - INFO :       Use random pruner...
2023-12-01 20:36:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:36:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:36:42 - INFO :       Start Pruning
2023-12-01 20:36:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:36:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:36:44 - INFO :       mathematical_induction: Total Sparsity 1.3675953459129033e-06
2023-12-01 20:36:44 - INFO :       
==================Finish================

2023-12-01 20:36:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:36:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:36:44 - INFO :       DATASET: tasksource/bigbench medical_questions_russian
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
2023-12-01 20:36:53 - INFO :       Use random pruner...
2023-12-01 20:36:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:36:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:36:54 - INFO :       Start Pruning
2023-12-01 20:36:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:36:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:36:55 - INFO :       medical_questions_russian: Total Sparsity 1.3594863763444586e-06
2023-12-01 20:36:55 - INFO :       
==================Finish================

2023-12-01 20:36:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:36:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:36:55 - INFO :       DATASET: tasksource/bigbench metaphor_boolean
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
2023-12-01 20:37:05 - INFO :       Use random pruner...
2023-12-01 20:37:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:37:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:37:06 - INFO :       Start Pruning
2023-12-01 20:37:07 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:37:07 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:37:07 - INFO :       metaphor_boolean: Total Sparsity 1.3621306055515601e-06
2023-12-01 20:37:07 - INFO :       
==================Finish================

2023-12-01 20:37:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:37:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:37:07 - INFO :       DATASET: tasksource/bigbench metaphor_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2023-12-01 20:37:16 - INFO :       Use random pruner...
2023-12-01 20:37:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:37:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:37:16 - INFO :       Start Pruning
2023-12-01 20:37:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:37:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:37:18 - INFO :       metaphor_understanding: Total Sparsity 1.3614254777629999e-06
2023-12-01 20:37:18 - INFO :       
==================Finish================

2023-12-01 20:37:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:37:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:37:18 - INFO :       DATASET: tasksource/bigbench misconceptions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  3.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]
2023-12-01 20:37:29 - INFO :       Use random pruner...
2023-12-01 20:37:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:37:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:37:29 - INFO :       Start Pruning
2023-12-01 20:37:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:37:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:37:31 - INFO :       misconceptions: Total Sparsity 1.360015222185879e-06
2023-12-01 20:37:31 - INFO :       
==================Finish================

2023-12-01 20:37:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:37:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:37:31 - INFO :       DATASET: tasksource/bigbench misconceptions_russian
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 20:37:41 - INFO :       Use random pruner...
2023-12-01 20:37:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:37:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:37:41 - INFO :       Start Pruning
2023-12-01 20:37:42 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:37:42 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:37:43 - INFO :       misconceptions_russian: Total Sparsity 1.3584286846616181e-06
2023-12-01 20:37:43 - INFO :       
==================Finish================

2023-12-01 20:37:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:37:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:37:43 - INFO :       DATASET: tasksource/bigbench mnist_ascii
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 20:37:52 - INFO :       Use random pruner...
2023-12-01 20:37:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:37:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:37:53 - INFO :       Start Pruning
2023-12-01 20:37:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:37:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:37:54 - INFO :       mnist_ascii: Total Sparsity 1.360015222185879e-06
2023-12-01 20:37:54 - INFO :       
==================Finish================

2023-12-01 20:37:54 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:37:54 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:37:54 - INFO :       DATASET: tasksource/bigbench moral_permissibility
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2023-12-01 20:38:03 - INFO :       Use random pruner...
2023-12-01 20:38:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:38:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:38:04 - INFO :       Start Pruning
2023-12-01 20:38:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:38:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:38:05 - INFO :       moral_permissibility: Total Sparsity 1.3538453540359754e-06
2023-12-01 20:38:05 - INFO :       
==================Finish================

2023-12-01 20:38:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:38:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:38:05 - INFO :       DATASET: tasksource/bigbench movie_dialog_same_or_different
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2023-12-01 20:38:15 - INFO :       Use random pruner...
2023-12-01 20:38:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:38:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:38:15 - INFO :       Start Pruning
2023-12-01 20:38:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:38:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:38:17 - INFO :       movie_dialog_same_or_different: Total Sparsity 1.3601915041330191e-06
2023-12-01 20:38:17 - INFO :       
==================Finish================

2023-12-01 20:38:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:38:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:38:17 - INFO :       DATASET: tasksource/bigbench movie_recommendation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]
2023-12-01 20:38:26 - INFO :       Use random pruner...
2023-12-01 20:38:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:38:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:38:26 - INFO :       Start Pruning
2023-12-01 20:38:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:38:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:38:28 - INFO :       movie_recommendation: Total Sparsity 1.3608966319215796e-06
2023-12-01 20:38:28 - INFO :       
==================Finish================

2023-12-01 20:38:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:38:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:38:28 - INFO :       DATASET: tasksource/bigbench navigate
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 20:38:37 - INFO :       Use random pruner...
2023-12-01 20:38:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:38:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:38:37 - INFO :       Start Pruning
2023-12-01 20:38:38 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:38:38 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:38:39 - INFO :       navigate: Total Sparsity 1.3638934250229613e-06
2023-12-01 20:38:39 - INFO :       
==================Finish================

2023-12-01 20:38:39 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:38:39 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:38:39 - INFO :       DATASET: tasksource/bigbench nonsense_words_grammar
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 20:38:46 - INFO :       Use random pruner...
2023-12-01 20:38:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:38:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:38:46 - INFO :       Start Pruning
2023-12-01 20:38:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:38:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:38:48 - INFO :       nonsense_words_grammar: Total Sparsity 1.3573709929787774e-06
2023-12-01 20:38:48 - INFO :       
==================Finish================

2023-12-01 20:38:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:38:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:38:48 - INFO :       DATASET: tasksource/bigbench novel_concepts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]
2023-12-01 20:38:57 - INFO :       Use random pruner...
2023-12-01 20:38:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:38:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:38:58 - INFO :       Start Pruning
2023-12-01 20:38:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:38:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:39:00 - INFO :       novel_concepts: Total Sparsity 1.354726763771676e-06
2023-12-01 20:39:00 - INFO :       
==================Finish================

2023-12-01 20:39:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:39:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:39:00 - INFO :       DATASET: tasksource/bigbench odd_one_out
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 20:39:09 - INFO :       Use random pruner...
2023-12-01 20:39:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:39:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:39:10 - INFO :       Start Pruning
2023-12-01 20:39:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:39:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:39:11 - INFO :       odd_one_out: Total Sparsity 1.363540861128681e-06
2023-12-01 20:39:11 - INFO :       
==================Finish================

2023-12-01 20:39:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:39:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:39:11 - INFO :       DATASET: tasksource/bigbench parsinlu_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2023-12-01 20:39:21 - INFO :       Use random pruner...
2023-12-01 20:39:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:39:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:39:21 - INFO :       Start Pruning
2023-12-01 20:39:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:39:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:39:23 - INFO :       parsinlu_qa: Total Sparsity 1.354550481824536e-06
2023-12-01 20:39:23 - INFO :       
==================Finish================

2023-12-01 20:39:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:39:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:39:23 - INFO :       DATASET: tasksource/bigbench penguins_in_a_table
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2023-12-01 20:39:33 - INFO :       Use random pruner...
2023-12-01 20:39:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:39:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:39:34 - INFO :       Start Pruning
2023-12-01 20:39:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:39:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:39:35 - INFO :       penguins_in_a_table: Total Sparsity 1.3591338124501784e-06
2023-12-01 20:39:35 - INFO :       
==================Finish================

2023-12-01 20:39:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:39:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:39:35 - INFO :       DATASET: tasksource/bigbench persian_idioms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 20:39:45 - INFO :       Use random pruner...
2023-12-01 20:39:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:39:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:39:45 - INFO :       Start Pruning
2023-12-01 20:39:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:39:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:39:47 - INFO :       persian_idioms: Total Sparsity 1.3575472749259176e-06
2023-12-01 20:39:47 - INFO :       
==================Finish================

2023-12-01 20:39:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:39:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:39:47 - INFO :       DATASET: tasksource/bigbench phrase_relatedness
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2023-12-01 20:39:56 - INFO :       Use random pruner...
2023-12-01 20:39:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:39:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:39:57 - INFO :       Start Pruning
2023-12-01 20:39:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:39:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:39:59 - INFO :       phrase_relatedness: Total Sparsity 1.3522588165117145e-06
2023-12-01 20:39:59 - INFO :       
==================Finish================

2023-12-01 20:39:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:39:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:39:59 - INFO :       DATASET: tasksource/bigbench physical_intuition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2023-12-01 20:40:09 - INFO :       Use random pruner...
2023-12-01 20:40:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:40:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:40:09 - INFO :       Start Pruning
2023-12-01 20:40:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:40:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:40:11 - INFO :       physical_intuition: Total Sparsity 1.3612491958158596e-06
2023-12-01 20:40:11 - INFO :       
==================Finish================

2023-12-01 20:40:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:40:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:40:11 - INFO :       DATASET: tasksource/bigbench physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]
2023-12-01 20:40:21 - INFO :       Use random pruner...
2023-12-01 20:40:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:40:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:40:21 - INFO :       Start Pruning
2023-12-01 20:40:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:40:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:40:23 - INFO :       physics: Total Sparsity 1.3661850903357826e-06
2023-12-01 20:40:23 - INFO :       
==================Finish================

2023-12-01 20:40:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:40:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:40:23 - INFO :       DATASET: tasksource/bigbench play_dialog_same_or_different
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]
2023-12-01 20:40:32 - INFO :       Use random pruner...
2023-12-01 20:40:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:40:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:40:33 - INFO :       Start Pruning
2023-12-01 20:40:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:40:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:40:35 - INFO :       play_dialog_same_or_different: Total Sparsity 1.3638934250229613e-06
2023-12-01 20:40:35 - INFO :       
==================Finish================

2023-12-01 20:40:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:40:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:40:35 - INFO :       DATASET: tasksource/bigbench presuppositions_as_nli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2023-12-01 20:40:44 - INFO :       Use random pruner...
2023-12-01 20:40:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:40:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:40:44 - INFO :       Start Pruning
2023-12-01 20:40:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:40:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:40:46 - INFO :       presuppositions_as_nli: Total Sparsity 1.3568421471373572e-06
2023-12-01 20:40:46 - INFO :       
==================Finish================

2023-12-01 20:40:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:40:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:40:46 - INFO :       DATASET: tasksource/bigbench question_selection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]
2023-12-01 20:40:56 - INFO :       Use random pruner...
2023-12-01 20:40:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:40:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:40:56 - INFO :       Start Pruning
2023-12-01 20:40:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:40:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:40:58 - INFO :       question_selection: Total Sparsity 1.3633645791815409e-06
2023-12-01 20:40:58 - INFO :       
==================Finish================

2023-12-01 20:40:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:40:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:40:58 - INFO :       DATASET: tasksource/bigbench reasoning_about_colored_objects
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2023-12-01 20:41:07 - INFO :       Use random pruner...
2023-12-01 20:41:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:41:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:41:07 - INFO :       Start Pruning
2023-12-01 20:41:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:41:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:41:09 - INFO :       reasoning_about_colored_objects: Total Sparsity 1.3601915041330191e-06
2023-12-01 20:41:09 - INFO :       
==================Finish================

2023-12-01 20:41:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:41:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:41:09 - INFO :       DATASET: tasksource/bigbench riddle_sense
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.91s/it]
2023-12-01 20:41:19 - INFO :       Use random pruner...
2023-12-01 20:41:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:41:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:41:19 - INFO :       Start Pruning
2023-12-01 20:41:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:41:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:41:21 - INFO :       riddle_sense: Total Sparsity 1.370592139014285e-06
2023-12-01 20:41:21 - INFO :       
==================Finish================

2023-12-01 20:41:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:41:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:41:21 - INFO :       DATASET: tasksource/bigbench ruin_names
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 20:41:28 - INFO :       Use random pruner...
2023-12-01 20:41:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:41:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:41:29 - INFO :       Start Pruning
2023-12-01 20:41:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:41:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:41:31 - INFO :       ruin_names: Total Sparsity 1.367066500071483e-06
2023-12-01 20:41:31 - INFO :       
==================Finish================

2023-12-01 20:41:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:41:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:41:31 - INFO :       DATASET: tasksource/bigbench salient_translation_error_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]
2023-12-01 20:41:40 - INFO :       Use random pruner...
2023-12-01 20:41:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:41:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:41:40 - INFO :       Start Pruning
2023-12-01 20:41:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:41:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:41:42 - INFO :       salient_translation_error_detection: Total Sparsity 1.3482043317274922e-06
2023-12-01 20:41:42 - INFO :       
==================Finish================

2023-12-01 20:41:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:41:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:41:42 - INFO :       DATASET: tasksource/bigbench sentence_ambiguity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]
2023-12-01 20:41:52 - INFO :       Use random pruner...
2023-12-01 20:41:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:41:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:41:52 - INFO :       Start Pruning
2023-12-01 20:41:53 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:41:53 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:41:54 - INFO :       sentence_ambiguity: Total Sparsity 1.370415857067145e-06
2023-12-01 20:41:54 - INFO :       
==================Finish================

2023-12-01 20:41:54 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:41:54 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:41:54 - INFO :       DATASET: tasksource/bigbench similarities_abstraction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]
2023-12-01 20:42:03 - INFO :       Use random pruner...
2023-12-01 20:42:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:42:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:42:04 - INFO :       Start Pruning
2023-12-01 20:42:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:42:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:42:06 - INFO :       similarities_abstraction: Total Sparsity 1.3730600862742465e-06
2023-12-01 20:42:06 - INFO :       
==================Finish================

2023-12-01 20:42:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:42:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:42:06 - INFO :       DATASET: tasksource/bigbench simple_ethical_questions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]
2023-12-01 20:42:14 - INFO :       Use random pruner...
2023-12-01 20:42:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:42:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:42:15 - INFO :       Start Pruning
2023-12-01 20:42:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:42:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:42:17 - INFO :       simple_ethical_questions: Total Sparsity 1.3568421471373572e-06
2023-12-01 20:42:17 - INFO :       
==================Finish================

2023-12-01 20:42:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:42:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:42:17 - INFO :       DATASET: tasksource/bigbench snarks
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 20:42:24 - INFO :       Use random pruner...
2023-12-01 20:42:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:42:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:42:25 - INFO :       Start Pruning
2023-12-01 20:42:26 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:42:26 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:42:27 - INFO :       snarks: Total Sparsity 1.3524350984588547e-06
2023-12-01 20:42:27 - INFO :       
==================Finish================

2023-12-01 20:42:27 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:42:27 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:42:27 - INFO :       DATASET: tasksource/bigbench social_iqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]
2023-12-01 20:42:35 - INFO :       Use random pruner...
2023-12-01 20:42:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:42:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:42:36 - INFO :       Start Pruning
2023-12-01 20:42:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:42:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:42:37 - INFO :       social_iqa: Total Sparsity 1.367066500071483e-06
2023-12-01 20:42:37 - INFO :       
==================Finish================

2023-12-01 20:42:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:42:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:42:37 - INFO :       DATASET: tasksource/bigbench social_support
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 20:42:45 - INFO :       Use random pruner...
2023-12-01 20:42:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:42:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:42:45 - INFO :       Start Pruning
2023-12-01 20:42:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:42:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:42:47 - INFO :       social_support: Total Sparsity 1.3614254777629999e-06
2023-12-01 20:42:47 - INFO :       
==================Finish================

2023-12-01 20:42:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:42:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:42:47 - INFO :       DATASET: tasksource/bigbench sports_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 20:42:57 - INFO :       Use random pruner...
2023-12-01 20:42:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:42:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:42:58 - INFO :       Start Pruning
2023-12-01 20:42:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:42:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:42:59 - INFO :       sports_understanding: Total Sparsity 1.3638934250229613e-06
2023-12-01 20:42:59 - INFO :       
==================Finish================

2023-12-01 20:42:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:42:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:42:59 - INFO :       DATASET: tasksource/bigbench strange_stories
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 20:43:09 - INFO :       Use random pruner...
2023-12-01 20:43:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:43:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:43:09 - INFO :       Start Pruning
2023-12-01 20:43:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:43:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:43:11 - INFO :       strange_stories: Total Sparsity 1.3517299706702942e-06
2023-12-01 20:43:11 - INFO :       
==================Finish================

2023-12-01 20:43:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:43:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:43:11 - INFO :       DATASET: tasksource/bigbench strategyqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2023-12-01 20:43:20 - INFO :       Use random pruner...
2023-12-01 20:43:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:43:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:43:21 - INFO :       Start Pruning
2023-12-01 20:43:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:43:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:43:23 - INFO :       strategyqa: Total Sparsity 1.3647748347586618e-06
2023-12-01 20:43:23 - INFO :       
==================Finish================

2023-12-01 20:43:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:43:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:43:23 - INFO :       DATASET: tasksource/bigbench suicide_risk
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2023-12-01 20:43:33 - INFO :       Use random pruner...
2023-12-01 20:43:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:43:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:43:33 - INFO :       Start Pruning
2023-12-01 20:43:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:43:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:43:35 - INFO :       suicide_risk: Total Sparsity 1.368829319542884e-06
2023-12-01 20:43:35 - INFO :       
==================Finish================

2023-12-01 20:43:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:43:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:43:35 - INFO :       DATASET: tasksource/bigbench swahili_english_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]
2023-12-01 20:43:45 - INFO :       Use random pruner...
2023-12-01 20:43:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:43:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:43:45 - INFO :       Start Pruning
2023-12-01 20:43:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:43:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:43:47 - INFO :       swahili_english_proverbs: Total Sparsity 1.3684767556486038e-06
2023-12-01 20:43:47 - INFO :       
==================Finish================

2023-12-01 20:43:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:43:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:43:47 - INFO :       DATASET: tasksource/bigbench swedish_to_german_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2023-12-01 20:43:56 - INFO :       Use random pruner...
2023-12-01 20:43:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:43:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:43:56 - INFO :       Start Pruning
2023-12-01 20:43:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:43:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:43:58 - INFO :       swedish_to_german_proverbs: Total Sparsity 1.3667139361772028e-06
2023-12-01 20:43:58 - INFO :       
==================Finish================

2023-12-01 20:43:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:43:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:43:58 - INFO :       DATASET: tasksource/bigbench symbol_interpretation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]
2023-12-01 20:44:09 - INFO :       Use random pruner...
2023-12-01 20:44:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:44:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:44:10 - INFO :       Start Pruning
2023-12-01 20:44:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:44:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:44:11 - INFO :       symbol_interpretation: Total Sparsity 1.3578998388201979e-06
2023-12-01 20:44:11 - INFO :       
==================Finish================

2023-12-01 20:44:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:44:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:44:11 - INFO :       DATASET: tasksource/bigbench temporal_sequences
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
2023-12-01 20:44:21 - INFO :       Use random pruner...
2023-12-01 20:44:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:44:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:44:22 - INFO :       Start Pruning
2023-12-01 20:44:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:44:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:44:24 - INFO :       temporal_sequences: Total Sparsity 1.3658325264415023e-06
2023-12-01 20:44:24 - INFO :       
==================Finish================

2023-12-01 20:44:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:44:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:44:24 - INFO :       DATASET: tasksource/bigbench timedial
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]
2023-12-01 20:44:33 - INFO :       Use random pruner...
2023-12-01 20:44:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:44:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:44:33 - INFO :       Start Pruning
2023-12-01 20:44:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:44:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:44:35 - INFO :       timedial: Total Sparsity 1.351377406776014e-06
2023-12-01 20:44:35 - INFO :       
==================Finish================

2023-12-01 20:44:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:44:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:44:35 - INFO :       DATASET: tasksource/bigbench tracking_shuffled_objects
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2023-12-01 20:44:45 - INFO :       Use random pruner...
2023-12-01 20:44:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:44:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:44:46 - INFO :       Start Pruning
2023-12-01 20:44:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:44:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:44:47 - INFO :       tracking_shuffled_objects: Total Sparsity 1.356313301295937e-06
2023-12-01 20:44:47 - INFO :       
==================Finish================

2023-12-01 20:44:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:44:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:44:47 - INFO :       DATASET: tasksource/bigbench understanding_fables
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
2023-12-01 20:44:57 - INFO :       Use random pruner...
2023-12-01 20:44:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:44:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:44:57 - INFO :       Start Pruning
2023-12-01 20:44:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:44:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:44:59 - INFO :       understanding_fables: Total Sparsity 1.3714735487499855e-06
2023-12-01 20:44:59 - INFO :       
==================Finish================

2023-12-01 20:44:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:44:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:44:59 - INFO :       DATASET: tasksource/bigbench undo_permutation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 20:45:07 - INFO :       Use random pruner...
2023-12-01 20:45:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:45:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:45:07 - INFO :       Start Pruning
2023-12-01 20:45:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:45:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:45:09 - INFO :       undo_permutation: Total Sparsity 1.3601915041330191e-06
2023-12-01 20:45:09 - INFO :       
==================Finish================

2023-12-01 20:45:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:45:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:45:09 - INFO :       DATASET: tasksource/bigbench unit_interpretation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]
2023-12-01 20:45:18 - INFO :       Use random pruner...
2023-12-01 20:45:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:45:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:45:19 - INFO :       Start Pruning
2023-12-01 20:45:19 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:45:19 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:45:20 - INFO :       unit_interpretation: Total Sparsity 1.3593100943973186e-06
2023-12-01 20:45:20 - INFO :       
==================Finish================

2023-12-01 20:45:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:45:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:45:20 - INFO :       DATASET: tasksource/bigbench vitaminc_fact_verification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  3.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]
2023-12-01 20:45:29 - INFO :       Use random pruner...
2023-12-01 20:45:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:45:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:45:29 - INFO :       Start Pruning
2023-12-01 20:45:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:45:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:45:31 - INFO :       vitaminc_fact_verification: Total Sparsity 1.3691818834371643e-06
2023-12-01 20:45:31 - INFO :       
==================Finish================

2023-12-01 20:45:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:45:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:45:31 - INFO :       DATASET: tasksource/bigbench what_is_the_tao
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 20:45:38 - INFO :       Use random pruner...
2023-12-01 20:45:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:45:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:45:38 - INFO :       Start Pruning
2023-12-01 20:45:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:45:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:45:40 - INFO :       what_is_the_tao: Total Sparsity 1.3649511167058018e-06
2023-12-01 20:45:40 - INFO :       
==================Finish================

2023-12-01 20:45:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:45:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:45:40 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 20:45:47 - INFO :       Use random pruner...
2023-12-01 20:45:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:45:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:45:47 - INFO :       Start Pruning
2023-12-01 20:45:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:45:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:45:49 - INFO :       which_wiki_edit: Total Sparsity 1.3607203499744394e-06
2023-12-01 20:45:49 - INFO :       
==================Finish================

2023-12-01 20:45:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:45:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:45:49 - INFO :       DATASET: tasksource/bigbench winowhy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]
2023-12-01 20:45:56 - INFO :       Use random pruner...
2023-12-01 20:45:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:45:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:45:56 - INFO :       Start Pruning
2023-12-01 20:45:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:45:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:45:58 - INFO :       winowhy: Total Sparsity 1.3598389402387389e-06
2023-12-01 20:45:58 - INFO :       
==================Finish================

2023-12-01 20:45:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:45:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:45:58 - INFO :       DATASET: tasksource/mmlu abstract_algebra
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]
2023-12-01 20:46:05 - INFO :       Use random pruner...
2023-12-01 20:46:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:46:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:46:05 - INFO :       Start Pruning
2023-12-01 20:46:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:46:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:46:07 - INFO :       abstract_algebra: Total Sparsity 1.3697107292785845e-06
2023-12-01 20:46:07 - INFO :       
==================Finish================

2023-12-01 20:46:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:46:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:46:07 - INFO :       DATASET: tasksource/mmlu anatomy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 20:46:15 - INFO :       Use random pruner...
2023-12-01 20:46:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:46:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:46:16 - INFO :       Start Pruning
2023-12-01 20:46:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:46:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:46:17 - INFO :       anatomy: Total Sparsity 1.3762331613227682e-06
2023-12-01 20:46:17 - INFO :       
==================Finish================

2023-12-01 20:46:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:46:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:46:17 - INFO :       DATASET: tasksource/mmlu astronomy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
2023-12-01 20:46:27 - INFO :       Use random pruner...
2023-12-01 20:46:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:46:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:46:28 - INFO :       Start Pruning
2023-12-01 20:46:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:46:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:46:29 - INFO :       astronomy: Total Sparsity 1.3556081735073764e-06
2023-12-01 20:46:29 - INFO :       
==================Finish================

2023-12-01 20:46:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:46:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:46:29 - INFO :       DATASET: tasksource/mmlu business_ethics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]
2023-12-01 20:46:39 - INFO :       Use random pruner...
2023-12-01 20:46:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:46:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:46:40 - INFO :       Start Pruning
2023-12-01 20:46:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:46:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:46:41 - INFO :       business_ethics: Total Sparsity 1.368653037595744e-06
2023-12-01 20:46:41 - INFO :       
==================Finish================

2023-12-01 20:46:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:46:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:46:41 - INFO :       DATASET: tasksource/mmlu clinical_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]
2023-12-01 20:46:50 - INFO :       Use random pruner...
2023-12-01 20:46:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:46:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:46:51 - INFO :       Start Pruning
2023-12-01 20:46:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:46:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:46:52 - INFO :       clinical_knowledge: Total Sparsity 1.3645985528115216e-06
2023-12-01 20:46:52 - INFO :       
==================Finish================

2023-12-01 20:46:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:46:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:46:52 - INFO :       DATASET: tasksource/mmlu college_biology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2023-12-01 20:47:00 - INFO :       Use random pruner...
2023-12-01 20:47:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:47:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:47:01 - INFO :       Start Pruning
2023-12-01 20:47:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:47:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:47:02 - INFO :       college_biology: Total Sparsity 1.369005601490024e-06
2023-12-01 20:47:02 - INFO :       
==================Finish================

2023-12-01 20:47:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:47:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:47:02 - INFO :       DATASET: tasksource/mmlu college_chemistry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2023-12-01 20:47:13 - INFO :       Use random pruner...
2023-12-01 20:47:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:47:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:47:13 - INFO :       Start Pruning
2023-12-01 20:47:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:47:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:47:15 - INFO :       college_chemistry: Total Sparsity 1.369005601490024e-06
2023-12-01 20:47:15 - INFO :       
==================Finish================

2023-12-01 20:47:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:47:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:47:15 - INFO :       DATASET: tasksource/mmlu college_computer_science
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]
2023-12-01 20:47:25 - INFO :       Use random pruner...
2023-12-01 20:47:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:47:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:47:25 - INFO :       Start Pruning
2023-12-01 20:47:26 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:47:26 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:47:27 - INFO :       college_computer_science: Total Sparsity 1.3577235568730577e-06
2023-12-01 20:47:27 - INFO :       
==================Finish================

2023-12-01 20:47:27 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:47:27 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:47:27 - INFO :       DATASET: tasksource/mmlu college_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.98s/it]
2023-12-01 20:47:36 - INFO :       Use random pruner...
2023-12-01 20:47:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:47:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:47:37 - INFO :       Start Pruning
2023-12-01 20:47:38 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:47:38 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:47:38 - INFO :       college_mathematics: Total Sparsity 1.3638934250229613e-06
2023-12-01 20:47:38 - INFO :       
==================Finish================

2023-12-01 20:47:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:47:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:47:38 - INFO :       DATASET: tasksource/mmlu college_medicine
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2023-12-01 20:47:48 - INFO :       Use random pruner...
2023-12-01 20:47:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:47:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:47:48 - INFO :       Start Pruning
2023-12-01 20:47:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:47:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:47:50 - INFO :       college_medicine: Total Sparsity 1.3601915041330191e-06
2023-12-01 20:47:50 - INFO :       
==================Finish================

2023-12-01 20:47:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:47:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:47:50 - INFO :       DATASET: tasksource/mmlu college_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]
2023-12-01 20:48:00 - INFO :       Use random pruner...
2023-12-01 20:48:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:48:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:48:00 - INFO :       Start Pruning
2023-12-01 20:48:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:48:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:48:02 - INFO :       college_physics: Total Sparsity 1.3610729138687196e-06
2023-12-01 20:48:02 - INFO :       
==================Finish================

2023-12-01 20:48:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:48:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:48:02 - INFO :       DATASET: tasksource/mmlu computer_security
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]
2023-12-01 20:48:12 - INFO :       Use random pruner...
2023-12-01 20:48:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:48:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:48:12 - INFO :       Start Pruning
2023-12-01 20:48:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:48:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:48:14 - INFO :       computer_security: Total Sparsity 1.3663613722829226e-06
2023-12-01 20:48:14 - INFO :       
==================Finish================

2023-12-01 20:48:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:48:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:48:14 - INFO :       DATASET: tasksource/mmlu conceptual_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]
2023-12-01 20:48:23 - INFO :       Use random pruner...
2023-12-01 20:48:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:48:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:48:24 - INFO :       Start Pruning
2023-12-01 20:48:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:48:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:48:25 - INFO :       conceptual_physics: Total Sparsity 1.3720023945914058e-06
2023-12-01 20:48:25 - INFO :       
==================Finish================

2023-12-01 20:48:25 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:48:25 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:48:25 - INFO :       DATASET: tasksource/mmlu econometrics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
2023-12-01 20:48:35 - INFO :       Use random pruner...
2023-12-01 20:48:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:48:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:48:36 - INFO :       Start Pruning
2023-12-01 20:48:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:48:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:48:38 - INFO :       econometrics: Total Sparsity 1.3711209848557053e-06
2023-12-01 20:48:38 - INFO :       
==================Finish================

2023-12-01 20:48:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:48:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:48:38 - INFO :       DATASET: tasksource/mmlu electrical_engineering
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2023-12-01 20:48:48 - INFO :       Use random pruner...
2023-12-01 20:48:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:48:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:48:48 - INFO :       Start Pruning
2023-12-01 20:48:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:48:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:48:50 - INFO :       electrical_engineering: Total Sparsity 1.3538453540359754e-06
2023-12-01 20:48:50 - INFO :       
==================Finish================

2023-12-01 20:48:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:48:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:48:50 - INFO :       DATASET: tasksource/mmlu elementary_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
2023-12-01 20:48:59 - INFO :       Use random pruner...
2023-12-01 20:48:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:48:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:49:00 - INFO :       Start Pruning
2023-12-01 20:49:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:49:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:49:02 - INFO :       elementary_mathematics: Total Sparsity 1.3649511167058018e-06
2023-12-01 20:49:02 - INFO :       
==================Finish================

2023-12-01 20:49:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:49:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:49:02 - INFO :       DATASET: tasksource/mmlu formal_logic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 20:49:10 - INFO :       Use random pruner...
2023-12-01 20:49:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:49:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:49:11 - INFO :       Start Pruning
2023-12-01 20:49:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:49:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:49:12 - INFO :       formal_logic: Total Sparsity 1.3631882972344008e-06
2023-12-01 20:49:12 - INFO :       
==================Finish================

2023-12-01 20:49:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:49:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:49:12 - INFO :       DATASET: tasksource/mmlu global_facts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]
2023-12-01 20:49:19 - INFO :       Use random pruner...
2023-12-01 20:49:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:49:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:49:20 - INFO :       Start Pruning
2023-12-01 20:49:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:49:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:49:21 - INFO :       global_facts: Total Sparsity 1.3601915041330191e-06
2023-12-01 20:49:21 - INFO :       
==================Finish================

2023-12-01 20:49:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:49:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:49:21 - INFO :       DATASET: tasksource/mmlu high_school_biology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 20:49:28 - INFO :       Use random pruner...
2023-12-01 20:49:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:49:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:49:28 - INFO :       Start Pruning
2023-12-01 20:49:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:49:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:49:30 - INFO :       high_school_biology: Total Sparsity 1.369005601490024e-06
2023-12-01 20:49:30 - INFO :       
==================Finish================

2023-12-01 20:49:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:49:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:49:30 - INFO :       DATASET: tasksource/mmlu high_school_chemistry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 20:49:37 - INFO :       Use random pruner...
2023-12-01 20:49:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:49:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:49:37 - INFO :       Start Pruning
2023-12-01 20:49:38 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:49:38 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:49:39 - INFO :       high_school_chemistry: Total Sparsity 1.3642459889172413e-06
2023-12-01 20:49:39 - INFO :       
==================Finish================

2023-12-01 20:49:39 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:49:39 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:49:39 - INFO :       DATASET: tasksource/mmlu high_school_computer_science
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 20:49:46 - INFO :       Use random pruner...
2023-12-01 20:49:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:49:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:49:46 - INFO :       Start Pruning
2023-12-01 20:49:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:49:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:49:48 - INFO :       high_school_computer_science: Total Sparsity 1.3651273986529418e-06
2023-12-01 20:49:48 - INFO :       
==================Finish================

2023-12-01 20:49:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:49:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:49:48 - INFO :       DATASET: tasksource/mmlu high_school_european_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 20:49:55 - INFO :       Use random pruner...
2023-12-01 20:49:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:49:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:49:55 - INFO :       Start Pruning
2023-12-01 20:49:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:49:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:49:57 - INFO :       high_school_european_history: Total Sparsity 1.3658325264415023e-06
2023-12-01 20:49:57 - INFO :       
==================Finish================

2023-12-01 20:49:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:49:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:49:57 - INFO :       DATASET: tasksource/mmlu high_school_geography
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 20:50:04 - INFO :       Use random pruner...
2023-12-01 20:50:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:50:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:50:04 - INFO :       Start Pruning
2023-12-01 20:50:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:50:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:50:06 - INFO :       high_school_geography: Total Sparsity 1.3681241917543236e-06
2023-12-01 20:50:06 - INFO :       
==================Finish================

2023-12-01 20:50:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:50:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:50:06 - INFO :       DATASET: tasksource/mmlu high_school_government_and_politics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2023-12-01 20:50:14 - INFO :       Use random pruner...
2023-12-01 20:50:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:50:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:50:15 - INFO :       Start Pruning
2023-12-01 20:50:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:50:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:50:16 - INFO :       high_school_government_and_politics: Total Sparsity 1.3626594513929806e-06
2023-12-01 20:50:16 - INFO :       
==================Finish================

2023-12-01 20:50:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:50:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:50:16 - INFO :       DATASET: tasksource/mmlu high_school_macroeconomics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2023-12-01 20:50:28 - INFO :       Use random pruner...
2023-12-01 20:50:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:50:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:50:28 - INFO :       Start Pruning
2023-12-01 20:50:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:50:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:50:30 - INFO :       high_school_macroeconomics: Total Sparsity 1.3610729138687196e-06
2023-12-01 20:50:30 - INFO :       
==================Finish================

2023-12-01 20:50:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:50:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:50:30 - INFO :       DATASET: tasksource/mmlu high_school_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 20:50:41 - INFO :       Use random pruner...
2023-12-01 20:50:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:50:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:50:41 - INFO :       Start Pruning
2023-12-01 20:50:42 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:50:42 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:50:43 - INFO :       high_school_mathematics: Total Sparsity 1.365479962547222e-06
2023-12-01 20:50:43 - INFO :       
==================Finish================

2023-12-01 20:50:43 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:50:43 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:50:43 - INFO :       DATASET: tasksource/mmlu high_school_microeconomics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]
2023-12-01 20:50:52 - INFO :       Use random pruner...
2023-12-01 20:50:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:50:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:50:53 - INFO :       Start Pruning
2023-12-01 20:50:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:50:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:50:54 - INFO :       high_school_microeconomics: Total Sparsity 1.3559607374016567e-06
2023-12-01 20:50:55 - INFO :       
==================Finish================

2023-12-01 20:50:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:50:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:50:55 - INFO :       DATASET: tasksource/mmlu high_school_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]
2023-12-01 20:51:05 - INFO :       Use random pruner...
2023-12-01 20:51:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:51:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:51:06 - INFO :       Start Pruning
2023-12-01 20:51:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:51:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:51:07 - INFO :       high_school_physics: Total Sparsity 1.363540861128681e-06
2023-12-01 20:51:07 - INFO :       
==================Finish================

2023-12-01 20:51:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:51:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:51:07 - INFO :       DATASET: tasksource/mmlu high_school_psychology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2023-12-01 20:51:16 - INFO :       Use random pruner...
2023-12-01 20:51:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:51:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:51:16 - INFO :       Start Pruning
2023-12-01 20:51:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:51:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:51:18 - INFO :       high_school_psychology: Total Sparsity 1.3684767556486038e-06
2023-12-01 20:51:18 - INFO :       
==================Finish================

2023-12-01 20:51:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:51:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:51:18 - INFO :       DATASET: tasksource/mmlu high_school_statistics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]
2023-12-01 20:51:28 - INFO :       Use random pruner...
2023-12-01 20:51:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:51:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:51:29 - INFO :       Start Pruning
2023-12-01 20:51:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:51:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:51:30 - INFO :       high_school_statistics: Total Sparsity 1.3571947110316374e-06
2023-12-01 20:51:30 - INFO :       
==================Finish================

2023-12-01 20:51:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:51:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:51:30 - INFO :       DATASET: tasksource/mmlu high_school_us_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2023-12-01 20:51:40 - INFO :       Use random pruner...
2023-12-01 20:51:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:51:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:51:40 - INFO :       Start Pruning
2023-12-01 20:51:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:51:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:51:42 - INFO :       high_school_us_history: Total Sparsity 1.3616017597101399e-06
2023-12-01 20:51:42 - INFO :       
==================Finish================

2023-12-01 20:51:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:51:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:51:42 - INFO :       DATASET: tasksource/mmlu high_school_world_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 20:51:52 - INFO :       Use random pruner...
2023-12-01 20:51:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:51:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:51:53 - INFO :       Start Pruning
2023-12-01 20:51:53 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:51:53 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:51:54 - INFO :       high_school_world_history: Total Sparsity 1.3605440680272994e-06
2023-12-01 20:51:54 - INFO :       
==================Finish================

2023-12-01 20:51:54 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:51:54 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:51:54 - INFO :       DATASET: tasksource/mmlu human_aging
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2023-12-01 20:52:02 - INFO :       Use random pruner...
2023-12-01 20:52:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:52:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:52:03 - INFO :       Start Pruning
2023-12-01 20:52:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:52:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:52:04 - INFO :       human_aging: Total Sparsity 1.369005601490024e-06
2023-12-01 20:52:04 - INFO :       
==================Finish================

2023-12-01 20:52:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:52:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:52:04 - INFO :       DATASET: tasksource/mmlu human_sexuality
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.98s/it]
2023-12-01 20:52:13 - INFO :       Use random pruner...
2023-12-01 20:52:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:52:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:52:14 - INFO :       Start Pruning
2023-12-01 20:52:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:52:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:52:15 - INFO :       human_sexuality: Total Sparsity 1.363540861128681e-06
2023-12-01 20:52:15 - INFO :       
==================Finish================

2023-12-01 20:52:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:52:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:52:15 - INFO :       DATASET: tasksource/mmlu international_law
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]
2023-12-01 20:52:25 - INFO :       Use random pruner...
2023-12-01 20:52:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:52:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:52:26 - INFO :       Start Pruning
2023-12-01 20:52:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:52:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:52:27 - INFO :       international_law: Total Sparsity 1.3593100943973186e-06
2023-12-01 20:52:27 - INFO :       
==================Finish================

2023-12-01 20:52:27 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:52:27 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:52:27 - INFO :       DATASET: tasksource/mmlu jurisprudence
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 20:52:36 - INFO :       Use random pruner...
2023-12-01 20:52:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:52:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:52:37 - INFO :       Start Pruning
2023-12-01 20:52:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:52:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:52:38 - INFO :       jurisprudence: Total Sparsity 1.367066500071483e-06
2023-12-01 20:52:38 - INFO :       
==================Finish================

2023-12-01 20:52:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:52:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:52:38 - INFO :       DATASET: tasksource/mmlu logical_fallacies
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2023-12-01 20:52:48 - INFO :       Use random pruner...
2023-12-01 20:52:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:52:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:52:48 - INFO :       Start Pruning
2023-12-01 20:52:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:52:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:52:50 - INFO :       logical_fallacies: Total Sparsity 1.374117777957087e-06
2023-12-01 20:52:50 - INFO :       
==================Finish================

2023-12-01 20:52:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:52:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:52:50 - INFO :       DATASET: tasksource/mmlu machine_learning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
2023-12-01 20:52:58 - INFO :       Use random pruner...
2023-12-01 20:52:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:52:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:52:59 - INFO :       Start Pruning
2023-12-01 20:53:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:53:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:53:01 - INFO :       machine_learning: Total Sparsity 1.3598389402387389e-06
2023-12-01 20:53:01 - INFO :       
==================Finish================

2023-12-01 20:53:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:53:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:53:01 - INFO :       DATASET: tasksource/mmlu management
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2023-12-01 20:53:10 - INFO :       Use random pruner...
2023-12-01 20:53:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:53:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:53:11 - INFO :       Start Pruning
2023-12-01 20:53:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:53:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:53:12 - INFO :       management: Total Sparsity 1.3730600862742465e-06
2023-12-01 20:53:12 - INFO :       
==================Finish================

2023-12-01 20:53:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:53:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:53:12 - INFO :       DATASET: tasksource/mmlu marketing
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]
2023-12-01 20:53:21 - INFO :       Use random pruner...
2023-12-01 20:53:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:53:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:53:21 - INFO :       Start Pruning
2023-12-01 20:53:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:53:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:53:23 - INFO :       marketing: Total Sparsity 1.3601915041330191e-06
2023-12-01 20:53:23 - INFO :       
==================Finish================

2023-12-01 20:53:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:53:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:53:23 - INFO :       DATASET: tasksource/mmlu medical_genetics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]
2023-12-01 20:53:32 - INFO :       Use random pruner...
2023-12-01 20:53:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:53:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:53:33 - INFO :       Start Pruning
2023-12-01 20:53:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:53:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:53:34 - INFO :       medical_genetics: Total Sparsity 1.3543741998773957e-06
2023-12-01 20:53:34 - INFO :       
==================Finish================

2023-12-01 20:53:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:53:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:53:34 - INFO :       DATASET: tasksource/mmlu miscellaneous
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]
2023-12-01 20:53:44 - INFO :       Use random pruner...
2023-12-01 20:53:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:53:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:53:45 - INFO :       Start Pruning
2023-12-01 20:53:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:53:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:53:46 - INFO :       miscellaneous: Total Sparsity 1.3594863763444586e-06
2023-12-01 20:53:46 - INFO :       
==================Finish================

2023-12-01 20:53:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:53:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:53:46 - INFO :       DATASET: tasksource/mmlu moral_disputes
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2023-12-01 20:53:56 - INFO :       Use random pruner...
2023-12-01 20:53:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:53:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:53:57 - INFO :       Start Pruning
2023-12-01 20:53:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:53:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:53:58 - INFO :       moral_disputes: Total Sparsity 1.3660088083886423e-06
2023-12-01 20:53:58 - INFO :       
==================Finish================

2023-12-01 20:53:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:53:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:53:58 - INFO :       DATASET: tasksource/mmlu moral_scenarios
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]
2023-12-01 20:54:07 - INFO :       Use random pruner...
2023-12-01 20:54:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:54:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:54:07 - INFO :       Start Pruning
2023-12-01 20:54:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:54:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:54:09 - INFO :       moral_scenarios: Total Sparsity 1.3684767556486038e-06
2023-12-01 20:54:09 - INFO :       
==================Finish================

2023-12-01 20:54:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:54:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:54:09 - INFO :       DATASET: tasksource/mmlu nutrition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]
2023-12-01 20:54:19 - INFO :       Use random pruner...
2023-12-01 20:54:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:54:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:54:19 - INFO :       Start Pruning
2023-12-01 20:54:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:54:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:54:21 - INFO :       nutrition: Total Sparsity 1.363717143075821e-06
2023-12-01 20:54:21 - INFO :       
==================Finish================

2023-12-01 20:54:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:54:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:54:21 - INFO :       DATASET: tasksource/mmlu philosophy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2023-12-01 20:54:30 - INFO :       Use random pruner...
2023-12-01 20:54:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:54:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:54:30 - INFO :       Start Pruning
2023-12-01 20:54:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:54:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:54:32 - INFO :       philosophy: Total Sparsity 1.3642459889172413e-06
2023-12-01 20:54:32 - INFO :       
==================Finish================

2023-12-01 20:54:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:54:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:54:32 - INFO :       DATASET: tasksource/mmlu prehistory
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 20:54:42 - INFO :       Use random pruner...
2023-12-01 20:54:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:54:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:54:42 - INFO :       Start Pruning
2023-12-01 20:54:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:54:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:54:44 - INFO :       prehistory: Total Sparsity 1.3573709929787774e-06
2023-12-01 20:54:44 - INFO :       
==================Finish================

2023-12-01 20:54:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:54:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:54:44 - INFO :       DATASET: tasksource/mmlu professional_accounting
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.38s/it]
2023-12-01 20:54:55 - INFO :       Use random pruner...
2023-12-01 20:54:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:54:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:54:55 - INFO :       Start Pruning
2023-12-01 20:54:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:54:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:54:57 - INFO :       professional_accounting: Total Sparsity 1.3626594513929806e-06
2023-12-01 20:54:57 - INFO :       
==================Finish================

2023-12-01 20:54:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:54:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:54:57 - INFO :       DATASET: tasksource/mmlu professional_law
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2023-12-01 20:55:08 - INFO :       Use random pruner...
2023-12-01 20:55:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:55:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:55:09 - INFO :       Start Pruning
2023-12-01 20:55:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:55:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:55:11 - INFO :       professional_law: Total Sparsity 1.3633645791815409e-06
2023-12-01 20:55:11 - INFO :       
==================Finish================

2023-12-01 20:55:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:55:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:55:11 - INFO :       DATASET: tasksource/mmlu professional_medicine
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
2023-12-01 20:55:19 - INFO :       Use random pruner...
2023-12-01 20:55:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:55:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:55:19 - INFO :       Start Pruning
2023-12-01 20:55:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:55:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:55:21 - INFO :       professional_medicine: Total Sparsity 1.3640697069701013e-06
2023-12-01 20:55:21 - INFO :       
==================Finish================

2023-12-01 20:55:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:55:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:55:21 - INFO :       DATASET: tasksource/mmlu professional_psychology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2023-12-01 20:55:30 - INFO :       Use random pruner...
2023-12-01 20:55:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:55:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:55:30 - INFO :       Start Pruning
2023-12-01 20:55:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:55:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:55:32 - INFO :       professional_psychology: Total Sparsity 1.3591338124501784e-06
2023-12-01 20:55:32 - INFO :       
==================Finish================

2023-12-01 20:55:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:55:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:55:32 - INFO :       DATASET: tasksource/mmlu public_relations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2023-12-01 20:55:41 - INFO :       Use random pruner...
2023-12-01 20:55:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:55:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:55:42 - INFO :       Start Pruning
2023-12-01 20:55:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:55:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:55:44 - INFO :       public_relations: Total Sparsity 1.3697107292785845e-06
2023-12-01 20:55:44 - INFO :       
==================Finish================

2023-12-01 20:55:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:55:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:55:44 - INFO :       DATASET: tasksource/mmlu security_studies
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]
2023-12-01 20:55:53 - INFO :       Use random pruner...
2023-12-01 20:55:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:55:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:55:53 - INFO :       Start Pruning
2023-12-01 20:55:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:55:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:55:55 - INFO :       security_studies: Total Sparsity 1.358076120767338e-06
2023-12-01 20:55:55 - INFO :       
==================Finish================

2023-12-01 20:55:55 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:55:55 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:55:55 - INFO :       DATASET: tasksource/mmlu sociology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2023-12-01 20:56:04 - INFO :       Use random pruner...
2023-12-01 20:56:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:56:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:56:04 - INFO :       Start Pruning
2023-12-01 20:56:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:56:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:56:06 - INFO :       sociology: Total Sparsity 1.3645985528115216e-06
2023-12-01 20:56:06 - INFO :       
==================Finish================

2023-12-01 20:56:06 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:56:06 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:56:06 - INFO :       DATASET: tasksource/mmlu us_foreign_policy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 20:56:14 - INFO :       Use random pruner...
2023-12-01 20:56:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:56:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:56:15 - INFO :       Start Pruning
2023-12-01 20:56:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:56:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:56:17 - INFO :       us_foreign_policy: Total Sparsity 1.36177804165728e-06
2023-12-01 20:56:17 - INFO :       
==================Finish================

2023-12-01 20:56:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:56:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:56:17 - INFO :       DATASET: tasksource/mmlu virology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]
2023-12-01 20:56:27 - INFO :       Use random pruner...
2023-12-01 20:56:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:56:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:56:27 - INFO :       Start Pruning
2023-12-01 20:56:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:56:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:56:29 - INFO :       virology: Total Sparsity 1.365303680600082e-06
2023-12-01 20:56:29 - INFO :       
==================Finish================

2023-12-01 20:56:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:56:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:56:29 - INFO :       DATASET: tasksource/mmlu world_religions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]
2023-12-01 20:56:38 - INFO :       Use random pruner...
2023-12-01 20:56:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:56:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:56:39 - INFO :       Start Pruning
2023-12-01 20:56:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:56:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:56:40 - INFO :       world_religions: Total Sparsity 1.3540216359831155e-06
2023-12-01 20:56:40 - INFO :       
==================Finish================

2023-12-01 20:56:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:56:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:56:40 - INFO :       DATASET: math_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]
2023-12-01 20:56:49 - INFO :       Use random pruner...
2023-12-01 20:56:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:56:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:56:50 - INFO :       Start Pruning
2023-12-01 20:56:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:56:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:56:52 - INFO :       math_qa: Total Sparsity 1.3674190639657633e-06
2023-12-01 20:56:52 - INFO :       
==================Finish================

2023-12-01 20:56:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:56:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:56:52 - INFO :       DATASET: EleutherAI/truthful_qa_mc
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2023-12-01 20:57:01 - INFO :       Use random pruner...
2023-12-01 20:57:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:57:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:57:01 - INFO :       Start Pruning
2023-12-01 20:57:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:57:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:57:03 - INFO :       truthful_qa_mc: Total Sparsity 1.3748229057456475e-06
2023-12-01 20:57:03 - INFO :       
==================Finish================

2023-12-01 20:57:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:57:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:57:03 - INFO :       DATASET: derek-thomas/ScienceQA
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]
2023-12-01 20:57:13 - INFO :       Use random pruner...
2023-12-01 20:57:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:57:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:57:13 - INFO :       Start Pruning
2023-12-01 20:57:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:57:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:57:15 - INFO :       ScienceQA: Total Sparsity 1.3661850903357826e-06
2023-12-01 20:57:15 - INFO :       
==================Finish================

2023-12-01 20:57:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:57:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:57:15 - INFO :       DATASET: commonsense_qa
Index 9
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]
2023-12-01 20:57:25 - INFO :       Use random pruner...
2023-12-01 20:57:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:57:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:57:26 - INFO :       Start Pruning
2023-12-01 20:57:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:57:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:57:28 - INFO :       commonsense_qa: Total Sparsity 1.3691818834371643e-06
2023-12-01 20:57:28 - INFO :       
==================Finish================

2023-12-01 20:57:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:57:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:57:28 - INFO :       DATASET: tasksource/bigbench abstract_narrative_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2023-12-01 20:57:36 - INFO :       Use random pruner...
2023-12-01 20:57:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:57:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:57:37 - INFO :       Start Pruning
2023-12-01 20:57:38 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:57:38 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:57:39 - INFO :       abstract_narrative_understanding: Total Sparsity 1.3640697069701013e-06
2023-12-01 20:57:39 - INFO :       
==================Finish================

2023-12-01 20:57:39 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:57:39 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:57:39 - INFO :       DATASET: tasksource/bigbench anachronisms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.19s/it]
2023-12-01 20:57:48 - INFO :       Use random pruner...
2023-12-01 20:57:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:57:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:57:49 - INFO :       Start Pruning
2023-12-01 20:57:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:57:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:57:50 - INFO :       anachronisms: Total Sparsity 1.370415857067145e-06
2023-12-01 20:57:50 - INFO :       
==================Finish================

2023-12-01 20:57:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:57:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:57:50 - INFO :       DATASET: tasksource/bigbench analogical_similarity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2023-12-01 20:57:58 - INFO :       Use random pruner...
2023-12-01 20:57:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:57:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:57:59 - INFO :       Start Pruning
2023-12-01 20:58:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:58:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:58:00 - INFO :       analogical_similarity: Total Sparsity 1.3693581653843043e-06
2023-12-01 20:58:00 - INFO :       
==================Finish================

2023-12-01 20:58:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:58:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:58:00 - INFO :       DATASET: tasksource/bigbench analytic_entailment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 20:58:07 - INFO :       Use random pruner...
2023-12-01 20:58:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:58:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:58:07 - INFO :       Start Pruning
2023-12-01 20:58:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:58:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:58:09 - INFO :       analytic_entailment: Total Sparsity 1.3594863763444586e-06
2023-12-01 20:58:09 - INFO :       
==================Finish================

2023-12-01 20:58:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:58:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:58:09 - INFO :       DATASET: tasksource/bigbench arithmetic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 20:58:16 - INFO :       Use random pruner...
2023-12-01 20:58:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:58:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:58:16 - INFO :       Start Pruning
2023-12-01 20:58:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:58:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:58:18 - INFO :       arithmetic: Total Sparsity 1.3734126501685267e-06
2023-12-01 20:58:18 - INFO :       
==================Finish================

2023-12-01 20:58:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:58:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:58:18 - INFO :       DATASET: tasksource/bigbench authorship_verification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 20:58:25 - INFO :       Use random pruner...
2023-12-01 20:58:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:58:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:58:25 - INFO :       Start Pruning
2023-12-01 20:58:26 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:58:26 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:58:27 - INFO :       authorship_verification: Total Sparsity 1.3633645791815409e-06
2023-12-01 20:58:27 - INFO :       
==================Finish================

2023-12-01 20:58:27 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:58:27 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:58:27 - INFO :       DATASET: tasksource/bigbench bbq_lite_json
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 20:58:34 - INFO :       Use random pruner...
2023-12-01 20:58:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:58:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:58:34 - INFO :       Start Pruning
2023-12-01 20:58:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:58:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:58:36 - INFO :       bbq_lite_json: Total Sparsity 1.3718261126442658e-06
2023-12-01 20:58:36 - INFO :       
==================Finish================

2023-12-01 20:58:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:58:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:58:36 - INFO :       DATASET: tasksource/bigbench causal_judgment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 20:58:44 - INFO :       Use random pruner...
2023-12-01 20:58:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:58:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:58:45 - INFO :       Start Pruning
2023-12-01 20:58:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:58:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:58:47 - INFO :       causal_judgment: Total Sparsity 1.3624831694458404e-06
2023-12-01 20:58:47 - INFO :       
==================Finish================

2023-12-01 20:58:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:58:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:58:47 - INFO :       DATASET: tasksource/bigbench cause_and_effect
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]
2023-12-01 20:58:54 - INFO :       Use random pruner...
2023-12-01 20:58:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:58:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:58:55 - INFO :       Start Pruning
2023-12-01 20:58:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:58:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:58:57 - INFO :       cause_and_effect: Total Sparsity 1.3589575305030384e-06
2023-12-01 20:58:57 - INFO :       
==================Finish================

2023-12-01 20:58:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:58:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:58:57 - INFO :       DATASET: tasksource/bigbench checkmate_in_one
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 20:59:05 - INFO :       Use random pruner...
2023-12-01 20:59:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:59:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:59:05 - INFO :       Start Pruning
2023-12-01 20:59:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:59:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:59:07 - INFO :       checkmate_in_one: Total Sparsity 1.3621306055515601e-06
2023-12-01 20:59:07 - INFO :       
==================Finish================

2023-12-01 20:59:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:59:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:59:07 - INFO :       DATASET: tasksource/bigbench cifar10_classification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 20:59:14 - INFO :       Use random pruner...
2023-12-01 20:59:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:59:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:59:15 - INFO :       Start Pruning
2023-12-01 20:59:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:59:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:59:16 - INFO :       cifar10_classification: Total Sparsity 1.3691818834371643e-06
2023-12-01 20:59:16 - INFO :       
==================Finish================

2023-12-01 20:59:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:59:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:59:16 - INFO :       DATASET: tasksource/bigbench code_line_description
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]
2023-12-01 20:59:25 - INFO :       Use random pruner...
2023-12-01 20:59:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:59:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:59:26 - INFO :       Start Pruning
2023-12-01 20:59:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:59:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:59:28 - INFO :       code_line_description: Total Sparsity 1.369005601490024e-06
2023-12-01 20:59:28 - INFO :       
==================Finish================

2023-12-01 20:59:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:59:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:59:28 - INFO :       DATASET: tasksource/bigbench color
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2023-12-01 20:59:38 - INFO :       Use random pruner...
2023-12-01 20:59:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:59:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:59:38 - INFO :       Start Pruning
2023-12-01 20:59:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:59:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:59:40 - INFO :       color: Total Sparsity 1.365479962547222e-06
2023-12-01 20:59:40 - INFO :       
==================Finish================

2023-12-01 20:59:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:59:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:59:40 - INFO :       DATASET: tasksource/bigbench common_morpheme
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2023-12-01 20:59:49 - INFO :       Use random pruner...
2023-12-01 20:59:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:59:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 20:59:49 - INFO :       Start Pruning
2023-12-01 20:59:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 20:59:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 20:59:51 - INFO :       common_morpheme: Total Sparsity 1.3612491958158596e-06
2023-12-01 20:59:51 - INFO :       
==================Finish================

2023-12-01 20:59:51 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 20:59:51 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 20:59:51 - INFO :       DATASET: tasksource/bigbench conceptual_combinations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2023-12-01 21:00:01 - INFO :       Use random pruner...
2023-12-01 21:00:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:00:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:00:01 - INFO :       Start Pruning
2023-12-01 21:00:02 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:00:02 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:00:03 - INFO :       conceptual_combinations: Total Sparsity 1.3619543236044201e-06
2023-12-01 21:00:03 - INFO :       
==================Finish================

2023-12-01 21:00:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:00:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:00:03 - INFO :       DATASET: tasksource/bigbench crash_blossom
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
2023-12-01 21:00:13 - INFO :       Use random pruner...
2023-12-01 21:00:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:00:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:00:14 - INFO :       Start Pruning
2023-12-01 21:00:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:00:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:00:15 - INFO :       crash_blossom: Total Sparsity 1.3727075223799662e-06
2023-12-01 21:00:15 - INFO :       
==================Finish================

2023-12-01 21:00:15 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:00:15 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:00:15 - INFO :       DATASET: tasksource/bigbench crass_ai
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2023-12-01 21:00:24 - INFO :       Use random pruner...
2023-12-01 21:00:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:00:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:00:24 - INFO :       Start Pruning
2023-12-01 21:00:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:00:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:00:26 - INFO :       crass_ai: Total Sparsity 1.3644222708643816e-06
2023-12-01 21:00:26 - INFO :       
==================Finish================

2023-12-01 21:00:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:00:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:00:26 - INFO :       DATASET: tasksource/bigbench cryobiology_spanish
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2023-12-01 21:00:34 - INFO :       Use random pruner...
2023-12-01 21:00:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:00:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:00:34 - INFO :       Start Pruning
2023-12-01 21:00:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:00:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:00:36 - INFO :       cryobiology_spanish: Total Sparsity 1.3663613722829226e-06
2023-12-01 21:00:36 - INFO :       
==================Finish================

2023-12-01 21:00:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:00:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:00:36 - INFO :       DATASET: tasksource/bigbench cs_algorithms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 21:00:48 - INFO :       Use random pruner...
2023-12-01 21:00:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:00:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:00:49 - INFO :       Start Pruning
2023-12-01 21:00:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:00:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:00:50 - INFO :       cs_algorithms: Total Sparsity 1.3557844554545167e-06
2023-12-01 21:00:50 - INFO :       
==================Finish================

2023-12-01 21:00:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:00:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:00:50 - INFO :       DATASET: tasksource/bigbench dark_humor_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.44s/it]
2023-12-01 21:01:03 - INFO :       Use random pruner...
2023-12-01 21:01:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:01:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:01:03 - INFO :       Start Pruning
2023-12-01 21:01:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:01:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:01:05 - INFO :       dark_humor_detection: Total Sparsity 1.360015222185879e-06
2023-12-01 21:01:05 - INFO :       
==================Finish================

2023-12-01 21:01:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:01:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:01:05 - INFO :       DATASET: tasksource/bigbench date_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.45s/it]
2023-12-01 21:01:18 - INFO :       Use random pruner...
2023-12-01 21:01:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:01:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:01:18 - INFO :       Start Pruning
2023-12-01 21:01:19 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:01:19 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:01:20 - INFO :       date_understanding: Total Sparsity 1.3515536887231542e-06
2023-12-01 21:01:20 - INFO :       
==================Finish================

2023-12-01 21:01:20 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:01:20 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:01:20 - INFO :       DATASET: tasksource/bigbench disambiguation_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2023-12-01 21:01:32 - INFO :       Use random pruner...
2023-12-01 21:01:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:01:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:01:32 - INFO :       Start Pruning
2023-12-01 21:01:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:01:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:01:34 - INFO :       disambiguation_qa: Total Sparsity 1.3660088083886423e-06
2023-12-01 21:01:34 - INFO :       
==================Finish================

2023-12-01 21:01:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:01:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:01:34 - INFO :       DATASET: tasksource/bigbench discourse_marker_prediction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.40s/it]
2023-12-01 21:01:46 - INFO :       Use random pruner...
2023-12-01 21:01:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:01:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:01:47 - INFO :       Start Pruning
2023-12-01 21:01:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:01:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:01:48 - INFO :       discourse_marker_prediction: Total Sparsity 1.3605440680272994e-06
2023-12-01 21:01:48 - INFO :       
==================Finish================

2023-12-01 21:01:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:01:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:01:48 - INFO :       DATASET: tasksource/bigbench dyck_languages
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.38s/it]
2023-12-01 21:02:00 - INFO :       Use random pruner...
2023-12-01 21:02:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:02:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:02:00 - INFO :       Start Pruning
2023-12-01 21:02:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:02:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:02:02 - INFO :       dyck_languages: Total Sparsity 1.3700632931728648e-06
2023-12-01 21:02:02 - INFO :       
==================Finish================

2023-12-01 21:02:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:02:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:02:02 - INFO :       DATASET: tasksource/bigbench elementary_math_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.27s/it]
2023-12-01 21:02:14 - INFO :       Use random pruner...
2023-12-01 21:02:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:02:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:02:14 - INFO :       Start Pruning
2023-12-01 21:02:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:02:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:02:16 - INFO :       elementary_math_qa: Total Sparsity 1.3538453540359754e-06
2023-12-01 21:02:16 - INFO :       
==================Finish================

2023-12-01 21:02:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:02:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:02:16 - INFO :       DATASET: tasksource/bigbench emoji_movie
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 21:02:28 - INFO :       Use random pruner...
2023-12-01 21:02:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:02:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:02:28 - INFO :       Start Pruning
2023-12-01 21:02:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:02:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:02:30 - INFO :       emoji_movie: Total Sparsity 1.3734126501685267e-06
2023-12-01 21:02:30 - INFO :       
==================Finish================

2023-12-01 21:02:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:02:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:02:30 - INFO :       DATASET: tasksource/bigbench empirical_judgments
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.38s/it]
2023-12-01 21:02:42 - INFO :       Use random pruner...
2023-12-01 21:02:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:02:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:02:42 - INFO :       Start Pruning
2023-12-01 21:02:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:02:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:02:44 - INFO :       empirical_judgments: Total Sparsity 1.3550793276659562e-06
2023-12-01 21:02:44 - INFO :       
==================Finish================

2023-12-01 21:02:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:02:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:02:44 - INFO :       DATASET: tasksource/bigbench english_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.39s/it]
2023-12-01 21:02:56 - INFO :       Use random pruner...
2023-12-01 21:02:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:02:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:02:56 - INFO :       Start Pruning
2023-12-01 21:02:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:02:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:02:58 - INFO :       english_proverbs: Total Sparsity 1.3557844554545167e-06
2023-12-01 21:02:58 - INFO :       
==================Finish================

2023-12-01 21:02:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:02:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:02:58 - INFO :       DATASET: tasksource/bigbench english_russian_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
2023-12-01 21:03:09 - INFO :       Use random pruner...
2023-12-01 21:03:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:03:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:03:09 - INFO :       Start Pruning
2023-12-01 21:03:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:03:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:03:11 - INFO :       english_russian_proverbs: Total Sparsity 1.3621306055515601e-06
2023-12-01 21:03:11 - INFO :       
==================Finish================

2023-12-01 21:03:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:03:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:03:11 - INFO :       DATASET: tasksource/bigbench entailed_polarity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]
2023-12-01 21:03:20 - INFO :       Use random pruner...
2023-12-01 21:03:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:03:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:03:20 - INFO :       Start Pruning
2023-12-01 21:03:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:03:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:03:22 - INFO :       entailed_polarity: Total Sparsity 1.3552556096130962e-06
2023-12-01 21:03:22 - INFO :       
==================Finish================

2023-12-01 21:03:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:03:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:03:22 - INFO :       DATASET: tasksource/bigbench entailed_polarity_hindi
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]
2023-12-01 21:03:31 - INFO :       Use random pruner...
2023-12-01 21:03:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:03:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:03:32 - INFO :       Start Pruning
2023-12-01 21:03:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:03:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:03:34 - INFO :       entailed_polarity_hindi: Total Sparsity 1.3633645791815409e-06
2023-12-01 21:03:34 - INFO :       
==================Finish================

2023-12-01 21:03:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:03:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:03:34 - INFO :       DATASET: tasksource/bigbench epistemic_reasoning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.27s/it]
2023-12-01 21:03:44 - INFO :       Use random pruner...
2023-12-01 21:03:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:03:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:03:44 - INFO :       Start Pruning
2023-12-01 21:03:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:03:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:03:46 - INFO :       epistemic_reasoning: Total Sparsity 1.3614254777629999e-06
2023-12-01 21:03:46 - INFO :       
==================Finish================

2023-12-01 21:03:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:03:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:03:46 - INFO :       DATASET: tasksource/bigbench evaluating_information_essentiality
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2023-12-01 21:03:55 - INFO :       Use random pruner...
2023-12-01 21:03:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:03:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:03:56 - INFO :       Start Pruning
2023-12-01 21:03:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:03:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:03:58 - INFO :       evaluating_information_essentiality: Total Sparsity 1.3626594513929806e-06
2023-12-01 21:03:58 - INFO :       
==================Finish================

2023-12-01 21:03:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:03:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:03:58 - INFO :       DATASET: tasksource/bigbench fact_checker
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.46s/it]
2023-12-01 21:04:07 - INFO :       Use random pruner...
2023-12-01 21:04:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:04:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:04:08 - INFO :       Start Pruning
2023-12-01 21:04:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:04:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:04:10 - INFO :       fact_checker: Total Sparsity 1.353140226247415e-06
2023-12-01 21:04:10 - INFO :       
==================Finish================

2023-12-01 21:04:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:04:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:04:10 - INFO :       DATASET: tasksource/bigbench fantasy_reasoning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]
2023-12-01 21:04:20 - INFO :       Use random pruner...
2023-12-01 21:04:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:04:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:04:21 - INFO :       Start Pruning
2023-12-01 21:04:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:04:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:04:22 - INFO :       fantasy_reasoning: Total Sparsity 1.3561370193487967e-06
2023-12-01 21:04:22 - INFO :       
==================Finish================

2023-12-01 21:04:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:04:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:04:22 - INFO :       DATASET: tasksource/bigbench figure_of_speech_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]
2023-12-01 21:04:31 - INFO :       Use random pruner...
2023-12-01 21:04:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:04:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:04:31 - INFO :       Start Pruning
2023-12-01 21:04:32 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:04:32 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:04:33 - INFO :       figure_of_speech_detection: Total Sparsity 1.3561370193487967e-06
2023-12-01 21:04:33 - INFO :       
==================Finish================

2023-12-01 21:04:33 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:04:33 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:04:33 - INFO :       DATASET: tasksource/bigbench formal_fallacies_syllogisms_negation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2023-12-01 21:04:43 - INFO :       Use random pruner...
2023-12-01 21:04:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:04:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:04:43 - INFO :       Start Pruning
2023-12-01 21:04:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:04:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:04:45 - INFO :       formal_fallacies_syllogisms_negation: Total Sparsity 1.3640697069701013e-06
2023-12-01 21:04:45 - INFO :       
==================Finish================

2023-12-01 21:04:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:04:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:04:45 - INFO :       DATASET: tasksource/bigbench general_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]
2023-12-01 21:04:55 - INFO :       Use random pruner...
2023-12-01 21:04:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:04:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:04:56 - INFO :       Start Pruning
2023-12-01 21:04:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:04:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:04:58 - INFO :       general_knowledge: Total Sparsity 1.367242782018623e-06
2023-12-01 21:04:58 - INFO :       
==================Finish================

2023-12-01 21:04:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:04:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:04:58 - INFO :       DATASET: tasksource/bigbench geometric_shapes
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]
2023-12-01 21:05:08 - INFO :       Use random pruner...
2023-12-01 21:05:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:05:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:05:09 - INFO :       Start Pruning
2023-12-01 21:05:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:05:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:05:11 - INFO :       geometric_shapes: Total Sparsity 1.3612491958158596e-06
2023-12-01 21:05:11 - INFO :       
==================Finish================

2023-12-01 21:05:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:05:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:05:11 - INFO :       DATASET: tasksource/bigbench goal_step_wikihow
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]
2023-12-01 21:05:21 - INFO :       Use random pruner...
2023-12-01 21:05:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:05:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:05:21 - INFO :       Start Pruning
2023-12-01 21:05:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:05:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:05:23 - INFO :       goal_step_wikihow: Total Sparsity 1.3607203499744394e-06
2023-12-01 21:05:23 - INFO :       
==================Finish================

2023-12-01 21:05:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:05:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:05:23 - INFO :       DATASET: tasksource/bigbench gre_reading_comprehension
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
2023-12-01 21:05:32 - INFO :       Use random pruner...
2023-12-01 21:05:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:05:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:05:32 - INFO :       Start Pruning
2023-12-01 21:05:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:05:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:05:34 - INFO :       gre_reading_comprehension: Total Sparsity 1.3656562444943623e-06
2023-12-01 21:05:34 - INFO :       
==================Finish================

2023-12-01 21:05:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:05:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:05:34 - INFO :       DATASET: tasksource/bigbench hhh_alignment
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.36s/it]
2023-12-01 21:05:45 - INFO :       Use random pruner...
2023-12-01 21:05:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:05:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:05:45 - INFO :       Start Pruning
2023-12-01 21:05:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:05:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:05:47 - INFO :       hhh_alignment: Total Sparsity 1.368829319542884e-06
2023-12-01 21:05:47 - INFO :       
==================Finish================

2023-12-01 21:05:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:05:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:05:47 - INFO :       DATASET: tasksource/bigbench hindu_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]
2023-12-01 21:05:59 - INFO :       Use random pruner...
2023-12-01 21:05:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:05:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:05:59 - INFO :       Start Pruning
2023-12-01 21:06:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:06:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:06:01 - INFO :       hindu_knowledge: Total Sparsity 1.3561370193487967e-06
2023-12-01 21:06:01 - INFO :       
==================Finish================

2023-12-01 21:06:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:06:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:06:01 - INFO :       DATASET: tasksource/bigbench hinglish_toxicity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
2023-12-01 21:06:11 - INFO :       Use random pruner...
2023-12-01 21:06:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:06:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:06:12 - INFO :       Start Pruning
2023-12-01 21:06:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:06:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:06:14 - INFO :       hinglish_toxicity: Total Sparsity 1.356489583243077e-06
2023-12-01 21:06:14 - INFO :       
==================Finish================

2023-12-01 21:06:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:06:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:06:14 - INFO :       DATASET: tasksource/bigbench human_organs_senses
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
2023-12-01 21:06:24 - INFO :       Use random pruner...
2023-12-01 21:06:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:06:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:06:24 - INFO :       Start Pruning
2023-12-01 21:06:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:06:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:06:26 - INFO :       human_organs_senses: Total Sparsity 1.3573709929787774e-06
2023-12-01 21:06:26 - INFO :       
==================Finish================

2023-12-01 21:06:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:06:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:06:26 - INFO :       DATASET: tasksource/bigbench hyperbaton
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2023-12-01 21:06:34 - INFO :       Use random pruner...
2023-12-01 21:06:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:06:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:06:35 - INFO :       Start Pruning
2023-12-01 21:06:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:06:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:06:36 - INFO :       hyperbaton: Total Sparsity 1.3557844554545167e-06
2023-12-01 21:06:36 - INFO :       
==================Finish================

2023-12-01 21:06:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:06:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:06:36 - INFO :       DATASET: tasksource/bigbench identify_math_theorems
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.49s/it]
2023-12-01 21:06:46 - INFO :       Use random pruner...
2023-12-01 21:06:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:06:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:06:46 - INFO :       Start Pruning
2023-12-01 21:06:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:06:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:06:48 - INFO :       identify_math_theorems: Total Sparsity 1.3642459889172413e-06
2023-12-01 21:06:48 - INFO :       
==================Finish================

2023-12-01 21:06:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:06:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:06:48 - INFO :       DATASET: tasksource/bigbench identify_odd_metaphor
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]
2023-12-01 21:06:57 - INFO :       Use random pruner...
2023-12-01 21:06:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:06:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:06:57 - INFO :       Start Pruning
2023-12-01 21:06:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:06:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:06:59 - INFO :       identify_odd_metaphor: Total Sparsity 1.3573709929787774e-06
2023-12-01 21:06:59 - INFO :       
==================Finish================

2023-12-01 21:06:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:06:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:06:59 - INFO :       DATASET: tasksource/bigbench implicatures
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 21:07:07 - INFO :       Use random pruner...
2023-12-01 21:07:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:07:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:07:08 - INFO :       Start Pruning
2023-12-01 21:07:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:07:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:07:09 - INFO :       implicatures: Total Sparsity 1.356489583243077e-06
2023-12-01 21:07:09 - INFO :       
==================Finish================

2023-12-01 21:07:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:07:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:07:09 - INFO :       DATASET: tasksource/bigbench implicit_relations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 21:07:19 - INFO :       Use random pruner...
2023-12-01 21:07:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:07:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:07:20 - INFO :       Start Pruning
2023-12-01 21:07:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:07:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:07:21 - INFO :       implicit_relations: Total Sparsity 1.3683004737014638e-06
2023-12-01 21:07:21 - INFO :       
==================Finish================

2023-12-01 21:07:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:07:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:07:21 - INFO :       DATASET: tasksource/bigbench indic_cause_and_effect
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  2.00s/it]
2023-12-01 21:07:30 - INFO :       Use random pruner...
2023-12-01 21:07:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:07:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:07:31 - INFO :       Start Pruning
2023-12-01 21:07:31 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:07:31 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:07:32 - INFO :       indic_cause_and_effect: Total Sparsity 1.3621306055515601e-06
2023-12-01 21:07:32 - INFO :       
==================Finish================

2023-12-01 21:07:32 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:07:32 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:07:32 - INFO :       DATASET: tasksource/bigbench intent_recognition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2023-12-01 21:07:41 - INFO :       Use random pruner...
2023-12-01 21:07:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:07:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:07:42 - INFO :       Start Pruning
2023-12-01 21:07:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:07:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:07:44 - INFO :       intent_recognition: Total Sparsity 1.3594863763444586e-06
2023-12-01 21:07:44 - INFO :       
==================Finish================

2023-12-01 21:07:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:07:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:07:44 - INFO :       DATASET: tasksource/bigbench international_phonetic_alphabet_nli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.34s/it]
2023-12-01 21:07:55 - INFO :       Use random pruner...
2023-12-01 21:07:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:07:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:07:56 - INFO :       Start Pruning
2023-12-01 21:07:57 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:07:57 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:07:58 - INFO :       international_phonetic_alphabet_nli: Total Sparsity 1.3656562444943623e-06
2023-12-01 21:07:58 - INFO :       
==================Finish================

2023-12-01 21:07:58 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:07:58 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:07:58 - INFO :       DATASET: tasksource/bigbench intersect_geometry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 21:08:09 - INFO :       Use random pruner...
2023-12-01 21:08:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:08:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:08:10 - INFO :       Start Pruning
2023-12-01 21:08:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:08:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:08:11 - INFO :       intersect_geometry: Total Sparsity 1.3570184290844972e-06
2023-12-01 21:08:11 - INFO :       
==================Finish================

2023-12-01 21:08:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:08:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:08:11 - INFO :       DATASET: tasksource/bigbench irony_identification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  3.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
2023-12-01 21:08:21 - INFO :       Use random pruner...
2023-12-01 21:08:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:08:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:08:22 - INFO :       Start Pruning
2023-12-01 21:08:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:08:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:08:24 - INFO :       irony_identification: Total Sparsity 1.3667139361772028e-06
2023-12-01 21:08:24 - INFO :       
==================Finish================

2023-12-01 21:08:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:08:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:08:24 - INFO :       DATASET: tasksource/bigbench kannada
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]
2023-12-01 21:08:32 - INFO :       Use random pruner...
2023-12-01 21:08:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:08:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:08:33 - INFO :       Start Pruning
2023-12-01 21:08:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:08:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:08:34 - INFO :       kannada: Total Sparsity 1.3593100943973186e-06
2023-12-01 21:08:34 - INFO :       
==================Finish================

2023-12-01 21:08:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:08:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:08:34 - INFO :       DATASET: tasksource/bigbench key_value_maps
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]
2023-12-01 21:08:42 - INFO :       Use random pruner...
2023-12-01 21:08:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:08:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:08:43 - INFO :       Start Pruning
2023-12-01 21:08:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:08:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:08:45 - INFO :       key_value_maps: Total Sparsity 1.3684767556486038e-06
2023-12-01 21:08:45 - INFO :       
==================Finish================

2023-12-01 21:08:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:08:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:08:45 - INFO :       DATASET: tasksource/bigbench known_unknowns
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]
2023-12-01 21:08:52 - INFO :       Use random pruner...
2023-12-01 21:08:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:08:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:08:53 - INFO :       Start Pruning
2023-12-01 21:08:54 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:08:54 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:08:54 - INFO :       known_unknowns: Total Sparsity 1.3626594513929806e-06
2023-12-01 21:08:54 - INFO :       
==================Finish================

2023-12-01 21:08:54 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:08:54 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:08:54 - INFO :       DATASET: tasksource/bigbench language_identification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]
2023-12-01 21:09:04 - INFO :       Use random pruner...
2023-12-01 21:09:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:09:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:09:05 - INFO :       Start Pruning
2023-12-01 21:09:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:09:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:09:07 - INFO :       language_identification: Total Sparsity 1.3628357333401206e-06
2023-12-01 21:09:07 - INFO :       
==================Finish================

2023-12-01 21:09:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:09:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:09:07 - INFO :       DATASET: tasksource/bigbench logic_grid_puzzle
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]
2023-12-01 21:09:16 - INFO :       Use random pruner...
2023-12-01 21:09:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:09:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:09:16 - INFO :       Start Pruning
2023-12-01 21:09:17 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:09:17 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:09:18 - INFO :       logic_grid_puzzle: Total Sparsity 1.367066500071483e-06
2023-12-01 21:09:18 - INFO :       
==================Finish================

2023-12-01 21:09:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:09:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:09:18 - INFO :       DATASET: tasksource/bigbench logical_args
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 21:09:28 - INFO :       Use random pruner...
2023-12-01 21:09:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:09:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:09:28 - INFO :       Start Pruning
2023-12-01 21:09:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:09:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:09:30 - INFO :       logical_args: Total Sparsity 1.3638934250229613e-06
2023-12-01 21:09:30 - INFO :       
==================Finish================

2023-12-01 21:09:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:09:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:09:30 - INFO :       DATASET: tasksource/bigbench logical_deduction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]
2023-12-01 21:09:39 - INFO :       Use random pruner...
2023-12-01 21:09:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:09:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:09:39 - INFO :       Start Pruning
2023-12-01 21:09:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:09:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:09:41 - INFO :       logical_deduction: Total Sparsity 1.3607203499744394e-06
2023-12-01 21:09:41 - INFO :       
==================Finish================

2023-12-01 21:09:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:09:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:09:41 - INFO :       DATASET: tasksource/bigbench logical_fallacy_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.49s/it]
2023-12-01 21:09:51 - INFO :       Use random pruner...
2023-12-01 21:09:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:09:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:09:51 - INFO :       Start Pruning
2023-12-01 21:09:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:09:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:09:53 - INFO :       logical_fallacy_detection: Total Sparsity 1.3570184290844972e-06
2023-12-01 21:09:53 - INFO :       
==================Finish================

2023-12-01 21:09:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:09:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:09:53 - INFO :       DATASET: tasksource/bigbench logical_sequence
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2023-12-01 21:10:02 - INFO :       Use random pruner...
2023-12-01 21:10:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:10:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:10:02 - INFO :       Start Pruning
2023-12-01 21:10:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:10:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:10:04 - INFO :       logical_sequence: Total Sparsity 1.3568421471373572e-06
2023-12-01 21:10:04 - INFO :       
==================Finish================

2023-12-01 21:10:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:10:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:10:04 - INFO :       DATASET: tasksource/bigbench mathematical_induction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.19s/it]
2023-12-01 21:10:15 - INFO :       Use random pruner...
2023-12-01 21:10:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:10:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:10:15 - INFO :       Start Pruning
2023-12-01 21:10:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:10:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:10:17 - INFO :       mathematical_induction: Total Sparsity 1.3598389402387389e-06
2023-12-01 21:10:17 - INFO :       
==================Finish================

2023-12-01 21:10:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:10:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:10:17 - INFO :       DATASET: tasksource/bigbench medical_questions_russian
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]
2023-12-01 21:10:28 - INFO :       Use random pruner...
2023-12-01 21:10:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:10:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:10:28 - INFO :       Start Pruning
2023-12-01 21:10:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:10:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:10:30 - INFO :       medical_questions_russian: Total Sparsity 1.3556081735073764e-06
2023-12-01 21:10:30 - INFO :       
==================Finish================

2023-12-01 21:10:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:10:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:10:30 - INFO :       DATASET: tasksource/bigbench metaphor_boolean
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]
2023-12-01 21:10:42 - INFO :       Use random pruner...
2023-12-01 21:10:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:10:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:10:43 - INFO :       Start Pruning
2023-12-01 21:10:43 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:10:43 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:10:44 - INFO :       metaphor_boolean: Total Sparsity 1.3633645791815409e-06
2023-12-01 21:10:44 - INFO :       
==================Finish================

2023-12-01 21:10:44 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:10:44 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:10:44 - INFO :       DATASET: tasksource/bigbench metaphor_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2023-12-01 21:10:55 - INFO :       Use random pruner...
2023-12-01 21:10:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:10:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:10:55 - INFO :       Start Pruning
2023-12-01 21:10:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:10:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:10:57 - INFO :       metaphor_understanding: Total Sparsity 1.3601915041330191e-06
2023-12-01 21:10:57 - INFO :       
==================Finish================

2023-12-01 21:10:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:10:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:10:57 - INFO :       DATASET: tasksource/bigbench misconceptions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2023-12-01 21:11:07 - INFO :       Use random pruner...
2023-12-01 21:11:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:11:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:11:08 - INFO :       Start Pruning
2023-12-01 21:11:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:11:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:11:10 - INFO :       misconceptions: Total Sparsity 1.3702395751200048e-06
2023-12-01 21:11:10 - INFO :       
==================Finish================

2023-12-01 21:11:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:11:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:11:10 - INFO :       DATASET: tasksource/bigbench misconceptions_russian
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2023-12-01 21:11:20 - INFO :       Use random pruner...
2023-12-01 21:11:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:11:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:11:21 - INFO :       Start Pruning
2023-12-01 21:11:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:11:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:11:23 - INFO :       misconceptions_russian: Total Sparsity 1.3616017597101399e-06
2023-12-01 21:11:23 - INFO :       
==================Finish================

2023-12-01 21:11:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:11:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:11:23 - INFO :       DATASET: tasksource/bigbench mnist_ascii
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.19s/it]
2023-12-01 21:11:34 - INFO :       Use random pruner...
2023-12-01 21:11:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:11:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:11:34 - INFO :       Start Pruning
2023-12-01 21:11:35 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:11:35 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:11:36 - INFO :       mnist_ascii: Total Sparsity 1.367066500071483e-06
2023-12-01 21:11:36 - INFO :       
==================Finish================

2023-12-01 21:11:36 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:11:36 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:11:36 - INFO :       DATASET: tasksource/bigbench moral_permissibility
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]
2023-12-01 21:11:44 - INFO :       Use random pruner...
2023-12-01 21:11:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:11:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:11:45 - INFO :       Start Pruning
2023-12-01 21:11:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:11:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:11:47 - INFO :       moral_permissibility: Total Sparsity 1.3608966319215796e-06
2023-12-01 21:11:47 - INFO :       
==================Finish================

2023-12-01 21:11:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:11:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:11:47 - INFO :       DATASET: tasksource/bigbench movie_dialog_same_or_different
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]
2023-12-01 21:11:57 - INFO :       Use random pruner...
2023-12-01 21:11:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:11:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:11:57 - INFO :       Start Pruning
2023-12-01 21:11:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:11:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:11:59 - INFO :       movie_dialog_same_or_different: Total Sparsity 1.3684767556486038e-06
2023-12-01 21:11:59 - INFO :       
==================Finish================

2023-12-01 21:11:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:11:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:11:59 - INFO :       DATASET: tasksource/bigbench movie_recommendation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]
2023-12-01 21:12:07 - INFO :       Use random pruner...
2023-12-01 21:12:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:12:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:12:08 - INFO :       Start Pruning
2023-12-01 21:12:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:12:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:12:10 - INFO :       movie_recommendation: Total Sparsity 1.3661850903357826e-06
2023-12-01 21:12:10 - INFO :       
==================Finish================

2023-12-01 21:12:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:12:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:12:10 - INFO :       DATASET: tasksource/bigbench navigate
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]
2023-12-01 21:12:20 - INFO :       Use random pruner...
2023-12-01 21:12:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:12:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:12:20 - INFO :       Start Pruning
2023-12-01 21:12:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:12:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:12:22 - INFO :       navigate: Total Sparsity 1.3594863763444586e-06
2023-12-01 21:12:22 - INFO :       
==================Finish================

2023-12-01 21:12:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:12:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:12:22 - INFO :       DATASET: tasksource/bigbench nonsense_words_grammar
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]
2023-12-01 21:12:31 - INFO :       Use random pruner...
2023-12-01 21:12:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:12:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:12:32 - INFO :       Start Pruning
2023-12-01 21:12:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:12:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:12:34 - INFO :       nonsense_words_grammar: Total Sparsity 1.3633645791815409e-06
2023-12-01 21:12:34 - INFO :       
==================Finish================

2023-12-01 21:12:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:12:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:12:34 - INFO :       DATASET: tasksource/bigbench novel_concepts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.42s/it]
2023-12-01 21:12:43 - INFO :       Use random pruner...
2023-12-01 21:12:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:12:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:12:43 - INFO :       Start Pruning
2023-12-01 21:12:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:12:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:12:45 - INFO :       novel_concepts: Total Sparsity 1.365303680600082e-06
2023-12-01 21:12:45 - INFO :       
==================Finish================

2023-12-01 21:12:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:12:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:12:45 - INFO :       DATASET: tasksource/bigbench odd_one_out
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
2023-12-01 21:12:55 - INFO :       Use random pruner...
2023-12-01 21:12:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:12:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:12:55 - INFO :       Start Pruning
2023-12-01 21:12:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:12:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:12:57 - INFO :       odd_one_out: Total Sparsity 1.3538453540359754e-06
2023-12-01 21:12:57 - INFO :       
==================Finish================

2023-12-01 21:12:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:12:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:12:57 - INFO :       DATASET: tasksource/bigbench parsinlu_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2023-12-01 21:13:07 - INFO :       Use random pruner...
2023-12-01 21:13:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:13:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:13:07 - INFO :       Start Pruning
2023-12-01 21:13:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:13:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:13:09 - INFO :       parsinlu_qa: Total Sparsity 1.363717143075821e-06
2023-12-01 21:13:09 - INFO :       
==================Finish================

2023-12-01 21:13:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:13:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:13:09 - INFO :       DATASET: tasksource/bigbench penguins_in_a_table
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.22s/it]
2023-12-01 21:13:19 - INFO :       Use random pruner...
2023-12-01 21:13:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:13:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:13:19 - INFO :       Start Pruning
2023-12-01 21:13:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:13:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:13:21 - INFO :       penguins_in_a_table: Total Sparsity 1.3695344473314445e-06
2023-12-01 21:13:21 - INFO :       
==================Finish================

2023-12-01 21:13:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:13:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:13:21 - INFO :       DATASET: tasksource/bigbench persian_idioms
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2023-12-01 21:13:32 - INFO :       Use random pruner...
2023-12-01 21:13:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:13:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:13:32 - INFO :       Start Pruning
2023-12-01 21:13:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:13:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:13:34 - INFO :       persian_idioms: Total Sparsity 1.3608966319215796e-06
2023-12-01 21:13:34 - INFO :       
==================Finish================

2023-12-01 21:13:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:13:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:13:34 - INFO :       DATASET: tasksource/bigbench phrase_relatedness
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2023-12-01 21:13:44 - INFO :       Use random pruner...
2023-12-01 21:13:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:13:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:13:44 - INFO :       Start Pruning
2023-12-01 21:13:45 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:13:45 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:13:46 - INFO :       phrase_relatedness: Total Sparsity 1.3679479098071835e-06
2023-12-01 21:13:46 - INFO :       
==================Finish================

2023-12-01 21:13:46 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:13:46 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:13:46 - INFO :       DATASET: tasksource/bigbench physical_intuition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]
2023-12-01 21:13:55 - INFO :       Use random pruner...
2023-12-01 21:13:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:13:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:13:55 - INFO :       Start Pruning
2023-12-01 21:13:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:13:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:13:57 - INFO :       physical_intuition: Total Sparsity 1.3552556096130962e-06
2023-12-01 21:13:57 - INFO :       
==================Finish================

2023-12-01 21:13:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:13:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:13:57 - INFO :       DATASET: tasksource/bigbench physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2023-12-01 21:14:06 - INFO :       Use random pruner...
2023-12-01 21:14:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:14:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:14:07 - INFO :       Start Pruning
2023-12-01 21:14:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:14:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:14:09 - INFO :       physics: Total Sparsity 1.367242782018623e-06
2023-12-01 21:14:09 - INFO :       
==================Finish================

2023-12-01 21:14:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:14:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:14:09 - INFO :       DATASET: tasksource/bigbench play_dialog_same_or_different
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 21:14:17 - INFO :       Use random pruner...
2023-12-01 21:14:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:14:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:14:17 - INFO :       Start Pruning
2023-12-01 21:14:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:14:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:14:19 - INFO :       play_dialog_same_or_different: Total Sparsity 1.3663613722829226e-06
2023-12-01 21:14:19 - INFO :       
==================Finish================

2023-12-01 21:14:19 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:14:19 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:14:19 - INFO :       DATASET: tasksource/bigbench presuppositions_as_nli
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]
2023-12-01 21:14:29 - INFO :       Use random pruner...
2023-12-01 21:14:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:14:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:14:29 - INFO :       Start Pruning
2023-12-01 21:14:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:14:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:14:31 - INFO :       presuppositions_as_nli: Total Sparsity 1.3492620234103328e-06
2023-12-01 21:14:31 - INFO :       
==================Finish================

2023-12-01 21:14:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:14:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:14:31 - INFO :       DATASET: tasksource/bigbench question_selection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2023-12-01 21:14:39 - INFO :       Use random pruner...
2023-12-01 21:14:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:14:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:14:39 - INFO :       Start Pruning
2023-12-01 21:14:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:14:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:14:41 - INFO :       question_selection: Total Sparsity 1.3631882972344008e-06
2023-12-01 21:14:41 - INFO :       
==================Finish================

2023-12-01 21:14:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:14:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:14:41 - INFO :       DATASET: tasksource/bigbench reasoning_about_colored_objects
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]
2023-12-01 21:14:49 - INFO :       Use random pruner...
2023-12-01 21:14:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:14:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:14:49 - INFO :       Start Pruning
2023-12-01 21:14:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:14:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:14:51 - INFO :       reasoning_about_colored_objects: Total Sparsity 1.3603677860801591e-06
2023-12-01 21:14:51 - INFO :       
==================Finish================

2023-12-01 21:14:51 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:14:51 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:14:51 - INFO :       DATASET: tasksource/bigbench riddle_sense
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 21:14:59 - INFO :       Use random pruner...
2023-12-01 21:14:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:14:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:15:00 - INFO :       Start Pruning
2023-12-01 21:15:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:15:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:15:02 - INFO :       riddle_sense: Total Sparsity 1.360015222185879e-06
2023-12-01 21:15:02 - INFO :       
==================Finish================

2023-12-01 21:15:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:15:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:15:02 - INFO :       DATASET: tasksource/bigbench ruin_names
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 21:15:09 - INFO :       Use random pruner...
2023-12-01 21:15:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:15:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:15:09 - INFO :       Start Pruning
2023-12-01 21:15:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:15:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:15:11 - INFO :       ruin_names: Total Sparsity 1.365303680600082e-06
2023-12-01 21:15:11 - INFO :       
==================Finish================

2023-12-01 21:15:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:15:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:15:11 - INFO :       DATASET: tasksource/bigbench salient_translation_error_detection
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 21:15:19 - INFO :       Use random pruner...
2023-12-01 21:15:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:15:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:15:19 - INFO :       Start Pruning
2023-12-01 21:15:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:15:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:15:21 - INFO :       salient_translation_error_detection: Total Sparsity 1.3610729138687196e-06
2023-12-01 21:15:21 - INFO :       
==================Finish================

2023-12-01 21:15:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:15:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:15:21 - INFO :       DATASET: tasksource/bigbench sentence_ambiguity
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
2023-12-01 21:15:29 - INFO :       Use random pruner...
2023-12-01 21:15:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:15:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:15:29 - INFO :       Start Pruning
2023-12-01 21:15:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:15:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:15:31 - INFO :       sentence_ambiguity: Total Sparsity 1.3571947110316374e-06
2023-12-01 21:15:31 - INFO :       
==================Finish================

2023-12-01 21:15:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:15:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:15:31 - INFO :       DATASET: tasksource/bigbench similarities_abstraction
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
2023-12-01 21:15:39 - INFO :       Use random pruner...
2023-12-01 21:15:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:15:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:15:39 - INFO :       Start Pruning
2023-12-01 21:15:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:15:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:15:41 - INFO :       similarities_abstraction: Total Sparsity 1.369005601490024e-06
2023-12-01 21:15:41 - INFO :       
==================Finish================

2023-12-01 21:15:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:15:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:15:41 - INFO :       DATASET: tasksource/bigbench simple_ethical_questions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]
2023-12-01 21:15:49 - INFO :       Use random pruner...
2023-12-01 21:15:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:15:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:15:49 - INFO :       Start Pruning
2023-12-01 21:15:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:15:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:15:51 - INFO :       simple_ethical_questions: Total Sparsity 1.3663613722829226e-06
2023-12-01 21:15:51 - INFO :       
==================Finish================

2023-12-01 21:15:51 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:15:51 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:15:51 - INFO :       DATASET: tasksource/bigbench snarks
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.35s/it]
2023-12-01 21:15:59 - INFO :       Use random pruner...
2023-12-01 21:15:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:15:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:15:59 - INFO :       Start Pruning
2023-12-01 21:16:00 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:16:00 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:16:01 - INFO :       snarks: Total Sparsity 1.3714735487499855e-06
2023-12-01 21:16:01 - INFO :       
==================Finish================

2023-12-01 21:16:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:16:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:16:01 - INFO :       DATASET: tasksource/bigbench social_iqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.44s/it]
2023-12-01 21:16:09 - INFO :       Use random pruner...
2023-12-01 21:16:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:16:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:16:09 - INFO :       Start Pruning
2023-12-01 21:16:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:16:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:16:11 - INFO :       social_iqa: Total Sparsity 1.3667139361772028e-06
2023-12-01 21:16:11 - INFO :       
==================Finish================

2023-12-01 21:16:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:16:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:16:11 - INFO :       DATASET: tasksource/bigbench social_support
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]
2023-12-01 21:16:19 - INFO :       Use random pruner...
2023-12-01 21:16:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:16:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:16:19 - INFO :       Start Pruning
2023-12-01 21:16:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:16:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:16:21 - INFO :       social_support: Total Sparsity 1.3612491958158596e-06
2023-12-01 21:16:21 - INFO :       
==================Finish================

2023-12-01 21:16:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:16:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:16:21 - INFO :       DATASET: tasksource/bigbench sports_understanding
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.48s/it]
2023-12-01 21:16:29 - INFO :       Use random pruner...
2023-12-01 21:16:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:16:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:16:29 - INFO :       Start Pruning
2023-12-01 21:16:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:16:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:16:31 - INFO :       sports_understanding: Total Sparsity 1.3675953459129033e-06
2023-12-01 21:16:31 - INFO :       
==================Finish================

2023-12-01 21:16:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:16:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:16:31 - INFO :       DATASET: tasksource/bigbench strange_stories
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]
2023-12-01 21:16:38 - INFO :       Use random pruner...
2023-12-01 21:16:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:16:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:16:38 - INFO :       Start Pruning
2023-12-01 21:16:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:16:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:16:40 - INFO :       strange_stories: Total Sparsity 1.3656562444943623e-06
2023-12-01 21:16:40 - INFO :       
==================Finish================

2023-12-01 21:16:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:16:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:16:40 - INFO :       DATASET: tasksource/bigbench strategyqa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]
2023-12-01 21:16:50 - INFO :       Use random pruner...
2023-12-01 21:16:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:16:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:16:51 - INFO :       Start Pruning
2023-12-01 21:16:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:16:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:16:52 - INFO :       strategyqa: Total Sparsity 1.3549030457188162e-06
2023-12-01 21:16:52 - INFO :       
==================Finish================

2023-12-01 21:16:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:16:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:16:52 - INFO :       DATASET: tasksource/bigbench suicide_risk
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]
2023-12-01 21:17:01 - INFO :       Use random pruner...
2023-12-01 21:17:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:17:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:17:02 - INFO :       Start Pruning
2023-12-01 21:17:03 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:17:03 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:17:03 - INFO :       suicide_risk: Total Sparsity 1.358252402714478e-06
2023-12-01 21:17:03 - INFO :       
==================Finish================

2023-12-01 21:17:03 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:17:03 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:17:03 - INFO :       DATASET: tasksource/bigbench swahili_english_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.33s/it]
2023-12-01 21:17:14 - INFO :       Use random pruner...
2023-12-01 21:17:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:17:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:17:15 - INFO :       Start Pruning
2023-12-01 21:17:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:17:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:17:16 - INFO :       swahili_english_proverbs: Total Sparsity 1.3534927901416952e-06
2023-12-01 21:17:16 - INFO :       
==================Finish================

2023-12-01 21:17:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:17:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:17:16 - INFO :       DATASET: tasksource/bigbench swedish_to_german_proverbs
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]
2023-12-01 21:17:27 - INFO :       Use random pruner...
2023-12-01 21:17:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:17:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:17:27 - INFO :       Start Pruning
2023-12-01 21:17:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:17:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:17:29 - INFO :       swedish_to_german_proverbs: Total Sparsity 1.3621306055515601e-06
2023-12-01 21:17:29 - INFO :       
==================Finish================

2023-12-01 21:17:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:17:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:17:29 - INFO :       DATASET: tasksource/bigbench symbol_interpretation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]
2023-12-01 21:17:38 - INFO :       Use random pruner...
2023-12-01 21:17:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:17:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:17:39 - INFO :       Start Pruning
2023-12-01 21:17:39 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:17:39 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:17:40 - INFO :       symbol_interpretation: Total Sparsity 1.3624831694458404e-06
2023-12-01 21:17:40 - INFO :       
==================Finish================

2023-12-01 21:17:40 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:17:40 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:17:40 - INFO :       DATASET: tasksource/bigbench temporal_sequences
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 21:17:50 - INFO :       Use random pruner...
2023-12-01 21:17:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:17:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:17:51 - INFO :       Start Pruning
2023-12-01 21:17:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:17:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:17:52 - INFO :       temporal_sequences: Total Sparsity 1.367066500071483e-06
2023-12-01 21:17:52 - INFO :       
==================Finish================

2023-12-01 21:17:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:17:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:17:52 - INFO :       DATASET: tasksource/bigbench timedial
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]
2023-12-01 21:18:03 - INFO :       Use random pruner...
2023-12-01 21:18:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:18:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:18:03 - INFO :       Start Pruning
2023-12-01 21:18:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:18:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:18:05 - INFO :       timedial: Total Sparsity 1.3624831694458404e-06
2023-12-01 21:18:05 - INFO :       
==================Finish================

2023-12-01 21:18:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:18:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:18:05 - INFO :       DATASET: tasksource/bigbench tracking_shuffled_objects
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]
2023-12-01 21:18:15 - INFO :       Use random pruner...
2023-12-01 21:18:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:18:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:18:16 - INFO :       Start Pruning
2023-12-01 21:18:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:18:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:18:17 - INFO :       tracking_shuffled_objects: Total Sparsity 1.3561370193487967e-06
2023-12-01 21:18:17 - INFO :       
==================Finish================

2023-12-01 21:18:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:18:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:18:17 - INFO :       DATASET: tasksource/bigbench understanding_fables
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
2023-12-01 21:18:27 - INFO :       Use random pruner...
2023-12-01 21:18:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:18:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:18:28 - INFO :       Start Pruning
2023-12-01 21:18:28 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:18:28 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:18:29 - INFO :       understanding_fables: Total Sparsity 1.3656562444943623e-06
2023-12-01 21:18:29 - INFO :       
==================Finish================

2023-12-01 21:18:29 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:18:29 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:18:29 - INFO :       DATASET: tasksource/bigbench undo_permutation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]
2023-12-01 21:18:39 - INFO :       Use random pruner...
2023-12-01 21:18:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:18:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:18:39 - INFO :       Start Pruning
2023-12-01 21:18:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:18:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:18:41 - INFO :       undo_permutation: Total Sparsity 1.3633645791815409e-06
2023-12-01 21:18:41 - INFO :       
==================Finish================

2023-12-01 21:18:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:18:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:18:41 - INFO :       DATASET: tasksource/bigbench unit_interpretation
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]
2023-12-01 21:18:51 - INFO :       Use random pruner...
2023-12-01 21:18:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:18:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:18:51 - INFO :       Start Pruning
2023-12-01 21:18:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:18:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:18:53 - INFO :       unit_interpretation: Total Sparsity 1.368829319542884e-06
2023-12-01 21:18:53 - INFO :       
==================Finish================

2023-12-01 21:18:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:18:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:18:53 - INFO :       DATASET: tasksource/bigbench vitaminc_fact_verification
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 21:19:00 - INFO :       Use random pruner...
2023-12-01 21:19:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:19:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:19:00 - INFO :       Start Pruning
2023-12-01 21:19:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:19:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:19:02 - INFO :       vitaminc_fact_verification: Total Sparsity 1.3616017597101399e-06
2023-12-01 21:19:02 - INFO :       
==================Finish================

2023-12-01 21:19:02 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:19:02 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:19:02 - INFO :       DATASET: tasksource/bigbench what_is_the_tao
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2023-12-01 21:19:10 - INFO :       Use random pruner...
2023-12-01 21:19:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:19:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:19:11 - INFO :       Start Pruning
2023-12-01 21:19:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:19:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:19:13 - INFO :       what_is_the_tao: Total Sparsity 1.3586049666087581e-06
2023-12-01 21:19:13 - INFO :       
==================Finish================

2023-12-01 21:19:13 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:19:13 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:19:13 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 21:19:19 - INFO :       Use random pruner...
2023-12-01 21:19:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:19:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:19:20 - INFO :       Start Pruning
2023-12-01 21:19:20 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:19:20 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:19:21 - INFO :       which_wiki_edit: Total Sparsity 1.354550481824536e-06
2023-12-01 21:19:21 - INFO :       
==================Finish================

2023-12-01 21:19:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:19:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:19:21 - INFO :       DATASET: tasksource/bigbench winowhy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 21:19:29 - INFO :       Use random pruner...
2023-12-01 21:19:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:19:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:19:29 - INFO :       Start Pruning
2023-12-01 21:19:30 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:19:30 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:19:31 - INFO :       winowhy: Total Sparsity 1.3631882972344008e-06
2023-12-01 21:19:31 - INFO :       
==================Finish================

2023-12-01 21:19:31 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:19:31 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:19:31 - INFO :       DATASET: tasksource/mmlu abstract_algebra
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.18s/it]
2023-12-01 21:19:40 - INFO :       Use random pruner...
2023-12-01 21:19:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:19:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:19:41 - INFO :       Start Pruning
2023-12-01 21:19:42 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:19:42 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:19:42 - INFO :       abstract_algebra: Total Sparsity 1.3661850903357826e-06
2023-12-01 21:19:42 - INFO :       
==================Finish================

2023-12-01 21:19:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:19:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:19:42 - INFO :       DATASET: tasksource/mmlu anatomy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 21:19:49 - INFO :       Use random pruner...
2023-12-01 21:19:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:19:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:19:49 - INFO :       Start Pruning
2023-12-01 21:19:50 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:19:50 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:19:51 - INFO :       anatomy: Total Sparsity 1.3619543236044201e-06
2023-12-01 21:19:51 - INFO :       
==================Finish================

2023-12-01 21:19:51 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:19:51 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:19:51 - INFO :       DATASET: tasksource/mmlu astronomy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2023-12-01 21:20:02 - INFO :       Use random pruner...
2023-12-01 21:20:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:20:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:20:03 - INFO :       Start Pruning
2023-12-01 21:20:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:20:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:20:05 - INFO :       astronomy: Total Sparsity 1.3693581653843043e-06
2023-12-01 21:20:05 - INFO :       
==================Finish================

2023-12-01 21:20:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:20:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:20:05 - INFO :       DATASET: tasksource/mmlu business_ethics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2023-12-01 21:20:15 - INFO :       Use random pruner...
2023-12-01 21:20:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:20:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:20:15 - INFO :       Start Pruning
2023-12-01 21:20:16 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:20:16 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:20:17 - INFO :       business_ethics: Total Sparsity 1.3566658651902172e-06
2023-12-01 21:20:17 - INFO :       
==================Finish================

2023-12-01 21:20:17 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:20:17 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:20:17 - INFO :       DATASET: tasksource/mmlu clinical_knowledge
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2023-12-01 21:20:25 - INFO :       Use random pruner...
2023-12-01 21:20:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:20:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:20:26 - INFO :       Start Pruning
2023-12-01 21:20:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:20:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:20:28 - INFO :       clinical_knowledge: Total Sparsity 1.3543741998773957e-06
2023-12-01 21:20:28 - INFO :       
==================Finish================

2023-12-01 21:20:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:20:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:20:28 - INFO :       DATASET: tasksource/mmlu college_biology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.24s/it]
2023-12-01 21:20:39 - INFO :       Use random pruner...
2023-12-01 21:20:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:20:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:20:40 - INFO :       Start Pruning
2023-12-01 21:20:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:20:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:20:42 - INFO :       college_biology: Total Sparsity 1.36177804165728e-06
2023-12-01 21:20:42 - INFO :       
==================Finish================

2023-12-01 21:20:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:20:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:20:42 - INFO :       DATASET: tasksource/mmlu college_chemistry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]
2023-12-01 21:20:54 - INFO :       Use random pruner...
2023-12-01 21:20:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:20:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:20:54 - INFO :       Start Pruning
2023-12-01 21:20:55 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:20:55 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:20:56 - INFO :       college_chemistry: Total Sparsity 1.3541979179302557e-06
2023-12-01 21:20:56 - INFO :       
==================Finish================

2023-12-01 21:20:56 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:20:56 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:20:56 - INFO :       DATASET: tasksource/mmlu college_computer_science
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.23s/it]
2023-12-01 21:21:08 - INFO :       Use random pruner...
2023-12-01 21:21:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:21:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:21:08 - INFO :       Start Pruning
2023-12-01 21:21:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:21:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:21:10 - INFO :       college_computer_science: Total Sparsity 1.3607203499744394e-06
2023-12-01 21:21:10 - INFO :       
==================Finish================

2023-12-01 21:21:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:21:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:21:10 - INFO :       DATASET: tasksource/mmlu college_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.41s/it]
2023-12-01 21:21:22 - INFO :       Use random pruner...
2023-12-01 21:21:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:21:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:21:22 - INFO :       Start Pruning
2023-12-01 21:21:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:21:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:21:24 - INFO :       college_mathematics: Total Sparsity 1.3661850903357826e-06
2023-12-01 21:21:24 - INFO :       
==================Finish================

2023-12-01 21:21:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:21:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:21:24 - INFO :       DATASET: tasksource/mmlu college_medicine
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 21:21:36 - INFO :       Use random pruner...
2023-12-01 21:21:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:21:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:21:36 - INFO :       Start Pruning
2023-12-01 21:21:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:21:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:21:38 - INFO :       college_medicine: Total Sparsity 1.3675953459129033e-06
2023-12-01 21:21:38 - INFO :       
==================Finish================

2023-12-01 21:21:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:21:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:21:38 - INFO :       DATASET: tasksource/mmlu college_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.22s/it]
2023-12-01 21:21:51 - INFO :       Use random pruner...
2023-12-01 21:21:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:21:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:21:51 - INFO :       Start Pruning
2023-12-01 21:21:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:21:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:21:53 - INFO :       college_physics: Total Sparsity 1.3573709929787774e-06
2023-12-01 21:21:53 - INFO :       
==================Finish================

2023-12-01 21:21:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:21:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:21:53 - INFO :       DATASET: tasksource/mmlu computer_security
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.32s/it]
2023-12-01 21:22:05 - INFO :       Use random pruner...
2023-12-01 21:22:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:22:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:22:05 - INFO :       Start Pruning
2023-12-01 21:22:06 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:22:06 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:22:07 - INFO :       computer_security: Total Sparsity 1.3584286846616181e-06
2023-12-01 21:22:07 - INFO :       
==================Finish================

2023-12-01 21:22:07 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:22:07 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:22:07 - INFO :       DATASET: tasksource/mmlu conceptual_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
2023-12-01 21:22:19 - INFO :       Use random pruner...
2023-12-01 21:22:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:22:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:22:20 - INFO :       Start Pruning
2023-12-01 21:22:21 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:22:21 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:22:21 - INFO :       conceptual_physics: Total Sparsity 1.3589575305030384e-06
2023-12-01 21:22:21 - INFO :       
==================Finish================

2023-12-01 21:22:21 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:22:21 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:22:21 - INFO :       DATASET: tasksource/mmlu econometrics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]
2023-12-01 21:22:33 - INFO :       Use random pruner...
2023-12-01 21:22:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:22:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:22:33 - INFO :       Start Pruning
2023-12-01 21:22:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:22:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:22:35 - INFO :       econometrics: Total Sparsity 1.3727075223799662e-06
2023-12-01 21:22:35 - INFO :       
==================Finish================

2023-12-01 21:22:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:22:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:22:35 - INFO :       DATASET: tasksource/mmlu electrical_engineering
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.28s/it]
2023-12-01 21:22:45 - INFO :       Use random pruner...
2023-12-01 21:22:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:22:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:22:45 - INFO :       Start Pruning
2023-12-01 21:22:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:22:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:22:47 - INFO :       electrical_engineering: Total Sparsity 1.3610729138687196e-06
2023-12-01 21:22:47 - INFO :       
==================Finish================

2023-12-01 21:22:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:22:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:22:47 - INFO :       DATASET: tasksource/mmlu elementary_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2023-12-01 21:22:56 - INFO :       Use random pruner...
2023-12-01 21:22:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:22:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:22:57 - INFO :       Start Pruning
2023-12-01 21:22:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:22:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:22:59 - INFO :       elementary_mathematics: Total Sparsity 1.3614254777629999e-06
2023-12-01 21:22:59 - INFO :       
==================Finish================

2023-12-01 21:22:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:22:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:22:59 - INFO :       DATASET: tasksource/mmlu formal_logic
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2023-12-01 21:23:07 - INFO :       Use random pruner...
2023-12-01 21:23:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:23:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:23:08 - INFO :       Start Pruning
2023-12-01 21:23:09 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:23:09 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:23:10 - INFO :       formal_logic: Total Sparsity 1.3603677860801591e-06
2023-12-01 21:23:10 - INFO :       
==================Finish================

2023-12-01 21:23:10 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:23:10 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:23:10 - INFO :       DATASET: tasksource/mmlu global_facts
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 21:23:16 - INFO :       Use random pruner...
2023-12-01 21:23:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:23:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:23:17 - INFO :       Start Pruning
2023-12-01 21:23:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:23:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:23:18 - INFO :       global_facts: Total Sparsity 1.3630120152872606e-06
2023-12-01 21:23:18 - INFO :       
==================Finish================

2023-12-01 21:23:18 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:23:18 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:23:18 - INFO :       DATASET: tasksource/mmlu high_school_biology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]
2023-12-01 21:23:28 - INFO :       Use random pruner...
2023-12-01 21:23:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:23:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:23:29 - INFO :       Start Pruning
2023-12-01 21:23:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:23:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:23:30 - INFO :       high_school_biology: Total Sparsity 1.3594863763444586e-06
2023-12-01 21:23:30 - INFO :       
==================Finish================

2023-12-01 21:23:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:23:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:23:30 - INFO :       DATASET: tasksource/mmlu high_school_chemistry
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.27s/it]
2023-12-01 21:23:38 - INFO :       Use random pruner...
2023-12-01 21:23:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:23:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:23:39 - INFO :       Start Pruning
2023-12-01 21:23:40 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:23:40 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:23:41 - INFO :       high_school_chemistry: Total Sparsity 1.367242782018623e-06
2023-12-01 21:23:41 - INFO :       
==================Finish================

2023-12-01 21:23:41 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:23:41 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:23:41 - INFO :       DATASET: tasksource/mmlu high_school_computer_science
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 21:23:50 - INFO :       Use random pruner...
2023-12-01 21:23:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:23:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:23:51 - INFO :       Start Pruning
2023-12-01 21:23:51 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:23:51 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:23:52 - INFO :       high_school_computer_science: Total Sparsity 1.3616017597101399e-06
2023-12-01 21:23:52 - INFO :       
==================Finish================

2023-12-01 21:23:52 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:23:52 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:23:52 - INFO :       DATASET: tasksource/mmlu high_school_european_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2023-12-01 21:24:02 - INFO :       Use random pruner...
2023-12-01 21:24:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:24:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:24:03 - INFO :       Start Pruning
2023-12-01 21:24:04 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:24:04 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:24:04 - INFO :       high_school_european_history: Total Sparsity 1.3640697069701013e-06
2023-12-01 21:24:04 - INFO :       
==================Finish================

2023-12-01 21:24:04 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:24:04 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:24:04 - INFO :       DATASET: tasksource/mmlu high_school_geography
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2023-12-01 21:24:13 - INFO :       Use random pruner...
2023-12-01 21:24:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:24:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:24:14 - INFO :       Start Pruning
2023-12-01 21:24:15 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:24:15 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:24:16 - INFO :       high_school_geography: Total Sparsity 1.3598389402387389e-06
2023-12-01 21:24:16 - INFO :       
==================Finish================

2023-12-01 21:24:16 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:24:16 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:24:16 - INFO :       DATASET: tasksource/mmlu high_school_government_and_politics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2023-12-01 21:24:25 - INFO :       Use random pruner...
2023-12-01 21:24:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:24:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:24:26 - INFO :       Start Pruning
2023-12-01 21:24:27 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:24:27 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:24:28 - INFO :       high_school_government_and_politics: Total Sparsity 1.3645985528115216e-06
2023-12-01 21:24:28 - INFO :       
==================Finish================

2023-12-01 21:24:28 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:24:28 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:24:28 - INFO :       DATASET: tasksource/mmlu high_school_macroeconomics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]
2023-12-01 21:24:37 - INFO :       Use random pruner...
2023-12-01 21:24:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:24:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:24:37 - INFO :       Start Pruning
2023-12-01 21:24:38 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:24:38 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:24:39 - INFO :       high_school_macroeconomics: Total Sparsity 1.365303680600082e-06
2023-12-01 21:24:39 - INFO :       
==================Finish================

2023-12-01 21:24:39 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:24:39 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:24:39 - INFO :       DATASET: tasksource/mmlu high_school_mathematics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 21:24:47 - INFO :       Use random pruner...
2023-12-01 21:24:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:24:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:24:48 - INFO :       Start Pruning
2023-12-01 21:24:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:24:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:24:49 - INFO :       high_school_mathematics: Total Sparsity 1.3642459889172413e-06
2023-12-01 21:24:49 - INFO :       
==================Finish================

2023-12-01 21:24:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:24:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:24:49 - INFO :       DATASET: tasksource/mmlu high_school_microeconomics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.23s/it]
2023-12-01 21:24:58 - INFO :       Use random pruner...
2023-12-01 21:24:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:24:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:24:58 - INFO :       Start Pruning
2023-12-01 21:24:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:24:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:25:00 - INFO :       high_school_microeconomics: Total Sparsity 1.352963944300275e-06
2023-12-01 21:25:00 - INFO :       
==================Finish================

2023-12-01 21:25:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:25:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:25:00 - INFO :       DATASET: tasksource/mmlu high_school_physics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]
2023-12-01 21:25:10 - INFO :       Use random pruner...
2023-12-01 21:25:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:25:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:25:11 - INFO :       Start Pruning
2023-12-01 21:25:11 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:25:11 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:25:12 - INFO :       high_school_physics: Total Sparsity 1.3571947110316374e-06
2023-12-01 21:25:12 - INFO :       
==================Finish================

2023-12-01 21:25:12 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:25:12 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:25:12 - INFO :       DATASET: tasksource/mmlu high_school_psychology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]
2023-12-01 21:25:22 - INFO :       Use random pruner...
2023-12-01 21:25:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:25:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:25:23 - INFO :       Start Pruning
2023-12-01 21:25:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:25:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:25:24 - INFO :       high_school_psychology: Total Sparsity 1.3603677860801591e-06
2023-12-01 21:25:24 - INFO :       
==================Finish================

2023-12-01 21:25:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:25:24 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:25:24 - INFO :       DATASET: tasksource/mmlu high_school_statistics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2023-12-01 21:25:36 - INFO :       Use random pruner...
2023-12-01 21:25:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:25:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:25:36 - INFO :       Start Pruning
2023-12-01 21:25:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:25:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:25:38 - INFO :       high_school_statistics: Total Sparsity 1.3571947110316374e-06
2023-12-01 21:25:38 - INFO :       
==================Finish================

2023-12-01 21:25:38 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:25:38 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:25:38 - INFO :       DATASET: tasksource/mmlu high_school_us_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.32s/it]
2023-12-01 21:25:47 - INFO :       Use random pruner...
2023-12-01 21:25:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:25:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:25:48 - INFO :       Start Pruning
2023-12-01 21:25:48 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:25:48 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:25:49 - INFO :       high_school_us_history: Total Sparsity 1.356313301295937e-06
2023-12-01 21:25:49 - INFO :       
==================Finish================

2023-12-01 21:25:49 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:25:49 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:25:49 - INFO :       DATASET: tasksource/mmlu high_school_world_history
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.22s/it]
2023-12-01 21:25:59 - INFO :       Use random pruner...
2023-12-01 21:25:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:25:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:26:00 - INFO :       Start Pruning
2023-12-01 21:26:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:26:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:26:01 - INFO :       high_school_world_history: Total Sparsity 1.3712972668028455e-06
2023-12-01 21:26:01 - INFO :       
==================Finish================

2023-12-01 21:26:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:26:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:26:01 - INFO :       DATASET: tasksource/mmlu human_aging
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2023-12-01 21:26:11 - INFO :       Use random pruner...
2023-12-01 21:26:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:26:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:26:12 - INFO :       Start Pruning
2023-12-01 21:26:13 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:26:13 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:26:14 - INFO :       human_aging: Total Sparsity 1.3559607374016567e-06
2023-12-01 21:26:14 - INFO :       
==================Finish================

2023-12-01 21:26:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:26:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:26:14 - INFO :       DATASET: tasksource/mmlu human_sexuality
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]
2023-12-01 21:26:23 - INFO :       Use random pruner...
2023-12-01 21:26:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:26:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:26:24 - INFO :       Start Pruning
2023-12-01 21:26:25 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:26:25 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:26:25 - INFO :       human_sexuality: Total Sparsity 1.358076120767338e-06
2023-12-01 21:26:25 - INFO :       
==================Finish================

2023-12-01 21:26:25 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:26:25 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:26:25 - INFO :       DATASET: tasksource/mmlu international_law
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]
2023-12-01 21:26:35 - INFO :       Use random pruner...
2023-12-01 21:26:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:26:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:26:36 - INFO :       Start Pruning
2023-12-01 21:26:37 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:26:37 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:26:37 - INFO :       international_law: Total Sparsity 1.3630120152872606e-06
2023-12-01 21:26:37 - INFO :       
==================Finish================

2023-12-01 21:26:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:26:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:26:37 - INFO :       DATASET: tasksource/mmlu jurisprudence
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2023-12-01 21:26:48 - INFO :       Use random pruner...
2023-12-01 21:26:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:26:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:26:48 - INFO :       Start Pruning
2023-12-01 21:26:49 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:26:49 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:26:50 - INFO :       jurisprudence: Total Sparsity 1.3584286846616181e-06
2023-12-01 21:26:50 - INFO :       
==================Finish================

2023-12-01 21:26:50 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:26:50 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:26:50 - INFO :       DATASET: tasksource/mmlu logical_fallacies
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.50s/it]
2023-12-01 21:26:59 - INFO :       Use random pruner...
2023-12-01 21:26:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:26:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:27:00 - INFO :       Start Pruning
2023-12-01 21:27:01 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:27:01 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:27:01 - INFO :       logical_fallacies: Total Sparsity 1.3674190639657633e-06
2023-12-01 21:27:01 - INFO :       
==================Finish================

2023-12-01 21:27:01 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:27:01 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:27:01 - INFO :       DATASET: tasksource/mmlu machine_learning
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]
2023-12-01 21:27:11 - INFO :       Use random pruner...
2023-12-01 21:27:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:27:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:27:11 - INFO :       Start Pruning
2023-12-01 21:27:12 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:27:12 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:27:13 - INFO :       machine_learning: Total Sparsity 1.3727075223799662e-06
2023-12-01 21:27:13 - INFO :       
==================Finish================

2023-12-01 21:27:13 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:27:13 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:27:13 - INFO :       DATASET: tasksource/mmlu management
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2023-12-01 21:27:21 - INFO :       Use random pruner...
2023-12-01 21:27:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:27:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:27:22 - INFO :       Start Pruning
2023-12-01 21:27:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:27:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:27:23 - INFO :       management: Total Sparsity 1.3644222708643816e-06
2023-12-01 21:27:23 - INFO :       
==================Finish================

2023-12-01 21:27:23 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:27:23 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:27:23 - INFO :       DATASET: tasksource/mmlu marketing
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]
2023-12-01 21:27:33 - INFO :       Use random pruner...
2023-12-01 21:27:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:27:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:27:33 - INFO :       Start Pruning
2023-12-01 21:27:34 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:27:34 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:27:35 - INFO :       marketing: Total Sparsity 1.370415857067145e-06
2023-12-01 21:27:35 - INFO :       
==================Finish================

2023-12-01 21:27:35 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:27:35 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:27:35 - INFO :       DATASET: tasksource/mmlu medical_genetics
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]
2023-12-01 21:27:45 - INFO :       Use random pruner...
2023-12-01 21:27:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:27:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:27:45 - INFO :       Start Pruning
2023-12-01 21:27:46 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:27:46 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:27:47 - INFO :       medical_genetics: Total Sparsity 1.363717143075821e-06
2023-12-01 21:27:47 - INFO :       
==================Finish================

2023-12-01 21:27:47 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:27:47 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:27:47 - INFO :       DATASET: tasksource/mmlu miscellaneous
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2023-12-01 21:27:57 - INFO :       Use random pruner...
2023-12-01 21:27:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:27:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:27:57 - INFO :       Start Pruning
2023-12-01 21:27:58 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:27:58 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:27:59 - INFO :       miscellaneous: Total Sparsity 1.3667139361772028e-06
2023-12-01 21:27:59 - INFO :       
==================Finish================

2023-12-01 21:27:59 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:27:59 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:27:59 - INFO :       DATASET: tasksource/mmlu moral_disputes
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2023-12-01 21:28:09 - INFO :       Use random pruner...
2023-12-01 21:28:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:28:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:28:09 - INFO :       Start Pruning
2023-12-01 21:28:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:28:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:28:11 - INFO :       moral_disputes: Total Sparsity 1.3642459889172413e-06
2023-12-01 21:28:11 - INFO :       
==================Finish================

2023-12-01 21:28:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:28:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:28:11 - INFO :       DATASET: tasksource/mmlu moral_scenarios
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.91s/it]
2023-12-01 21:28:20 - INFO :       Use random pruner...
2023-12-01 21:28:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:28:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:28:21 - INFO :       Start Pruning
2023-12-01 21:28:22 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:28:22 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:28:22 - INFO :       moral_scenarios: Total Sparsity 1.3587812485558984e-06
2023-12-01 21:28:22 - INFO :       
==================Finish================

2023-12-01 21:28:22 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:28:22 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:28:22 - INFO :       DATASET: tasksource/mmlu nutrition
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2023-12-01 21:28:31 - INFO :       Use random pruner...
2023-12-01 21:28:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:28:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:28:32 - INFO :       Start Pruning
2023-12-01 21:28:33 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:28:33 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:28:34 - INFO :       nutrition: Total Sparsity 1.3640697069701013e-06
2023-12-01 21:28:34 - INFO :       
==================Finish================

2023-12-01 21:28:34 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:28:34 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:28:34 - INFO :       DATASET: tasksource/mmlu philosophy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2023-12-01 21:28:43 - INFO :       Use random pruner...
2023-12-01 21:28:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:28:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:28:43 - INFO :       Start Pruning
2023-12-01 21:28:44 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:28:44 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:28:45 - INFO :       philosophy: Total Sparsity 1.3623068874987003e-06
2023-12-01 21:28:45 - INFO :       
==================Finish================

2023-12-01 21:28:45 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:28:45 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:28:45 - INFO :       DATASET: tasksource/mmlu prehistory
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2023-12-01 21:28:55 - INFO :       Use random pruner...
2023-12-01 21:28:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:28:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:28:55 - INFO :       Start Pruning
2023-12-01 21:28:56 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:28:56 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:28:57 - INFO :       prehistory: Total Sparsity 1.3651273986529418e-06
2023-12-01 21:28:57 - INFO :       
==================Finish================

2023-12-01 21:28:57 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:28:57 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:28:57 - INFO :       DATASET: tasksource/mmlu professional_accounting
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2023-12-01 21:29:07 - INFO :       Use random pruner...
2023-12-01 21:29:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:29:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:29:07 - INFO :       Start Pruning
2023-12-01 21:29:08 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:29:08 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:29:09 - INFO :       professional_accounting: Total Sparsity 1.3651273986529418e-06
2023-12-01 21:29:09 - INFO :       
==================Finish================

2023-12-01 21:29:09 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:29:09 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:29:09 - INFO :       DATASET: tasksource/mmlu professional_law
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.21s/it]
2023-12-01 21:29:17 - INFO :       Use random pruner...
2023-12-01 21:29:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:29:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:29:17 - INFO :       Start Pruning
2023-12-01 21:29:18 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:29:18 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:29:19 - INFO :       professional_law: Total Sparsity 1.3601915041330191e-06
2023-12-01 21:29:19 - INFO :       
==================Finish================

2023-12-01 21:29:19 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:29:19 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:29:19 - INFO :       DATASET: tasksource/mmlu professional_medicine
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.19s/it]
2023-12-01 21:29:28 - INFO :       Use random pruner...
2023-12-01 21:29:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:29:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:29:28 - INFO :       Start Pruning
2023-12-01 21:29:29 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:29:29 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:29:30 - INFO :       professional_medicine: Total Sparsity 1.366890218124343e-06
2023-12-01 21:29:30 - INFO :       
==================Finish================

2023-12-01 21:29:30 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:29:30 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:29:30 - INFO :       DATASET: tasksource/mmlu professional_psychology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2023-12-01 21:29:40 - INFO :       Use random pruner...
2023-12-01 21:29:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:29:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:29:40 - INFO :       Start Pruning
2023-12-01 21:29:41 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:29:41 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:29:42 - INFO :       professional_psychology: Total Sparsity 1.3577235568730577e-06
2023-12-01 21:29:42 - INFO :       
==================Finish================

2023-12-01 21:29:42 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:29:42 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:29:42 - INFO :       DATASET: tasksource/mmlu public_relations
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 21:29:51 - INFO :       Use random pruner...
2023-12-01 21:29:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:29:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:29:51 - INFO :       Start Pruning
2023-12-01 21:29:52 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:29:52 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:29:53 - INFO :       public_relations: Total Sparsity 1.3550793276659562e-06
2023-12-01 21:29:53 - INFO :       
==================Finish================

2023-12-01 21:29:53 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:29:53 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:29:53 - INFO :       DATASET: tasksource/mmlu security_studies
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]
2023-12-01 21:30:03 - INFO :       Use random pruner...
2023-12-01 21:30:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:30:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:30:04 - INFO :       Start Pruning
2023-12-01 21:30:05 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:30:05 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:30:05 - INFO :       security_studies: Total Sparsity 1.3679479098071835e-06
2023-12-01 21:30:05 - INFO :       
==================Finish================

2023-12-01 21:30:05 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:30:05 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:30:05 - INFO :       DATASET: tasksource/mmlu sociology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.25s/it]
2023-12-01 21:30:12 - INFO :       Use random pruner...
2023-12-01 21:30:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:30:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:30:13 - INFO :       Start Pruning
2023-12-01 21:30:14 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:30:14 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:30:14 - INFO :       sociology: Total Sparsity 1.3575472749259176e-06
2023-12-01 21:30:14 - INFO :       
==================Finish================

2023-12-01 21:30:14 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:30:14 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:30:14 - INFO :       DATASET: tasksource/mmlu us_foreign_policy
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
2023-12-01 21:30:24 - INFO :       Use random pruner...
2023-12-01 21:30:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:30:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:30:25 - INFO :       Start Pruning
2023-12-01 21:30:26 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:30:26 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:30:26 - INFO :       us_foreign_policy: Total Sparsity 1.3605440680272994e-06
2023-12-01 21:30:26 - INFO :       
==================Finish================

2023-12-01 21:30:26 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:30:26 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:30:26 - INFO :       DATASET: tasksource/mmlu virology
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.20s/it]
2023-12-01 21:30:35 - INFO :       Use random pruner...
2023-12-01 21:30:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:30:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:30:35 - INFO :       Start Pruning
2023-12-01 21:30:36 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:30:36 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:30:37 - INFO :       virology: Total Sparsity 1.3630120152872606e-06
2023-12-01 21:30:37 - INFO :       
==================Finish================

2023-12-01 21:30:37 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:30:37 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:30:37 - INFO :       DATASET: tasksource/mmlu world_religions
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]
2023-12-01 21:30:46 - INFO :       Use random pruner...
2023-12-01 21:30:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:30:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:30:46 - INFO :       Start Pruning
2023-12-01 21:30:47 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:30:47 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:30:48 - INFO :       world_religions: Total Sparsity 1.3681241917543236e-06
2023-12-01 21:30:48 - INFO :       
==================Finish================

2023-12-01 21:30:48 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:30:48 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:30:48 - INFO :       DATASET: math_qa
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  2.00s/it]
2023-12-01 21:30:58 - INFO :       Use random pruner...
2023-12-01 21:30:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:30:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:30:58 - INFO :       Start Pruning
2023-12-01 21:30:59 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:30:59 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:31:00 - INFO :       math_qa: Total Sparsity 1.356489583243077e-06
2023-12-01 21:31:00 - INFO :       
==================Finish================

2023-12-01 21:31:00 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:31:00 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:31:00 - INFO :       DATASET: EleutherAI/truthful_qa_mc
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2023-12-01 21:31:09 - INFO :       Use random pruner...
2023-12-01 21:31:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:31:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:31:09 - INFO :       Start Pruning
2023-12-01 21:31:10 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:31:10 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:31:11 - INFO :       truthful_qa_mc: Total Sparsity 1.3605440680272994e-06
2023-12-01 21:31:11 - INFO :       
==================Finish================

2023-12-01 21:31:11 - INFO :       Memory Requirement: 11468.64892578125 MiB

2023-12-01 21:31:11 - INFO :       
********************************************************************************************************************************************************************************************************

2023-12-01 21:31:11 - INFO :       DATASET: derek-thomas/ScienceQA
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2023-12-01 21:31:21 - INFO :       Use random pruner...
2023-12-01 21:31:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:31:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2023-12-01 21:31:22 - INFO :       Start Pruning
2023-12-01 21:31:23 - INFO :       After Iter 1/1, #parameters: 5935140864
2023-12-01 21:31:23 - INFO :       #Param before: 6738415616, #Param after: 5935140864, Ratio = 88.0792%
2023-12-01 21:31:24 - INFO :       ScienceQA: Total Sparsity 1.3631882972344008e-06
2023-12-01 21:31:24 - INFO :       
==================Finish================

2023-12-01 21:31:24 - INFO :       Memory Requirement: 11468.64892578125 MiB

