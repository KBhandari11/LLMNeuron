Begin: Memory Requirement: 0.0 MiB

2024-04-21 23:24:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:24:42 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
Index 0
Sparsity 3.5000000000000004 %
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]/home/bhandk/miniconda3/envs/MLNeuron/lib/python3.9/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()
  return self.fget.__get__(instance, owner)()
Loading checkpoint shards:  50%|█████     | 1/2 [05:43<05:43, 343.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [08:59<00:00, 256.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [08:59<00:00, 269.87s/it]
/home/bhandk/miniconda3/envs/MLNeuron/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/bhandk/miniconda3/envs/MLNeuron/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`. This was detected when initializing the generation config instance, which means the corresponding file may hold incorrect parameterization and should be fixed.
  warnings.warn(
/home/bhandk/miniconda3/envs/MLNeuron/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:492: UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `temperature`.
  warnings.warn(
/home/bhandk/miniconda3/envs/MLNeuron/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:497: UserWarning: `do_sample` is set to `False`. However, `top_p` is set to `0.6` -- this flag is only used in sample-based generation modes. You should set `do_sample=True` or unset `top_p`.
  warnings.warn(
2024-04-21 23:33:49 - INFO :       Use taylor pruner...
2024-04-21 23:33:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:33:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:33:50 - INFO :       Start Pruning
2024-04-21 23:33:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:33:53 - INFO :       Loss = 3.70703125
2024-04-21 23:33:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:33:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:33:56 - INFO :       which_wiki_edit: Total Sparsity 1.35603977736369e-06
../utils/evaluation.py:28: RuntimeWarning: divide by zero encountered in log
  np.log(probs[i].item()) for i in range(len(lbls_map))
2024-04-21 23:35:34 - INFO :       which_wiki_edit: Total Accuracy (29, 50, 0.58)
2024-04-21 23:35:35 - INFO :       
==================Finish================

2024-04-21 23:35:35 - INFO :       Memory Requirement: 12844.30322265625 MiB

2024-04-21 23:35:35 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:35:35 - INFO :       DATASET: tasksource/bigbench abstract_narrative_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-21 23:35:44 - INFO :       Use taylor pruner...
2024-04-21 23:35:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:35:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:35:44 - INFO :       Start Pruning
2024-04-21 23:35:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:35:46 - INFO :       Loss = 5.09765625
2024-04-21 23:35:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:35:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:35:49 - INFO :       abstract_narrative_understanding: Total Sparsity 1.3573127553288283e-06
2024-04-21 23:36:32 - INFO :       abstract_narrative_understanding: Total Accuracy (19, 50, 0.38)
2024-04-21 23:36:32 - INFO :       
==================Finish================

2024-04-21 23:36:32 - INFO :       Memory Requirement: 12759.77392578125 MiB

2024-04-21 23:36:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:36:32 - INFO :       DATASET: tasksource/bigbench anachronisms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2024-04-21 23:36:41 - INFO :       Use taylor pruner...
2024-04-21 23:36:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:36:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:36:41 - INFO :       Start Pruning
2024-04-21 23:36:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:36:43 - INFO :       Loss = 14.3046875
2024-04-21 23:36:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:36:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:36:47 - INFO :       anachronisms: Total Sparsity 1.3584266110483244e-06
2024-04-21 23:37:23 - INFO :       anachronisms: Total Accuracy (27, 46, 0.5869565217391305)
2024-04-21 23:37:23 - INFO :       
==================Finish================

2024-04-21 23:37:23 - INFO :       Memory Requirement: 12734.77392578125 MiB

2024-04-21 23:37:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:37:23 - INFO :       DATASET: tasksource/bigbench analogical_similarity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]
2024-04-21 23:37:34 - INFO :       Use taylor pruner...
2024-04-21 23:37:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:37:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:37:35 - INFO :       Start Pruning
2024-04-21 23:37:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:37:37 - INFO :       Loss = 1.3515625
2024-04-21 23:37:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:37:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:37:40 - INFO :       analogical_similarity: Total Sparsity 1.3557215328724054e-06
2024-04-21 23:38:33 - INFO :       analogical_similarity: Total Accuracy (3, 50, 0.06)
2024-04-21 23:38:33 - INFO :       
==================Finish================

2024-04-21 23:38:33 - INFO :       Memory Requirement: 12718.77392578125 MiB

2024-04-21 23:38:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:38:33 - INFO :       DATASET: tasksource/bigbench analytic_entailment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]
2024-04-21 23:38:45 - INFO :       Use taylor pruner...
2024-04-21 23:38:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:38:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:38:45 - INFO :       Start Pruning
2024-04-21 23:38:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:38:48 - INFO :       Loss = 14.1171875
2024-04-21 23:38:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:38:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:38:50 - INFO :       analytic_entailment: Total Sparsity 1.35603977736369e-06
2024-04-21 23:39:04 - INFO :       analytic_entailment: Total Accuracy (8, 16, 0.5)
2024-04-21 23:39:05 - INFO :       
==================Finish================

2024-04-21 23:39:05 - INFO :       Memory Requirement: 12706.77392578125 MiB

2024-04-21 23:39:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:39:05 - INFO :       DATASET: tasksource/bigbench arithmetic
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2024-04-21 23:39:16 - INFO :       Use taylor pruner...
2024-04-21 23:39:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:39:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:39:17 - INFO :       Start Pruning
2024-04-21 23:39:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:39:20 - INFO :       Loss = 11.6015625
2024-04-21 23:39:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:39:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:39:23 - INFO :       arithmetic: Total Sparsity 1.3554032883811208e-06
2024-04-21 23:40:04 - INFO :       arithmetic: Total Accuracy (1, 50, 0.02)
2024-04-21 23:40:04 - INFO :       
==================Finish================

2024-04-21 23:40:04 - INFO :       Memory Requirement: 12698.77392578125 MiB

2024-04-21 23:40:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:40:04 - INFO :       DATASET: tasksource/bigbench authorship_verification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-21 23:40:15 - INFO :       Use taylor pruner...
2024-04-21 23:40:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:40:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:40:16 - INFO :       Start Pruning
2024-04-21 23:40:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:40:18 - INFO :       Loss = 2.591796875
2024-04-21 23:40:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:40:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:40:21 - INFO :       authorship_verification: Total Sparsity 1.3546076771529093e-06
2024-04-21 23:42:28 - INFO :       authorship_verification: Total Accuracy (15, 50, 0.3)
2024-04-21 23:42:28 - INFO :       
==================Finish================

2024-04-21 23:42:28 - INFO :       Memory Requirement: 12700.28857421875 MiB

2024-04-21 23:42:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:42:28 - INFO :       DATASET: tasksource/bigbench bbq_lite_json
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.91s/it]
2024-04-21 23:42:39 - INFO :       Use taylor pruner...
2024-04-21 23:42:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:42:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:42:39 - INFO :       Start Pruning
2024-04-21 23:42:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:42:41 - INFO :       Loss = 13.765625
2024-04-21 23:42:42 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:42:42 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:42:44 - INFO :       bbq_lite_json: Total Sparsity 1.3590631000308936e-06
2024-04-21 23:43:25 - INFO :       bbq_lite_json: Total Accuracy (3, 50, 0.06)
2024-04-21 23:43:25 - INFO :       
==================Finish================

2024-04-21 23:43:25 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-21 23:43:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:43:25 - INFO :       DATASET: tasksource/bigbench causal_judgment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]
2024-04-21 23:43:35 - INFO :       Use taylor pruner...
2024-04-21 23:43:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:43:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:43:36 - INFO :       Start Pruning
2024-04-21 23:43:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:43:38 - INFO :       Loss = 7.3515625
2024-04-21 23:43:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:43:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:43:42 - INFO :       causal_judgment: Total Sparsity 1.3520617212226323e-06
2024-04-21 23:44:14 - INFO :       causal_judgment: Total Accuracy (17, 38, 0.4473684210526316)
2024-04-21 23:44:14 - INFO :       
==================Finish================

2024-04-21 23:44:14 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-21 23:44:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:44:14 - INFO :       DATASET: tasksource/bigbench cause_and_effect
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-21 23:44:23 - INFO :       Use taylor pruner...
2024-04-21 23:44:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:44:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:44:23 - INFO :       Start Pruning
2024-04-21 23:44:25 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:44:26 - INFO :       Loss = 13.5859375
2024-04-21 23:44:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:44:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:44:29 - INFO :       cause_and_effect: Total Sparsity 1.3604952002416743e-06
2024-04-21 23:44:53 - INFO :       cause_and_effect: Total Accuracy (23, 30, 0.7666666666666667)
2024-04-21 23:44:54 - INFO :       
==================Finish================

2024-04-21 23:44:54 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-21 23:44:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:44:54 - INFO :       DATASET: tasksource/bigbench checkmate_in_one
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-21 23:45:02 - INFO :       Use taylor pruner...
2024-04-21 23:45:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:45:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:45:03 - INFO :       Start Pruning
2024-04-21 23:45:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:45:05 - INFO :       Loss = 2.025390625
2024-04-21 23:45:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:45:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:45:08 - INFO :       checkmate_in_one: Total Sparsity 1.3558806551180476e-06
2024-04-21 23:45:56 - INFO :       checkmate_in_one: Total Accuracy (3, 50, 0.06)
2024-04-21 23:45:57 - INFO :       
==================Finish================

2024-04-21 23:45:57 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-21 23:45:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:45:57 - INFO :       DATASET: tasksource/bigbench cifar10_classification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2024-04-21 23:46:06 - INFO :       Use taylor pruner...
2024-04-21 23:46:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:46:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:46:07 - INFO :       Start Pruning
Token indices sequence length is longer than the specified maximum sequence length for this model (6858 > 4096). Running this sequence through the model will result in indexing errors
2024-04-21 23:46:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:46:10 - INFO :       Loss = 4.2265625
2024-04-21 23:46:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:46:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:46:14 - INFO :       cifar10_classification: Total Sparsity 1.3547667993985515e-06
2024-04-21 23:48:06 - INFO :       cifar10_classification: Total Accuracy (1, 50, 0.02)
2024-04-21 23:48:07 - INFO :       
==================Finish================

2024-04-21 23:48:07 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-21 23:48:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:48:07 - INFO :       DATASET: tasksource/bigbench code_line_description
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
2024-04-21 23:48:17 - INFO :       Use taylor pruner...
2024-04-21 23:48:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:48:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:48:18 - INFO :       Start Pruning
2024-04-21 23:48:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:48:20 - INFO :       Loss = 11.046875
2024-04-21 23:48:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:48:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:48:24 - INFO :       code_line_description: Total Sparsity 1.3574718775744707e-06
2024-04-21 23:48:37 - INFO :       code_line_description: Total Accuracy (12, 16, 0.75)
2024-04-21 23:48:37 - INFO :       
==================Finish================

2024-04-21 23:48:37 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-21 23:48:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:48:37 - INFO :       DATASET: tasksource/bigbench color
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-21 23:48:46 - INFO :       Use taylor pruner...
2024-04-21 23:48:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:48:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:48:46 - INFO :       Start Pruning
2024-04-21 23:48:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:48:48 - INFO :       Loss = 11.109375
2024-04-21 23:48:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:48:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:48:51 - INFO :       color: Total Sparsity 1.3563580218549744e-06
2024-04-21 23:49:33 - INFO :       color: Total Accuracy (1, 50, 0.02)
2024-04-21 23:49:33 - INFO :       
==================Finish================

2024-04-21 23:49:33 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-21 23:49:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:49:33 - INFO :       DATASET: tasksource/bigbench common_morpheme
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-21 23:49:42 - INFO :       Use taylor pruner...
2024-04-21 23:49:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:49:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:49:42 - INFO :       Start Pruning
2024-04-21 23:49:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:49:45 - INFO :       Loss = 13.21875
2024-04-21 23:49:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:49:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:49:49 - INFO :       common_morpheme: Total Sparsity 1.3600178335047475e-06
2024-04-21 23:50:02 - INFO :       common_morpheme: Total Accuracy (4, 16, 0.25)
2024-04-21 23:50:03 - INFO :       
==================Finish================

2024-04-21 23:50:03 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-21 23:50:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:50:03 - INFO :       DATASET: tasksource/bigbench conceptual_combinations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2024-04-21 23:50:12 - INFO :       Use taylor pruner...
2024-04-21 23:50:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:50:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:50:13 - INFO :       Start Pruning
2024-04-21 23:50:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:50:15 - INFO :       Loss = 10.734375
2024-04-21 23:50:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:50:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:50:17 - INFO :       conceptual_combinations: Total Sparsity 1.3609725669786013e-06
2024-04-21 23:50:34 - INFO :       conceptual_combinations: Total Accuracy (10, 19, 0.5263157894736842)
2024-04-21 23:50:34 - INFO :       
==================Finish================

2024-04-21 23:50:34 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-21 23:50:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:50:34 - INFO :       DATASET: tasksource/bigbench crash_blossom
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]
2024-04-21 23:50:43 - INFO :       Use taylor pruner...
2024-04-21 23:50:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:50:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:50:43 - INFO :       Start Pruning
2024-04-21 23:50:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:50:45 - INFO :       Loss = 13.53125
2024-04-21 23:50:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:50:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:50:48 - INFO :       crash_blossom: Total Sparsity 1.3569945108375437e-06
2024-04-21 23:51:02 - INFO :       crash_blossom: Total Accuracy (6, 16, 0.375)
2024-04-21 23:51:02 - INFO :       
==================Finish================

2024-04-21 23:51:02 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-21 23:51:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:51:02 - INFO :       DATASET: tasksource/bigbench crass_ai
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-21 23:51:11 - INFO :       Use taylor pruner...
2024-04-21 23:51:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:51:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:51:12 - INFO :       Start Pruning
2024-04-21 23:51:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:51:14 - INFO :       Loss = 11.375
2024-04-21 23:51:15 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:51:15 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:51:17 - INFO :       crass_ai: Total Sparsity 1.358744855539609e-06
2024-04-21 23:51:31 - INFO :       crass_ai: Total Accuracy (6, 16, 0.375)
2024-04-21 23:51:31 - INFO :       
==================Finish================

2024-04-21 23:51:31 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-21 23:51:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:51:31 - INFO :       DATASET: tasksource/bigbench cryobiology_spanish
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2024-04-21 23:51:40 - INFO :       Use taylor pruner...
2024-04-21 23:51:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:51:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:51:40 - INFO :       Start Pruning
2024-04-21 23:51:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:51:42 - INFO :       Loss = 13.5390625
2024-04-21 23:51:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:51:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:51:45 - INFO :       cryobiology_spanish: Total Sparsity 1.3568353885919015e-06
2024-04-21 23:52:10 - INFO :       cryobiology_spanish: Total Accuracy (24, 29, 0.8275862068965517)
2024-04-21 23:52:10 - INFO :       
==================Finish================

2024-04-21 23:52:10 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-21 23:52:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:52:10 - INFO :       DATASET: tasksource/bigbench cs_algorithms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
2024-04-21 23:52:19 - INFO :       Use taylor pruner...
2024-04-21 23:52:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:52:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:52:20 - INFO :       Start Pruning
2024-04-21 23:52:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:52:22 - INFO :       Loss = 13.8984375
2024-04-21 23:52:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:52:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:52:25 - INFO :       cs_algorithms: Total Sparsity 1.360813444732959e-06
2024-04-21 23:53:07 - INFO :       cs_algorithms: Total Accuracy (3, 50, 0.06)
2024-04-21 23:53:07 - INFO :       
==================Finish================

2024-04-21 23:53:07 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-21 23:53:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:53:07 - INFO :       DATASET: tasksource/bigbench dark_humor_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-21 23:53:16 - INFO :       Use taylor pruner...
2024-04-21 23:53:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:53:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:53:17 - INFO :       Start Pruning
2024-04-21 23:53:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:53:19 - INFO :       Loss = 13.3046875
2024-04-21 23:53:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:53:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:53:22 - INFO :       dark_humor_detection: Total Sparsity 1.3568353885919015e-06
2024-04-21 23:53:36 - INFO :       dark_humor_detection: Total Accuracy (10, 16, 0.625)
2024-04-21 23:53:36 - INFO :       
==================Finish================

2024-04-21 23:53:36 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-21 23:53:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:53:36 - INFO :       DATASET: tasksource/bigbench date_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.30s/it]
2024-04-21 23:53:47 - INFO :       Use taylor pruner...
2024-04-21 23:53:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:53:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:53:47 - INFO :       Start Pruning
2024-04-21 23:53:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:53:49 - INFO :       Loss = 11.1640625
2024-04-21 23:53:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:53:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:53:52 - INFO :       date_understanding: Total Sparsity 1.3585857332939668e-06
2024-04-21 23:54:35 - INFO :       date_understanding: Total Accuracy (9, 50, 0.18)
2024-04-21 23:54:35 - INFO :       
==================Finish================

2024-04-21 23:54:35 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-21 23:54:35 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:54:35 - INFO :       DATASET: tasksource/bigbench disambiguation_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-21 23:54:44 - INFO :       Use taylor pruner...
2024-04-21 23:54:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:54:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:54:45 - INFO :       Start Pruning
2024-04-21 23:54:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:54:47 - INFO :       Loss = 12.3203125
2024-04-21 23:54:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:54:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:54:50 - INFO :       disambiguation_qa: Total Sparsity 1.357630999820113e-06
2024-04-21 23:55:32 - INFO :       disambiguation_qa: Total Accuracy (21, 50, 0.42)
2024-04-21 23:55:32 - INFO :       
==================Finish================

2024-04-21 23:55:32 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-21 23:55:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:55:32 - INFO :       DATASET: tasksource/bigbench discourse_marker_prediction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]
2024-04-21 23:55:42 - INFO :       Use taylor pruner...
2024-04-21 23:55:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:55:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:55:42 - INFO :       Start Pruning
2024-04-21 23:55:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:55:45 - INFO :       Loss = 0.81103515625
2024-04-21 23:55:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:55:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:55:47 - INFO :       discourse_marker_prediction: Total Sparsity 1.35397118817034e-06
2024-04-21 23:56:36 - INFO :       discourse_marker_prediction: Total Accuracy (12, 50, 0.24)
2024-04-21 23:56:36 - INFO :       
==================Finish================

2024-04-21 23:56:36 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-21 23:56:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:56:36 - INFO :       DATASET: tasksource/bigbench dyck_languages
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-21 23:56:45 - INFO :       Use taylor pruner...
2024-04-21 23:56:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:56:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:56:45 - INFO :       Start Pruning
2024-04-21 23:56:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:56:47 - INFO :       Loss = 1.1123046875
2024-04-21 23:56:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:56:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:56:50 - INFO :       dyck_languages: Total Sparsity 1.352379965713917e-06
2024-04-21 23:57:39 - INFO :       dyck_languages: Total Accuracy (0, 50, 0.0)
2024-04-21 23:57:39 - INFO :       
==================Finish================

2024-04-21 23:57:39 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-21 23:57:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:57:39 - INFO :       DATASET: tasksource/bigbench elementary_math_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-21 23:57:48 - INFO :       Use taylor pruner...
2024-04-21 23:57:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:57:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:57:49 - INFO :       Start Pruning
2024-04-21 23:57:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:57:51 - INFO :       Loss = 11.9296875
2024-04-21 23:57:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:57:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:57:54 - INFO :       elementary_math_qa: Total Sparsity 1.3595404667678207e-06
2024-04-21 23:58:36 - INFO :       elementary_math_qa: Total Accuracy (11, 50, 0.22)
2024-04-21 23:58:36 - INFO :       
==================Finish================

2024-04-21 23:58:36 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-21 23:58:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:58:36 - INFO :       DATASET: tasksource/bigbench emoji_movie
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2024-04-21 23:58:46 - INFO :       Use taylor pruner...
2024-04-21 23:58:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:58:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:58:46 - INFO :       Start Pruning
2024-04-21 23:58:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:58:49 - INFO :       Loss = 11.875
2024-04-21 23:58:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:58:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:58:51 - INFO :       emoji_movie: Total Sparsity 1.353334699187771e-06
2024-04-21 23:59:08 - INFO :       emoji_movie: Total Accuracy (11, 20, 0.55)
2024-04-21 23:59:08 - INFO :       
==================Finish================

2024-04-21 23:59:08 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-21 23:59:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:59:08 - INFO :       DATASET: tasksource/bigbench empirical_judgments
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-21 23:59:18 - INFO :       Use taylor pruner...
2024-04-21 23:59:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:59:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:59:18 - INFO :       Start Pruning
2024-04-21 23:59:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:59:20 - INFO :       Loss = 12.5546875
2024-04-21 23:59:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:59:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:59:23 - INFO :       empirical_judgments: Total Sparsity 1.3573127553288283e-06
2024-04-21 23:59:40 - INFO :       empirical_judgments: Total Accuracy (8, 19, 0.42105263157894735)
2024-04-21 23:59:40 - INFO :       
==================Finish================

2024-04-21 23:59:40 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-21 23:59:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-21 23:59:40 - INFO :       DATASET: tasksource/bigbench english_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2024-04-21 23:59:49 - INFO :       Use taylor pruner...
2024-04-21 23:59:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:59:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-21 23:59:50 - INFO :       Start Pruning
2024-04-21 23:59:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-21 23:59:52 - INFO :       Loss = 10.65625
2024-04-21 23:59:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-21 23:59:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-21 23:59:55 - INFO :       english_proverbs: Total Sparsity 1.3574718775744707e-06
2024-04-22 00:00:10 - INFO :       english_proverbs: Total Accuracy (3, 16, 0.1875)
2024-04-22 00:00:10 - INFO :       
==================Finish================

2024-04-22 00:00:10 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:00:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:00:10 - INFO :       DATASET: tasksource/bigbench english_russian_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2024-04-22 00:00:19 - INFO :       Use taylor pruner...
2024-04-22 00:00:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:00:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:00:20 - INFO :       Start Pruning
2024-04-22 00:00:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:00:22 - INFO :       Loss = 11.5859375
2024-04-22 00:00:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:00:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:00:25 - INFO :       english_russian_proverbs: Total Sparsity 1.3585857332939668e-06
2024-04-22 00:00:39 - INFO :       english_russian_proverbs: Total Accuracy (2, 16, 0.125)
2024-04-22 00:00:39 - INFO :       
==================Finish================

2024-04-22 00:00:39 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:00:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:00:39 - INFO :       DATASET: tasksource/bigbench entailed_polarity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-22 00:00:48 - INFO :       Use taylor pruner...
2024-04-22 00:00:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:00:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:00:48 - INFO :       Start Pruning
2024-04-22 00:00:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:00:50 - INFO :       Loss = 14.4140625
2024-04-22 00:00:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:00:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:00:53 - INFO :       entailed_polarity: Total Sparsity 1.3590631000308936e-06
2024-04-22 00:01:17 - INFO :       entailed_polarity: Total Accuracy (28, 29, 0.9655172413793104)
2024-04-22 00:01:17 - INFO :       
==================Finish================

2024-04-22 00:01:17 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:01:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:01:17 - INFO :       DATASET: tasksource/bigbench entailed_polarity_hindi
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]
2024-04-22 00:01:26 - INFO :       Use taylor pruner...
2024-04-22 00:01:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:01:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:01:26 - INFO :       Start Pruning
2024-04-22 00:01:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:01:28 - INFO :       Loss = 9.671875
2024-04-22 00:01:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:01:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:01:31 - INFO :       entailed_polarity_hindi: Total Sparsity 1.3566762663462592e-06
2024-04-22 00:01:54 - INFO :       entailed_polarity_hindi: Total Accuracy (16, 27, 0.5925925925925926)
2024-04-22 00:01:54 - INFO :       
==================Finish================

2024-04-22 00:01:54 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:01:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:01:54 - INFO :       DATASET: tasksource/bigbench epistemic_reasoning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2024-04-22 00:02:02 - INFO :       Use taylor pruner...
2024-04-22 00:02:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:02:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:02:03 - INFO :       Start Pruning
2024-04-22 00:02:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:02:05 - INFO :       Loss = 13.0
2024-04-22 00:02:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:02:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:02:07 - INFO :       epistemic_reasoning: Total Sparsity 1.3557215328724054e-06
2024-04-22 00:02:51 - INFO :       epistemic_reasoning: Total Accuracy (31, 50, 0.62)
2024-04-22 00:02:51 - INFO :       
==================Finish================

2024-04-22 00:02:51 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:02:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:02:51 - INFO :       DATASET: tasksource/bigbench evaluating_information_essentiality
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-22 00:03:02 - INFO :       Use taylor pruner...
2024-04-22 00:03:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:03:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:03:03 - INFO :       Start Pruning
2024-04-22 00:03:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:03:05 - INFO :       Loss = 5.9609375
2024-04-22 00:03:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:03:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:03:08 - INFO :       evaluating_information_essentiality: Total Sparsity 1.35397118817034e-06
2024-04-22 00:03:22 - INFO :       evaluating_information_essentiality: Total Accuracy (1, 16, 0.0625)
2024-04-22 00:03:22 - INFO :       
==================Finish================

2024-04-22 00:03:22 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:03:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:03:22 - INFO :       DATASET: tasksource/bigbench fact_checker
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2024-04-22 00:03:31 - INFO :       Use taylor pruner...
2024-04-22 00:03:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:03:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:03:31 - INFO :       Start Pruning
2024-04-22 00:03:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:03:34 - INFO :       Loss = 14.3984375
2024-04-22 00:03:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:03:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:03:37 - INFO :       fact_checker: Total Sparsity 1.3581083665570398e-06
2024-04-22 00:04:19 - INFO :       fact_checker: Total Accuracy (41, 50, 0.82)
2024-04-22 00:04:19 - INFO :       
==================Finish================

2024-04-22 00:04:19 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:04:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:04:19 - INFO :       DATASET: tasksource/bigbench fantasy_reasoning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]
2024-04-22 00:04:29 - INFO :       Use taylor pruner...
2024-04-22 00:04:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:04:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:04:30 - INFO :       Start Pruning
2024-04-22 00:04:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:04:32 - INFO :       Loss = 12.8828125
2024-04-22 00:04:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:04:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:04:36 - INFO :       fantasy_reasoning: Total Sparsity 1.359222222276536e-06
2024-04-22 00:05:10 - INFO :       fantasy_reasoning: Total Accuracy (22, 40, 0.55)
2024-04-22 00:05:10 - INFO :       
==================Finish================

2024-04-22 00:05:10 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:05:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:05:10 - INFO :       DATASET: tasksource/bigbench figure_of_speech_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-22 00:05:18 - INFO :       Use taylor pruner...
2024-04-22 00:05:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:05:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:05:19 - INFO :       Start Pruning
2024-04-22 00:05:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:05:21 - INFO :       Loss = 11.8671875
2024-04-22 00:05:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:05:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:05:24 - INFO :       figure_of_speech_detection: Total Sparsity 1.3569945108375437e-06
2024-04-22 00:05:39 - INFO :       figure_of_speech_detection: Total Accuracy (3, 16, 0.1875)
2024-04-22 00:05:39 - INFO :       
==================Finish================

2024-04-22 00:05:39 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:05:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:05:39 - INFO :       DATASET: tasksource/bigbench formal_fallacies_syllogisms_negation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.49s/it]
2024-04-22 00:05:47 - INFO :       Use taylor pruner...
2024-04-22 00:05:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:05:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:05:48 - INFO :       Start Pruning
2024-04-22 00:05:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:05:50 - INFO :       Loss = 11.6953125
2024-04-22 00:05:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:05:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:05:53 - INFO :       formal_fallacies_syllogisms_negation: Total Sparsity 1.358744855539609e-06
2024-04-22 00:06:37 - INFO :       formal_fallacies_syllogisms_negation: Total Accuracy (23, 50, 0.46)
2024-04-22 00:06:37 - INFO :       
==================Finish================

2024-04-22 00:06:37 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:06:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:06:37 - INFO :       DATASET: tasksource/bigbench general_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]
2024-04-22 00:06:47 - INFO :       Use taylor pruner...
2024-04-22 00:06:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:06:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:06:47 - INFO :       Start Pruning
2024-04-22 00:06:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:06:51 - INFO :       Loss = 12.359375
2024-04-22 00:06:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:06:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:06:54 - INFO :       general_knowledge: Total Sparsity 1.3546076771529093e-06
2024-04-22 00:07:08 - INFO :       general_knowledge: Total Accuracy (12, 16, 0.75)
2024-04-22 00:07:08 - INFO :       
==================Finish================

2024-04-22 00:07:08 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:07:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:07:08 - INFO :       DATASET: tasksource/bigbench geometric_shapes
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2024-04-22 00:07:17 - INFO :       Use taylor pruner...
2024-04-22 00:07:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:07:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:07:18 - INFO :       Start Pruning
2024-04-22 00:07:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:07:20 - INFO :       Loss = 8.3046875
2024-04-22 00:07:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:07:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:07:23 - INFO :       geometric_shapes: Total Sparsity 1.3563580218549744e-06
2024-04-22 00:08:06 - INFO :       geometric_shapes: Total Accuracy (6, 50, 0.12)
2024-04-22 00:08:06 - INFO :       
==================Finish================

2024-04-22 00:08:06 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:08:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:08:06 - INFO :       DATASET: tasksource/bigbench goal_step_wikihow
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2024-04-22 00:08:16 - INFO :       Use taylor pruner...
2024-04-22 00:08:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:08:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:08:17 - INFO :       Start Pruning
2024-04-22 00:08:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:08:19 - INFO :       Loss = 12.515625
2024-04-22 00:08:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:08:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:08:22 - INFO :       goal_step_wikihow: Total Sparsity 1.3600178335047475e-06
2024-04-22 00:09:04 - INFO :       goal_step_wikihow: Total Accuracy (20, 50, 0.4)
2024-04-22 00:09:04 - INFO :       
==================Finish================

2024-04-22 00:09:04 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:09:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:09:04 - INFO :       DATASET: tasksource/bigbench gre_reading_comprehension
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.45s/it]
2024-04-22 00:09:12 - INFO :       Use taylor pruner...
2024-04-22 00:09:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:09:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:09:12 - INFO :       Start Pruning
2024-04-22 00:09:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:09:14 - INFO :       Loss = 3.67578125
2024-04-22 00:09:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:09:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:09:17 - INFO :       gre_reading_comprehension: Total Sparsity 1.357153633083186e-06
2024-04-22 00:09:34 - INFO :       gre_reading_comprehension: Total Accuracy (6, 16, 0.375)
2024-04-22 00:09:34 - INFO :       
==================Finish================

2024-04-22 00:09:34 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:09:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:09:34 - INFO :       DATASET: tasksource/bigbench hhh_alignment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]
2024-04-22 00:09:42 - INFO :       Use taylor pruner...
2024-04-22 00:09:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:09:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:09:42 - INFO :       Start Pruning
2024-04-22 00:09:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:09:44 - INFO :       Loss = 11.359375
2024-04-22 00:09:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:09:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:09:47 - INFO :       hhh_alignment: Total Sparsity 1.3584266110483244e-06
2024-04-22 00:10:25 - INFO :       hhh_alignment: Total Accuracy (29, 42, 0.6904761904761905)
2024-04-22 00:10:26 - INFO :       
==================Finish================

2024-04-22 00:10:26 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:10:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:10:26 - INFO :       DATASET: tasksource/bigbench hindu_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2024-04-22 00:10:35 - INFO :       Use taylor pruner...
2024-04-22 00:10:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:10:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:10:35 - INFO :       Start Pruning
2024-04-22 00:10:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:10:37 - INFO :       Loss = 13.9375
2024-04-22 00:10:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:10:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:10:40 - INFO :       hindu_knowledge: Total Sparsity 1.361449933715528e-06
2024-04-22 00:11:10 - INFO :       hindu_knowledge: Total Accuracy (20, 35, 0.5714285714285714)
2024-04-22 00:11:10 - INFO :       
==================Finish================

2024-04-22 00:11:10 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:11:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:11:10 - INFO :       DATASET: tasksource/bigbench hinglish_toxicity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-22 00:11:18 - INFO :       Use taylor pruner...
2024-04-22 00:11:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:11:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:11:19 - INFO :       Start Pruning
2024-04-22 00:11:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:11:21 - INFO :       Loss = 14.84375
2024-04-22 00:11:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:11:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:11:24 - INFO :       hinglish_toxicity: Total Sparsity 1.3579492443113975e-06
2024-04-22 00:11:57 - INFO :       hinglish_toxicity: Total Accuracy (20, 40, 0.5)
2024-04-22 00:11:57 - INFO :       
==================Finish================

2024-04-22 00:11:57 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:11:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:11:57 - INFO :       DATASET: tasksource/bigbench human_organs_senses
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2024-04-22 00:12:07 - INFO :       Use taylor pruner...
2024-04-22 00:12:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:12:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:12:07 - INFO :       Start Pruning
2024-04-22 00:12:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:12:10 - INFO :       Loss = 14.0859375
2024-04-22 00:12:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:12:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:12:13 - INFO :       human_organs_senses: Total Sparsity 1.3590631000308936e-06
2024-04-22 00:12:26 - INFO :       human_organs_senses: Total Accuracy (8, 16, 0.5)
2024-04-22 00:12:26 - INFO :       
==================Finish================

2024-04-22 00:12:26 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:12:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:12:26 - INFO :       DATASET: tasksource/bigbench hyperbaton
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2024-04-22 00:12:35 - INFO :       Use taylor pruner...
2024-04-22 00:12:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:12:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:12:35 - INFO :       Start Pruning
2024-04-22 00:12:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:12:37 - INFO :       Loss = 14.90625
2024-04-22 00:12:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:12:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:12:40 - INFO :       hyperbaton: Total Sparsity 1.3601769557503897e-06
2024-04-22 00:13:20 - INFO :       hyperbaton: Total Accuracy (22, 50, 0.44)
2024-04-22 00:13:20 - INFO :       
==================Finish================

2024-04-22 00:13:20 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:13:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:13:20 - INFO :       DATASET: tasksource/bigbench identify_math_theorems
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.49s/it]
2024-04-22 00:13:28 - INFO :       Use taylor pruner...
2024-04-22 00:13:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:13:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:13:29 - INFO :       Start Pruning
2024-04-22 00:13:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:13:31 - INFO :       Loss = 0.84033203125
2024-04-22 00:13:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:13:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:13:34 - INFO :       identify_math_theorems: Total Sparsity 1.355085043889836e-06
2024-04-22 00:13:50 - INFO :       identify_math_theorems: Total Accuracy (7, 16, 0.4375)
2024-04-22 00:13:51 - INFO :       
==================Finish================

2024-04-22 00:13:51 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:13:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:13:51 - INFO :       DATASET: tasksource/bigbench identify_odd_metaphor
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-22 00:13:59 - INFO :       Use taylor pruner...
2024-04-22 00:13:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:13:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:13:59 - INFO :       Start Pruning
2024-04-22 00:14:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:14:01 - INFO :       Loss = 11.1015625
2024-04-22 00:14:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:14:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:14:05 - INFO :       identify_odd_metaphor: Total Sparsity 1.358744855539609e-06
2024-04-22 00:14:19 - INFO :       identify_odd_metaphor: Total Accuracy (8, 16, 0.5)
2024-04-22 00:14:19 - INFO :       
==================Finish================

2024-04-22 00:14:19 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:14:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:14:19 - INFO :       DATASET: tasksource/bigbench implicatures
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]
2024-04-22 00:14:27 - INFO :       Use taylor pruner...
2024-04-22 00:14:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:14:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:14:27 - INFO :       Start Pruning
2024-04-22 00:14:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:14:30 - INFO :       Loss = 14.2421875
2024-04-22 00:14:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:14:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:14:32 - INFO :       implicatures: Total Sparsity 1.3585857332939668e-06
2024-04-22 00:15:15 - INFO :       implicatures: Total Accuracy (34, 50, 0.68)
2024-04-22 00:15:16 - INFO :       
==================Finish================

2024-04-22 00:15:16 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:15:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:15:16 - INFO :       DATASET: tasksource/bigbench implicit_relations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-22 00:15:24 - INFO :       Use taylor pruner...
2024-04-22 00:15:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:15:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:15:25 - INFO :       Start Pruning
2024-04-22 00:15:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:15:27 - INFO :       Loss = 7.875
2024-04-22 00:15:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:15:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:15:30 - INFO :       implicit_relations: Total Sparsity 1.3549259216441938e-06
2024-04-22 00:15:46 - INFO :       implicit_relations: Total Accuracy (6, 17, 0.35294117647058826)
2024-04-22 00:15:47 - INFO :       
==================Finish================

2024-04-22 00:15:47 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:15:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:15:47 - INFO :       DATASET: tasksource/bigbench indic_cause_and_effect
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-22 00:15:55 - INFO :       Use taylor pruner...
2024-04-22 00:15:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:15:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:15:55 - INFO :       Start Pruning
2024-04-22 00:15:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:15:58 - INFO :       Loss = 7.421875
2024-04-22 00:15:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:15:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:16:01 - INFO :       indic_cause_and_effect: Total Sparsity 1.3536529436790554e-06
2024-04-22 00:16:47 - INFO :       indic_cause_and_effect: Total Accuracy (33, 50, 0.66)
2024-04-22 00:16:48 - INFO :       
==================Finish================

2024-04-22 00:16:48 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:16:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:16:48 - INFO :       DATASET: tasksource/bigbench intent_recognition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.47s/it]
2024-04-22 00:16:56 - INFO :       Use taylor pruner...
2024-04-22 00:16:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:16:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:16:56 - INFO :       Start Pruning
2024-04-22 00:16:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:16:59 - INFO :       Loss = 10.421875
2024-04-22 00:17:00 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:17:00 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:17:02 - INFO :       intent_recognition: Total Sparsity 1.357153633083186e-06
2024-04-22 00:17:44 - INFO :       intent_recognition: Total Accuracy (24, 50, 0.48)
2024-04-22 00:17:44 - INFO :       
==================Finish================

2024-04-22 00:17:44 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:17:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:17:44 - INFO :       DATASET: tasksource/bigbench international_phonetic_alphabet_nli
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2024-04-22 00:17:55 - INFO :       Use taylor pruner...
2024-04-22 00:17:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:17:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:17:56 - INFO :       Start Pruning
2024-04-22 00:17:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:17:58 - INFO :       Loss = 9.140625
2024-04-22 00:18:00 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:18:00 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:18:01 - INFO :       international_phonetic_alphabet_nli: Total Sparsity 1.355085043889836e-06
2024-04-22 00:18:23 - INFO :       international_phonetic_alphabet_nli: Total Accuracy (10, 25, 0.4)
2024-04-22 00:18:23 - INFO :       
==================Finish================

2024-04-22 00:18:23 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:18:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:18:23 - INFO :       DATASET: tasksource/bigbench intersect_geometry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-22 00:18:31 - INFO :       Use taylor pruner...
2024-04-22 00:18:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:18:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:18:32 - INFO :       Start Pruning
2024-04-22 00:18:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:18:34 - INFO :       Loss = 3.48046875
2024-04-22 00:18:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:18:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:18:37 - INFO :       intersect_geometry: Total Sparsity 1.355562410626763e-06
2024-04-22 00:19:23 - INFO :       intersect_geometry: Total Accuracy (1, 50, 0.02)
2024-04-22 00:19:23 - INFO :       
==================Finish================

2024-04-22 00:19:23 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:19:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:19:23 - INFO :       DATASET: tasksource/bigbench irony_identification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-22 00:19:34 - INFO :       Use taylor pruner...
2024-04-22 00:19:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:19:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:19:35 - INFO :       Start Pruning
2024-04-22 00:19:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:19:37 - INFO :       Loss = 13.8671875
2024-04-22 00:19:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:19:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:19:40 - INFO :       irony_identification: Total Sparsity 1.3585857332939668e-06
2024-04-22 00:19:57 - INFO :       irony_identification: Total Accuracy (11, 19, 0.5789473684210527)
2024-04-22 00:19:58 - INFO :       
==================Finish================

2024-04-22 00:19:58 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:19:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:19:58 - INFO :       DATASET: tasksource/bigbench kannada
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-22 00:20:07 - INFO :       Use taylor pruner...
2024-04-22 00:20:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:20:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:20:08 - INFO :       Start Pruning
2024-04-22 00:20:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:20:10 - INFO :       Loss = 5.2734375
2024-04-22 00:20:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:20:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:20:12 - INFO :       kannada: Total Sparsity 1.3530164546964862e-06
2024-04-22 00:21:01 - INFO :       kannada: Total Accuracy (12, 50, 0.24)
2024-04-22 00:21:02 - INFO :       
==================Finish================

2024-04-22 00:21:02 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:21:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:21:02 - INFO :       DATASET: tasksource/bigbench key_value_maps
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-22 00:21:10 - INFO :       Use taylor pruner...
2024-04-22 00:21:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:21:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:21:11 - INFO :       Start Pruning
2024-04-22 00:21:12 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:21:13 - INFO :       Loss = 8.2578125
2024-04-22 00:21:15 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:21:15 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:21:17 - INFO :       key_value_maps: Total Sparsity 1.357153633083186e-06
2024-04-22 00:21:35 - INFO :       key_value_maps: Total Accuracy (12, 21, 0.5714285714285714)
2024-04-22 00:21:35 - INFO :       
==================Finish================

2024-04-22 00:21:35 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:21:35 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:21:35 - INFO :       DATASET: tasksource/bigbench known_unknowns
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]
2024-04-22 00:21:45 - INFO :       Use taylor pruner...
2024-04-22 00:21:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:21:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:21:46 - INFO :       Start Pruning
2024-04-22 00:21:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:21:48 - INFO :       Loss = 14.390625
2024-04-22 00:21:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:21:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:21:51 - INFO :       known_unknowns: Total Sparsity 1.359699589013463e-06
2024-04-22 00:22:05 - INFO :       known_unknowns: Total Accuracy (9, 16, 0.5625)
2024-04-22 00:22:05 - INFO :       
==================Finish================

2024-04-22 00:22:05 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:22:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:22:05 - INFO :       DATASET: tasksource/bigbench language_identification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-22 00:22:14 - INFO :       Use taylor pruner...
2024-04-22 00:22:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:22:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:22:15 - INFO :       Start Pruning
2024-04-22 00:22:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:22:17 - INFO :       Loss = 8.5390625
2024-04-22 00:22:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:22:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:22:20 - INFO :       language_identification: Total Sparsity 1.3525390879595594e-06
2024-04-22 00:23:03 - INFO :       language_identification: Total Accuracy (11, 50, 0.22)
2024-04-22 00:23:03 - INFO :       
==================Finish================

2024-04-22 00:23:03 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:23:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:23:03 - INFO :       DATASET: tasksource/bigbench logic_grid_puzzle
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-22 00:23:13 - INFO :       Use taylor pruner...
2024-04-22 00:23:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:23:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:23:13 - INFO :       Start Pruning
2024-04-22 00:23:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:23:16 - INFO :       Loss = 6.33984375
2024-04-22 00:23:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:23:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:23:19 - INFO :       logic_grid_puzzle: Total Sparsity 1.352379965713917e-06
2024-04-22 00:24:05 - INFO :       logic_grid_puzzle: Total Accuracy (12, 50, 0.24)
2024-04-22 00:24:05 - INFO :       
==================Finish================

2024-04-22 00:24:05 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:24:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:24:05 - INFO :       DATASET: tasksource/bigbench logical_args
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]
2024-04-22 00:24:14 - INFO :       Use taylor pruner...
2024-04-22 00:24:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:24:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:24:14 - INFO :       Start Pruning
2024-04-22 00:24:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:24:16 - INFO :       Loss = 7.56640625
2024-04-22 00:24:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:24:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:24:19 - INFO :       logical_args: Total Sparsity 1.3584266110483244e-06
2024-04-22 00:24:34 - INFO :       logical_args: Total Accuracy (9, 16, 0.5625)
2024-04-22 00:24:34 - INFO :       
==================Finish================

2024-04-22 00:24:34 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:24:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:24:34 - INFO :       DATASET: tasksource/bigbench logical_deduction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-22 00:24:42 - INFO :       Use taylor pruner...
2024-04-22 00:24:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:24:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:24:43 - INFO :       Start Pruning
2024-04-22 00:24:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:24:45 - INFO :       Loss = 10.953125
2024-04-22 00:24:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:24:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:24:48 - INFO :       logical_deduction: Total Sparsity 1.3579492443113975e-06
2024-04-22 00:25:32 - INFO :       logical_deduction: Total Accuracy (13, 50, 0.26)
2024-04-22 00:25:32 - INFO :       
==================Finish================

2024-04-22 00:25:32 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:25:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:25:32 - INFO :       DATASET: tasksource/bigbench logical_fallacy_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
2024-04-22 00:25:44 - INFO :       Use taylor pruner...
2024-04-22 00:25:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:25:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:25:44 - INFO :       Start Pruning
2024-04-22 00:25:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:25:46 - INFO :       Loss = 13.8984375
2024-04-22 00:25:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:25:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:25:49 - INFO :       logical_fallacy_detection: Total Sparsity 1.3581083665570398e-06
2024-04-22 00:26:34 - INFO :       logical_fallacy_detection: Total Accuracy (29, 50, 0.58)
2024-04-22 00:26:34 - INFO :       
==================Finish================

2024-04-22 00:26:34 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:26:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:26:34 - INFO :       DATASET: tasksource/bigbench logical_sequence
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-22 00:26:43 - INFO :       Use taylor pruner...
2024-04-22 00:26:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:26:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:26:44 - INFO :       Start Pruning
2024-04-22 00:26:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:26:46 - INFO :       Loss = 12.2109375
2024-04-22 00:26:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:26:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:26:49 - INFO :       logical_sequence: Total Sparsity 1.3584266110483244e-06
2024-04-22 00:27:03 - INFO :       logical_sequence: Total Accuracy (5, 16, 0.3125)
2024-04-22 00:27:03 - INFO :       
==================Finish================

2024-04-22 00:27:03 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:27:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:27:03 - INFO :       DATASET: tasksource/bigbench mathematical_induction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.29s/it]
2024-04-22 00:27:12 - INFO :       Use taylor pruner...
2024-04-22 00:27:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:27:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:27:13 - INFO :       Start Pruning
2024-04-22 00:27:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:27:15 - INFO :       Loss = 14.3203125
2024-04-22 00:27:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:27:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:27:19 - INFO :       mathematical_induction: Total Sparsity 1.3590631000308936e-06
2024-04-22 00:27:32 - INFO :       mathematical_induction: Total Accuracy (9, 16, 0.5625)
2024-04-22 00:27:32 - INFO :       
==================Finish================

2024-04-22 00:27:32 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:27:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:27:32 - INFO :       DATASET: tasksource/bigbench medical_questions_russian
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-22 00:27:40 - INFO :       Use taylor pruner...
2024-04-22 00:27:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:27:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:27:40 - INFO :       Start Pruning
2024-04-22 00:27:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:27:42 - INFO :       Loss = 11.5390625
2024-04-22 00:27:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:27:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:27:45 - INFO :       medical_questions_russian: Total Sparsity 1.3530164546964862e-06
2024-04-22 00:28:29 - INFO :       medical_questions_russian: Total Accuracy (11, 50, 0.22)
2024-04-22 00:28:30 - INFO :       
==================Finish================

2024-04-22 00:28:30 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:28:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:28:30 - INFO :       DATASET: tasksource/bigbench metaphor_boolean
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2024-04-22 00:28:38 - INFO :       Use taylor pruner...
2024-04-22 00:28:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:28:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:28:39 - INFO :       Start Pruning
2024-04-22 00:28:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:28:41 - INFO :       Loss = 13.625
2024-04-22 00:28:42 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:28:42 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:28:44 - INFO :       metaphor_boolean: Total Sparsity 1.3573127553288283e-06
2024-04-22 00:29:27 - INFO :       metaphor_boolean: Total Accuracy (18, 50, 0.36)
2024-04-22 00:29:27 - INFO :       
==================Finish================

2024-04-22 00:29:27 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:29:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:29:27 - INFO :       DATASET: tasksource/bigbench metaphor_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-22 00:29:37 - INFO :       Use taylor pruner...
2024-04-22 00:29:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:29:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:29:37 - INFO :       Start Pruning
2024-04-22 00:29:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:29:39 - INFO :       Loss = 10.0703125
2024-04-22 00:29:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:29:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:29:42 - INFO :       metaphor_understanding: Total Sparsity 1.3566762663462592e-06
2024-04-22 00:30:22 - INFO :       metaphor_understanding: Total Accuracy (28, 46, 0.6086956521739131)
2024-04-22 00:30:22 - INFO :       
==================Finish================

2024-04-22 00:30:22 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:30:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:30:22 - INFO :       DATASET: tasksource/bigbench misconceptions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-22 00:30:30 - INFO :       Use taylor pruner...
2024-04-22 00:30:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:30:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:30:31 - INFO :       Start Pruning
2024-04-22 00:30:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:30:33 - INFO :       Loss = 14.375
2024-04-22 00:30:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:30:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:30:36 - INFO :       misconceptions: Total Sparsity 1.3585857332939668e-06
2024-04-22 00:31:12 - INFO :       misconceptions: Total Accuracy (21, 43, 0.4883720930232558)
2024-04-22 00:31:12 - INFO :       
==================Finish================

2024-04-22 00:31:12 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:31:12 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:31:12 - INFO :       DATASET: tasksource/bigbench mnist_ascii
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-22 00:31:21 - INFO :       Use taylor pruner...
2024-04-22 00:31:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:31:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:31:21 - INFO :       Start Pruning
2024-04-22 00:31:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:31:23 - INFO :       Loss = 5.69921875
2024-04-22 00:31:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:31:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:31:27 - INFO :       mnist_ascii: Total Sparsity 1.3541303104159823e-06
2024-04-22 00:32:45 - INFO :       mnist_ascii: Total Accuracy (6, 50, 0.12)
2024-04-22 00:32:46 - INFO :       
==================Finish================

2024-04-22 00:32:46 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:32:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:32:46 - INFO :       DATASET: tasksource/bigbench moral_permissibility
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]
2024-04-22 00:32:54 - INFO :       Use taylor pruner...
2024-04-22 00:32:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:32:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:32:55 - INFO :       Start Pruning
2024-04-22 00:32:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:32:57 - INFO :       Loss = 12.1640625
2024-04-22 00:32:58 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:32:58 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:33:00 - INFO :       moral_permissibility: Total Sparsity 1.3542894326616245e-06
2024-04-22 00:33:42 - INFO :       moral_permissibility: Total Accuracy (26, 50, 0.52)
2024-04-22 00:33:42 - INFO :       
==================Finish================

2024-04-22 00:33:42 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:33:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:33:42 - INFO :       DATASET: tasksource/bigbench movie_dialog_same_or_different
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2024-04-22 00:33:52 - INFO :       Use taylor pruner...
2024-04-22 00:33:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:33:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:33:52 - INFO :       Start Pruning
2024-04-22 00:33:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:33:55 - INFO :       Loss = 11.8515625
2024-04-22 00:33:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:33:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:33:59 - INFO :       movie_dialog_same_or_different: Total Sparsity 1.3563580218549744e-06
2024-04-22 00:34:41 - INFO :       movie_dialog_same_or_different: Total Accuracy (23, 50, 0.46)
2024-04-22 00:34:41 - INFO :       
==================Finish================

2024-04-22 00:34:41 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:34:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:34:41 - INFO :       DATASET: tasksource/bigbench movie_recommendation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]
2024-04-22 00:34:50 - INFO :       Use taylor pruner...
2024-04-22 00:34:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:34:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:34:50 - INFO :       Start Pruning
2024-04-22 00:34:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:34:52 - INFO :       Loss = 13.09375
2024-04-22 00:34:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:34:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:34:56 - INFO :       movie_recommendation: Total Sparsity 1.360336077996032e-06
2024-04-22 00:35:37 - INFO :       movie_recommendation: Total Accuracy (22, 50, 0.44)
2024-04-22 00:35:38 - INFO :       
==================Finish================

2024-04-22 00:35:38 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:35:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:35:38 - INFO :       DATASET: tasksource/bigbench navigate
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-22 00:35:45 - INFO :       Use taylor pruner...
2024-04-22 00:35:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:35:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:35:46 - INFO :       Start Pruning
2024-04-22 00:35:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:35:48 - INFO :       Loss = 14.5
2024-04-22 00:35:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:35:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:35:51 - INFO :       navigate: Total Sparsity 1.3584266110483244e-06
2024-04-22 00:36:31 - INFO :       navigate: Total Accuracy (30, 50, 0.6)
2024-04-22 00:36:32 - INFO :       
==================Finish================

2024-04-22 00:36:32 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:36:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:36:32 - INFO :       DATASET: tasksource/bigbench nonsense_words_grammar
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2024-04-22 00:36:39 - INFO :       Use taylor pruner...
2024-04-22 00:36:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:36:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:36:40 - INFO :       Start Pruning
2024-04-22 00:36:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:36:42 - INFO :       Loss = 13.9453125
2024-04-22 00:36:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:36:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:36:45 - INFO :       nonsense_words_grammar: Total Sparsity 1.3558806551180476e-06
2024-04-22 00:36:58 - INFO :       nonsense_words_grammar: Total Accuracy (6, 16, 0.375)
2024-04-22 00:36:58 - INFO :       
==================Finish================

2024-04-22 00:36:58 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:36:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:36:58 - INFO :       DATASET: tasksource/bigbench novel_concepts
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
2024-04-22 00:37:07 - INFO :       Use taylor pruner...
2024-04-22 00:37:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:37:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:37:07 - INFO :       Start Pruning
2024-04-22 00:37:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:37:09 - INFO :       Loss = 11.2421875
2024-04-22 00:37:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:37:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:37:12 - INFO :       novel_concepts: Total Sparsity 1.3584266110483244e-06
2024-04-22 00:37:26 - INFO :       novel_concepts: Total Accuracy (5, 16, 0.3125)
2024-04-22 00:37:26 - INFO :       
==================Finish================

2024-04-22 00:37:26 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:37:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:37:26 - INFO :       DATASET: tasksource/bigbench odd_one_out
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2024-04-22 00:37:35 - INFO :       Use taylor pruner...
2024-04-22 00:37:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:37:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:37:35 - INFO :       Start Pruning
2024-04-22 00:37:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:37:37 - INFO :       Loss = 14.015625
2024-04-22 00:37:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:37:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:37:40 - INFO :       odd_one_out: Total Sparsity 1.3590631000308936e-06
2024-04-22 00:37:54 - INFO :       odd_one_out: Total Accuracy (3, 17, 0.17647058823529413)
2024-04-22 00:37:54 - INFO :       
==================Finish================

2024-04-22 00:37:54 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:37:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:37:54 - INFO :       DATASET: tasksource/bigbench parsinlu_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.98s/it]
2024-04-22 00:38:04 - INFO :       Use taylor pruner...
2024-04-22 00:38:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:38:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:38:05 - INFO :       Start Pruning
2024-04-22 00:38:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:38:07 - INFO :       Loss = 11.3203125
2024-04-22 00:38:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:38:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:38:10 - INFO :       parsinlu_qa: Total Sparsity 1.359699589013463e-06
2024-04-22 00:38:52 - INFO :       parsinlu_qa: Total Accuracy (14, 50, 0.28)
2024-04-22 00:38:52 - INFO :       
==================Finish================

2024-04-22 00:38:52 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:38:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:38:52 - INFO :       DATASET: tasksource/bigbench penguins_in_a_table
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]
2024-04-22 00:39:03 - INFO :       Use taylor pruner...
2024-04-22 00:39:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:39:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:39:04 - INFO :       Start Pruning
2024-04-22 00:39:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:39:06 - INFO :       Loss = 7.4765625
2024-04-22 00:39:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:39:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:39:09 - INFO :       penguins_in_a_table: Total Sparsity 1.3557215328724054e-06
2024-04-22 00:39:34 - INFO :       penguins_in_a_table: Total Accuracy (10, 29, 0.3448275862068966)
2024-04-22 00:39:34 - INFO :       
==================Finish================

2024-04-22 00:39:34 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:39:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:39:34 - INFO :       DATASET: tasksource/bigbench persian_idioms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-22 00:39:43 - INFO :       Use taylor pruner...
2024-04-22 00:39:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:39:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:39:43 - INFO :       Start Pruning
2024-04-22 00:39:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:39:46 - INFO :       Loss = 9.9453125
2024-04-22 00:39:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:39:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:39:48 - INFO :       persian_idioms: Total Sparsity 1.3558806551180476e-06
2024-04-22 00:40:03 - INFO :       persian_idioms: Total Accuracy (5, 16, 0.3125)
2024-04-22 00:40:03 - INFO :       
==================Finish================

2024-04-22 00:40:03 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:40:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:40:03 - INFO :       DATASET: tasksource/bigbench phrase_relatedness
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.63s/it]
2024-04-22 00:40:15 - INFO :       Use taylor pruner...
2024-04-22 00:40:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:40:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:40:16 - INFO :       Start Pruning
2024-04-22 00:40:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:40:18 - INFO :       Loss = 13.1640625
2024-04-22 00:40:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:40:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:40:21 - INFO :       phrase_relatedness: Total Sparsity 1.3590631000308936e-06
2024-04-22 00:40:38 - INFO :       phrase_relatedness: Total Accuracy (9, 20, 0.45)
2024-04-22 00:40:38 - INFO :       
==================Finish================

2024-04-22 00:40:38 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:40:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:40:38 - INFO :       DATASET: tasksource/bigbench physical_intuition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.46s/it]
2024-04-22 00:40:49 - INFO :       Use taylor pruner...
2024-04-22 00:40:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:40:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:40:49 - INFO :       Start Pruning
2024-04-22 00:40:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:40:52 - INFO :       Loss = 13.03125
2024-04-22 00:40:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:40:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:40:54 - INFO :       physical_intuition: Total Sparsity 1.360336077996032e-06
2024-04-22 00:41:07 - INFO :       physical_intuition: Total Accuracy (6, 16, 0.375)
2024-04-22 00:41:08 - INFO :       
==================Finish================

2024-04-22 00:41:08 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:41:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:41:08 - INFO :       DATASET: tasksource/bigbench physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-22 00:41:16 - INFO :       Use taylor pruner...
2024-04-22 00:41:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:41:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:41:17 - INFO :       Start Pruning
2024-04-22 00:41:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:41:19 - INFO :       Loss = 9.9453125
2024-04-22 00:41:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:41:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:41:22 - INFO :       physics: Total Sparsity 1.3568353885919015e-06
2024-04-22 00:42:00 - INFO :       physics: Total Accuracy (41, 45, 0.9111111111111111)
2024-04-22 00:42:00 - INFO :       
==================Finish================

2024-04-22 00:42:00 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:42:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:42:00 - INFO :       DATASET: tasksource/bigbench play_dialog_same_or_different
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]
2024-04-22 00:42:09 - INFO :       Use taylor pruner...
2024-04-22 00:42:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:42:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:42:10 - INFO :       Start Pruning
2024-04-22 00:42:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:42:12 - INFO :       Loss = 8.6796875
2024-04-22 00:42:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:42:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:42:15 - INFO :       play_dialog_same_or_different: Total Sparsity 1.358744855539609e-06
2024-04-22 00:43:00 - INFO :       play_dialog_same_or_different: Total Accuracy (16, 50, 0.32)
2024-04-22 00:43:00 - INFO :       
==================Finish================

2024-04-22 00:43:00 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:43:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:43:00 - INFO :       DATASET: tasksource/bigbench presuppositions_as_nli
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]
2024-04-22 00:43:10 - INFO :       Use taylor pruner...
2024-04-22 00:43:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:43:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:43:10 - INFO :       Start Pruning
2024-04-22 00:43:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:43:12 - INFO :       Loss = 10.7578125
2024-04-22 00:43:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:43:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:43:15 - INFO :       presuppositions_as_nli: Total Sparsity 1.3563580218549744e-06
2024-04-22 00:43:57 - INFO :       presuppositions_as_nli: Total Accuracy (14, 50, 0.28)
2024-04-22 00:43:58 - INFO :       
==================Finish================

2024-04-22 00:43:58 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:43:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:43:58 - INFO :       DATASET: tasksource/bigbench question_selection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
2024-04-22 00:44:08 - INFO :       Use taylor pruner...
2024-04-22 00:44:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:44:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:44:08 - INFO :       Start Pruning
2024-04-22 00:44:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:44:10 - INFO :       Loss = 5.15234375
2024-04-22 00:44:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:44:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:44:13 - INFO :       question_selection: Total Sparsity 1.3552441661354783e-06
2024-04-22 00:45:01 - INFO :       question_selection: Total Accuracy (28, 50, 0.56)
2024-04-22 00:45:02 - INFO :       
==================Finish================

2024-04-22 00:45:02 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:45:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:45:02 - INFO :       DATASET: tasksource/bigbench reasoning_about_colored_objects
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-22 00:45:11 - INFO :       Use taylor pruner...
2024-04-22 00:45:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:45:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:45:11 - INFO :       Start Pruning
2024-04-22 00:45:12 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:45:13 - INFO :       Loss = 9.875
2024-04-22 00:45:15 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:45:15 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:45:16 - INFO :       reasoning_about_colored_objects: Total Sparsity 1.3577901220657553e-06
2024-04-22 00:45:59 - INFO :       reasoning_about_colored_objects: Total Accuracy (15, 50, 0.3)
2024-04-22 00:45:59 - INFO :       
==================Finish================

2024-04-22 00:45:59 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:45:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:45:59 - INFO :       DATASET: tasksource/bigbench riddle_sense
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-22 00:46:08 - INFO :       Use taylor pruner...
2024-04-22 00:46:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:46:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:46:08 - INFO :       Start Pruning
2024-04-22 00:46:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:46:10 - INFO :       Loss = 13.0390625
2024-04-22 00:46:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:46:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:46:13 - INFO :       riddle_sense: Total Sparsity 1.3590631000308936e-06
2024-04-22 00:46:26 - INFO :       riddle_sense: Total Accuracy (2, 16, 0.125)
2024-04-22 00:46:26 - INFO :       
==================Finish================

2024-04-22 00:46:26 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:46:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:46:26 - INFO :       DATASET: tasksource/bigbench ruin_names
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-22 00:46:35 - INFO :       Use taylor pruner...
2024-04-22 00:46:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:46:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:46:35 - INFO :       Start Pruning
2024-04-22 00:46:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:46:37 - INFO :       Loss = 13.0234375
2024-04-22 00:46:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:46:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:46:40 - INFO :       ruin_names: Total Sparsity 1.365587112102228e-06
2024-04-22 00:47:23 - INFO :       ruin_names: Total Accuracy (8, 50, 0.16)
2024-04-22 00:47:23 - INFO :       
==================Finish================

2024-04-22 00:47:23 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:47:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:47:23 - INFO :       DATASET: tasksource/bigbench salient_translation_error_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-22 00:47:32 - INFO :       Use taylor pruner...
2024-04-22 00:47:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:47:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:47:32 - INFO :       Start Pruning
2024-04-22 00:47:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:47:35 - INFO :       Loss = 8.109375
2024-04-22 00:47:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:47:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:47:38 - INFO :       salient_translation_error_detection: Total Sparsity 1.3584266110483244e-06
2024-04-22 00:48:22 - INFO :       salient_translation_error_detection: Total Accuracy (11, 50, 0.22)
2024-04-22 00:48:23 - INFO :       
==================Finish================

2024-04-22 00:48:23 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:48:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:48:23 - INFO :       DATASET: tasksource/bigbench sentence_ambiguity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2024-04-22 00:48:32 - INFO :       Use taylor pruner...
2024-04-22 00:48:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:48:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:48:33 - INFO :       Start Pruning
2024-04-22 00:48:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:48:34 - INFO :       Loss = 14.3359375
2024-04-22 00:48:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:48:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:48:37 - INFO :       sentence_ambiguity: Total Sparsity 1.3569945108375437e-06
2024-04-22 00:48:50 - INFO :       sentence_ambiguity: Total Accuracy (8, 16, 0.5)
2024-04-22 00:48:50 - INFO :       
==================Finish================

2024-04-22 00:48:50 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:48:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:48:50 - INFO :       DATASET: tasksource/bigbench similarities_abstraction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-22 00:49:00 - INFO :       Use taylor pruner...
2024-04-22 00:49:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:49:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:49:00 - INFO :       Start Pruning
2024-04-22 00:49:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:49:02 - INFO :       Loss = 13.453125
2024-04-22 00:49:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:49:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:49:05 - INFO :       similarities_abstraction: Total Sparsity 1.359699589013463e-06
2024-04-22 00:49:18 - INFO :       similarities_abstraction: Total Accuracy (8, 16, 0.5)
2024-04-22 00:49:18 - INFO :       
==================Finish================

2024-04-22 00:49:18 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:49:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:49:18 - INFO :       DATASET: tasksource/bigbench simple_ethical_questions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2024-04-22 00:49:29 - INFO :       Use taylor pruner...
2024-04-22 00:49:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:49:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:49:30 - INFO :       Start Pruning
2024-04-22 00:49:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:49:32 - INFO :       Loss = 10.6953125
2024-04-22 00:49:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:49:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:49:35 - INFO :       simple_ethical_questions: Total Sparsity 1.35603977736369e-06
2024-04-22 00:49:55 - INFO :       simple_ethical_questions: Total Accuracy (18, 23, 0.782608695652174)
2024-04-22 00:49:55 - INFO :       
==================Finish================

2024-04-22 00:49:55 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:49:55 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:49:55 - INFO :       DATASET: tasksource/bigbench snarks
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2024-04-22 00:50:04 - INFO :       Use taylor pruner...
2024-04-22 00:50:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:50:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:50:04 - INFO :       Start Pruning
2024-04-22 00:50:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:50:06 - INFO :       Loss = 13.953125
2024-04-22 00:50:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:50:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:50:09 - INFO :       snarks: Total Sparsity 1.3534938214334132e-06
2024-04-22 00:50:39 - INFO :       snarks: Total Accuracy (13, 36, 0.3611111111111111)
2024-04-22 00:50:40 - INFO :       
==================Finish================

2024-04-22 00:50:40 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:50:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:50:40 - INFO :       DATASET: tasksource/bigbench social_iqa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2024-04-22 00:50:50 - INFO :       Use taylor pruner...
2024-04-22 00:50:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:50:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:50:50 - INFO :       Start Pruning
2024-04-22 00:50:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:50:53 - INFO :       Loss = 12.9296875
2024-04-22 00:50:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:50:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:50:56 - INFO :       social_iqa: Total Sparsity 1.3590631000308936e-06
2024-04-22 00:51:38 - INFO :       social_iqa: Total Accuracy (24, 50, 0.48)
2024-04-22 00:51:38 - INFO :       
==================Finish================

2024-04-22 00:51:38 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:51:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:51:38 - INFO :       DATASET: tasksource/bigbench social_support
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2024-04-22 00:51:48 - INFO :       Use taylor pruner...
2024-04-22 00:51:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:51:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:51:48 - INFO :       Start Pruning
2024-04-22 00:51:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:51:51 - INFO :       Loss = 13.71875
2024-04-22 00:51:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:51:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:51:54 - INFO :       social_support: Total Sparsity 1.3589039777852514e-06
2024-04-22 00:52:38 - INFO :       social_support: Total Accuracy (36, 50, 0.72)
2024-04-22 00:52:39 - INFO :       
==================Finish================

2024-04-22 00:52:39 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:52:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:52:39 - INFO :       DATASET: tasksource/bigbench sports_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2024-04-22 00:52:49 - INFO :       Use taylor pruner...
2024-04-22 00:52:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:52:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:52:49 - INFO :       Start Pruning
2024-04-22 00:52:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:52:52 - INFO :       Loss = 15.0078125
2024-04-22 00:52:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:52:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:52:55 - INFO :       sports_understanding: Total Sparsity 1.35603977736369e-06
2024-04-22 00:53:35 - INFO :       sports_understanding: Total Accuracy (29, 50, 0.58)
2024-04-22 00:53:36 - INFO :       
==================Finish================

2024-04-22 00:53:36 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:53:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:53:36 - INFO :       DATASET: tasksource/bigbench strange_stories
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-22 00:53:44 - INFO :       Use taylor pruner...
2024-04-22 00:53:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:53:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:53:45 - INFO :       Start Pruning
2024-04-22 00:53:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:53:47 - INFO :       Loss = 11.34375
2024-04-22 00:53:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:53:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:53:50 - INFO :       strange_stories: Total Sparsity 1.3549259216441938e-06
2024-04-22 00:54:19 - INFO :       strange_stories: Total Accuracy (16, 34, 0.47058823529411764)
2024-04-22 00:54:19 - INFO :       
==================Finish================

2024-04-22 00:54:19 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:54:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:54:19 - INFO :       DATASET: tasksource/bigbench strategyqa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-22 00:54:28 - INFO :       Use taylor pruner...
2024-04-22 00:54:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:54:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:54:28 - INFO :       Start Pruning
2024-04-22 00:54:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:54:31 - INFO :       Loss = 14.3359375
2024-04-22 00:54:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:54:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:54:34 - INFO :       strategyqa: Total Sparsity 1.3554032883811208e-06
2024-04-22 00:55:14 - INFO :       strategyqa: Total Accuracy (30, 50, 0.6)
2024-04-22 00:55:14 - INFO :       
==================Finish================

2024-04-22 00:55:14 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:55:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:55:14 - INFO :       DATASET: tasksource/bigbench suicide_risk
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]
2024-04-22 00:55:25 - INFO :       Use taylor pruner...
2024-04-22 00:55:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:55:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:55:25 - INFO :       Start Pruning
2024-04-22 00:55:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:55:27 - INFO :       Loss = 10.96875
2024-04-22 00:55:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:55:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:55:31 - INFO :       suicide_risk: Total Sparsity 1.3581083665570398e-06
2024-04-22 00:55:44 - INFO :       suicide_risk: Total Accuracy (5, 16, 0.3125)
2024-04-22 00:55:44 - INFO :       
==================Finish================

2024-04-22 00:55:44 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:55:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:55:44 - INFO :       DATASET: tasksource/bigbench swahili_english_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-22 00:55:53 - INFO :       Use taylor pruner...
2024-04-22 00:55:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:55:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:55:53 - INFO :       Start Pruning
2024-04-22 00:55:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:55:55 - INFO :       Loss = 10.890625
2024-04-22 00:55:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:55:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:55:58 - INFO :       swahili_english_proverbs: Total Sparsity 1.3554032883811208e-06
2024-04-22 00:56:23 - INFO :       swahili_english_proverbs: Total Accuracy (18, 30, 0.6)
2024-04-22 00:56:23 - INFO :       
==================Finish================

2024-04-22 00:56:23 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:56:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:56:23 - INFO :       DATASET: tasksource/bigbench swedish_to_german_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-22 00:56:32 - INFO :       Use taylor pruner...
2024-04-22 00:56:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:56:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:56:32 - INFO :       Start Pruning
2024-04-22 00:56:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:56:35 - INFO :       Loss = 11.3046875
2024-04-22 00:56:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:56:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:56:38 - INFO :       swedish_to_german_proverbs: Total Sparsity 1.357630999820113e-06
2024-04-22 00:56:51 - INFO :       swedish_to_german_proverbs: Total Accuracy (8, 16, 0.5)
2024-04-22 00:56:51 - INFO :       
==================Finish================

2024-04-22 00:56:51 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:56:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:56:51 - INFO :       DATASET: tasksource/bigbench symbol_interpretation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-22 00:57:00 - INFO :       Use taylor pruner...
2024-04-22 00:57:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:57:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:57:01 - INFO :       Start Pruning
2024-04-22 00:57:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:57:03 - INFO :       Loss = 4.671875
2024-04-22 00:57:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:57:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:57:06 - INFO :       symbol_interpretation: Total Sparsity 1.3577901220657553e-06
2024-04-22 00:58:10 - INFO :       symbol_interpretation: Total Accuracy (16, 50, 0.32)
2024-04-22 00:58:11 - INFO :       
==================Finish================

2024-04-22 00:58:11 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 00:58:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:58:11 - INFO :       DATASET: tasksource/bigbench temporal_sequences
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]
2024-04-22 00:58:21 - INFO :       Use taylor pruner...
2024-04-22 00:58:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:58:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:58:21 - INFO :       Start Pruning
2024-04-22 00:58:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:58:23 - INFO :       Loss = 8.1796875
2024-04-22 00:58:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:58:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:58:26 - INFO :       temporal_sequences: Total Sparsity 1.358267488802682e-06
2024-04-22 00:59:09 - INFO :       temporal_sequences: Total Accuracy (18, 50, 0.36)
2024-04-22 00:59:10 - INFO :       
==================Finish================

2024-04-22 00:59:10 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 00:59:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 00:59:10 - INFO :       DATASET: tasksource/bigbench timedial
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
2024-04-22 00:59:20 - INFO :       Use taylor pruner...
2024-04-22 00:59:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:59:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 00:59:21 - INFO :       Start Pruning
2024-04-22 00:59:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 00:59:23 - INFO :       Loss = 7.91796875
2024-04-22 00:59:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 00:59:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 00:59:26 - INFO :       timedial: Total Sparsity 1.3579492443113975e-06
2024-04-22 01:00:11 - INFO :       timedial: Total Accuracy (10, 50, 0.2)
2024-04-22 01:00:12 - INFO :       
==================Finish================

2024-04-22 01:00:12 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:00:12 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:00:12 - INFO :       DATASET: tasksource/bigbench tracking_shuffled_objects
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-22 01:00:21 - INFO :       Use taylor pruner...
2024-04-22 01:00:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:00:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:00:21 - INFO :       Start Pruning
2024-04-22 01:00:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:00:24 - INFO :       Loss = 9.984375
2024-04-22 01:00:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:00:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:00:27 - INFO :       tracking_shuffled_objects: Total Sparsity 1.3585857332939668e-06
2024-04-22 01:01:10 - INFO :       tracking_shuffled_objects: Total Accuracy (4, 50, 0.08)
2024-04-22 01:01:10 - INFO :       
==================Finish================

2024-04-22 01:01:10 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:01:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:01:10 - INFO :       DATASET: tasksource/bigbench understanding_fables
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2024-04-22 01:01:20 - INFO :       Use taylor pruner...
2024-04-22 01:01:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:01:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:01:20 - INFO :       Start Pruning
2024-04-22 01:01:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:01:22 - INFO :       Loss = 7.30078125
2024-04-22 01:01:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:01:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:01:25 - INFO :       understanding_fables: Total Sparsity 1.3589039777852514e-06
2024-04-22 01:01:58 - INFO :       understanding_fables: Total Accuracy (9, 37, 0.24324324324324326)
2024-04-22 01:01:58 - INFO :       
==================Finish================

2024-04-22 01:01:58 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:01:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:01:58 - INFO :       DATASET: tasksource/bigbench undo_permutation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]
2024-04-22 01:02:08 - INFO :       Use taylor pruner...
2024-04-22 01:02:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:02:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:02:08 - INFO :       Start Pruning
2024-04-22 01:02:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:02:10 - INFO :       Loss = 7.80078125
2024-04-22 01:02:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:02:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:02:14 - INFO :       undo_permutation: Total Sparsity 1.3542894326616245e-06
2024-04-22 01:02:59 - INFO :       undo_permutation: Total Accuracy (25, 50, 0.5)
2024-04-22 01:02:59 - INFO :       
==================Finish================

2024-04-22 01:02:59 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:02:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:02:59 - INFO :       DATASET: tasksource/bigbench unit_interpretation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-22 01:03:08 - INFO :       Use taylor pruner...
2024-04-22 01:03:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:03:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:03:09 - INFO :       Start Pruning
2024-04-22 01:03:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:03:11 - INFO :       Loss = 10.8515625
2024-04-22 01:03:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:03:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:03:15 - INFO :       unit_interpretation: Total Sparsity 1.3585857332939668e-06
2024-04-22 01:03:32 - INFO :       unit_interpretation: Total Accuracy (5, 20, 0.25)
2024-04-22 01:03:32 - INFO :       
==================Finish================

2024-04-22 01:03:32 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:03:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:03:32 - INFO :       DATASET: tasksource/bigbench vitaminc_fact_verification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]
2024-04-22 01:03:40 - INFO :       Use taylor pruner...
2024-04-22 01:03:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:03:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:03:41 - INFO :       Start Pruning
2024-04-22 01:03:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:03:43 - INFO :       Loss = 11.6015625
2024-04-22 01:03:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:03:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:03:46 - INFO :       vitaminc_fact_verification: Total Sparsity 1.3525390879595594e-06
2024-04-22 01:04:28 - INFO :       vitaminc_fact_verification: Total Accuracy (15, 50, 0.3)
2024-04-22 01:04:28 - INFO :       
==================Finish================

2024-04-22 01:04:28 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:04:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:04:28 - INFO :       DATASET: tasksource/bigbench what_is_the_tao
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]
2024-04-22 01:04:37 - INFO :       Use taylor pruner...
2024-04-22 01:04:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:04:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:04:38 - INFO :       Start Pruning
2024-04-22 01:04:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:04:40 - INFO :       Loss = 12.6015625
2024-04-22 01:04:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:04:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:04:43 - INFO :       what_is_the_tao: Total Sparsity 1.3617681782068128e-06
2024-04-22 01:04:56 - INFO :       what_is_the_tao: Total Accuracy (6, 16, 0.375)
2024-04-22 01:04:57 - INFO :       
==================Finish================

2024-04-22 01:04:57 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:04:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:04:57 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]
2024-04-22 01:05:07 - INFO :       Use taylor pruner...
2024-04-22 01:05:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:05:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:05:08 - INFO :       Start Pruning
Token indices sequence length is longer than the specified maximum sequence length for this model (87272 > 4096). Running this sequence through the model will result in indexing errors
2024-04-22 01:05:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:05:11 - INFO :       Loss = 1.388671875
2024-04-22 01:05:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:05:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:05:13 - INFO :       which_wiki_edit: Total Sparsity 1.3504704987662094e-06
2024-04-22 01:06:51 - INFO :       which_wiki_edit: Total Accuracy (23, 50, 0.46)
2024-04-22 01:06:51 - INFO :       
==================Finish================

2024-04-22 01:06:51 - INFO :       Memory Requirement: 12719.80908203125 MiB

2024-04-22 01:06:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:06:51 - INFO :       DATASET: tasksource/bigbench winowhy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-22 01:07:00 - INFO :       Use taylor pruner...
2024-04-22 01:07:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:07:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:07:00 - INFO :       Start Pruning
2024-04-22 01:07:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:07:02 - INFO :       Loss = 14.046875
2024-04-22 01:07:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:07:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:07:05 - INFO :       winowhy: Total Sparsity 1.3584266110483244e-06
2024-04-22 01:07:46 - INFO :       winowhy: Total Accuracy (25, 50, 0.5)
2024-04-22 01:07:46 - INFO :       
==================Finish================

2024-04-22 01:07:46 - INFO :       Memory Requirement: 12682.77392578125 MiB

2024-04-22 01:07:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:07:46 - INFO :       DATASET: tasksource/mmlu abstract_algebra
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2024-04-22 01:07:56 - INFO :       Use taylor pruner...
2024-04-22 01:07:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:07:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:07:56 - INFO :       Start Pruning
2024-04-22 01:07:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:07:59 - INFO :       Loss = 13.4296875
2024-04-22 01:08:00 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:08:00 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:08:02 - INFO :       abstract_algebra: Total Sparsity 1.3554032883811208e-06
2024-04-22 01:08:11 - INFO :       abstract_algebra: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-22 01:08:11 - INFO :       
==================Finish================

2024-04-22 01:08:11 - INFO :       Memory Requirement: 12677.77392578125 MiB

2024-04-22 01:08:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:08:11 - INFO :       DATASET: tasksource/mmlu anatomy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-22 01:08:20 - INFO :       Use taylor pruner...
2024-04-22 01:08:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:08:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:08:21 - INFO :       Start Pruning
2024-04-22 01:08:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:08:24 - INFO :       Loss = 14.0546875
2024-04-22 01:08:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:08:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:08:27 - INFO :       anatomy: Total Sparsity 1.3558806551180476e-06
2024-04-22 01:08:41 - INFO :       anatomy: Total Accuracy (8, 14, 0.5714285714285714)
2024-04-22 01:08:41 - INFO :       
==================Finish================

2024-04-22 01:08:41 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:08:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:08:41 - INFO :       DATASET: tasksource/mmlu astronomy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.51s/it]
2024-04-22 01:08:59 - INFO :       Use taylor pruner...
2024-04-22 01:08:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:08:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:09:00 - INFO :       Start Pruning
2024-04-22 01:09:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:09:02 - INFO :       Loss = 14.234375
2024-04-22 01:09:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:09:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:09:06 - INFO :       astronomy: Total Sparsity 1.3577901220657553e-06
2024-04-22 01:09:22 - INFO :       astronomy: Total Accuracy (6, 16, 0.375)
2024-04-22 01:09:22 - INFO :       
==================Finish================

2024-04-22 01:09:22 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:09:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:09:22 - INFO :       DATASET: tasksource/mmlu business_ethics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.49s/it]
2024-04-22 01:09:40 - INFO :       Use taylor pruner...
2024-04-22 01:09:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:09:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:09:41 - INFO :       Start Pruning
2024-04-22 01:09:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:09:43 - INFO :       Loss = 13.6171875
2024-04-22 01:09:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:09:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:09:47 - INFO :       business_ethics: Total Sparsity 1.360813444732959e-06
2024-04-22 01:09:57 - INFO :       business_ethics: Total Accuracy (6, 11, 0.5454545454545454)
2024-04-22 01:09:57 - INFO :       
==================Finish================

2024-04-22 01:09:57 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:09:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:09:57 - INFO :       DATASET: tasksource/mmlu clinical_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-22 01:10:06 - INFO :       Use taylor pruner...
2024-04-22 01:10:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:10:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:10:06 - INFO :       Start Pruning
2024-04-22 01:10:08 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:10:09 - INFO :       Loss = 14.03125
2024-04-22 01:10:10 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:10:10 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:10:12 - INFO :       clinical_knowledge: Total Sparsity 1.35603977736369e-06
2024-04-22 01:10:36 - INFO :       clinical_knowledge: Total Accuracy (11, 29, 0.3793103448275862)
2024-04-22 01:10:36 - INFO :       
==================Finish================

2024-04-22 01:10:36 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:10:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:10:36 - INFO :       DATASET: tasksource/mmlu college_biology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2024-04-22 01:10:46 - INFO :       Use taylor pruner...
2024-04-22 01:10:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:10:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:10:46 - INFO :       Start Pruning
2024-04-22 01:10:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:10:48 - INFO :       Loss = 13.7578125
2024-04-22 01:10:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:10:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:10:52 - INFO :       college_biology: Total Sparsity 1.358267488802682e-06
2024-04-22 01:11:05 - INFO :       college_biology: Total Accuracy (9, 16, 0.5625)
2024-04-22 01:11:05 - INFO :       
==================Finish================

2024-04-22 01:11:05 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:11:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:11:05 - INFO :       DATASET: tasksource/mmlu college_chemistry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2024-04-22 01:11:15 - INFO :       Use taylor pruner...
2024-04-22 01:11:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:11:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:11:15 - INFO :       Start Pruning
num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-22 01:11:16 - WARNING :       num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-22 01:11:16 - WARNING :       num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-22 01:11:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:11:17 - INFO :       Loss = 14.03125
2024-04-22 01:11:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:11:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:11:20 - INFO :       college_chemistry: Total Sparsity 1.3590631000308936e-06
2024-04-22 01:11:27 - INFO :       college_chemistry: Total Accuracy (3, 8, 0.375)
2024-04-22 01:11:27 - INFO :       
==================Finish================

2024-04-22 01:11:27 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:11:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:11:27 - INFO :       DATASET: tasksource/mmlu college_computer_science
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2024-04-22 01:11:38 - INFO :       Use taylor pruner...
2024-04-22 01:11:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:11:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:11:39 - INFO :       Start Pruning
2024-04-22 01:11:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:11:41 - INFO :       Loss = 12.2109375
2024-04-22 01:11:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:11:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:11:45 - INFO :       college_computer_science: Total Sparsity 1.3574718775744707e-06
2024-04-22 01:11:54 - INFO :       college_computer_science: Total Accuracy (1, 11, 0.09090909090909091)
2024-04-22 01:11:54 - INFO :       
==================Finish================

2024-04-22 01:11:54 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:11:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:11:54 - INFO :       DATASET: tasksource/mmlu college_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.32s/it]
2024-04-22 01:12:13 - INFO :       Use taylor pruner...
2024-04-22 01:12:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:12:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:12:14 - INFO :       Start Pruning
2024-04-22 01:12:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:12:16 - INFO :       Loss = 13.6953125
2024-04-22 01:12:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:12:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:12:21 - INFO :       college_mathematics: Total Sparsity 1.3590631000308936e-06
2024-04-22 01:12:32 - INFO :       college_mathematics: Total Accuracy (2, 11, 0.18181818181818182)
2024-04-22 01:12:32 - INFO :       
==================Finish================

2024-04-22 01:12:32 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:12:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:12:32 - INFO :       DATASET: tasksource/mmlu college_medicine
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.81s/it]
2024-04-22 01:12:53 - INFO :       Use taylor pruner...
2024-04-22 01:12:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:12:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:12:54 - INFO :       Start Pruning
2024-04-22 01:12:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:12:56 - INFO :       Loss = 12.8828125
2024-04-22 01:12:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:12:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:12:59 - INFO :       college_medicine: Total Sparsity 1.3619273004524551e-06
2024-04-22 01:13:20 - INFO :       college_medicine: Total Accuracy (10, 22, 0.45454545454545453)
2024-04-22 01:13:20 - INFO :       
==================Finish================

2024-04-22 01:13:20 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:13:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:13:20 - INFO :       DATASET: tasksource/mmlu college_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  2.00s/it]
2024-04-22 01:13:31 - INFO :       Use taylor pruner...
2024-04-22 01:13:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:13:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:13:32 - INFO :       Start Pruning
2024-04-22 01:13:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:13:34 - INFO :       Loss = 12.046875
2024-04-22 01:13:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:13:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:13:37 - INFO :       college_physics: Total Sparsity 1.355562410626763e-06
2024-04-22 01:13:46 - INFO :       college_physics: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-22 01:13:46 - INFO :       
==================Finish================

2024-04-22 01:13:46 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:13:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:13:46 - INFO :       DATASET: tasksource/mmlu computer_security
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]
2024-04-22 01:13:57 - INFO :       Use taylor pruner...
2024-04-22 01:13:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:13:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:13:57 - INFO :       Start Pruning
2024-04-22 01:13:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:14:00 - INFO :       Loss = 14.765625
2024-04-22 01:14:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:14:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:14:02 - INFO :       computer_security: Total Sparsity 1.3604952002416743e-06
2024-04-22 01:14:12 - INFO :       computer_security: Total Accuracy (5, 11, 0.45454545454545453)
2024-04-22 01:14:12 - INFO :       
==================Finish================

2024-04-22 01:14:12 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:14:12 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:14:12 - INFO :       DATASET: tasksource/mmlu conceptual_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2024-04-22 01:14:21 - INFO :       Use taylor pruner...
2024-04-22 01:14:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:14:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:14:21 - INFO :       Start Pruning
2024-04-22 01:14:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:14:23 - INFO :       Loss = 14.1953125
2024-04-22 01:14:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:14:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:14:27 - INFO :       conceptual_physics: Total Sparsity 1.360813444732959e-06
2024-04-22 01:14:52 - INFO :       conceptual_physics: Total Accuracy (7, 26, 0.2692307692307692)
2024-04-22 01:14:52 - INFO :       
==================Finish================

2024-04-22 01:14:52 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:14:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:14:52 - INFO :       DATASET: tasksource/mmlu econometrics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.86s/it]
2024-04-22 01:15:11 - INFO :       Use taylor pruner...
2024-04-22 01:15:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:15:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:15:11 - INFO :       Start Pruning
2024-04-22 01:15:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:15:14 - INFO :       Loss = 12.1328125
2024-04-22 01:15:15 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:15:15 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:15:17 - INFO :       econometrics: Total Sparsity 1.3577901220657553e-06
2024-04-22 01:15:28 - INFO :       econometrics: Total Accuracy (2, 12, 0.16666666666666666)
2024-04-22 01:15:28 - INFO :       
==================Finish================

2024-04-22 01:15:28 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:15:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:15:28 - INFO :       DATASET: tasksource/mmlu electrical_engineering
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.56s/it]
2024-04-22 01:15:45 - INFO :       Use taylor pruner...
2024-04-22 01:15:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:15:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:15:45 - INFO :       Start Pruning
2024-04-22 01:15:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:15:47 - INFO :       Loss = 14.765625
2024-04-22 01:15:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:15:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:15:50 - INFO :       electrical_engineering: Total Sparsity 1.357630999820113e-06
2024-04-22 01:16:04 - INFO :       electrical_engineering: Total Accuracy (5, 16, 0.3125)
2024-04-22 01:16:04 - INFO :       
==================Finish================

2024-04-22 01:16:04 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:16:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:16:04 - INFO :       DATASET: tasksource/mmlu elementary_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-22 01:16:12 - INFO :       Use taylor pruner...
2024-04-22 01:16:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:16:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:16:13 - INFO :       Start Pruning
2024-04-22 01:16:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:16:15 - INFO :       Loss = 13.453125
2024-04-22 01:16:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:16:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:16:17 - INFO :       elementary_mathematics: Total Sparsity 1.3542894326616245e-06
2024-04-22 01:16:54 - INFO :       elementary_mathematics: Total Accuracy (8, 41, 0.1951219512195122)
2024-04-22 01:16:54 - INFO :       
==================Finish================

2024-04-22 01:16:54 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:16:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:16:54 - INFO :       DATASET: tasksource/mmlu formal_logic
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]
2024-04-22 01:17:04 - INFO :       Use taylor pruner...
2024-04-22 01:17:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:17:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:17:05 - INFO :       Start Pruning
2024-04-22 01:17:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:17:07 - INFO :       Loss = 11.703125
2024-04-22 01:17:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:17:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:17:10 - INFO :       formal_logic: Total Sparsity 1.3584266110483244e-06
2024-04-22 01:17:23 - INFO :       formal_logic: Total Accuracy (2, 14, 0.14285714285714285)
2024-04-22 01:17:23 - INFO :       
==================Finish================

2024-04-22 01:17:23 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:17:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:17:23 - INFO :       DATASET: tasksource/mmlu global_facts
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-22 01:17:32 - INFO :       Use taylor pruner...
2024-04-22 01:17:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:17:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:17:32 - INFO :       Start Pruning
2024-04-22 01:17:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:17:35 - INFO :       Loss = 13.890625
2024-04-22 01:17:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:17:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:17:39 - INFO :       global_facts: Total Sparsity 1.3581083665570398e-06
2024-04-22 01:17:49 - INFO :       global_facts: Total Accuracy (1, 10, 0.1)
2024-04-22 01:17:49 - INFO :       
==================Finish================

2024-04-22 01:17:49 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:17:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:17:49 - INFO :       DATASET: tasksource/mmlu high_school_biology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.33s/it]
2024-04-22 01:18:07 - INFO :       Use taylor pruner...
2024-04-22 01:18:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:18:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:18:08 - INFO :       Start Pruning
2024-04-22 01:18:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:18:10 - INFO :       Loss = 13.2265625
2024-04-22 01:18:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:18:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:18:14 - INFO :       high_school_biology: Total Sparsity 1.3616090559611704e-06
2024-04-22 01:18:44 - INFO :       high_school_biology: Total Accuracy (13, 32, 0.40625)
2024-04-22 01:18:44 - INFO :       
==================Finish================

2024-04-22 01:18:44 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:18:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:18:44 - INFO :       DATASET: tasksource/mmlu high_school_chemistry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-22 01:18:53 - INFO :       Use taylor pruner...
2024-04-22 01:18:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:18:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:18:53 - INFO :       Start Pruning
2024-04-22 01:18:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:18:55 - INFO :       Loss = 10.8671875
2024-04-22 01:18:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:18:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:18:58 - INFO :       high_school_chemistry: Total Sparsity 1.358744855539609e-06
2024-04-22 01:19:17 - INFO :       high_school_chemistry: Total Accuracy (5, 22, 0.22727272727272727)
2024-04-22 01:19:17 - INFO :       
==================Finish================

2024-04-22 01:19:17 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:19:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:19:17 - INFO :       DATASET: tasksource/mmlu high_school_computer_science
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-22 01:19:26 - INFO :       Use taylor pruner...
2024-04-22 01:19:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:19:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:19:26 - INFO :       Start Pruning
num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-22 01:19:27 - WARNING :       num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-22 01:19:27 - WARNING :       num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-22 01:19:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:19:28 - INFO :       Loss = 12.4296875
2024-04-22 01:19:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:19:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:19:31 - INFO :       high_school_computer_science: Total Sparsity 1.356517144100617e-06
2024-04-22 01:19:39 - INFO :       high_school_computer_science: Total Accuracy (5, 9, 0.5555555555555556)
2024-04-22 01:19:39 - INFO :       
==================Finish================

2024-04-22 01:19:39 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:19:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:19:39 - INFO :       DATASET: tasksource/mmlu high_school_european_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]
2024-04-22 01:19:48 - INFO :       Use taylor pruner...
2024-04-22 01:19:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:19:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:19:48 - INFO :       Start Pruning
2024-04-22 01:19:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:19:50 - INFO :       Loss = 5.1015625
2024-04-22 01:19:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:19:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:19:53 - INFO :       high_school_european_history: Total Sparsity 1.35603977736369e-06
2024-04-22 01:20:11 - INFO :       high_school_european_history: Total Accuracy (10, 18, 0.5555555555555556)
2024-04-22 01:20:11 - INFO :       
==================Finish================

2024-04-22 01:20:11 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:20:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:20:11 - INFO :       DATASET: tasksource/mmlu high_school_geography
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-22 01:20:20 - INFO :       Use taylor pruner...
2024-04-22 01:20:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:20:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:20:21 - INFO :       Start Pruning
2024-04-22 01:20:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:20:23 - INFO :       Loss = 14.28125
2024-04-22 01:20:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:20:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:20:25 - INFO :       high_school_geography: Total Sparsity 1.362404667189382e-06
2024-04-22 01:20:44 - INFO :       high_school_geography: Total Accuracy (15, 22, 0.6818181818181818)
2024-04-22 01:20:44 - INFO :       
==================Finish================

2024-04-22 01:20:44 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:20:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:20:44 - INFO :       DATASET: tasksource/mmlu high_school_government_and_politics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2024-04-22 01:20:53 - INFO :       Use taylor pruner...
2024-04-22 01:20:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:20:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:20:54 - INFO :       Start Pruning
2024-04-22 01:20:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:20:56 - INFO :       Loss = 13.828125
2024-04-22 01:20:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:20:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:20:59 - INFO :       high_school_government_and_politics: Total Sparsity 1.3590631000308936e-06
2024-04-22 01:21:17 - INFO :       high_school_government_and_politics: Total Accuracy (9, 21, 0.42857142857142855)
2024-04-22 01:21:17 - INFO :       
==================Finish================

2024-04-22 01:21:17 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:21:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:21:17 - INFO :       DATASET: tasksource/mmlu high_school_macroeconomics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-22 01:21:25 - INFO :       Use taylor pruner...
2024-04-22 01:21:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:21:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:21:26 - INFO :       Start Pruning
2024-04-22 01:21:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:21:28 - INFO :       Loss = 13.96875
2024-04-22 01:21:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:21:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:21:31 - INFO :       high_school_macroeconomics: Total Sparsity 1.3595404667678207e-06
2024-04-22 01:22:09 - INFO :       high_school_macroeconomics: Total Accuracy (14, 43, 0.32558139534883723)
2024-04-22 01:22:09 - INFO :       
==================Finish================

2024-04-22 01:22:09 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:22:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:22:09 - INFO :       DATASET: tasksource/mmlu high_school_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.35s/it]
2024-04-22 01:22:28 - INFO :       Use taylor pruner...
2024-04-22 01:22:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:22:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:22:28 - INFO :       Start Pruning
2024-04-22 01:22:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:22:32 - INFO :       Loss = 13.25
2024-04-22 01:22:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:22:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:22:35 - INFO :       high_school_mathematics: Total Sparsity 1.3561988996093322e-06
2024-04-22 01:23:04 - INFO :       high_school_mathematics: Total Accuracy (5, 29, 0.1724137931034483)
2024-04-22 01:23:04 - INFO :       
==================Finish================

2024-04-22 01:23:04 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:23:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:23:04 - INFO :       DATASET: tasksource/mmlu high_school_microeconomics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.32s/it]
2024-04-22 01:23:16 - INFO :       Use taylor pruner...
2024-04-22 01:23:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:23:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:23:17 - INFO :       Start Pruning
2024-04-22 01:23:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:23:19 - INFO :       Loss = 13.1484375
2024-04-22 01:23:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:23:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:23:22 - INFO :       high_school_microeconomics: Total Sparsity 1.3569945108375437e-06
2024-04-22 01:23:44 - INFO :       high_school_microeconomics: Total Accuracy (12, 26, 0.46153846153846156)
2024-04-22 01:23:44 - INFO :       
==================Finish================

2024-04-22 01:23:44 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:23:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:23:44 - INFO :       DATASET: tasksource/mmlu high_school_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-22 01:23:53 - INFO :       Use taylor pruner...
2024-04-22 01:23:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:23:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:23:53 - INFO :       Start Pruning
2024-04-22 01:23:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:23:56 - INFO :       Loss = 11.328125
2024-04-22 01:23:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:23:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:23:59 - INFO :       high_school_physics: Total Sparsity 1.3600178335047475e-06
2024-04-22 01:24:15 - INFO :       high_school_physics: Total Accuracy (5, 17, 0.29411764705882354)
2024-04-22 01:24:16 - INFO :       
==================Finish================

2024-04-22 01:24:16 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:24:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:24:16 - INFO :       DATASET: tasksource/mmlu high_school_psychology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.17s/it]
2024-04-22 01:24:32 - INFO :       Use taylor pruner...
2024-04-22 01:24:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:24:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:24:33 - INFO :       Start Pruning
2024-04-22 01:24:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:24:36 - INFO :       Loss = 13.609375
2024-04-22 01:24:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:24:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:24:39 - INFO :       high_school_psychology: Total Sparsity 1.3612908114698858e-06
2024-04-22 01:25:27 - INFO :       high_school_psychology: Total Accuracy (34, 50, 0.68)
2024-04-22 01:25:27 - INFO :       
==================Finish================

2024-04-22 01:25:27 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:25:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:25:27 - INFO :       DATASET: tasksource/mmlu high_school_statistics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.71s/it]
2024-04-22 01:25:44 - INFO :       Use taylor pruner...
2024-04-22 01:25:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:25:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:25:45 - INFO :       Start Pruning
2024-04-22 01:25:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:25:47 - INFO :       Loss = 11.8828125
2024-04-22 01:25:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:25:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:25:51 - INFO :       high_school_statistics: Total Sparsity 1.3538120659246977e-06
2024-04-22 01:26:11 - INFO :       high_school_statistics: Total Accuracy (8, 23, 0.34782608695652173)
2024-04-22 01:26:11 - INFO :       
==================Finish================

2024-04-22 01:26:11 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:26:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:26:11 - INFO :       DATASET: tasksource/mmlu high_school_us_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-22 01:26:20 - INFO :       Use taylor pruner...
2024-04-22 01:26:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:26:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:26:20 - INFO :       Start Pruning
2024-04-22 01:26:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:26:23 - INFO :       Loss = 7.71484375
2024-04-22 01:26:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:26:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:26:26 - INFO :       high_school_us_history: Total Sparsity 1.3577901220657553e-06
2024-04-22 01:26:46 - INFO :       high_school_us_history: Total Accuracy (12, 22, 0.5454545454545454)
2024-04-22 01:26:46 - INFO :       
==================Finish================

2024-04-22 01:26:46 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:26:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:26:46 - INFO :       DATASET: tasksource/mmlu high_school_world_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]
2024-04-22 01:26:56 - INFO :       Use taylor pruner...
2024-04-22 01:26:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:26:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:26:56 - INFO :       Start Pruning
2024-04-22 01:26:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:26:58 - INFO :       Loss = 7.10546875
2024-04-22 01:27:00 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:27:00 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:27:02 - INFO :       high_school_world_history: Total Sparsity 1.353334699187771e-06
2024-04-22 01:27:26 - INFO :       high_school_world_history: Total Accuracy (13, 26, 0.5)
2024-04-22 01:27:26 - INFO :       
==================Finish================

2024-04-22 01:27:26 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:27:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:27:26 - INFO :       DATASET: tasksource/mmlu human_aging
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-22 01:27:35 - INFO :       Use taylor pruner...
2024-04-22 01:27:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:27:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:27:35 - INFO :       Start Pruning
2024-04-22 01:27:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:27:38 - INFO :       Loss = 14.3515625
2024-04-22 01:27:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:27:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:27:41 - INFO :       human_aging: Total Sparsity 1.3601769557503897e-06
2024-04-22 01:28:01 - INFO :       human_aging: Total Accuracy (11, 23, 0.4782608695652174)
2024-04-22 01:28:01 - INFO :       
==================Finish================

2024-04-22 01:28:01 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:28:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:28:01 - INFO :       DATASET: tasksource/mmlu human_sexuality
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]
2024-04-22 01:28:11 - INFO :       Use taylor pruner...
2024-04-22 01:28:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:28:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:28:12 - INFO :       Start Pruning
2024-04-22 01:28:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:28:14 - INFO :       Loss = 13.109375
2024-04-22 01:28:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:28:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:28:17 - INFO :       human_sexuality: Total Sparsity 1.358744855539609e-06
2024-04-22 01:28:28 - INFO :       human_sexuality: Total Accuracy (4, 12, 0.3333333333333333)
2024-04-22 01:28:28 - INFO :       
==================Finish================

2024-04-22 01:28:28 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:28:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:28:28 - INFO :       DATASET: tasksource/mmlu international_law
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-22 01:28:38 - INFO :       Use taylor pruner...
2024-04-22 01:28:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:28:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:28:38 - INFO :       Start Pruning
2024-04-22 01:28:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:28:41 - INFO :       Loss = 12.8984375
2024-04-22 01:28:42 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:28:42 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:28:44 - INFO :       international_law: Total Sparsity 1.355085043889836e-06
2024-04-22 01:28:56 - INFO :       international_law: Total Accuracy (12, 13, 0.9230769230769231)
2024-04-22 01:28:56 - INFO :       
==================Finish================

2024-04-22 01:28:56 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:28:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:28:56 - INFO :       DATASET: tasksource/mmlu jurisprudence
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2024-04-22 01:29:06 - INFO :       Use taylor pruner...
2024-04-22 01:29:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:29:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:29:07 - INFO :       Start Pruning
2024-04-22 01:29:08 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:29:09 - INFO :       Loss = 13.078125
2024-04-22 01:29:10 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:29:10 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:29:11 - INFO :       jurisprudence: Total Sparsity 1.3568353885919015e-06
2024-04-22 01:29:21 - INFO :       jurisprudence: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-22 01:29:21 - INFO :       
==================Finish================

2024-04-22 01:29:21 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:29:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:29:21 - INFO :       DATASET: tasksource/mmlu logical_fallacies
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.49s/it]
2024-04-22 01:29:29 - INFO :       Use taylor pruner...
2024-04-22 01:29:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:29:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:29:30 - INFO :       Start Pruning
2024-04-22 01:29:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:29:32 - INFO :       Loss = 13.578125
2024-04-22 01:29:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:29:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:29:36 - INFO :       logical_fallacies: Total Sparsity 1.3584266110483244e-06
2024-04-22 01:29:51 - INFO :       logical_fallacies: Total Accuracy (11, 18, 0.6111111111111112)
2024-04-22 01:29:51 - INFO :       
==================Finish================

2024-04-22 01:29:51 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:29:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:29:51 - INFO :       DATASET: tasksource/mmlu machine_learning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2024-04-22 01:30:01 - INFO :       Use taylor pruner...
2024-04-22 01:30:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:30:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:30:01 - INFO :       Start Pruning
2024-04-22 01:30:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:30:04 - INFO :       Loss = 13.5234375
2024-04-22 01:30:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:30:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:30:07 - INFO :       machine_learning: Total Sparsity 1.359699589013463e-06
2024-04-22 01:30:17 - INFO :       machine_learning: Total Accuracy (4, 11, 0.36363636363636365)
2024-04-22 01:30:17 - INFO :       
==================Finish================

2024-04-22 01:30:17 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:30:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:30:17 - INFO :       DATASET: tasksource/mmlu management
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2024-04-22 01:30:25 - INFO :       Use taylor pruner...
2024-04-22 01:30:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:30:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:30:26 - INFO :       Start Pruning
2024-04-22 01:30:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:30:28 - INFO :       Loss = 14.6875
2024-04-22 01:30:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:30:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:30:31 - INFO :       management: Total Sparsity 1.3581083665570398e-06
2024-04-22 01:30:40 - INFO :       management: Total Accuracy (7, 11, 0.6363636363636364)
2024-04-22 01:30:40 - INFO :       
==================Finish================

2024-04-22 01:30:40 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:30:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:30:40 - INFO :       DATASET: tasksource/mmlu marketing
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-22 01:30:48 - INFO :       Use taylor pruner...
2024-04-22 01:30:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:30:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:30:49 - INFO :       Start Pruning
2024-04-22 01:30:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:30:51 - INFO :       Loss = 14.359375
2024-04-22 01:30:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:30:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:30:54 - INFO :       marketing: Total Sparsity 1.3574718775744707e-06
2024-04-22 01:31:15 - INFO :       marketing: Total Accuracy (18, 25, 0.72)
2024-04-22 01:31:15 - INFO :       
==================Finish================

2024-04-22 01:31:15 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:31:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:31:15 - INFO :       DATASET: tasksource/mmlu medical_genetics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
2024-04-22 01:31:24 - INFO :       Use taylor pruner...
2024-04-22 01:31:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:31:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:31:25 - INFO :       Start Pruning
2024-04-22 01:31:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:31:27 - INFO :       Loss = 14.140625
2024-04-22 01:31:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:31:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:31:30 - INFO :       medical_genetics: Total Sparsity 1.356517144100617e-06
2024-04-22 01:31:39 - INFO :       medical_genetics: Total Accuracy (9, 11, 0.8181818181818182)
2024-04-22 01:31:39 - INFO :       
==================Finish================

2024-04-22 01:31:39 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:31:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:31:39 - INFO :       DATASET: tasksource/mmlu miscellaneous
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2024-04-22 01:31:50 - INFO :       Use taylor pruner...
2024-04-22 01:31:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:31:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:31:50 - INFO :       Start Pruning
2024-04-22 01:31:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:31:53 - INFO :       Loss = 14.3828125
2024-04-22 01:31:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:31:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:31:56 - INFO :       miscellaneous: Total Sparsity 1.361449933715528e-06
2024-04-22 01:32:38 - INFO :       miscellaneous: Total Accuracy (29, 50, 0.58)
2024-04-22 01:32:38 - INFO :       
==================Finish================

2024-04-22 01:32:38 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:32:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:32:38 - INFO :       DATASET: tasksource/mmlu moral_disputes
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2024-04-22 01:32:47 - INFO :       Use taylor pruner...
2024-04-22 01:32:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:32:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:32:48 - INFO :       Start Pruning
2024-04-22 01:32:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:32:51 - INFO :       Loss = 13.625
2024-04-22 01:32:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:32:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:32:54 - INFO :       moral_disputes: Total Sparsity 1.3584266110483244e-06
2024-04-22 01:33:27 - INFO :       moral_disputes: Total Accuracy (18, 38, 0.47368421052631576)
2024-04-22 01:33:27 - INFO :       
==================Finish================

2024-04-22 01:33:27 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:33:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:33:27 - INFO :       DATASET: tasksource/mmlu moral_scenarios
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-22 01:33:36 - INFO :       Use taylor pruner...
2024-04-22 01:33:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:33:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:33:36 - INFO :       Start Pruning
2024-04-22 01:33:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:33:38 - INFO :       Loss = 12.0
2024-04-22 01:33:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:33:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:33:41 - INFO :       moral_scenarios: Total Sparsity 1.3552441661354783e-06
2024-04-22 01:34:24 - INFO :       moral_scenarios: Total Accuracy (0, 50, 0.0)
2024-04-22 01:34:24 - INFO :       
==================Finish================

2024-04-22 01:34:24 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:34:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:34:24 - INFO :       DATASET: tasksource/mmlu nutrition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-22 01:34:33 - INFO :       Use taylor pruner...
2024-04-22 01:34:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:34:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:34:33 - INFO :       Start Pruning
2024-04-22 01:34:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:34:35 - INFO :       Loss = 13.28125
2024-04-22 01:34:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:34:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:34:39 - INFO :       nutrition: Total Sparsity 1.3590631000308936e-06
2024-04-22 01:35:08 - INFO :       nutrition: Total Accuracy (20, 33, 0.6060606060606061)
2024-04-22 01:35:08 - INFO :       
==================Finish================

2024-04-22 01:35:08 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:35:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:35:08 - INFO :       DATASET: tasksource/mmlu philosophy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]
2024-04-22 01:35:18 - INFO :       Use taylor pruner...
2024-04-22 01:35:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:35:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:35:18 - INFO :       Start Pruning
2024-04-22 01:35:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:35:20 - INFO :       Loss = 13.4609375
2024-04-22 01:35:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:35:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:35:24 - INFO :       philosophy: Total Sparsity 1.3590631000308936e-06
2024-04-22 01:35:53 - INFO :       philosophy: Total Accuracy (18, 34, 0.5294117647058824)
2024-04-22 01:35:53 - INFO :       
==================Finish================

2024-04-22 01:35:53 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:35:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:35:53 - INFO :       DATASET: tasksource/mmlu prehistory
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-22 01:36:01 - INFO :       Use taylor pruner...
2024-04-22 01:36:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:36:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:36:02 - INFO :       Start Pruning
2024-04-22 01:36:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:36:05 - INFO :       Loss = 13.609375
2024-04-22 01:36:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:36:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:36:08 - INFO :       prehistory: Total Sparsity 1.357630999820113e-06
2024-04-22 01:36:38 - INFO :       prehistory: Total Accuracy (16, 35, 0.45714285714285713)
2024-04-22 01:36:39 - INFO :       
==================Finish================

2024-04-22 01:36:39 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:36:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:36:39 - INFO :       DATASET: tasksource/mmlu professional_accounting
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2024-04-22 01:36:49 - INFO :       Use taylor pruner...
2024-04-22 01:36:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:36:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:36:49 - INFO :       Start Pruning
2024-04-22 01:36:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:36:51 - INFO :       Loss = 11.546875
2024-04-22 01:36:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:36:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:36:54 - INFO :       professional_accounting: Total Sparsity 1.35603977736369e-06
2024-04-22 01:37:22 - INFO :       professional_accounting: Total Accuracy (11, 31, 0.3548387096774194)
2024-04-22 01:37:22 - INFO :       
==================Finish================

2024-04-22 01:37:22 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:37:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:37:22 - INFO :       DATASET: tasksource/mmlu professional_law
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]
2024-04-22 01:37:32 - INFO :       Use taylor pruner...
2024-04-22 01:37:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:37:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:37:32 - INFO :       Start Pruning
2024-04-22 01:37:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:37:34 - INFO :       Loss = 10.2890625
2024-04-22 01:37:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:37:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:37:37 - INFO :       professional_law: Total Sparsity 1.3558806551180476e-06
2024-04-22 01:38:24 - INFO :       professional_law: Total Accuracy (13, 50, 0.26)
2024-04-22 01:38:24 - INFO :       
==================Finish================

2024-04-22 01:38:24 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:38:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:38:24 - INFO :       DATASET: tasksource/mmlu professional_medicine
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-22 01:38:33 - INFO :       Use taylor pruner...
2024-04-22 01:38:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:38:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:38:33 - INFO :       Start Pruning
2024-04-22 01:38:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:38:35 - INFO :       Loss = 10.25
2024-04-22 01:38:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:38:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:38:38 - INFO :       professional_medicine: Total Sparsity 1.35603977736369e-06
2024-04-22 01:39:06 - INFO :       professional_medicine: Total Accuracy (17, 31, 0.5483870967741935)
2024-04-22 01:39:06 - INFO :       
==================Finish================

2024-04-22 01:39:06 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:39:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:39:06 - INFO :       DATASET: tasksource/mmlu professional_psychology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
2024-04-22 01:39:16 - INFO :       Use taylor pruner...
2024-04-22 01:39:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:39:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:39:16 - INFO :       Start Pruning
2024-04-22 01:39:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:39:18 - INFO :       Loss = 12.8203125
2024-04-22 01:39:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:39:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:39:21 - INFO :       professional_psychology: Total Sparsity 1.359699589013463e-06
2024-04-22 01:40:05 - INFO :       professional_psychology: Total Accuracy (24, 50, 0.48)
2024-04-22 01:40:05 - INFO :       
==================Finish================

2024-04-22 01:40:05 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:40:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:40:05 - INFO :       DATASET: tasksource/mmlu public_relations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.92s/it]
2024-04-22 01:40:15 - INFO :       Use taylor pruner...
2024-04-22 01:40:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:40:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:40:16 - INFO :       Start Pruning
2024-04-22 01:40:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:40:18 - INFO :       Loss = 14.2890625
2024-04-22 01:40:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:40:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:40:21 - INFO :       public_relations: Total Sparsity 1.3600178335047475e-06
2024-04-22 01:40:31 - INFO :       public_relations: Total Accuracy (8, 12, 0.6666666666666666)
2024-04-22 01:40:31 - INFO :       
==================Finish================

2024-04-22 01:40:31 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:40:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:40:31 - INFO :       DATASET: tasksource/mmlu security_studies
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]
2024-04-22 01:40:41 - INFO :       Use taylor pruner...
2024-04-22 01:40:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:40:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:40:41 - INFO :       Start Pruning
2024-04-22 01:40:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:40:44 - INFO :       Loss = 12.828125
2024-04-22 01:40:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:40:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:40:47 - INFO :       security_studies: Total Sparsity 1.3584266110483244e-06
2024-04-22 01:41:11 - INFO :       security_studies: Total Accuracy (10, 27, 0.37037037037037035)
2024-04-22 01:41:11 - INFO :       
==================Finish================

2024-04-22 01:41:11 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:41:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:41:11 - INFO :       DATASET: tasksource/mmlu sociology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2024-04-22 01:41:22 - INFO :       Use taylor pruner...
2024-04-22 01:41:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:41:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:41:23 - INFO :       Start Pruning
2024-04-22 01:41:25 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:41:26 - INFO :       Loss = 14.0546875
2024-04-22 01:41:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:41:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:41:29 - INFO :       sociology: Total Sparsity 1.357630999820113e-06
2024-04-22 01:41:47 - INFO :       sociology: Total Accuracy (14, 22, 0.6363636363636364)
2024-04-22 01:41:47 - INFO :       
==================Finish================

2024-04-22 01:41:47 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:41:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:41:47 - INFO :       DATASET: tasksource/mmlu us_foreign_policy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2024-04-22 01:41:57 - INFO :       Use taylor pruner...
2024-04-22 01:41:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:41:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:41:57 - INFO :       Start Pruning
2024-04-22 01:41:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:42:00 - INFO :       Loss = 14.2734375
2024-04-22 01:42:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:42:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:42:03 - INFO :       us_foreign_policy: Total Sparsity 1.3577901220657553e-06
2024-04-22 01:42:13 - INFO :       us_foreign_policy: Total Accuracy (5, 11, 0.45454545454545453)
2024-04-22 01:42:13 - INFO :       
==================Finish================

2024-04-22 01:42:13 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:42:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:42:13 - INFO :       DATASET: tasksource/mmlu virology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]
2024-04-22 01:42:22 - INFO :       Use taylor pruner...
2024-04-22 01:42:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:42:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:42:23 - INFO :       Start Pruning
2024-04-22 01:42:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:42:25 - INFO :       Loss = 14.296875
2024-04-22 01:42:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:42:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:42:28 - INFO :       virology: Total Sparsity 1.360336077996032e-06
2024-04-22 01:42:43 - INFO :       virology: Total Accuracy (9, 18, 0.5)
2024-04-22 01:42:44 - INFO :       
==================Finish================

2024-04-22 01:42:44 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:42:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:42:44 - INFO :       DATASET: tasksource/mmlu world_religions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-22 01:42:54 - INFO :       Use taylor pruner...
2024-04-22 01:42:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:42:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:42:55 - INFO :       Start Pruning
2024-04-22 01:42:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:42:58 - INFO :       Loss = 14.2109375
2024-04-22 01:42:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:42:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:43:00 - INFO :       world_religions: Total Sparsity 1.359699589013463e-06
2024-04-22 01:43:16 - INFO :       world_religions: Total Accuracy (14, 19, 0.7368421052631579)
2024-04-22 01:43:17 - INFO :       
==================Finish================

2024-04-22 01:43:17 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:43:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:43:17 - INFO :       DATASET: math_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2024-04-22 01:43:25 - INFO :       Use taylor pruner...
2024-04-22 01:43:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:43:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:43:26 - INFO :       Start Pruning
2024-04-22 01:43:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:43:28 - INFO :       Loss = 13.8046875
2024-04-22 01:43:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:43:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:43:31 - INFO :       math_qa: Total Sparsity 1.353334699187771e-06
2024-04-22 01:44:10 - INFO :       math_qa: Accuracy (9, 50, 0.18)
2024-04-22 01:44:10 - INFO :       
==================Finish================

2024-04-22 01:44:10 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:44:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:44:10 - INFO :       DATASET: EleutherAI/truthful_qa_mc
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
2024-04-22 01:44:19 - INFO :       Use taylor pruner...
2024-04-22 01:44:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:44:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:44:20 - INFO :       Start Pruning
2024-04-22 01:44:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:44:22 - INFO :       Loss = 13.4765625
2024-04-22 01:44:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:44:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:44:25 - INFO :       truthful_qa_mc: Total Sparsity 1.3590631000308936e-06
2024-04-22 01:45:01 - INFO :       truthful_qa_mc: Accuracy (18, 50, 0.36)
2024-04-22 01:45:01 - INFO :       
==================Finish================

2024-04-22 01:45:01 - INFO :       Memory Requirement: 12676.77392578125 MiB

2024-04-22 01:45:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:45:01 - INFO :       DATASET: derek-thomas/ScienceQA
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]
2024-04-22 01:45:10 - INFO :       Use taylor pruner...
2024-04-22 01:45:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:45:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:45:11 - INFO :       Start Pruning
2024-04-22 01:45:12 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:45:13 - INFO :       Loss = 13.90625
2024-04-22 01:45:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:45:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:45:16 - INFO :       ScienceQA: Total Sparsity 1.3593813445221782e-06
2024-04-22 01:45:53 - INFO :       ScienceQA: Accuracy (23, 50, 0.46)
2024-04-22 01:45:53 - INFO :       
==================Finish================

2024-04-22 01:45:53 - INFO :       Memory Requirement: 12674.77392578125 MiB

2024-04-22 01:45:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:45:53 - INFO :       DATASET: commonsense_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]
2024-04-22 01:46:02 - INFO :       Use taylor pruner...
2024-04-22 01:46:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:46:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:46:02 - INFO :       Start Pruning
2024-04-22 01:46:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:46:05 - INFO :       Loss = 14.2265625
2024-04-22 01:46:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:46:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:46:08 - INFO :       commonsense_qa: Total Sparsity 1.3622455449437396e-06
2024-04-22 01:46:45 - INFO :       commonsense_qa: Accuracy (25, 50, 0.5)
2024-04-22 01:46:45 - INFO :       
==================Finish================

2024-04-22 01:46:45 - INFO :       Memory Requirement: 12676.77392578125 MiB

End: Memory Requirement: 3979.2666015625 MiB

Begin: Memory Requirement: 3979.2666015625 MiB

2024-04-22 01:46:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:46:45 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Index 1
Sparsity 3.5000000000000004 %
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.41s/it]
2024-04-22 01:46:57 - INFO :       Use taylor pruner...
2024-04-22 01:46:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:46:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:46:58 - INFO :       Start Pruning
2024-04-22 01:46:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:47:01 - INFO :       Loss = 1.8583984375
2024-04-22 01:47:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:47:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:47:04 - INFO :       which_wiki_edit: Total Sparsity 1.3482427873272173e-06
2024-04-22 01:48:42 - INFO :       which_wiki_edit: Total Accuracy (27, 50, 0.54)
2024-04-22 01:48:42 - INFO :       
==================Finish================

2024-04-22 01:48:42 - INFO :       Memory Requirement: 16849.60302734375 MiB

2024-04-22 01:48:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:48:42 - INFO :       DATASET: tasksource/bigbench abstract_narrative_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]
2024-04-22 01:48:51 - INFO :       Use taylor pruner...
2024-04-22 01:48:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:48:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:48:51 - INFO :       Start Pruning
2024-04-22 01:48:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:48:53 - INFO :       Loss = 6.83203125
2024-04-22 01:48:55 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:48:55 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:48:56 - INFO :       abstract_narrative_understanding: Total Sparsity 1.3600178335047475e-06
2024-04-22 01:49:39 - INFO :       abstract_narrative_understanding: Total Accuracy (19, 50, 0.38)
2024-04-22 01:49:39 - INFO :       
==================Finish================

2024-04-22 01:49:39 - INFO :       Memory Requirement: 16772.79052734375 MiB

2024-04-22 01:49:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:49:39 - INFO :       DATASET: tasksource/bigbench anachronisms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]
2024-04-22 01:49:49 - INFO :       Use taylor pruner...
2024-04-22 01:49:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:49:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:49:49 - INFO :       Start Pruning
2024-04-22 01:49:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:49:52 - INFO :       Loss = 14.734375
2024-04-22 01:49:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:49:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:49:55 - INFO :       anachronisms: Total Sparsity 1.355085043889836e-06
2024-04-22 01:50:31 - INFO :       anachronisms: Total Accuracy (23, 46, 0.5)
2024-04-22 01:50:32 - INFO :       
==================Finish================

2024-04-22 01:50:32 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-22 01:50:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:50:32 - INFO :       DATASET: tasksource/bigbench analogical_similarity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]
2024-04-22 01:50:43 - INFO :       Use taylor pruner...
2024-04-22 01:50:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:50:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:50:44 - INFO :       Start Pruning
2024-04-22 01:50:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:50:47 - INFO :       Loss = 1.3515625
2024-04-22 01:50:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:50:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:50:51 - INFO :       analogical_similarity: Total Sparsity 1.3557215328724054e-06
2024-04-22 01:51:45 - INFO :       analogical_similarity: Total Accuracy (3, 50, 0.06)
2024-04-22 01:51:45 - INFO :       
==================Finish================

2024-04-22 01:51:45 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-22 01:51:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:51:45 - INFO :       DATASET: tasksource/bigbench analytic_entailment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]
2024-04-22 01:51:54 - INFO :       Use taylor pruner...
2024-04-22 01:51:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:51:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:51:54 - INFO :       Start Pruning
2024-04-22 01:51:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:51:57 - INFO :       Loss = 14.2109375
2024-04-22 01:51:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:51:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:52:01 - INFO :       analytic_entailment: Total Sparsity 1.3573127553288283e-06
2024-04-22 01:52:13 - INFO :       analytic_entailment: Total Accuracy (8, 16, 0.5)
2024-04-22 01:52:14 - INFO :       
==================Finish================

2024-04-22 01:52:14 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-22 01:52:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:52:14 - INFO :       DATASET: tasksource/bigbench arithmetic
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2024-04-22 01:52:23 - INFO :       Use taylor pruner...
2024-04-22 01:52:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:52:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:52:23 - INFO :       Start Pruning
2024-04-22 01:52:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:52:25 - INFO :       Loss = 10.9375
2024-04-22 01:52:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:52:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:52:29 - INFO :       arithmetic: Total Sparsity 1.3547667993985515e-06
2024-04-22 01:53:11 - INFO :       arithmetic: Total Accuracy (2, 50, 0.04)
2024-04-22 01:53:11 - INFO :       
==================Finish================

2024-04-22 01:53:11 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-22 01:53:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:53:11 - INFO :       DATASET: tasksource/bigbench authorship_verification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-22 01:53:20 - INFO :       Use taylor pruner...
2024-04-22 01:53:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:53:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:53:21 - INFO :       Start Pruning
2024-04-22 01:53:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:53:23 - INFO :       Loss = 2.615234375
2024-04-22 01:53:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:53:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:53:26 - INFO :       authorship_verification: Total Sparsity 1.3515843544857055e-06
2024-04-22 01:55:34 - INFO :       authorship_verification: Total Accuracy (28, 50, 0.56)
2024-04-22 01:55:34 - INFO :       
==================Finish================

2024-04-22 01:55:34 - INFO :       Memory Requirement: 16794.029296875 MiB

2024-04-22 01:55:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:55:34 - INFO :       DATASET: tasksource/bigbench bbq_lite_json
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-22 01:55:43 - INFO :       Use taylor pruner...
2024-04-22 01:55:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:55:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:55:43 - INFO :       Start Pruning
2024-04-22 01:55:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:55:45 - INFO :       Loss = 12.625
2024-04-22 01:55:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:55:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:55:48 - INFO :       bbq_lite_json: Total Sparsity 1.3579492443113975e-06
2024-04-22 01:56:30 - INFO :       bbq_lite_json: Total Accuracy (5, 50, 0.1)
2024-04-22 01:56:30 - INFO :       
==================Finish================

2024-04-22 01:56:30 - INFO :       Memory Requirement: 16771.79052734375 MiB

2024-04-22 01:56:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:56:30 - INFO :       DATASET: tasksource/bigbench causal_judgment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-22 01:56:39 - INFO :       Use taylor pruner...
2024-04-22 01:56:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:56:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:56:39 - INFO :       Start Pruning
2024-04-22 01:56:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:56:42 - INFO :       Loss = 8.65625
2024-04-22 01:56:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:56:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:56:45 - INFO :       causal_judgment: Total Sparsity 1.3552441661354783e-06
2024-04-22 01:57:19 - INFO :       causal_judgment: Total Accuracy (17, 38, 0.4473684210526316)
2024-04-22 01:57:19 - INFO :       
==================Finish================

2024-04-22 01:57:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 01:57:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:57:19 - INFO :       DATASET: tasksource/bigbench cause_and_effect
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2024-04-22 01:57:27 - INFO :       Use taylor pruner...
2024-04-22 01:57:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:57:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:57:27 - INFO :       Start Pruning
2024-04-22 01:57:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:57:30 - INFO :       Loss = 13.109375
2024-04-22 01:57:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:57:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:57:33 - INFO :       cause_and_effect: Total Sparsity 1.3601769557503897e-06
2024-04-22 01:57:58 - INFO :       cause_and_effect: Total Accuracy (26, 30, 0.8666666666666667)
2024-04-22 01:57:58 - INFO :       
==================Finish================

2024-04-22 01:57:58 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 01:57:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:57:58 - INFO :       DATASET: tasksource/bigbench checkmate_in_one
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]
2024-04-22 01:58:07 - INFO :       Use taylor pruner...
2024-04-22 01:58:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:58:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:58:08 - INFO :       Start Pruning
2024-04-22 01:58:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:58:10 - INFO :       Loss = 3.646484375
2024-04-22 01:58:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:58:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:58:13 - INFO :       checkmate_in_one: Total Sparsity 1.3566762663462592e-06
2024-04-22 01:59:03 - INFO :       checkmate_in_one: Total Accuracy (2, 50, 0.04)
2024-04-22 01:59:03 - INFO :       
==================Finish================

2024-04-22 01:59:03 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 01:59:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 01:59:03 - INFO :       DATASET: tasksource/bigbench cifar10_classification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]
2024-04-22 01:59:12 - INFO :       Use taylor pruner...
2024-04-22 01:59:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:59:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 01:59:12 - INFO :       Start Pruning
2024-04-22 01:59:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 01:59:14 - INFO :       Loss = 5.1875
2024-04-22 01:59:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 01:59:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 01:59:18 - INFO :       cifar10_classification: Total Sparsity 1.354448554907267e-06
2024-04-22 02:01:10 - INFO :       cifar10_classification: Total Accuracy (0, 50, 0.0)
2024-04-22 02:01:10 - INFO :       
==================Finish================

2024-04-22 02:01:10 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:01:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:01:10 - INFO :       DATASET: tasksource/bigbench code_line_description
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-22 02:01:19 - INFO :       Use taylor pruner...
2024-04-22 02:01:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:01:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:01:19 - INFO :       Start Pruning
2024-04-22 02:01:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:01:22 - INFO :       Loss = 10.1328125
2024-04-22 02:01:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:01:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:01:25 - INFO :       code_line_description: Total Sparsity 1.3566762663462592e-06
2024-04-22 02:01:38 - INFO :       code_line_description: Total Accuracy (11, 16, 0.6875)
2024-04-22 02:01:38 - INFO :       
==================Finish================

2024-04-22 02:01:38 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:01:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:01:38 - INFO :       DATASET: tasksource/bigbench color
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:01<00:01,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:02<00:00,  1.49s/it]
2024-04-22 02:01:47 - INFO :       Use taylor pruner...
2024-04-22 02:01:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:01:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:01:48 - INFO :       Start Pruning
2024-04-22 02:01:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:01:50 - INFO :       Loss = 10.6328125
2024-04-22 02:01:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:01:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:01:53 - INFO :       color: Total Sparsity 1.3574718775744707e-06
2024-04-22 02:02:36 - INFO :       color: Total Accuracy (1, 50, 0.02)
2024-04-22 02:02:36 - INFO :       
==================Finish================

2024-04-22 02:02:36 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:02:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:02:36 - INFO :       DATASET: tasksource/bigbench common_morpheme
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
2024-04-22 02:02:45 - INFO :       Use taylor pruner...
2024-04-22 02:02:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:02:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:02:45 - INFO :       Start Pruning
2024-04-22 02:02:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:02:47 - INFO :       Loss = 13.03125
2024-04-22 02:02:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:02:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:02:50 - INFO :       common_morpheme: Total Sparsity 1.3606543224873167e-06
2024-04-22 02:03:03 - INFO :       common_morpheme: Total Accuracy (5, 16, 0.3125)
2024-04-22 02:03:04 - INFO :       
==================Finish================

2024-04-22 02:03:04 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:03:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:03:04 - INFO :       DATASET: tasksource/bigbench conceptual_combinations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-22 02:03:13 - INFO :       Use taylor pruner...
2024-04-22 02:03:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:03:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:03:13 - INFO :       Start Pruning
2024-04-22 02:03:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:03:16 - INFO :       Loss = 11.4453125
2024-04-22 02:03:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:03:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:03:20 - INFO :       conceptual_combinations: Total Sparsity 1.3574718775744707e-06
2024-04-22 02:03:37 - INFO :       conceptual_combinations: Total Accuracy (8, 19, 0.42105263157894735)
2024-04-22 02:03:37 - INFO :       
==================Finish================

2024-04-22 02:03:37 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:03:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:03:37 - INFO :       DATASET: tasksource/bigbench crash_blossom
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]
2024-04-22 02:03:46 - INFO :       Use taylor pruner...
2024-04-22 02:03:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:03:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:03:47 - INFO :       Start Pruning
2024-04-22 02:03:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:03:49 - INFO :       Loss = 13.609375
2024-04-22 02:03:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:03:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:03:52 - INFO :       crash_blossom: Total Sparsity 1.3593813445221782e-06
2024-04-22 02:04:05 - INFO :       crash_blossom: Total Accuracy (5, 16, 0.3125)
2024-04-22 02:04:05 - INFO :       
==================Finish================

2024-04-22 02:04:05 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:04:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:04:05 - INFO :       DATASET: tasksource/bigbench crass_ai
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2024-04-22 02:04:15 - INFO :       Use taylor pruner...
2024-04-22 02:04:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:04:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:04:16 - INFO :       Start Pruning
2024-04-22 02:04:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:04:18 - INFO :       Loss = 11.28125
2024-04-22 02:04:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:04:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:04:21 - INFO :       crass_ai: Total Sparsity 1.358267488802682e-06
2024-04-22 02:04:34 - INFO :       crass_ai: Total Accuracy (6, 16, 0.375)
2024-04-22 02:04:34 - INFO :       
==================Finish================

2024-04-22 02:04:34 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:04:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:04:34 - INFO :       DATASET: tasksource/bigbench cryobiology_spanish
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-22 02:04:43 - INFO :       Use taylor pruner...
2024-04-22 02:04:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:04:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:04:44 - INFO :       Start Pruning
2024-04-22 02:04:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:04:46 - INFO :       Loss = 13.4453125
2024-04-22 02:04:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:04:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:04:49 - INFO :       cryobiology_spanish: Total Sparsity 1.3601769557503897e-06
2024-04-22 02:05:14 - INFO :       cryobiology_spanish: Total Accuracy (23, 29, 0.7931034482758621)
2024-04-22 02:05:14 - INFO :       
==================Finish================

2024-04-22 02:05:14 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:05:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:05:14 - INFO :       DATASET: tasksource/bigbench cs_algorithms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]
2024-04-22 02:05:23 - INFO :       Use taylor pruner...
2024-04-22 02:05:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:05:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:05:23 - INFO :       Start Pruning
2024-04-22 02:05:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:05:25 - INFO :       Loss = 13.2890625
2024-04-22 02:05:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:05:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:05:28 - INFO :       cs_algorithms: Total Sparsity 1.359222222276536e-06
2024-04-22 02:06:11 - INFO :       cs_algorithms: Total Accuracy (6, 50, 0.12)
2024-04-22 02:06:11 - INFO :       
==================Finish================

2024-04-22 02:06:11 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:06:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:06:11 - INFO :       DATASET: tasksource/bigbench dark_humor_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]
2024-04-22 02:06:21 - INFO :       Use taylor pruner...
2024-04-22 02:06:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:06:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:06:21 - INFO :       Start Pruning
2024-04-22 02:06:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:06:24 - INFO :       Loss = 13.546875
2024-04-22 02:06:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:06:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:06:28 - INFO :       dark_humor_detection: Total Sparsity 1.3581083665570398e-06
2024-04-22 02:06:41 - INFO :       dark_humor_detection: Total Accuracy (7, 16, 0.4375)
2024-04-22 02:06:41 - INFO :       
==================Finish================

2024-04-22 02:06:41 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:06:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:06:41 - INFO :       DATASET: tasksource/bigbench date_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-22 02:06:50 - INFO :       Use taylor pruner...
2024-04-22 02:06:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:06:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:06:51 - INFO :       Start Pruning
2024-04-22 02:06:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:06:54 - INFO :       Loss = 11.125
2024-04-22 02:06:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:06:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:06:57 - INFO :       date_understanding: Total Sparsity 1.3557215328724054e-06
2024-04-22 02:07:40 - INFO :       date_understanding: Total Accuracy (10, 50, 0.2)
2024-04-22 02:07:40 - INFO :       
==================Finish================

2024-04-22 02:07:40 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:07:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:07:40 - INFO :       DATASET: tasksource/bigbench disambiguation_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2024-04-22 02:07:49 - INFO :       Use taylor pruner...
2024-04-22 02:07:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:07:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:07:50 - INFO :       Start Pruning
2024-04-22 02:07:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:07:52 - INFO :       Loss = 12.5234375
2024-04-22 02:07:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:07:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:07:56 - INFO :       disambiguation_qa: Total Sparsity 1.357153633083186e-06
2024-04-22 02:08:38 - INFO :       disambiguation_qa: Total Accuracy (21, 50, 0.42)
2024-04-22 02:08:38 - INFO :       
==================Finish================

2024-04-22 02:08:38 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:08:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:08:38 - INFO :       DATASET: tasksource/bigbench discourse_marker_prediction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]
2024-04-22 02:08:47 - INFO :       Use taylor pruner...
2024-04-22 02:08:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:08:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:08:47 - INFO :       Start Pruning
2024-04-22 02:08:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:08:49 - INFO :       Loss = 4.51953125
2024-04-22 02:08:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:08:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:08:53 - INFO :       discourse_marker_prediction: Total Sparsity 1.3579492443113975e-06
2024-04-22 02:09:40 - INFO :       discourse_marker_prediction: Total Accuracy (12, 50, 0.24)
2024-04-22 02:09:40 - INFO :       
==================Finish================

2024-04-22 02:09:40 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:09:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:09:40 - INFO :       DATASET: tasksource/bigbench dyck_languages
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-22 02:09:49 - INFO :       Use taylor pruner...
2024-04-22 02:09:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:09:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:09:50 - INFO :       Start Pruning
2024-04-22 02:09:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:09:52 - INFO :       Loss = 1.1591796875
2024-04-22 02:09:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:09:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:09:55 - INFO :       dyck_languages: Total Sparsity 1.355085043889836e-06
2024-04-22 02:10:45 - INFO :       dyck_languages: Total Accuracy (1, 50, 0.02)
2024-04-22 02:10:45 - INFO :       
==================Finish================

2024-04-22 02:10:45 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:10:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:10:45 - INFO :       DATASET: tasksource/bigbench elementary_math_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-22 02:10:55 - INFO :       Use taylor pruner...
2024-04-22 02:10:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:10:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:10:55 - INFO :       Start Pruning
2024-04-22 02:10:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:10:57 - INFO :       Loss = 10.5703125
2024-04-22 02:10:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:10:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:11:00 - INFO :       elementary_math_qa: Total Sparsity 1.3579492443113975e-06
2024-04-22 02:11:43 - INFO :       elementary_math_qa: Total Accuracy (13, 50, 0.26)
2024-04-22 02:11:43 - INFO :       
==================Finish================

2024-04-22 02:11:43 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:11:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:11:43 - INFO :       DATASET: tasksource/bigbench emoji_movie
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2024-04-22 02:11:52 - INFO :       Use taylor pruner...
2024-04-22 02:11:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:11:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:11:53 - INFO :       Start Pruning
2024-04-22 02:11:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:11:55 - INFO :       Loss = 12.6953125
2024-04-22 02:11:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:11:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:11:58 - INFO :       emoji_movie: Total Sparsity 1.3581083665570398e-06
2024-04-22 02:12:14 - INFO :       emoji_movie: Total Accuracy (12, 20, 0.6)
2024-04-22 02:12:14 - INFO :       
==================Finish================

2024-04-22 02:12:14 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:12:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:12:14 - INFO :       DATASET: tasksource/bigbench empirical_judgments
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]
2024-04-22 02:12:24 - INFO :       Use taylor pruner...
2024-04-22 02:12:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:12:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:12:25 - INFO :       Start Pruning
2024-04-22 02:12:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:12:27 - INFO :       Loss = 12.6484375
2024-04-22 02:12:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:12:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:12:31 - INFO :       empirical_judgments: Total Sparsity 1.358267488802682e-06
2024-04-22 02:12:46 - INFO :       empirical_judgments: Total Accuracy (5, 19, 0.2631578947368421)
2024-04-22 02:12:46 - INFO :       
==================Finish================

2024-04-22 02:12:46 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:12:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:12:46 - INFO :       DATASET: tasksource/bigbench english_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]
2024-04-22 02:12:55 - INFO :       Use taylor pruner...
2024-04-22 02:12:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:12:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:12:55 - INFO :       Start Pruning
2024-04-22 02:12:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:12:57 - INFO :       Loss = 10.59375
2024-04-22 02:12:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:12:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:13:00 - INFO :       english_proverbs: Total Sparsity 1.355085043889836e-06
2024-04-22 02:13:14 - INFO :       english_proverbs: Total Accuracy (3, 16, 0.1875)
2024-04-22 02:13:14 - INFO :       
==================Finish================

2024-04-22 02:13:14 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:13:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:13:14 - INFO :       DATASET: tasksource/bigbench english_russian_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-22 02:13:24 - INFO :       Use taylor pruner...
2024-04-22 02:13:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:13:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:13:25 - INFO :       Start Pruning
2024-04-22 02:13:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:13:27 - INFO :       Loss = 11.5625
2024-04-22 02:13:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:13:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:13:30 - INFO :       english_russian_proverbs: Total Sparsity 1.357153633083186e-06
2024-04-22 02:13:44 - INFO :       english_russian_proverbs: Total Accuracy (2, 16, 0.125)
2024-04-22 02:13:44 - INFO :       
==================Finish================

2024-04-22 02:13:44 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:13:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:13:44 - INFO :       DATASET: tasksource/bigbench entailed_polarity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]
2024-04-22 02:13:53 - INFO :       Use taylor pruner...
2024-04-22 02:13:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:13:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:13:53 - INFO :       Start Pruning
2024-04-22 02:13:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:13:56 - INFO :       Loss = 14.375
2024-04-22 02:13:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:13:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:13:59 - INFO :       entailed_polarity: Total Sparsity 1.3598587112591052e-06
2024-04-22 02:14:23 - INFO :       entailed_polarity: Total Accuracy (28, 29, 0.9655172413793104)
2024-04-22 02:14:23 - INFO :       
==================Finish================

2024-04-22 02:14:23 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:14:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:14:23 - INFO :       DATASET: tasksource/bigbench entailed_polarity_hindi
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-22 02:14:32 - INFO :       Use taylor pruner...
2024-04-22 02:14:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:14:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:14:32 - INFO :       Start Pruning
2024-04-22 02:14:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:14:35 - INFO :       Loss = 9.9921875
2024-04-22 02:14:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:14:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:14:38 - INFO :       entailed_polarity_hindi: Total Sparsity 1.357630999820113e-06
2024-04-22 02:15:00 - INFO :       entailed_polarity_hindi: Total Accuracy (21, 27, 0.7777777777777778)
2024-04-22 02:15:00 - INFO :       
==================Finish================

2024-04-22 02:15:00 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:15:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:15:00 - INFO :       DATASET: tasksource/bigbench epistemic_reasoning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]
2024-04-22 02:15:09 - INFO :       Use taylor pruner...
2024-04-22 02:15:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:15:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:15:10 - INFO :       Start Pruning
2024-04-22 02:15:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:15:12 - INFO :       Loss = 12.65625
2024-04-22 02:15:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:15:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:15:15 - INFO :       epistemic_reasoning: Total Sparsity 1.3584266110483244e-06
2024-04-22 02:15:57 - INFO :       epistemic_reasoning: Total Accuracy (31, 50, 0.62)
2024-04-22 02:15:57 - INFO :       
==================Finish================

2024-04-22 02:15:57 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:15:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:15:57 - INFO :       DATASET: tasksource/bigbench evaluating_information_essentiality
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]
2024-04-22 02:16:07 - INFO :       Use taylor pruner...
2024-04-22 02:16:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:16:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:16:07 - INFO :       Start Pruning
2024-04-22 02:16:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:16:10 - INFO :       Loss = 7.73828125
2024-04-22 02:16:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:16:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:16:13 - INFO :       evaluating_information_essentiality: Total Sparsity 1.3520617212226323e-06
2024-04-22 02:16:27 - INFO :       evaluating_information_essentiality: Total Accuracy (1, 16, 0.0625)
2024-04-22 02:16:27 - INFO :       
==================Finish================

2024-04-22 02:16:27 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:16:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:16:27 - INFO :       DATASET: tasksource/bigbench fact_checker
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]
2024-04-22 02:16:36 - INFO :       Use taylor pruner...
2024-04-22 02:16:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:16:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:16:36 - INFO :       Start Pruning
2024-04-22 02:16:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:16:39 - INFO :       Loss = 14.203125
2024-04-22 02:16:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:16:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:16:42 - INFO :       fact_checker: Total Sparsity 1.3577901220657553e-06
2024-04-22 02:17:23 - INFO :       fact_checker: Total Accuracy (39, 50, 0.78)
2024-04-22 02:17:23 - INFO :       
==================Finish================

2024-04-22 02:17:23 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:17:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:17:23 - INFO :       DATASET: tasksource/bigbench fantasy_reasoning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  2.00s/it]
2024-04-22 02:17:33 - INFO :       Use taylor pruner...
2024-04-22 02:17:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:17:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:17:33 - INFO :       Start Pruning
2024-04-22 02:17:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:17:35 - INFO :       Loss = 13.0390625
2024-04-22 02:17:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:17:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:17:38 - INFO :       fantasy_reasoning: Total Sparsity 1.3612908114698858e-06
2024-04-22 02:18:12 - INFO :       fantasy_reasoning: Total Accuracy (21, 40, 0.525)
2024-04-22 02:18:12 - INFO :       
==================Finish================

2024-04-22 02:18:12 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:18:12 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:18:12 - INFO :       DATASET: tasksource/bigbench figure_of_speech_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]
2024-04-22 02:18:23 - INFO :       Use taylor pruner...
2024-04-22 02:18:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:18:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:18:23 - INFO :       Start Pruning
2024-04-22 02:18:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:18:25 - INFO :       Loss = 11.796875
2024-04-22 02:18:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:18:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:18:29 - INFO :       figure_of_speech_detection: Total Sparsity 1.3557215328724054e-06
2024-04-22 02:18:42 - INFO :       figure_of_speech_detection: Total Accuracy (3, 16, 0.1875)
2024-04-22 02:18:42 - INFO :       
==================Finish================

2024-04-22 02:18:42 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:18:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:18:42 - INFO :       DATASET: tasksource/bigbench formal_fallacies_syllogisms_negation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2024-04-22 02:18:52 - INFO :       Use taylor pruner...
2024-04-22 02:18:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:18:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:18:53 - INFO :       Start Pruning
2024-04-22 02:18:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:18:55 - INFO :       Loss = 12.2109375
2024-04-22 02:18:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:18:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:18:58 - INFO :       formal_fallacies_syllogisms_negation: Total Sparsity 1.3593813445221782e-06
2024-04-22 02:19:42 - INFO :       formal_fallacies_syllogisms_negation: Total Accuracy (23, 50, 0.46)
2024-04-22 02:19:42 - INFO :       
==================Finish================

2024-04-22 02:19:42 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:19:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:19:42 - INFO :       DATASET: tasksource/bigbench general_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2024-04-22 02:19:52 - INFO :       Use taylor pruner...
2024-04-22 02:19:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:19:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:19:53 - INFO :       Start Pruning
2024-04-22 02:19:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:19:55 - INFO :       Loss = 11.5859375
2024-04-22 02:19:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:19:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:19:58 - INFO :       general_knowledge: Total Sparsity 1.3606543224873167e-06
2024-04-22 02:20:11 - INFO :       general_knowledge: Total Accuracy (11, 16, 0.6875)
2024-04-22 02:20:11 - INFO :       
==================Finish================

2024-04-22 02:20:11 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:20:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:20:11 - INFO :       DATASET: tasksource/bigbench geometric_shapes
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-22 02:20:20 - INFO :       Use taylor pruner...
2024-04-22 02:20:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:20:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:20:21 - INFO :       Start Pruning
2024-04-22 02:20:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:20:23 - INFO :       Loss = 9.0546875
2024-04-22 02:20:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:20:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:20:26 - INFO :       geometric_shapes: Total Sparsity 1.3581083665570398e-06
2024-04-22 02:21:09 - INFO :       geometric_shapes: Total Accuracy (6, 50, 0.12)
2024-04-22 02:21:09 - INFO :       
==================Finish================

2024-04-22 02:21:09 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:21:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:21:09 - INFO :       DATASET: tasksource/bigbench goal_step_wikihow
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]
2024-04-22 02:21:21 - INFO :       Use taylor pruner...
2024-04-22 02:21:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:21:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:21:21 - INFO :       Start Pruning
2024-04-22 02:21:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:21:23 - INFO :       Loss = 12.609375
2024-04-22 02:21:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:21:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:21:27 - INFO :       goal_step_wikihow: Total Sparsity 1.3549259216441938e-06
2024-04-22 02:22:09 - INFO :       goal_step_wikihow: Total Accuracy (16, 50, 0.32)
2024-04-22 02:22:09 - INFO :       
==================Finish================

2024-04-22 02:22:09 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:22:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:22:09 - INFO :       DATASET: tasksource/bigbench gre_reading_comprehension
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2024-04-22 02:22:19 - INFO :       Use taylor pruner...
2024-04-22 02:22:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:22:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:22:19 - INFO :       Start Pruning
2024-04-22 02:22:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:22:21 - INFO :       Loss = 3.369140625
2024-04-22 02:22:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:22:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:22:24 - INFO :       gre_reading_comprehension: Total Sparsity 1.357153633083186e-06
2024-04-22 02:22:41 - INFO :       gre_reading_comprehension: Total Accuracy (5, 16, 0.3125)
2024-04-22 02:22:41 - INFO :       
==================Finish================

2024-04-22 02:22:41 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:22:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:22:41 - INFO :       DATASET: tasksource/bigbench hhh_alignment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]
2024-04-22 02:22:51 - INFO :       Use taylor pruner...
2024-04-22 02:22:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:22:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:22:52 - INFO :       Start Pruning
2024-04-22 02:22:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:22:54 - INFO :       Loss = 9.1875
2024-04-22 02:22:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:22:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:22:57 - INFO :       hhh_alignment: Total Sparsity 1.3558806551180476e-06
2024-04-22 02:23:36 - INFO :       hhh_alignment: Total Accuracy (28, 42, 0.6666666666666666)
2024-04-22 02:23:37 - INFO :       
==================Finish================

2024-04-22 02:23:37 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:23:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:23:37 - INFO :       DATASET: tasksource/bigbench hindu_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2024-04-22 02:23:46 - INFO :       Use taylor pruner...
2024-04-22 02:23:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:23:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:23:47 - INFO :       Start Pruning
2024-04-22 02:23:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:23:49 - INFO :       Loss = 13.40625
2024-04-22 02:23:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:23:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:23:52 - INFO :       hindu_knowledge: Total Sparsity 1.361449933715528e-06
2024-04-22 02:24:22 - INFO :       hindu_knowledge: Total Accuracy (21, 35, 0.6)
2024-04-22 02:24:23 - INFO :       
==================Finish================

2024-04-22 02:24:23 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:24:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:24:23 - INFO :       DATASET: tasksource/bigbench hinglish_toxicity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.43s/it]
2024-04-22 02:24:36 - INFO :       Use taylor pruner...
2024-04-22 02:24:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:24:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:24:36 - INFO :       Start Pruning
2024-04-22 02:24:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:24:39 - INFO :       Loss = 11.3984375
2024-04-22 02:24:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:24:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:24:42 - INFO :       hinglish_toxicity: Total Sparsity 1.3554032883811208e-06
2024-04-22 02:25:15 - INFO :       hinglish_toxicity: Total Accuracy (19, 40, 0.475)
2024-04-22 02:25:16 - INFO :       
==================Finish================

2024-04-22 02:25:16 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:25:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:25:16 - INFO :       DATASET: tasksource/bigbench human_organs_senses
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]
2024-04-22 02:25:25 - INFO :       Use taylor pruner...
2024-04-22 02:25:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:25:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:25:25 - INFO :       Start Pruning
2024-04-22 02:25:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:25:28 - INFO :       Loss = 14.3125
2024-04-22 02:25:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:25:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:25:32 - INFO :       human_organs_senses: Total Sparsity 1.3569945108375437e-06
2024-04-22 02:25:46 - INFO :       human_organs_senses: Total Accuracy (7, 16, 0.4375)
2024-04-22 02:25:46 - INFO :       
==================Finish================

2024-04-22 02:25:46 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:25:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:25:46 - INFO :       DATASET: tasksource/bigbench hyperbaton
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.98s/it]
2024-04-22 02:25:56 - INFO :       Use taylor pruner...
2024-04-22 02:25:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:25:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:25:56 - INFO :       Start Pruning
2024-04-22 02:25:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:25:59 - INFO :       Loss = 15.2109375
2024-04-22 02:26:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:26:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:26:02 - INFO :       hyperbaton: Total Sparsity 1.361449933715528e-06
2024-04-22 02:26:44 - INFO :       hyperbaton: Total Accuracy (22, 50, 0.44)
2024-04-22 02:26:44 - INFO :       
==================Finish================

2024-04-22 02:26:44 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:26:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:26:44 - INFO :       DATASET: tasksource/bigbench identify_math_theorems
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-22 02:26:53 - INFO :       Use taylor pruner...
2024-04-22 02:26:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:26:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:26:54 - INFO :       Start Pruning
2024-04-22 02:26:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:26:56 - INFO :       Loss = 1.474609375
2024-04-22 02:26:58 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:26:58 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:27:00 - INFO :       identify_math_theorems: Total Sparsity 1.3541303104159823e-06
2024-04-22 02:27:16 - INFO :       identify_math_theorems: Total Accuracy (7, 16, 0.4375)
2024-04-22 02:27:16 - INFO :       
==================Finish================

2024-04-22 02:27:16 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:27:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:27:16 - INFO :       DATASET: tasksource/bigbench identify_odd_metaphor
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2024-04-22 02:27:26 - INFO :       Use taylor pruner...
2024-04-22 02:27:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:27:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:27:26 - INFO :       Start Pruning
2024-04-22 02:27:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:27:28 - INFO :       Loss = 11.03125
2024-04-22 02:27:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:27:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:27:32 - INFO :       identify_odd_metaphor: Total Sparsity 1.355085043889836e-06
2024-04-22 02:27:45 - INFO :       identify_odd_metaphor: Total Accuracy (10, 16, 0.625)
2024-04-22 02:27:45 - INFO :       
==================Finish================

2024-04-22 02:27:45 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:27:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:27:45 - INFO :       DATASET: tasksource/bigbench implicatures
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]
2024-04-22 02:27:54 - INFO :       Use taylor pruner...
2024-04-22 02:27:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:27:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:27:55 - INFO :       Start Pruning
2024-04-22 02:27:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:27:57 - INFO :       Loss = 13.96875
2024-04-22 02:27:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:27:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:28:01 - INFO :       implicatures: Total Sparsity 1.358267488802682e-06
2024-04-22 02:28:46 - INFO :       implicatures: Total Accuracy (31, 50, 0.62)
2024-04-22 02:28:46 - INFO :       
==================Finish================

2024-04-22 02:28:46 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:28:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:28:46 - INFO :       DATASET: tasksource/bigbench implicit_relations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]
2024-04-22 02:28:56 - INFO :       Use taylor pruner...
2024-04-22 02:28:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:28:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:28:57 - INFO :       Start Pruning
2024-04-22 02:28:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:28:59 - INFO :       Loss = 6.234375
2024-04-22 02:29:00 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:29:00 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:29:02 - INFO :       implicit_relations: Total Sparsity 1.357153633083186e-06
2024-04-22 02:29:18 - INFO :       implicit_relations: Total Accuracy (4, 17, 0.23529411764705882)
2024-04-22 02:29:18 - INFO :       
==================Finish================

2024-04-22 02:29:18 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:29:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:29:18 - INFO :       DATASET: tasksource/bigbench indic_cause_and_effect
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]
2024-04-22 02:29:27 - INFO :       Use taylor pruner...
2024-04-22 02:29:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:29:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:29:27 - INFO :       Start Pruning
2024-04-22 02:29:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:29:29 - INFO :       Loss = 4.0859375
2024-04-22 02:29:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:29:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:29:33 - INFO :       indic_cause_and_effect: Total Sparsity 1.3542894326616245e-06
2024-04-22 02:30:19 - INFO :       indic_cause_and_effect: Total Accuracy (30, 50, 0.6)
2024-04-22 02:30:19 - INFO :       
==================Finish================

2024-04-22 02:30:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:30:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:30:19 - INFO :       DATASET: tasksource/bigbench intent_recognition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]
2024-04-22 02:30:28 - INFO :       Use taylor pruner...
2024-04-22 02:30:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:30:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:30:29 - INFO :       Start Pruning
2024-04-22 02:30:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:30:31 - INFO :       Loss = 10.328125
2024-04-22 02:30:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:30:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:30:35 - INFO :       intent_recognition: Total Sparsity 1.3573127553288283e-06
2024-04-22 02:31:18 - INFO :       intent_recognition: Total Accuracy (27, 50, 0.54)
2024-04-22 02:31:18 - INFO :       
==================Finish================

2024-04-22 02:31:18 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:31:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:31:18 - INFO :       DATASET: tasksource/bigbench international_phonetic_alphabet_nli
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.27s/it]
2024-04-22 02:31:29 - INFO :       Use taylor pruner...
2024-04-22 02:31:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:31:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:31:29 - INFO :       Start Pruning
2024-04-22 02:31:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:31:32 - INFO :       Loss = 8.359375
2024-04-22 02:31:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:31:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:31:36 - INFO :       international_phonetic_alphabet_nli: Total Sparsity 1.3577901220657553e-06
2024-04-22 02:31:57 - INFO :       international_phonetic_alphabet_nli: Total Accuracy (10, 25, 0.4)
2024-04-22 02:31:57 - INFO :       
==================Finish================

2024-04-22 02:31:57 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:31:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:31:57 - INFO :       DATASET: tasksource/bigbench intersect_geometry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.51s/it]
2024-04-22 02:32:07 - INFO :       Use taylor pruner...
2024-04-22 02:32:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:32:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:32:08 - INFO :       Start Pruning
2024-04-22 02:32:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:32:11 - INFO :       Loss = 3.75
2024-04-22 02:32:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:32:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:32:15 - INFO :       intersect_geometry: Total Sparsity 1.3536529436790554e-06
2024-04-22 02:33:03 - INFO :       intersect_geometry: Total Accuracy (1, 50, 0.02)
2024-04-22 02:33:03 - INFO :       
==================Finish================

2024-04-22 02:33:03 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:33:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:33:03 - INFO :       DATASET: tasksource/bigbench irony_identification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]
2024-04-22 02:33:11 - INFO :       Use taylor pruner...
2024-04-22 02:33:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:33:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:33:12 - INFO :       Start Pruning
2024-04-22 02:33:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:33:15 - INFO :       Loss = 13.6484375
2024-04-22 02:33:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:33:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:33:18 - INFO :       irony_identification: Total Sparsity 1.3595404667678207e-06
2024-04-22 02:33:34 - INFO :       irony_identification: Total Accuracy (11, 19, 0.5789473684210527)
2024-04-22 02:33:34 - INFO :       
==================Finish================

2024-04-22 02:33:34 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:33:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:33:34 - INFO :       DATASET: tasksource/bigbench kannada
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]
2024-04-22 02:33:44 - INFO :       Use taylor pruner...
2024-04-22 02:33:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:33:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:33:44 - INFO :       Start Pruning
2024-04-22 02:33:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:33:46 - INFO :       Loss = 6.3671875
2024-04-22 02:33:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:33:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:33:51 - INFO :       kannada: Total Sparsity 1.3549259216441938e-06
2024-04-22 02:34:41 - INFO :       kannada: Total Accuracy (12, 50, 0.24)
2024-04-22 02:34:42 - INFO :       
==================Finish================

2024-04-22 02:34:42 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:34:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:34:42 - INFO :       DATASET: tasksource/bigbench key_value_maps
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2024-04-22 02:34:53 - INFO :       Use taylor pruner...
2024-04-22 02:34:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:34:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:34:53 - INFO :       Start Pruning
2024-04-22 02:34:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:34:56 - INFO :       Loss = 6.6875
2024-04-22 02:34:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:34:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:34:59 - INFO :       key_value_maps: Total Sparsity 1.3552441661354783e-06
2024-04-22 02:35:18 - INFO :       key_value_maps: Total Accuracy (11, 21, 0.5238095238095238)
2024-04-22 02:35:19 - INFO :       
==================Finish================

2024-04-22 02:35:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:35:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:35:19 - INFO :       DATASET: tasksource/bigbench known_unknowns
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.67s/it]
2024-04-22 02:35:32 - INFO :       Use taylor pruner...
2024-04-22 02:35:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:35:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:35:33 - INFO :       Start Pruning
2024-04-22 02:35:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:35:35 - INFO :       Loss = 14.53125
2024-04-22 02:35:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:35:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:35:38 - INFO :       known_unknowns: Total Sparsity 1.3585857332939668e-06
2024-04-22 02:35:51 - INFO :       known_unknowns: Total Accuracy (7, 16, 0.4375)
2024-04-22 02:35:51 - INFO :       
==================Finish================

2024-04-22 02:35:51 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:35:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:35:51 - INFO :       DATASET: tasksource/bigbench language_identification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]
2024-04-22 02:36:02 - INFO :       Use taylor pruner...
2024-04-22 02:36:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:36:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:36:02 - INFO :       Start Pruning
2024-04-22 02:36:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:36:04 - INFO :       Loss = 7.546875
2024-04-22 02:36:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:36:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:36:08 - INFO :       language_identification: Total Sparsity 1.3514252322400633e-06
2024-04-22 02:36:52 - INFO :       language_identification: Total Accuracy (9, 50, 0.18)
2024-04-22 02:36:52 - INFO :       
==================Finish================

2024-04-22 02:36:52 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:36:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:36:52 - INFO :       DATASET: tasksource/bigbench logic_grid_puzzle
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
2024-04-22 02:37:02 - INFO :       Use taylor pruner...
2024-04-22 02:37:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:37:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:37:03 - INFO :       Start Pruning
2024-04-22 02:37:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:37:05 - INFO :       Loss = 6.60546875
2024-04-22 02:37:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:37:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:37:08 - INFO :       logic_grid_puzzle: Total Sparsity 1.3509478655031362e-06
2024-04-22 02:37:54 - INFO :       logic_grid_puzzle: Total Accuracy (15, 50, 0.3)
2024-04-22 02:37:54 - INFO :       
==================Finish================

2024-04-22 02:37:54 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:37:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:37:54 - INFO :       DATASET: tasksource/bigbench logical_args
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2024-04-22 02:38:04 - INFO :       Use taylor pruner...
2024-04-22 02:38:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:38:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:38:04 - INFO :       Start Pruning
2024-04-22 02:38:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:38:06 - INFO :       Loss = 8.2421875
2024-04-22 02:38:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:38:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:38:10 - INFO :       logical_args: Total Sparsity 1.3584266110483244e-06
2024-04-22 02:38:25 - INFO :       logical_args: Total Accuracy (8, 16, 0.5)
2024-04-22 02:38:25 - INFO :       
==================Finish================

2024-04-22 02:38:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:38:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:38:25 - INFO :       DATASET: tasksource/bigbench logical_deduction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-22 02:38:34 - INFO :       Use taylor pruner...
2024-04-22 02:38:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:38:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:38:35 - INFO :       Start Pruning
2024-04-22 02:38:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:38:38 - INFO :       Loss = 11.25
2024-04-22 02:38:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:38:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:38:41 - INFO :       logical_deduction: Total Sparsity 1.3616090559611704e-06
2024-04-22 02:39:29 - INFO :       logical_deduction: Total Accuracy (11, 50, 0.22)
2024-04-22 02:39:29 - INFO :       
==================Finish================

2024-04-22 02:39:29 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:39:29 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:39:29 - INFO :       DATASET: tasksource/bigbench logical_fallacy_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.56s/it]
2024-04-22 02:39:47 - INFO :       Use taylor pruner...
2024-04-22 02:39:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:39:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:39:47 - INFO :       Start Pruning
2024-04-22 02:39:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:39:50 - INFO :       Loss = 13.96875
2024-04-22 02:39:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:39:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:39:54 - INFO :       logical_fallacy_detection: Total Sparsity 1.3595404667678207e-06
2024-04-22 02:40:41 - INFO :       logical_fallacy_detection: Total Accuracy (34, 50, 0.68)
2024-04-22 02:40:41 - INFO :       
==================Finish================

2024-04-22 02:40:42 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:40:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:40:42 - INFO :       DATASET: tasksource/bigbench logical_sequence
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2024-04-22 02:40:51 - INFO :       Use taylor pruner...
2024-04-22 02:40:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:40:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:40:51 - INFO :       Start Pruning
2024-04-22 02:40:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:40:53 - INFO :       Loss = 11.125
2024-04-22 02:40:55 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:40:55 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:40:57 - INFO :       logical_sequence: Total Sparsity 1.3585857332939668e-06
2024-04-22 02:41:11 - INFO :       logical_sequence: Total Accuracy (4, 16, 0.25)
2024-04-22 02:41:11 - INFO :       
==================Finish================

2024-04-22 02:41:11 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:41:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:41:11 - INFO :       DATASET: tasksource/bigbench mathematical_induction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]
2024-04-22 02:41:22 - INFO :       Use taylor pruner...
2024-04-22 02:41:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:41:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:41:23 - INFO :       Start Pruning
2024-04-22 02:41:25 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:41:26 - INFO :       Loss = 13.234375
2024-04-22 02:41:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:41:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:41:29 - INFO :       mathematical_induction: Total Sparsity 1.3566762663462592e-06
2024-04-22 02:41:42 - INFO :       mathematical_induction: Total Accuracy (10, 16, 0.625)
2024-04-22 02:41:43 - INFO :       
==================Finish================

2024-04-22 02:41:43 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:41:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:41:43 - INFO :       DATASET: tasksource/bigbench medical_questions_russian
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]
2024-04-22 02:41:53 - INFO :       Use taylor pruner...
2024-04-22 02:41:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:41:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:41:54 - INFO :       Start Pruning
2024-04-22 02:41:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:41:56 - INFO :       Loss = 12.7421875
2024-04-22 02:41:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:41:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:41:59 - INFO :       medical_questions_russian: Total Sparsity 1.3541303104159823e-06
2024-04-22 02:42:44 - INFO :       medical_questions_russian: Total Accuracy (12, 50, 0.24)
2024-04-22 02:42:45 - INFO :       
==================Finish================

2024-04-22 02:42:45 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:42:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:42:45 - INFO :       DATASET: tasksource/bigbench metaphor_boolean
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
2024-04-22 02:42:54 - INFO :       Use taylor pruner...
2024-04-22 02:42:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:42:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:42:55 - INFO :       Start Pruning
2024-04-22 02:42:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:42:57 - INFO :       Loss = 13.3359375
2024-04-22 02:42:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:42:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:43:01 - INFO :       metaphor_boolean: Total Sparsity 1.3601769557503897e-06
2024-04-22 02:43:43 - INFO :       metaphor_boolean: Total Accuracy (18, 50, 0.36)
2024-04-22 02:43:44 - INFO :       
==================Finish================

2024-04-22 02:43:44 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:43:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:43:44 - INFO :       DATASET: tasksource/bigbench metaphor_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]
2024-04-22 02:43:54 - INFO :       Use taylor pruner...
2024-04-22 02:43:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:43:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:43:54 - INFO :       Start Pruning
2024-04-22 02:43:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:43:57 - INFO :       Loss = 9.921875
2024-04-22 02:43:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:43:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:44:01 - INFO :       metaphor_understanding: Total Sparsity 1.3566762663462592e-06
2024-04-22 02:44:42 - INFO :       metaphor_understanding: Total Accuracy (33, 46, 0.717391304347826)
2024-04-22 02:44:42 - INFO :       
==================Finish================

2024-04-22 02:44:42 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:44:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:44:42 - INFO :       DATASET: tasksource/bigbench misconceptions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.43s/it]
2024-04-22 02:44:53 - INFO :       Use taylor pruner...
2024-04-22 02:44:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:44:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:44:53 - INFO :       Start Pruning
2024-04-22 02:44:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:44:56 - INFO :       Loss = 14.4609375
2024-04-22 02:44:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:44:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:44:59 - INFO :       misconceptions: Total Sparsity 1.3595404667678207e-06
2024-04-22 02:45:36 - INFO :       misconceptions: Total Accuracy (20, 43, 0.46511627906976744)
2024-04-22 02:45:36 - INFO :       
==================Finish================

2024-04-22 02:45:36 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:45:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:45:36 - INFO :       DATASET: tasksource/bigbench mnist_ascii
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2024-04-22 02:45:45 - INFO :       Use taylor pruner...
2024-04-22 02:45:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:45:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:45:46 - INFO :       Start Pruning
2024-04-22 02:45:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:45:48 - INFO :       Loss = 5.421875
2024-04-22 02:45:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:45:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:45:51 - INFO :       mnist_ascii: Total Sparsity 1.355562410626763e-06
2024-04-22 02:47:13 - INFO :       mnist_ascii: Total Accuracy (6, 50, 0.12)
2024-04-22 02:47:14 - INFO :       
==================Finish================

2024-04-22 02:47:14 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:47:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:47:14 - INFO :       DATASET: tasksource/bigbench moral_permissibility
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2024-04-22 02:47:24 - INFO :       Use taylor pruner...
2024-04-22 02:47:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:47:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:47:25 - INFO :       Start Pruning
2024-04-22 02:47:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:47:27 - INFO :       Loss = 11.6328125
2024-04-22 02:47:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:47:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:47:32 - INFO :       moral_permissibility: Total Sparsity 1.35190259897699e-06
2024-04-22 02:48:16 - INFO :       moral_permissibility: Total Accuracy (26, 50, 0.52)
2024-04-22 02:48:16 - INFO :       
==================Finish================

2024-04-22 02:48:16 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:48:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:48:16 - INFO :       DATASET: tasksource/bigbench movie_dialog_same_or_different
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2024-04-22 02:48:26 - INFO :       Use taylor pruner...
2024-04-22 02:48:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:48:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:48:27 - INFO :       Start Pruning
2024-04-22 02:48:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:48:30 - INFO :       Loss = 12.28125
2024-04-22 02:48:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:48:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:48:33 - INFO :       movie_dialog_same_or_different: Total Sparsity 1.3566762663462592e-06
2024-04-22 02:49:18 - INFO :       movie_dialog_same_or_different: Total Accuracy (23, 50, 0.46)
2024-04-22 02:49:18 - INFO :       
==================Finish================

2024-04-22 02:49:18 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:49:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:49:18 - INFO :       DATASET: tasksource/bigbench movie_recommendation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2024-04-22 02:49:27 - INFO :       Use taylor pruner...
2024-04-22 02:49:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:49:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:49:28 - INFO :       Start Pruning
2024-04-22 02:49:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:49:30 - INFO :       Loss = 12.6171875
2024-04-22 02:49:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:49:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:49:33 - INFO :       movie_recommendation: Total Sparsity 1.3604952002416743e-06
2024-04-22 02:50:17 - INFO :       movie_recommendation: Total Accuracy (21, 50, 0.42)
2024-04-22 02:50:17 - INFO :       
==================Finish================

2024-04-22 02:50:17 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:50:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:50:17 - INFO :       DATASET: tasksource/bigbench navigate
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]
2024-04-22 02:50:26 - INFO :       Use taylor pruner...
2024-04-22 02:50:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:50:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:50:27 - INFO :       Start Pruning
2024-04-22 02:50:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:50:29 - INFO :       Loss = 14.6015625
2024-04-22 02:50:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:50:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:50:32 - INFO :       navigate: Total Sparsity 1.3577901220657553e-06
2024-04-22 02:51:16 - INFO :       navigate: Total Accuracy (29, 50, 0.58)
2024-04-22 02:51:17 - INFO :       
==================Finish================

2024-04-22 02:51:17 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:51:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:51:17 - INFO :       DATASET: tasksource/bigbench nonsense_words_grammar
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]
2024-04-22 02:51:28 - INFO :       Use taylor pruner...
2024-04-22 02:51:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:51:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:51:28 - INFO :       Start Pruning
2024-04-22 02:51:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:51:30 - INFO :       Loss = 13.9765625
2024-04-22 02:51:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:51:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:51:34 - INFO :       nonsense_words_grammar: Total Sparsity 1.3589039777852514e-06
2024-04-22 02:51:48 - INFO :       nonsense_words_grammar: Total Accuracy (9, 16, 0.5625)
2024-04-22 02:51:48 - INFO :       
==================Finish================

2024-04-22 02:51:48 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:51:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:51:48 - INFO :       DATASET: tasksource/bigbench novel_concepts
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2024-04-22 02:51:58 - INFO :       Use taylor pruner...
2024-04-22 02:51:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:51:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:51:58 - INFO :       Start Pruning
2024-04-22 02:52:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:52:01 - INFO :       Loss = 11.5390625
2024-04-22 02:52:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:52:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:52:05 - INFO :       novel_concepts: Total Sparsity 1.3593813445221782e-06
2024-04-22 02:52:19 - INFO :       novel_concepts: Total Accuracy (6, 16, 0.375)
2024-04-22 02:52:19 - INFO :       
==================Finish================

2024-04-22 02:52:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:52:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:52:19 - INFO :       DATASET: tasksource/bigbench odd_one_out
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]
2024-04-22 02:52:29 - INFO :       Use taylor pruner...
2024-04-22 02:52:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:52:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:52:30 - INFO :       Start Pruning
2024-04-22 02:52:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:52:32 - INFO :       Loss = 13.8828125
2024-04-22 02:52:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:52:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:52:35 - INFO :       odd_one_out: Total Sparsity 1.3590631000308936e-06
2024-04-22 02:52:49 - INFO :       odd_one_out: Total Accuracy (1, 17, 0.058823529411764705)
2024-04-22 02:52:49 - INFO :       
==================Finish================

2024-04-22 02:52:49 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:52:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:52:49 - INFO :       DATASET: tasksource/bigbench parsinlu_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]
2024-04-22 02:52:59 - INFO :       Use taylor pruner...
2024-04-22 02:52:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:52:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:52:59 - INFO :       Start Pruning
2024-04-22 02:53:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:53:02 - INFO :       Loss = 7.73828125
2024-04-22 02:53:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:53:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:53:05 - INFO :       parsinlu_qa: Total Sparsity 1.3566762663462592e-06
2024-04-22 02:53:49 - INFO :       parsinlu_qa: Total Accuracy (14, 50, 0.28)
2024-04-22 02:53:49 - INFO :       
==================Finish================

2024-04-22 02:53:49 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:53:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:53:49 - INFO :       DATASET: tasksource/bigbench penguins_in_a_table
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]
2024-04-22 02:53:58 - INFO :       Use taylor pruner...
2024-04-22 02:53:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:53:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:53:59 - INFO :       Start Pruning
2024-04-22 02:54:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:54:01 - INFO :       Loss = 8.2421875
2024-04-22 02:54:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:54:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:54:05 - INFO :       penguins_in_a_table: Total Sparsity 1.3522208434682746e-06
2024-04-22 02:54:31 - INFO :       penguins_in_a_table: Total Accuracy (8, 29, 0.27586206896551724)
2024-04-22 02:54:31 - INFO :       
==================Finish================

2024-04-22 02:54:31 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:54:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:54:31 - INFO :       DATASET: tasksource/bigbench persian_idioms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2024-04-22 02:54:40 - INFO :       Use taylor pruner...
2024-04-22 02:54:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:54:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:54:40 - INFO :       Start Pruning
2024-04-22 02:54:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:54:43 - INFO :       Loss = 11.28125
2024-04-22 02:54:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:54:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:54:47 - INFO :       persian_idioms: Total Sparsity 1.35603977736369e-06
2024-04-22 02:55:00 - INFO :       persian_idioms: Total Accuracy (5, 16, 0.3125)
2024-04-22 02:55:01 - INFO :       
==================Finish================

2024-04-22 02:55:01 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:55:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:55:01 - INFO :       DATASET: tasksource/bigbench phrase_relatedness
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2024-04-22 02:55:11 - INFO :       Use taylor pruner...
2024-04-22 02:55:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:55:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:55:11 - INFO :       Start Pruning
2024-04-22 02:55:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:55:14 - INFO :       Loss = 13.3046875
2024-04-22 02:55:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:55:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:55:18 - INFO :       phrase_relatedness: Total Sparsity 1.3606543224873167e-06
2024-04-22 02:55:36 - INFO :       phrase_relatedness: Total Accuracy (10, 20, 0.5)
2024-04-22 02:55:36 - INFO :       
==================Finish================

2024-04-22 02:55:36 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:55:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:55:36 - INFO :       DATASET: tasksource/bigbench physical_intuition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2024-04-22 02:55:45 - INFO :       Use taylor pruner...
2024-04-22 02:55:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:55:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:55:46 - INFO :       Start Pruning
2024-04-22 02:55:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:55:49 - INFO :       Loss = 13.390625
2024-04-22 02:55:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:55:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:55:52 - INFO :       physical_intuition: Total Sparsity 1.360336077996032e-06
2024-04-22 02:56:06 - INFO :       physical_intuition: Total Accuracy (5, 16, 0.3125)
2024-04-22 02:56:07 - INFO :       
==================Finish================

2024-04-22 02:56:07 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:56:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:56:07 - INFO :       DATASET: tasksource/bigbench physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2024-04-22 02:56:17 - INFO :       Use taylor pruner...
2024-04-22 02:56:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:56:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:56:17 - INFO :       Start Pruning
2024-04-22 02:56:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:56:21 - INFO :       Loss = 9.3671875
2024-04-22 02:56:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:56:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:56:25 - INFO :       physics: Total Sparsity 1.3589039777852514e-06
2024-04-22 02:57:05 - INFO :       physics: Total Accuracy (41, 45, 0.9111111111111111)
2024-04-22 02:57:05 - INFO :       
==================Finish================

2024-04-22 02:57:05 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:57:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:57:05 - INFO :       DATASET: tasksource/bigbench play_dialog_same_or_different
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]
2024-04-22 02:57:15 - INFO :       Use taylor pruner...
2024-04-22 02:57:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:57:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:57:15 - INFO :       Start Pruning
2024-04-22 02:57:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:57:18 - INFO :       Loss = 9.5234375
2024-04-22 02:57:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:57:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:57:21 - INFO :       play_dialog_same_or_different: Total Sparsity 1.3546076771529093e-06
2024-04-22 02:58:08 - INFO :       play_dialog_same_or_different: Total Accuracy (16, 50, 0.32)
2024-04-22 02:58:08 - INFO :       
==================Finish================

2024-04-22 02:58:08 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:58:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:58:08 - INFO :       DATASET: tasksource/bigbench presuppositions_as_nli
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2024-04-22 02:58:17 - INFO :       Use taylor pruner...
2024-04-22 02:58:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:58:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:58:18 - INFO :       Start Pruning
2024-04-22 02:58:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:58:21 - INFO :       Loss = 10.7734375
2024-04-22 02:58:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:58:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:58:24 - INFO :       presuppositions_as_nli: Total Sparsity 1.3561988996093322e-06
2024-04-22 02:59:08 - INFO :       presuppositions_as_nli: Total Accuracy (14, 50, 0.28)
2024-04-22 02:59:08 - INFO :       
==================Finish================

2024-04-22 02:59:08 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 02:59:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 02:59:08 - INFO :       DATASET: tasksource/bigbench question_selection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2024-04-22 02:59:17 - INFO :       Use taylor pruner...
2024-04-22 02:59:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:59:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 02:59:18 - INFO :       Start Pruning
2024-04-22 02:59:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 02:59:20 - INFO :       Loss = 5.28125
2024-04-22 02:59:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 02:59:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 02:59:24 - INFO :       question_selection: Total Sparsity 1.3547667993985515e-06
2024-04-22 03:00:14 - INFO :       question_selection: Total Accuracy (32, 50, 0.64)
2024-04-22 03:00:15 - INFO :       
==================Finish================

2024-04-22 03:00:15 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:00:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:00:15 - INFO :       DATASET: tasksource/bigbench reasoning_about_colored_objects
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-22 03:00:24 - INFO :       Use taylor pruner...
2024-04-22 03:00:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:00:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:00:24 - INFO :       Start Pruning
2024-04-22 03:00:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:00:27 - INFO :       Loss = 7.640625
2024-04-22 03:00:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:00:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:00:31 - INFO :       reasoning_about_colored_objects: Total Sparsity 1.3585857332939668e-06
2024-04-22 03:01:16 - INFO :       reasoning_about_colored_objects: Total Accuracy (13, 50, 0.26)
2024-04-22 03:01:16 - INFO :       
==================Finish================

2024-04-22 03:01:16 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:01:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:01:16 - INFO :       DATASET: tasksource/bigbench riddle_sense
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]
2024-04-22 03:01:25 - INFO :       Use taylor pruner...
2024-04-22 03:01:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:01:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:01:26 - INFO :       Start Pruning
2024-04-22 03:01:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:01:29 - INFO :       Loss = 13.3515625
2024-04-22 03:01:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:01:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:01:32 - INFO :       riddle_sense: Total Sparsity 1.3612908114698858e-06
2024-04-22 03:01:46 - INFO :       riddle_sense: Total Accuracy (2, 16, 0.125)
2024-04-22 03:01:47 - INFO :       
==================Finish================

2024-04-22 03:01:47 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:01:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:01:47 - INFO :       DATASET: tasksource/bigbench ruin_names
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-22 03:01:56 - INFO :       Use taylor pruner...
2024-04-22 03:01:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:01:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:01:57 - INFO :       Start Pruning
2024-04-22 03:01:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:01:59 - INFO :       Loss = 12.75
2024-04-22 03:02:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:02:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:02:02 - INFO :       ruin_names: Total Sparsity 1.356517144100617e-06
2024-04-22 03:02:47 - INFO :       ruin_names: Total Accuracy (7, 50, 0.14)
2024-04-22 03:02:47 - INFO :       
==================Finish================

2024-04-22 03:02:47 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:02:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:02:47 - INFO :       DATASET: tasksource/bigbench salient_translation_error_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2024-04-22 03:02:56 - INFO :       Use taylor pruner...
2024-04-22 03:02:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:02:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:02:57 - INFO :       Start Pruning
2024-04-22 03:02:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:02:59 - INFO :       Loss = 7.24609375
2024-04-22 03:03:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:03:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:03:03 - INFO :       salient_translation_error_detection: Total Sparsity 1.3554032883811208e-06
2024-04-22 03:03:49 - INFO :       salient_translation_error_detection: Total Accuracy (11, 50, 0.22)
2024-04-22 03:03:50 - INFO :       
==================Finish================

2024-04-22 03:03:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:03:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:03:50 - INFO :       DATASET: tasksource/bigbench sentence_ambiguity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.21s/it]
2024-04-22 03:04:01 - INFO :       Use taylor pruner...
2024-04-22 03:04:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:04:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:04:01 - INFO :       Start Pruning
2024-04-22 03:04:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:04:03 - INFO :       Loss = 14.3828125
2024-04-22 03:04:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:04:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:04:07 - INFO :       sentence_ambiguity: Total Sparsity 1.3601769557503897e-06
2024-04-22 03:04:21 - INFO :       sentence_ambiguity: Total Accuracy (9, 16, 0.5625)
2024-04-22 03:04:21 - INFO :       
==================Finish================

2024-04-22 03:04:21 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:04:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:04:21 - INFO :       DATASET: tasksource/bigbench similarities_abstraction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.91s/it]
2024-04-22 03:04:30 - INFO :       Use taylor pruner...
2024-04-22 03:04:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:04:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:04:30 - INFO :       Start Pruning
2024-04-22 03:04:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:04:33 - INFO :       Loss = 13.4375
2024-04-22 03:04:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:04:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:04:37 - INFO :       similarities_abstraction: Total Sparsity 1.362404667189382e-06
2024-04-22 03:04:51 - INFO :       similarities_abstraction: Total Accuracy (10, 16, 0.625)
2024-04-22 03:04:51 - INFO :       
==================Finish================

2024-04-22 03:04:51 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:04:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:04:51 - INFO :       DATASET: tasksource/bigbench simple_ethical_questions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2024-04-22 03:05:00 - INFO :       Use taylor pruner...
2024-04-22 03:05:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:05:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:05:01 - INFO :       Start Pruning
2024-04-22 03:05:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:05:03 - INFO :       Loss = 10.703125
2024-04-22 03:05:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:05:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:05:07 - INFO :       simple_ethical_questions: Total Sparsity 1.3549259216441938e-06
2024-04-22 03:05:28 - INFO :       simple_ethical_questions: Total Accuracy (18, 23, 0.782608695652174)
2024-04-22 03:05:28 - INFO :       
==================Finish================

2024-04-22 03:05:28 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:05:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:05:28 - INFO :       DATASET: tasksource/bigbench snarks
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]
2024-04-22 03:05:37 - INFO :       Use taylor pruner...
2024-04-22 03:05:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:05:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:05:37 - INFO :       Start Pruning
2024-04-22 03:05:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:05:40 - INFO :       Loss = 14.1015625
2024-04-22 03:05:42 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:05:42 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:05:43 - INFO :       snarks: Total Sparsity 1.3566762663462592e-06
2024-04-22 03:06:15 - INFO :       snarks: Total Accuracy (12, 36, 0.3333333333333333)
2024-04-22 03:06:16 - INFO :       
==================Finish================

2024-04-22 03:06:16 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:06:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:06:16 - INFO :       DATASET: tasksource/bigbench social_iqa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
2024-04-22 03:06:27 - INFO :       Use taylor pruner...
2024-04-22 03:06:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:06:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:06:27 - INFO :       Start Pruning
2024-04-22 03:06:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:06:30 - INFO :       Loss = 13.8125
2024-04-22 03:06:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:06:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:06:33 - INFO :       social_iqa: Total Sparsity 1.358267488802682e-06
2024-04-22 03:07:16 - INFO :       social_iqa: Total Accuracy (22, 50, 0.44)
2024-04-22 03:07:16 - INFO :       
==================Finish================

2024-04-22 03:07:16 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:07:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:07:16 - INFO :       DATASET: tasksource/bigbench social_support
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-22 03:07:28 - INFO :       Use taylor pruner...
2024-04-22 03:07:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:07:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:07:29 - INFO :       Start Pruning
2024-04-22 03:07:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:07:35 - INFO :       Loss = 10.578125
2024-04-22 03:07:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:07:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:07:39 - INFO :       social_support: Total Sparsity 1.3546076771529093e-06
2024-04-22 03:08:23 - INFO :       social_support: Total Accuracy (24, 50, 0.48)
2024-04-22 03:08:24 - INFO :       
==================Finish================

2024-04-22 03:08:24 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:08:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:08:24 - INFO :       DATASET: tasksource/bigbench sports_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2024-04-22 03:08:33 - INFO :       Use taylor pruner...
2024-04-22 03:08:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:08:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:08:33 - INFO :       Start Pruning
2024-04-22 03:08:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:08:36 - INFO :       Loss = 14.6953125
2024-04-22 03:08:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:08:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:08:39 - INFO :       sports_understanding: Total Sparsity 1.3569945108375437e-06
2024-04-22 03:09:22 - INFO :       sports_understanding: Total Accuracy (29, 50, 0.58)
2024-04-22 03:09:22 - INFO :       
==================Finish================

2024-04-22 03:09:22 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:09:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:09:22 - INFO :       DATASET: tasksource/bigbench strange_stories
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]
2024-04-22 03:09:32 - INFO :       Use taylor pruner...
2024-04-22 03:09:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:09:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:09:33 - INFO :       Start Pruning
2024-04-22 03:09:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:09:35 - INFO :       Loss = 10.1640625
2024-04-22 03:09:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:09:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:09:38 - INFO :       strange_stories: Total Sparsity 1.3558806551180476e-06
2024-04-22 03:10:09 - INFO :       strange_stories: Total Accuracy (16, 34, 0.47058823529411764)
2024-04-22 03:10:09 - INFO :       
==================Finish================

2024-04-22 03:10:09 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:10:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:10:09 - INFO :       DATASET: tasksource/bigbench strategyqa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]
2024-04-22 03:10:19 - INFO :       Use taylor pruner...
2024-04-22 03:10:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:10:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:10:19 - INFO :       Start Pruning
2024-04-22 03:10:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:10:22 - INFO :       Loss = 14.4375
2024-04-22 03:10:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:10:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:10:25 - INFO :       strategyqa: Total Sparsity 1.358267488802682e-06
2024-04-22 03:11:08 - INFO :       strategyqa: Total Accuracy (29, 50, 0.58)
2024-04-22 03:11:08 - INFO :       
==================Finish================

2024-04-22 03:11:08 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:11:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:11:08 - INFO :       DATASET: tasksource/bigbench suicide_risk
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]
2024-04-22 03:11:18 - INFO :       Use taylor pruner...
2024-04-22 03:11:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:11:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:11:18 - INFO :       Start Pruning
2024-04-22 03:11:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:11:21 - INFO :       Loss = 9.78125
2024-04-22 03:11:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:11:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:11:24 - INFO :       suicide_risk: Total Sparsity 1.3579492443113975e-06
2024-04-22 03:11:38 - INFO :       suicide_risk: Total Accuracy (3, 16, 0.1875)
2024-04-22 03:11:38 - INFO :       
==================Finish================

2024-04-22 03:11:38 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:11:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:11:38 - INFO :       DATASET: tasksource/bigbench swahili_english_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.21s/it]
2024-04-22 03:11:49 - INFO :       Use taylor pruner...
2024-04-22 03:11:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:11:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:11:49 - INFO :       Start Pruning
2024-04-22 03:11:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:11:51 - INFO :       Loss = 10.7109375
2024-04-22 03:11:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:11:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:11:55 - INFO :       swahili_english_proverbs: Total Sparsity 1.357630999820113e-06
2024-04-22 03:12:21 - INFO :       swahili_english_proverbs: Total Accuracy (14, 30, 0.4666666666666667)
2024-04-22 03:12:21 - INFO :       
==================Finish================

2024-04-22 03:12:21 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:12:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:12:21 - INFO :       DATASET: tasksource/bigbench swedish_to_german_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]
2024-04-22 03:12:30 - INFO :       Use taylor pruner...
2024-04-22 03:12:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:12:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:12:31 - INFO :       Start Pruning
2024-04-22 03:12:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:12:33 - INFO :       Loss = 11.328125
2024-04-22 03:12:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:12:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:12:37 - INFO :       swedish_to_german_proverbs: Total Sparsity 1.358744855539609e-06
2024-04-22 03:12:51 - INFO :       swedish_to_german_proverbs: Total Accuracy (7, 16, 0.4375)
2024-04-22 03:12:51 - INFO :       
==================Finish================

2024-04-22 03:12:51 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:12:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:12:51 - INFO :       DATASET: tasksource/bigbench symbol_interpretation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2024-04-22 03:13:02 - INFO :       Use taylor pruner...
2024-04-22 03:13:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:13:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:13:02 - INFO :       Start Pruning
2024-04-22 03:13:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:13:04 - INFO :       Loss = 5.609375
2024-04-22 03:13:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:13:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:13:08 - INFO :       symbol_interpretation: Total Sparsity 1.3581083665570398e-06
2024-04-22 03:14:15 - INFO :       symbol_interpretation: Total Accuracy (16, 50, 0.32)
2024-04-22 03:14:16 - INFO :       
==================Finish================

2024-04-22 03:14:16 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:14:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:14:16 - INFO :       DATASET: tasksource/bigbench temporal_sequences
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.67s/it]
2024-04-22 03:14:28 - INFO :       Use taylor pruner...
2024-04-22 03:14:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:14:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:14:29 - INFO :       Start Pruning
2024-04-22 03:14:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:14:31 - INFO :       Loss = 8.359375
2024-04-22 03:14:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:14:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:14:35 - INFO :       temporal_sequences: Total Sparsity 1.359699589013463e-06
2024-04-22 03:15:19 - INFO :       temporal_sequences: Total Accuracy (14, 50, 0.28)
2024-04-22 03:15:19 - INFO :       
==================Finish================

2024-04-22 03:15:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:15:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:15:19 - INFO :       DATASET: tasksource/bigbench timedial
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]
2024-04-22 03:15:30 - INFO :       Use taylor pruner...
2024-04-22 03:15:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:15:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:15:30 - INFO :       Start Pruning
2024-04-22 03:15:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:15:32 - INFO :       Loss = 9.0234375
2024-04-22 03:15:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:15:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:15:36 - INFO :       timedial: Total Sparsity 1.3558806551180476e-06
2024-04-22 03:16:25 - INFO :       timedial: Total Accuracy (11, 50, 0.22)
2024-04-22 03:16:25 - INFO :       
==================Finish================

2024-04-22 03:16:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:16:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:16:25 - INFO :       DATASET: tasksource/bigbench tracking_shuffled_objects
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.60s/it]
2024-04-22 03:16:36 - INFO :       Use taylor pruner...
2024-04-22 03:16:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:16:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:16:37 - INFO :       Start Pruning
2024-04-22 03:16:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:16:39 - INFO :       Loss = 8.203125
2024-04-22 03:16:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:16:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:16:42 - INFO :       tracking_shuffled_objects: Total Sparsity 1.355562410626763e-06
2024-04-22 03:17:26 - INFO :       tracking_shuffled_objects: Total Accuracy (6, 50, 0.12)
2024-04-22 03:17:26 - INFO :       
==================Finish================

2024-04-22 03:17:26 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:17:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:17:26 - INFO :       DATASET: tasksource/bigbench understanding_fables
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.21s/it]
2024-04-22 03:17:37 - INFO :       Use taylor pruner...
2024-04-22 03:17:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:17:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:17:38 - INFO :       Start Pruning
2024-04-22 03:17:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:17:40 - INFO :       Loss = 6.98046875
2024-04-22 03:17:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:17:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:17:43 - INFO :       understanding_fables: Total Sparsity 1.3557215328724054e-06
2024-04-22 03:18:17 - INFO :       understanding_fables: Total Accuracy (13, 37, 0.35135135135135137)
2024-04-22 03:18:17 - INFO :       
==================Finish================

2024-04-22 03:18:17 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:18:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:18:17 - INFO :       DATASET: tasksource/bigbench undo_permutation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]
2024-04-22 03:18:26 - INFO :       Use taylor pruner...
2024-04-22 03:18:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:18:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:18:27 - INFO :       Start Pruning
2024-04-22 03:18:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:18:29 - INFO :       Loss = 7.81640625
2024-04-22 03:18:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:18:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:18:33 - INFO :       undo_permutation: Total Sparsity 1.356517144100617e-06
2024-04-22 03:19:18 - INFO :       undo_permutation: Total Accuracy (25, 50, 0.5)
2024-04-22 03:19:19 - INFO :       
==================Finish================

2024-04-22 03:19:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:19:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:19:19 - INFO :       DATASET: tasksource/bigbench unit_interpretation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]
2024-04-22 03:19:29 - INFO :       Use taylor pruner...
2024-04-22 03:19:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:19:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:19:30 - INFO :       Start Pruning
2024-04-22 03:19:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:19:32 - INFO :       Loss = 10.9140625
2024-04-22 03:19:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:19:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:19:36 - INFO :       unit_interpretation: Total Sparsity 1.3606543224873167e-06
2024-04-22 03:19:53 - INFO :       unit_interpretation: Total Accuracy (6, 20, 0.3)
2024-04-22 03:19:53 - INFO :       
==================Finish================

2024-04-22 03:19:53 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:19:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:19:53 - INFO :       DATASET: tasksource/bigbench vitaminc_fact_verification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]
2024-04-22 03:20:03 - INFO :       Use taylor pruner...
2024-04-22 03:20:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:20:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:20:03 - INFO :       Start Pruning
2024-04-22 03:20:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:20:06 - INFO :       Loss = 11.9453125
2024-04-22 03:20:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:20:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:20:09 - INFO :       vitaminc_fact_verification: Total Sparsity 1.3566762663462592e-06
2024-04-22 03:20:52 - INFO :       vitaminc_fact_verification: Total Accuracy (16, 50, 0.32)
2024-04-22 03:20:53 - INFO :       
==================Finish================

2024-04-22 03:20:53 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:20:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:20:53 - INFO :       DATASET: tasksource/bigbench what_is_the_tao
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]
2024-04-22 03:21:04 - INFO :       Use taylor pruner...
2024-04-22 03:21:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:21:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:21:04 - INFO :       Start Pruning
2024-04-22 03:21:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:21:07 - INFO :       Loss = 12.6328125
2024-04-22 03:21:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:21:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:21:10 - INFO :       what_is_the_tao: Total Sparsity 1.358267488802682e-06
2024-04-22 03:21:24 - INFO :       what_is_the_tao: Total Accuracy (5, 16, 0.3125)
2024-04-22 03:21:24 - INFO :       
==================Finish================

2024-04-22 03:21:24 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 03:21:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:21:24 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]
2024-04-22 03:21:35 - INFO :       Use taylor pruner...
2024-04-22 03:21:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:21:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:21:35 - INFO :       Start Pruning
Token indices sequence length is longer than the specified maximum sequence length for this model (5287 > 4096). Running this sequence through the model will result in indexing errors
2024-04-22 03:21:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:21:37 - INFO :       Loss = 1.60546875
2024-04-22 03:21:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:21:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:21:41 - INFO :       which_wiki_edit: Total Sparsity 1.3504704987662094e-06
2024-04-22 03:23:22 - INFO :       which_wiki_edit: Total Accuracy (25, 50, 0.5)
2024-04-22 03:23:22 - INFO :       
==================Finish================

2024-04-22 03:23:22 - INFO :       Memory Requirement: 16809.46826171875 MiB

2024-04-22 03:23:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:23:22 - INFO :       DATASET: tasksource/bigbench winowhy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2024-04-22 03:23:31 - INFO :       Use taylor pruner...
2024-04-22 03:23:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:23:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:23:32 - INFO :       Start Pruning
2024-04-22 03:23:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:23:34 - INFO :       Loss = 14.078125
2024-04-22 03:23:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:23:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:23:38 - INFO :       winowhy: Total Sparsity 1.3600178335047475e-06
2024-04-22 03:24:19 - INFO :       winowhy: Total Accuracy (25, 50, 0.5)
2024-04-22 03:24:21 - INFO :       
==================Finish================

2024-04-22 03:24:21 - INFO :       Memory Requirement: 16777.79052734375 MiB

2024-04-22 03:24:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:24:21 - INFO :       DATASET: tasksource/mmlu abstract_algebra
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.96s/it]
2024-04-22 03:24:32 - INFO :       Use taylor pruner...
2024-04-22 03:24:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:24:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:24:32 - INFO :       Start Pruning
2024-04-22 03:24:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:24:34 - INFO :       Loss = 13.875
2024-04-22 03:24:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:24:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:24:38 - INFO :       abstract_algebra: Total Sparsity 1.3558806551180476e-06
2024-04-22 03:24:48 - INFO :       abstract_algebra: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-22 03:24:48 - INFO :       
==================Finish================

2024-04-22 03:24:48 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:24:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:24:48 - INFO :       DATASET: tasksource/mmlu anatomy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2024-04-22 03:25:01 - INFO :       Use taylor pruner...
2024-04-22 03:25:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:25:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:25:02 - INFO :       Start Pruning
2024-04-22 03:25:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:25:04 - INFO :       Loss = 13.8359375
2024-04-22 03:25:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:25:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:25:07 - INFO :       anatomy: Total Sparsity 1.3590631000308936e-06
2024-04-22 03:25:19 - INFO :       anatomy: Total Accuracy (8, 14, 0.5714285714285714)
2024-04-22 03:25:19 - INFO :       
==================Finish================

2024-04-22 03:25:19 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:25:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:25:19 - INFO :       DATASET: tasksource/mmlu astronomy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2024-04-22 03:25:29 - INFO :       Use taylor pruner...
2024-04-22 03:25:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:25:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:25:30 - INFO :       Start Pruning
2024-04-22 03:25:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:25:32 - INFO :       Loss = 12.8046875
2024-04-22 03:25:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:25:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:25:35 - INFO :       astronomy: Total Sparsity 1.3561988996093322e-06
2024-04-22 03:25:49 - INFO :       astronomy: Total Accuracy (4, 16, 0.25)
2024-04-22 03:25:49 - INFO :       
==================Finish================

2024-04-22 03:25:49 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:25:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:25:49 - INFO :       DATASET: tasksource/mmlu business_ethics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]
2024-04-22 03:26:01 - INFO :       Use taylor pruner...
2024-04-22 03:26:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:26:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:26:01 - INFO :       Start Pruning
2024-04-22 03:26:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:26:03 - INFO :       Loss = 13.3515625
2024-04-22 03:26:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:26:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:26:07 - INFO :       business_ethics: Total Sparsity 1.3585857332939668e-06
2024-04-22 03:26:17 - INFO :       business_ethics: Total Accuracy (6, 11, 0.5454545454545454)
2024-04-22 03:26:17 - INFO :       
==================Finish================

2024-04-22 03:26:17 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:26:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:26:17 - INFO :       DATASET: tasksource/mmlu clinical_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2024-04-22 03:26:26 - INFO :       Use taylor pruner...
2024-04-22 03:26:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:26:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:26:27 - INFO :       Start Pruning
2024-04-22 03:26:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:26:29 - INFO :       Loss = 14.296875
2024-04-22 03:26:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:26:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:26:32 - INFO :       clinical_knowledge: Total Sparsity 1.3627229116806667e-06
2024-04-22 03:26:57 - INFO :       clinical_knowledge: Total Accuracy (13, 29, 0.4482758620689655)
2024-04-22 03:26:57 - INFO :       
==================Finish================

2024-04-22 03:26:57 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:26:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:26:57 - INFO :       DATASET: tasksource/mmlu college_biology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]
2024-04-22 03:27:09 - INFO :       Use taylor pruner...
2024-04-22 03:27:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:27:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:27:10 - INFO :       Start Pruning
2024-04-22 03:27:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:27:12 - INFO :       Loss = 12.03125
2024-04-22 03:27:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:27:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:27:15 - INFO :       college_biology: Total Sparsity 1.3616090559611704e-06
2024-04-22 03:27:29 - INFO :       college_biology: Total Accuracy (8, 16, 0.5)
2024-04-22 03:27:29 - INFO :       
==================Finish================

2024-04-22 03:27:29 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:27:29 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:27:29 - INFO :       DATASET: tasksource/mmlu college_chemistry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2024-04-22 03:27:39 - INFO :       Use taylor pruner...
2024-04-22 03:27:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:27:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:27:39 - INFO :       Start Pruning
num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-22 03:27:40 - WARNING :       num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-22 03:27:40 - WARNING :       num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-22 03:27:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:27:41 - INFO :       Loss = 13.5859375
2024-04-22 03:27:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:27:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:27:44 - INFO :       college_chemistry: Total Sparsity 1.3531755769421284e-06
2024-04-22 03:27:51 - INFO :       college_chemistry: Total Accuracy (2, 8, 0.25)
2024-04-22 03:27:51 - INFO :       
==================Finish================

2024-04-22 03:27:51 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:27:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:27:51 - INFO :       DATASET: tasksource/mmlu college_computer_science
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]
2024-04-22 03:28:01 - INFO :       Use taylor pruner...
2024-04-22 03:28:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:28:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:28:02 - INFO :       Start Pruning
2024-04-22 03:28:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:28:03 - INFO :       Loss = 12.0390625
2024-04-22 03:28:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:28:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:28:07 - INFO :       college_computer_science: Total Sparsity 1.3600178335047475e-06
2024-04-22 03:28:17 - INFO :       college_computer_science: Total Accuracy (2, 11, 0.18181818181818182)
2024-04-22 03:28:17 - INFO :       
==================Finish================

2024-04-22 03:28:17 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:28:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:28:17 - INFO :       DATASET: tasksource/mmlu college_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]
2024-04-22 03:28:27 - INFO :       Use taylor pruner...
2024-04-22 03:28:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:28:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:28:27 - INFO :       Start Pruning
2024-04-22 03:28:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:28:29 - INFO :       Loss = 13.34375
2024-04-22 03:28:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:28:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:28:33 - INFO :       college_mathematics: Total Sparsity 1.3563580218549744e-06
2024-04-22 03:28:42 - INFO :       college_mathematics: Total Accuracy (2, 11, 0.18181818181818182)
2024-04-22 03:28:42 - INFO :       
==================Finish================

2024-04-22 03:28:42 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:28:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:28:42 - INFO :       DATASET: tasksource/mmlu college_medicine
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2024-04-22 03:28:52 - INFO :       Use taylor pruner...
2024-04-22 03:28:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:28:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:28:52 - INFO :       Start Pruning
2024-04-22 03:28:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:28:54 - INFO :       Loss = 13.859375
2024-04-22 03:28:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:28:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:28:57 - INFO :       college_medicine: Total Sparsity 1.35603977736369e-06
2024-04-22 03:29:17 - INFO :       college_medicine: Total Accuracy (8, 22, 0.36363636363636365)
2024-04-22 03:29:17 - INFO :       
==================Finish================

2024-04-22 03:29:17 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:29:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:29:17 - INFO :       DATASET: tasksource/mmlu college_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  3.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2024-04-22 03:29:28 - INFO :       Use taylor pruner...
2024-04-22 03:29:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:29:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:29:28 - INFO :       Start Pruning
2024-04-22 03:29:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:29:31 - INFO :       Loss = 12.8671875
2024-04-22 03:29:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:29:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:29:34 - INFO :       college_physics: Total Sparsity 1.360336077996032e-06
2024-04-22 03:29:43 - INFO :       college_physics: Total Accuracy (4, 11, 0.36363636363636365)
2024-04-22 03:29:43 - INFO :       
==================Finish================

2024-04-22 03:29:43 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:29:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:29:43 - INFO :       DATASET: tasksource/mmlu computer_security
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]
2024-04-22 03:29:53 - INFO :       Use taylor pruner...
2024-04-22 03:29:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:29:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:29:53 - INFO :       Start Pruning
/home/bhandk/miniconda3/envs/MLNeuron/lib/python3.9/site-packages/datasets/load.py:1429: FutureWarning: The repository for tasksource/mmlu contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/tasksource/mmlu
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
2024-04-22 03:30:12 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:30:13 - INFO :       Loss = 14.1796875
2024-04-22 03:30:15 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:30:15 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:30:17 - INFO :       computer_security: Total Sparsity 1.3595404667678207e-06
2024-04-22 03:30:27 - INFO :       computer_security: Total Accuracy (5, 11, 0.45454545454545453)
2024-04-22 03:30:27 - INFO :       
==================Finish================

2024-04-22 03:30:27 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:30:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:30:27 - INFO :       DATASET: tasksource/mmlu conceptual_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.06s/it]
2024-04-22 03:30:38 - INFO :       Use taylor pruner...
2024-04-22 03:30:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:30:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:30:38 - INFO :       Start Pruning
2024-04-22 03:30:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:30:40 - INFO :       Loss = 14.4609375
2024-04-22 03:30:42 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:30:42 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:30:44 - INFO :       conceptual_physics: Total Sparsity 1.3577901220657553e-06
2024-04-22 03:31:07 - INFO :       conceptual_physics: Total Accuracy (7, 26, 0.2692307692307692)
2024-04-22 03:31:07 - INFO :       
==================Finish================

2024-04-22 03:31:07 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:31:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:31:07 - INFO :       DATASET: tasksource/mmlu econometrics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-22 03:31:16 - INFO :       Use taylor pruner...
2024-04-22 03:31:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:31:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:31:17 - INFO :       Start Pruning
2024-04-22 03:31:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:31:19 - INFO :       Loss = 11.421875
2024-04-22 03:31:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:31:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:31:22 - INFO :       econometrics: Total Sparsity 1.3568353885919015e-06
2024-04-22 03:31:33 - INFO :       econometrics: Total Accuracy (2, 12, 0.16666666666666666)
2024-04-22 03:31:33 - INFO :       
==================Finish================

2024-04-22 03:31:33 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:31:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:31:33 - INFO :       DATASET: tasksource/mmlu electrical_engineering
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]
2024-04-22 03:31:43 - INFO :       Use taylor pruner...
2024-04-22 03:31:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:31:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:31:44 - INFO :       Start Pruning
2024-04-22 03:31:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:31:46 - INFO :       Loss = 14.75
2024-04-22 03:31:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:31:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:31:49 - INFO :       electrical_engineering: Total Sparsity 1.3566762663462592e-06
2024-04-22 03:32:04 - INFO :       electrical_engineering: Total Accuracy (5, 16, 0.3125)
2024-04-22 03:32:04 - INFO :       
==================Finish================

2024-04-22 03:32:04 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:32:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:32:04 - INFO :       DATASET: tasksource/mmlu elementary_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]
2024-04-22 03:32:14 - INFO :       Use taylor pruner...
2024-04-22 03:32:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:32:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:32:15 - INFO :       Start Pruning
2024-04-22 03:32:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:32:17 - INFO :       Loss = 13.5703125
2024-04-22 03:32:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:32:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:32:20 - INFO :       elementary_mathematics: Total Sparsity 1.3554032883811208e-06
2024-04-22 03:32:57 - INFO :       elementary_mathematics: Total Accuracy (9, 41, 0.21951219512195122)
2024-04-22 03:32:57 - INFO :       
==================Finish================

2024-04-22 03:32:57 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:32:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:32:57 - INFO :       DATASET: tasksource/mmlu formal_logic
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.23s/it]
2024-04-22 03:33:07 - INFO :       Use taylor pruner...
2024-04-22 03:33:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:33:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:33:08 - INFO :       Start Pruning
2024-04-22 03:33:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:33:10 - INFO :       Loss = 11.9453125
2024-04-22 03:33:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:33:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:33:13 - INFO :       formal_logic: Total Sparsity 1.3604952002416743e-06
2024-04-22 03:33:26 - INFO :       formal_logic: Total Accuracy (1, 14, 0.07142857142857142)
2024-04-22 03:33:26 - INFO :       
==================Finish================

2024-04-22 03:33:26 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:33:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:33:26 - INFO :       DATASET: tasksource/mmlu global_facts
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]
2024-04-22 03:33:35 - INFO :       Use taylor pruner...
2024-04-22 03:33:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:33:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:33:36 - INFO :       Start Pruning
2024-04-22 03:33:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:33:38 - INFO :       Loss = 14.1953125
2024-04-22 03:33:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:33:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:33:41 - INFO :       global_facts: Total Sparsity 1.357630999820113e-06
2024-04-22 03:33:50 - INFO :       global_facts: Total Accuracy (2, 10, 0.2)
2024-04-22 03:33:50 - INFO :       
==================Finish================

2024-04-22 03:33:50 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:33:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:33:50 - INFO :       DATASET: tasksource/mmlu high_school_biology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
2024-04-22 03:34:00 - INFO :       Use taylor pruner...
2024-04-22 03:34:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:34:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:34:00 - INFO :       Start Pruning
2024-04-22 03:34:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:34:02 - INFO :       Loss = 13.8671875
2024-04-22 03:34:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:34:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:34:06 - INFO :       high_school_biology: Total Sparsity 1.3593813445221782e-06
2024-04-22 03:34:34 - INFO :       high_school_biology: Total Accuracy (11, 32, 0.34375)
2024-04-22 03:34:34 - INFO :       
==================Finish================

2024-04-22 03:34:34 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:34:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:34:34 - INFO :       DATASET: tasksource/mmlu high_school_chemistry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-22 03:34:44 - INFO :       Use taylor pruner...
2024-04-22 03:34:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:34:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:34:45 - INFO :       Start Pruning
2024-04-22 03:35:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:35:06 - INFO :       Loss = 12.9296875
2024-04-22 03:35:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:35:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:35:09 - INFO :       high_school_chemistry: Total Sparsity 1.3593813445221782e-06
2024-04-22 03:35:29 - INFO :       high_school_chemistry: Total Accuracy (3, 22, 0.13636363636363635)
2024-04-22 03:35:29 - INFO :       
==================Finish================

2024-04-22 03:35:29 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:35:29 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:35:29 - INFO :       DATASET: tasksource/mmlu high_school_computer_science
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]
2024-04-22 03:35:39 - INFO :       Use taylor pruner...
2024-04-22 03:35:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:35:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:35:40 - INFO :       Start Pruning
num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-22 03:35:41 - WARNING :       num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-22 03:35:41 - WARNING :       num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-22 03:35:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:35:42 - INFO :       Loss = 13.671875
2024-04-22 03:35:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:35:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:35:45 - INFO :       high_school_computer_science: Total Sparsity 1.3622455449437396e-06
2024-04-22 03:35:54 - INFO :       high_school_computer_science: Total Accuracy (5, 9, 0.5555555555555556)
2024-04-22 03:35:55 - INFO :       
==================Finish================

2024-04-22 03:35:55 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:35:55 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:35:55 - INFO :       DATASET: tasksource/mmlu high_school_european_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]
2024-04-22 03:36:04 - INFO :       Use taylor pruner...
2024-04-22 03:36:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:36:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:36:04 - INFO :       Start Pruning
2024-04-22 03:36:07 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:36:08 - INFO :       Loss = 6.48046875
2024-04-22 03:36:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:36:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:36:11 - INFO :       high_school_european_history: Total Sparsity 1.3522208434682746e-06
2024-04-22 03:36:29 - INFO :       high_school_european_history: Total Accuracy (11, 18, 0.6111111111111112)
2024-04-22 03:36:29 - INFO :       
==================Finish================

2024-04-22 03:36:29 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:36:29 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:36:29 - INFO :       DATASET: tasksource/mmlu high_school_geography
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]
2024-04-22 03:36:39 - INFO :       Use taylor pruner...
2024-04-22 03:36:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:36:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:36:40 - INFO :       Start Pruning
2024-04-22 03:36:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:36:43 - INFO :       Loss = 14.2265625
2024-04-22 03:36:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:36:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:36:46 - INFO :       high_school_geography: Total Sparsity 1.3563580218549744e-06
2024-04-22 03:37:06 - INFO :       high_school_geography: Total Accuracy (15, 22, 0.6818181818181818)
2024-04-22 03:37:06 - INFO :       
==================Finish================

2024-04-22 03:37:06 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:37:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:37:06 - INFO :       DATASET: tasksource/mmlu high_school_government_and_politics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]
2024-04-22 03:37:16 - INFO :       Use taylor pruner...
2024-04-22 03:37:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:37:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:37:16 - INFO :       Start Pruning
2024-04-22 03:37:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:37:20 - INFO :       Loss = 13.875
2024-04-22 03:37:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:37:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:37:23 - INFO :       high_school_government_and_politics: Total Sparsity 1.3568353885919015e-06
2024-04-22 03:37:42 - INFO :       high_school_government_and_politics: Total Accuracy (8, 21, 0.38095238095238093)
2024-04-22 03:37:42 - INFO :       
==================Finish================

2024-04-22 03:37:42 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:37:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:37:42 - INFO :       DATASET: tasksource/mmlu high_school_macroeconomics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.62s/it]
2024-04-22 03:37:52 - INFO :       Use taylor pruner...
2024-04-22 03:37:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:37:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:37:52 - INFO :       Start Pruning
2024-04-22 03:37:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:37:54 - INFO :       Loss = 13.859375
2024-04-22 03:37:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:37:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:37:57 - INFO :       high_school_macroeconomics: Total Sparsity 1.358267488802682e-06
2024-04-22 03:38:36 - INFO :       high_school_macroeconomics: Total Accuracy (14, 43, 0.32558139534883723)
2024-04-22 03:38:36 - INFO :       
==================Finish================

2024-04-22 03:38:36 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:38:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:38:36 - INFO :       DATASET: tasksource/mmlu high_school_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]
2024-04-22 03:38:47 - INFO :       Use taylor pruner...
2024-04-22 03:38:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:38:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:38:48 - INFO :       Start Pruning
2024-04-22 03:38:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:38:50 - INFO :       Loss = 13.3359375
2024-04-22 03:38:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:38:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:38:53 - INFO :       high_school_mathematics: Total Sparsity 1.3584266110483244e-06
2024-04-22 03:39:20 - INFO :       high_school_mathematics: Total Accuracy (6, 29, 0.20689655172413793)
2024-04-22 03:39:20 - INFO :       
==================Finish================

2024-04-22 03:39:20 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:39:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:39:20 - INFO :       DATASET: tasksource/mmlu high_school_microeconomics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.26s/it]
2024-04-22 03:39:30 - INFO :       Use taylor pruner...
2024-04-22 03:39:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:39:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:39:31 - INFO :       Start Pruning
2024-04-22 03:39:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:39:33 - INFO :       Loss = 12.90625
2024-04-22 03:39:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:39:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:39:36 - INFO :       high_school_microeconomics: Total Sparsity 1.358744855539609e-06
2024-04-22 03:39:59 - INFO :       high_school_microeconomics: Total Accuracy (9, 26, 0.34615384615384615)
2024-04-22 03:39:59 - INFO :       
==================Finish================

2024-04-22 03:39:59 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:39:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:39:59 - INFO :       DATASET: tasksource/mmlu high_school_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.10s/it]
2024-04-22 03:40:12 - INFO :       Use taylor pruner...
2024-04-22 03:40:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:40:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:40:13 - INFO :       Start Pruning
2024-04-22 03:40:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:40:15 - INFO :       Loss = 11.5703125
2024-04-22 03:40:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:40:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:40:19 - INFO :       high_school_physics: Total Sparsity 1.3536529436790554e-06
2024-04-22 03:40:34 - INFO :       high_school_physics: Total Accuracy (6, 17, 0.35294117647058826)
2024-04-22 03:40:34 - INFO :       
==================Finish================

2024-04-22 03:40:34 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:40:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:40:34 - INFO :       DATASET: tasksource/mmlu high_school_psychology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]
2024-04-22 03:40:44 - INFO :       Use taylor pruner...
2024-04-22 03:40:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:40:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:40:44 - INFO :       Start Pruning
2024-04-22 03:40:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:40:46 - INFO :       Loss = 14.34375
2024-04-22 03:40:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:40:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:40:50 - INFO :       high_school_psychology: Total Sparsity 1.3595404667678207e-06
2024-04-22 03:41:34 - INFO :       high_school_psychology: Total Accuracy (33, 50, 0.66)
2024-04-22 03:41:34 - INFO :       
==================Finish================

2024-04-22 03:41:34 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:41:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:41:34 - INFO :       DATASET: tasksource/mmlu high_school_statistics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.34s/it]
2024-04-22 03:41:46 - INFO :       Use taylor pruner...
2024-04-22 03:41:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:41:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:41:47 - INFO :       Start Pruning
2024-04-22 03:41:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:41:49 - INFO :       Loss = 13.9296875
2024-04-22 03:41:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:41:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:41:52 - INFO :       high_school_statistics: Total Sparsity 1.3633594006632357e-06
2024-04-22 03:42:13 - INFO :       high_school_statistics: Total Accuracy (7, 23, 0.30434782608695654)
2024-04-22 03:42:13 - INFO :       
==================Finish================

2024-04-22 03:42:13 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:42:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:42:13 - INFO :       DATASET: tasksource/mmlu high_school_us_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]
2024-04-22 03:42:23 - INFO :       Use taylor pruner...
2024-04-22 03:42:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:42:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:42:24 - INFO :       Start Pruning
2024-04-22 03:42:25 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:42:26 - INFO :       Loss = 5.109375
2024-04-22 03:42:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:42:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:42:29 - INFO :       high_school_us_history: Total Sparsity 1.3585857332939668e-06
2024-04-22 03:42:50 - INFO :       high_school_us_history: Total Accuracy (13, 22, 0.5909090909090909)
2024-04-22 03:42:50 - INFO :       
==================Finish================

2024-04-22 03:42:50 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:42:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:42:50 - INFO :       DATASET: tasksource/mmlu high_school_world_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2024-04-22 03:43:02 - INFO :       Use taylor pruner...
2024-04-22 03:43:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:43:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:43:03 - INFO :       Start Pruning
2024-04-22 03:43:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:43:05 - INFO :       Loss = 5.01953125
2024-04-22 03:43:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:43:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:43:09 - INFO :       high_school_world_history: Total Sparsity 1.3554032883811208e-06
2024-04-22 03:43:34 - INFO :       high_school_world_history: Total Accuracy (12, 26, 0.46153846153846156)
2024-04-22 03:43:35 - INFO :       
==================Finish================

2024-04-22 03:43:35 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:43:35 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:43:35 - INFO :       DATASET: tasksource/mmlu human_aging
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]
2024-04-22 03:43:45 - INFO :       Use taylor pruner...
2024-04-22 03:43:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:43:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:43:46 - INFO :       Start Pruning
2024-04-22 03:43:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:43:48 - INFO :       Loss = 13.671875
2024-04-22 03:43:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:43:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:43:51 - INFO :       human_aging: Total Sparsity 1.359699589013463e-06
2024-04-22 03:44:10 - INFO :       human_aging: Total Accuracy (10, 23, 0.43478260869565216)
2024-04-22 03:44:10 - INFO :       
==================Finish================

2024-04-22 03:44:10 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:44:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:44:10 - INFO :       DATASET: tasksource/mmlu human_sexuality
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]
2024-04-22 03:44:20 - INFO :       Use taylor pruner...
2024-04-22 03:44:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:44:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:44:21 - INFO :       Start Pruning
2024-04-22 03:44:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:44:23 - INFO :       Loss = 13.4765625
2024-04-22 03:44:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:44:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:44:27 - INFO :       human_sexuality: Total Sparsity 1.358744855539609e-06
2024-04-22 03:44:37 - INFO :       human_sexuality: Total Accuracy (4, 12, 0.3333333333333333)
2024-04-22 03:44:37 - INFO :       
==================Finish================

2024-04-22 03:44:37 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:44:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:44:37 - INFO :       DATASET: tasksource/mmlu international_law
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2024-04-22 03:44:48 - INFO :       Use taylor pruner...
2024-04-22 03:44:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:44:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:44:48 - INFO :       Start Pruning
2024-04-22 03:44:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:44:50 - INFO :       Loss = 13.0
2024-04-22 03:44:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:44:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:44:54 - INFO :       international_law: Total Sparsity 1.3561988996093322e-06
2024-04-22 03:45:06 - INFO :       international_law: Total Accuracy (11, 13, 0.8461538461538461)
2024-04-22 03:45:06 - INFO :       
==================Finish================

2024-04-22 03:45:06 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:45:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:45:06 - INFO :       DATASET: tasksource/mmlu jurisprudence
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2024-04-22 03:45:16 - INFO :       Use taylor pruner...
2024-04-22 03:45:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:45:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:45:16 - INFO :       Start Pruning
2024-04-22 03:45:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:45:18 - INFO :       Loss = 12.859375
2024-04-22 03:45:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:45:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:45:22 - INFO :       jurisprudence: Total Sparsity 1.3547667993985515e-06
2024-04-22 03:45:32 - INFO :       jurisprudence: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-22 03:45:32 - INFO :       
==================Finish================

2024-04-22 03:45:32 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:45:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:45:32 - INFO :       DATASET: tasksource/mmlu logical_fallacies
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2024-04-22 03:45:41 - INFO :       Use taylor pruner...
2024-04-22 03:45:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:45:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:45:42 - INFO :       Start Pruning
2024-04-22 03:45:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:45:44 - INFO :       Loss = 14.4296875
2024-04-22 03:45:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:45:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:45:47 - INFO :       logical_fallacies: Total Sparsity 1.3590631000308936e-06
2024-04-22 03:46:03 - INFO :       logical_fallacies: Total Accuracy (11, 18, 0.6111111111111112)
2024-04-22 03:46:03 - INFO :       
==================Finish================

2024-04-22 03:46:03 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:46:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:46:03 - INFO :       DATASET: tasksource/mmlu machine_learning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]
2024-04-22 03:46:15 - INFO :       Use taylor pruner...
2024-04-22 03:46:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:46:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:46:16 - INFO :       Start Pruning
2024-04-22 03:46:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:46:18 - INFO :       Loss = 12.03125
2024-04-22 03:46:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:46:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:46:22 - INFO :       machine_learning: Total Sparsity 1.3558806551180476e-06
2024-04-22 03:46:32 - INFO :       machine_learning: Total Accuracy (4, 11, 0.36363636363636365)
2024-04-22 03:46:32 - INFO :       
==================Finish================

2024-04-22 03:46:32 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:46:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:46:32 - INFO :       DATASET: tasksource/mmlu management
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2024-04-22 03:46:43 - INFO :       Use taylor pruner...
2024-04-22 03:46:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:46:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:46:43 - INFO :       Start Pruning
2024-04-22 03:46:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:46:48 - INFO :       Loss = 14.0390625
2024-04-22 03:46:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:46:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:46:51 - INFO :       management: Total Sparsity 1.360336077996032e-06
2024-04-22 03:47:01 - INFO :       management: Total Accuracy (8, 11, 0.7272727272727273)
2024-04-22 03:47:01 - INFO :       
==================Finish================

2024-04-22 03:47:01 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:47:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:47:01 - INFO :       DATASET: tasksource/mmlu marketing
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-22 03:47:11 - INFO :       Use taylor pruner...
2024-04-22 03:47:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:47:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:47:12 - INFO :       Start Pruning
2024-04-22 03:47:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:47:15 - INFO :       Loss = 14.0703125
2024-04-22 03:47:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:47:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:47:18 - INFO :       marketing: Total Sparsity 1.3584266110483244e-06
2024-04-22 03:47:40 - INFO :       marketing: Total Accuracy (18, 25, 0.72)
2024-04-22 03:47:40 - INFO :       
==================Finish================

2024-04-22 03:47:40 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:47:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:47:40 - INFO :       DATASET: tasksource/mmlu medical_genetics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2024-04-22 03:47:50 - INFO :       Use taylor pruner...
2024-04-22 03:47:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:47:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:47:51 - INFO :       Start Pruning
2024-04-22 03:47:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:47:52 - INFO :       Loss = 13.765625
2024-04-22 03:47:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:47:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:47:56 - INFO :       medical_genetics: Total Sparsity 1.3568353885919015e-06
2024-04-22 03:48:06 - INFO :       medical_genetics: Total Accuracy (9, 11, 0.8181818181818182)
2024-04-22 03:48:06 - INFO :       
==================Finish================

2024-04-22 03:48:06 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:48:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:48:06 - INFO :       DATASET: tasksource/mmlu miscellaneous
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2024-04-22 03:48:17 - INFO :       Use taylor pruner...
2024-04-22 03:48:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:48:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:48:17 - INFO :       Start Pruning
2024-04-22 03:48:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:48:19 - INFO :       Loss = 12.7578125
2024-04-22 03:48:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:48:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:48:23 - INFO :       miscellaneous: Total Sparsity 1.357153633083186e-06
2024-04-22 03:49:07 - INFO :       miscellaneous: Total Accuracy (29, 50, 0.58)
2024-04-22 03:49:07 - INFO :       
==================Finish================

2024-04-22 03:49:07 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:49:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:49:07 - INFO :       DATASET: tasksource/mmlu moral_disputes
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.20s/it]
2024-04-22 03:49:19 - INFO :       Use taylor pruner...
2024-04-22 03:49:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:49:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:49:19 - INFO :       Start Pruning
2024-04-22 03:49:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:49:21 - INFO :       Loss = 13.03125
2024-04-22 03:49:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:49:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:49:24 - INFO :       moral_disputes: Total Sparsity 1.359699589013463e-06
2024-04-22 03:49:58 - INFO :       moral_disputes: Total Accuracy (19, 38, 0.5)
2024-04-22 03:49:58 - INFO :       
==================Finish================

2024-04-22 03:49:58 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:49:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:49:58 - INFO :       DATASET: tasksource/mmlu moral_scenarios
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-22 03:50:08 - INFO :       Use taylor pruner...
2024-04-22 03:50:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:50:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:50:09 - INFO :       Start Pruning
2024-04-22 03:50:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:50:11 - INFO :       Loss = 12.671875
2024-04-22 03:50:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:50:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:50:14 - INFO :       moral_scenarios: Total Sparsity 1.360336077996032e-06
2024-04-22 03:50:59 - INFO :       moral_scenarios: Total Accuracy (0, 50, 0.0)
2024-04-22 03:50:59 - INFO :       
==================Finish================

2024-04-22 03:50:59 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:50:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:50:59 - INFO :       DATASET: tasksource/mmlu nutrition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2024-04-22 03:51:09 - INFO :       Use taylor pruner...
2024-04-22 03:51:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:51:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:51:10 - INFO :       Start Pruning
2024-04-22 03:51:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:51:12 - INFO :       Loss = 14.0390625
2024-04-22 03:51:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:51:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:51:15 - INFO :       nutrition: Total Sparsity 1.358267488802682e-06
2024-04-22 03:51:45 - INFO :       nutrition: Total Accuracy (17, 33, 0.5151515151515151)
2024-04-22 03:51:45 - INFO :       
==================Finish================

2024-04-22 03:51:45 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:51:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:51:45 - INFO :       DATASET: tasksource/mmlu philosophy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2024-04-22 03:51:54 - INFO :       Use taylor pruner...
2024-04-22 03:51:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:51:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:51:55 - INFO :       Start Pruning
2024-04-22 03:51:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:51:57 - INFO :       Loss = 12.8125
2024-04-22 03:51:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:51:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:52:01 - INFO :       philosophy: Total Sparsity 1.3568353885919015e-06
2024-04-22 03:52:30 - INFO :       philosophy: Total Accuracy (15, 34, 0.4411764705882353)
2024-04-22 03:52:30 - INFO :       
==================Finish================

2024-04-22 03:52:30 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:52:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:52:30 - INFO :       DATASET: tasksource/mmlu prehistory
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.98s/it]
2024-04-22 03:52:42 - INFO :       Use taylor pruner...
2024-04-22 03:52:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:52:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:52:42 - INFO :       Start Pruning
2024-04-22 03:53:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:53:04 - INFO :       Loss = 13.984375
2024-04-22 03:53:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:53:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:53:07 - INFO :       prehistory: Total Sparsity 1.3595404667678207e-06
2024-04-22 03:53:39 - INFO :       prehistory: Total Accuracy (17, 35, 0.4857142857142857)
2024-04-22 03:53:39 - INFO :       
==================Finish================

2024-04-22 03:53:39 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:53:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:53:39 - INFO :       DATASET: tasksource/mmlu professional_accounting
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2024-04-22 03:53:49 - INFO :       Use taylor pruner...
2024-04-22 03:53:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:53:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:53:49 - INFO :       Start Pruning
2024-04-22 03:53:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:53:52 - INFO :       Loss = 12.40625
2024-04-22 03:53:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:53:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:53:56 - INFO :       professional_accounting: Total Sparsity 1.3590631000308936e-06
2024-04-22 03:54:24 - INFO :       professional_accounting: Total Accuracy (11, 31, 0.3548387096774194)
2024-04-22 03:54:24 - INFO :       
==================Finish================

2024-04-22 03:54:24 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:54:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:54:24 - INFO :       DATASET: tasksource/mmlu professional_law
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.65s/it]
2024-04-22 03:54:37 - INFO :       Use taylor pruner...
2024-04-22 03:54:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:54:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:54:38 - INFO :       Start Pruning
2024-04-22 03:54:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:54:41 - INFO :       Loss = 9.65625
2024-04-22 03:54:42 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:54:42 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:54:44 - INFO :       professional_law: Total Sparsity 1.3574718775744707e-06
2024-04-22 03:55:32 - INFO :       professional_law: Total Accuracy (13, 50, 0.26)
2024-04-22 03:55:32 - INFO :       
==================Finish================

2024-04-22 03:55:32 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:55:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:55:32 - INFO :       DATASET: tasksource/mmlu professional_medicine
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]
2024-04-22 03:55:42 - INFO :       Use taylor pruner...
2024-04-22 03:55:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:55:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:55:42 - INFO :       Start Pruning
2024-04-22 03:55:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:55:45 - INFO :       Loss = 10.640625
2024-04-22 03:55:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:55:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:55:48 - INFO :       professional_medicine: Total Sparsity 1.3577901220657553e-06
2024-04-22 03:56:17 - INFO :       professional_medicine: Total Accuracy (14, 31, 0.45161290322580644)
2024-04-22 03:56:17 - INFO :       
==================Finish================

2024-04-22 03:56:17 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:56:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:56:17 - INFO :       DATASET: tasksource/mmlu professional_psychology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
2024-04-22 03:56:30 - INFO :       Use taylor pruner...
2024-04-22 03:56:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:56:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:56:31 - INFO :       Start Pruning
2024-04-22 03:56:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:56:33 - INFO :       Loss = 13.5
2024-04-22 03:56:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:56:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:56:37 - INFO :       professional_psychology: Total Sparsity 1.3601769557503897e-06
2024-04-22 03:57:21 - INFO :       professional_psychology: Total Accuracy (21, 50, 0.42)
2024-04-22 03:57:21 - INFO :       
==================Finish================

2024-04-22 03:57:21 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:57:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:57:21 - INFO :       DATASET: tasksource/mmlu public_relations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.47s/it]
2024-04-22 03:57:34 - INFO :       Use taylor pruner...
2024-04-22 03:57:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:57:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:57:35 - INFO :       Start Pruning
2024-04-22 03:57:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:57:38 - INFO :       Loss = 14.1015625
2024-04-22 03:57:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:57:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:57:42 - INFO :       public_relations: Total Sparsity 1.357630999820113e-06
2024-04-22 03:57:52 - INFO :       public_relations: Total Accuracy (8, 12, 0.6666666666666666)
2024-04-22 03:57:52 - INFO :       
==================Finish================

2024-04-22 03:57:52 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:57:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:57:52 - INFO :       DATASET: tasksource/mmlu security_studies
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.93s/it]
2024-04-22 03:58:04 - INFO :       Use taylor pruner...
2024-04-22 03:58:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:58:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:58:04 - INFO :       Start Pruning
2024-04-22 03:58:07 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:58:09 - INFO :       Loss = 11.953125
2024-04-22 03:58:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:58:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:58:12 - INFO :       security_studies: Total Sparsity 1.357153633083186e-06
2024-04-22 03:58:39 - INFO :       security_studies: Total Accuracy (11, 27, 0.4074074074074074)
2024-04-22 03:58:40 - INFO :       
==================Finish================

2024-04-22 03:58:40 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:58:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:58:40 - INFO :       DATASET: tasksource/mmlu sociology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-22 03:58:48 - INFO :       Use taylor pruner...
2024-04-22 03:58:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:58:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:58:49 - INFO :       Start Pruning
2024-04-22 03:58:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:58:51 - INFO :       Loss = 13.796875
2024-04-22 03:58:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:58:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:58:54 - INFO :       sociology: Total Sparsity 1.3557215328724054e-06
2024-04-22 03:59:14 - INFO :       sociology: Total Accuracy (15, 22, 0.6818181818181818)
2024-04-22 03:59:14 - INFO :       
==================Finish================

2024-04-22 03:59:14 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:59:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:59:14 - INFO :       DATASET: tasksource/mmlu us_foreign_policy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2024-04-22 03:59:24 - INFO :       Use taylor pruner...
2024-04-22 03:59:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:59:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:59:25 - INFO :       Start Pruning
2024-04-22 03:59:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:59:27 - INFO :       Loss = 13.65625
2024-04-22 03:59:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:59:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:59:30 - INFO :       us_foreign_policy: Total Sparsity 1.357153633083186e-06
2024-04-22 03:59:40 - INFO :       us_foreign_policy: Total Accuracy (5, 11, 0.45454545454545453)
2024-04-22 03:59:40 - INFO :       
==================Finish================

2024-04-22 03:59:40 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 03:59:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 03:59:40 - INFO :       DATASET: tasksource/mmlu virology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.77s/it]
2024-04-22 03:59:53 - INFO :       Use taylor pruner...
2024-04-22 03:59:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:59:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 03:59:53 - INFO :       Start Pruning
2024-04-22 03:59:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 03:59:56 - INFO :       Loss = 14.2734375
2024-04-22 03:59:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 03:59:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 03:59:59 - INFO :       virology: Total Sparsity 1.3601769557503897e-06
2024-04-22 04:00:15 - INFO :       virology: Total Accuracy (7, 18, 0.3888888888888889)
2024-04-22 04:00:16 - INFO :       
==================Finish================

2024-04-22 04:00:16 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 04:00:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:00:16 - INFO :       DATASET: tasksource/mmlu world_religions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2024-04-22 04:00:26 - INFO :       Use taylor pruner...
2024-04-22 04:00:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:00:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:00:26 - INFO :       Start Pruning
2024-04-22 04:00:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:00:28 - INFO :       Loss = 14.1484375
2024-04-22 04:00:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:00:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:00:32 - INFO :       world_religions: Total Sparsity 1.3595404667678207e-06
2024-04-22 04:00:48 - INFO :       world_religions: Total Accuracy (12, 19, 0.631578947368421)
2024-04-22 04:00:48 - INFO :       
==================Finish================

2024-04-22 04:00:48 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 04:00:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:00:48 - INFO :       DATASET: math_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]
2024-04-22 04:00:59 - INFO :       Use taylor pruner...
2024-04-22 04:00:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:00:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:00:59 - INFO :       Start Pruning
2024-04-22 04:01:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:01:01 - INFO :       Loss = 13.1171875
2024-04-22 04:01:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:01:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:01:05 - INFO :       math_qa: Total Sparsity 1.3577901220657553e-06
2024-04-22 04:01:45 - INFO :       math_qa: Accuracy (11, 50, 0.22)
2024-04-22 04:01:45 - INFO :       
==================Finish================

2024-04-22 04:01:45 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 04:01:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:01:45 - INFO :       DATASET: EleutherAI/truthful_qa_mc
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2024-04-22 04:01:56 - INFO :       Use taylor pruner...
2024-04-22 04:01:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:01:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:01:57 - INFO :       Start Pruning
2024-04-22 04:02:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:02:01 - INFO :       Loss = 13.4609375
2024-04-22 04:02:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:02:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:02:04 - INFO :       truthful_qa_mc: Total Sparsity 1.3611316892242436e-06
2024-04-22 04:02:42 - INFO :       truthful_qa_mc: Accuracy (18, 50, 0.36)
2024-04-22 04:02:42 - INFO :       
==================Finish================

2024-04-22 04:02:42 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 04:02:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:02:42 - INFO :       DATASET: derek-thomas/ScienceQA
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-22 04:02:52 - INFO :       Use taylor pruner...
2024-04-22 04:02:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:02:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:02:53 - INFO :       Start Pruning
2024-04-22 04:02:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:02:57 - INFO :       Loss = 14.328125
2024-04-22 04:02:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:02:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:03:01 - INFO :       ScienceQA: Total Sparsity 1.3581083665570398e-06
2024-04-22 04:03:39 - INFO :       ScienceQA: Accuracy (22, 50, 0.44)
2024-04-22 04:03:39 - INFO :       
==================Finish================

2024-04-22 04:03:39 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 04:03:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:03:39 - INFO :       DATASET: commonsense_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2024-04-22 04:03:49 - INFO :       Use taylor pruner...
2024-04-22 04:03:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:03:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:03:50 - INFO :       Start Pruning
2024-04-22 04:03:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:03:54 - INFO :       Loss = 14.2421875
2024-04-22 04:03:55 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:03:55 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:03:57 - INFO :       commonsense_qa: Total Sparsity 1.3609725669786013e-06
2024-04-22 04:04:36 - INFO :       commonsense_qa: Accuracy (24, 50, 0.48)
2024-04-22 04:04:36 - INFO :       
==================Finish================

2024-04-22 04:04:36 - INFO :       Memory Requirement: 16770.79052734375 MiB

End: Memory Requirement: 3979.2666015625 MiB

Begin: Memory Requirement: 3979.2666015625 MiB

2024-04-22 04:04:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:04:36 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Index 2
Sparsity 3.5000000000000004 %
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]
2024-04-22 04:04:46 - INFO :       Use taylor pruner...
2024-04-22 04:04:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:04:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:04:46 - INFO :       Start Pruning
Token indices sequence length is longer than the specified maximum sequence length for this model (8689 > 4096). Running this sequence through the model will result in indexing errors
2024-04-22 04:04:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:04:49 - INFO :       Loss = 2.390625
2024-04-22 04:04:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:04:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:04:52 - INFO :       which_wiki_edit: Total Sparsity 1.3542894326616245e-06
2024-04-22 04:06:33 - INFO :       which_wiki_edit: Total Accuracy (30, 50, 0.6)
2024-04-22 04:06:33 - INFO :       
==================Finish================

2024-04-22 04:06:33 - INFO :       Memory Requirement: 16849.60302734375 MiB

2024-04-22 04:06:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:06:33 - INFO :       DATASET: tasksource/bigbench abstract_narrative_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2024-04-22 04:06:42 - INFO :       Use taylor pruner...
2024-04-22 04:06:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:06:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:06:43 - INFO :       Start Pruning
2024-04-22 04:06:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:06:45 - INFO :       Loss = 7.796875
2024-04-22 04:06:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:06:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:06:49 - INFO :       abstract_narrative_understanding: Total Sparsity 1.3595404667678207e-06
2024-04-22 04:07:33 - INFO :       abstract_narrative_understanding: Total Accuracy (19, 50, 0.38)
2024-04-22 04:07:33 - INFO :       
==================Finish================

2024-04-22 04:07:33 - INFO :       Memory Requirement: 16772.79052734375 MiB

2024-04-22 04:07:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:07:33 - INFO :       DATASET: tasksource/bigbench anachronisms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]
2024-04-22 04:07:43 - INFO :       Use taylor pruner...
2024-04-22 04:07:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:07:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:07:43 - INFO :       Start Pruning
2024-04-22 04:07:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:07:46 - INFO :       Loss = 14.546875
2024-04-22 04:07:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:07:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:07:49 - INFO :       anachronisms: Total Sparsity 1.3554032883811208e-06
2024-04-22 04:08:28 - INFO :       anachronisms: Total Accuracy (27, 46, 0.5869565217391305)
2024-04-22 04:08:28 - INFO :       
==================Finish================

2024-04-22 04:08:28 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-22 04:08:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:08:28 - INFO :       DATASET: tasksource/bigbench analogical_similarity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]
2024-04-22 04:08:38 - INFO :       Use taylor pruner...
2024-04-22 04:08:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:08:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:08:38 - INFO :       Start Pruning
2024-04-22 04:08:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:08:41 - INFO :       Loss = 1.3515625
2024-04-22 04:08:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:08:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:08:44 - INFO :       analogical_similarity: Total Sparsity 1.3557215328724054e-06
2024-04-22 04:09:41 - INFO :       analogical_similarity: Total Accuracy (3, 50, 0.06)
2024-04-22 04:09:41 - INFO :       
==================Finish================

2024-04-22 04:09:41 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-22 04:09:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:09:41 - INFO :       DATASET: tasksource/bigbench analytic_entailment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.09s/it]
2024-04-22 04:09:53 - INFO :       Use taylor pruner...
2024-04-22 04:09:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:09:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:09:53 - INFO :       Start Pruning
2024-04-22 04:09:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:09:58 - INFO :       Loss = 14.296875
2024-04-22 04:09:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:09:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:10:01 - INFO :       analytic_entailment: Total Sparsity 1.3573127553288283e-06
2024-04-22 04:10:14 - INFO :       analytic_entailment: Total Accuracy (8, 16, 0.5)
2024-04-22 04:10:15 - INFO :       
==================Finish================

2024-04-22 04:10:15 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-22 04:10:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:10:15 - INFO :       DATASET: tasksource/bigbench arithmetic
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
2024-04-22 04:10:26 - INFO :       Use taylor pruner...
2024-04-22 04:10:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:10:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:10:26 - INFO :       Start Pruning
2024-04-22 04:10:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:10:30 - INFO :       Loss = 10.625
2024-04-22 04:10:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:10:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:10:33 - INFO :       arithmetic: Total Sparsity 1.3546076771529093e-06
2024-04-22 04:11:17 - INFO :       arithmetic: Total Accuracy (2, 50, 0.04)
2024-04-22 04:11:17 - INFO :       
==================Finish================

2024-04-22 04:11:17 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-22 04:11:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:11:17 - INFO :       DATASET: tasksource/bigbench authorship_verification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]
2024-04-22 04:11:57 - INFO :       Use taylor pruner...
2024-04-22 04:11:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:11:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:11:57 - INFO :       Start Pruning
2024-04-22 04:12:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:12:02 - INFO :       Loss = 2.837890625
2024-04-22 04:12:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:12:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:12:05 - INFO :       authorship_verification: Total Sparsity 1.3590631000308936e-06
2024-04-22 04:14:16 - INFO :       authorship_verification: Total Accuracy (19, 50, 0.38)
2024-04-22 04:14:17 - INFO :       
==================Finish================

2024-04-22 04:14:17 - INFO :       Memory Requirement: 16794.029296875 MiB

2024-04-22 04:14:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:14:17 - INFO :       DATASET: tasksource/bigbench bbq_lite_json
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]
2024-04-22 04:14:26 - INFO :       Use taylor pruner...
2024-04-22 04:14:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:14:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:14:27 - INFO :       Start Pruning
2024-04-22 04:14:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:14:30 - INFO :       Loss = 12.5546875
2024-04-22 04:14:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:14:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:14:34 - INFO :       bbq_lite_json: Total Sparsity 1.357630999820113e-06
2024-04-22 04:15:17 - INFO :       bbq_lite_json: Total Accuracy (3, 50, 0.06)
2024-04-22 04:15:17 - INFO :       
==================Finish================

2024-04-22 04:15:17 - INFO :       Memory Requirement: 16771.79052734375 MiB

2024-04-22 04:15:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:15:17 - INFO :       DATASET: tasksource/bigbench causal_judgment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.95s/it]
2024-04-22 04:15:28 - INFO :       Use taylor pruner...
2024-04-22 04:15:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:15:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:15:29 - INFO :       Start Pruning
2024-04-22 04:15:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:15:36 - INFO :       Loss = 9.2734375
2024-04-22 04:15:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:15:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:15:40 - INFO :       causal_judgment: Total Sparsity 1.3549259216441938e-06
2024-04-22 04:16:15 - INFO :       causal_judgment: Total Accuracy (17, 38, 0.4473684210526316)
2024-04-22 04:16:15 - INFO :       
==================Finish================

2024-04-22 04:16:15 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:16:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:16:15 - INFO :       DATASET: tasksource/bigbench cause_and_effect
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]
2024-04-22 04:16:24 - INFO :       Use taylor pruner...
2024-04-22 04:16:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:16:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:16:24 - INFO :       Start Pruning
2024-04-22 04:16:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:16:27 - INFO :       Loss = 13.84375
2024-04-22 04:16:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:16:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:16:30 - INFO :       cause_and_effect: Total Sparsity 1.3574718775744707e-06
2024-04-22 04:16:56 - INFO :       cause_and_effect: Total Accuracy (24, 30, 0.8)
2024-04-22 04:16:57 - INFO :       
==================Finish================

2024-04-22 04:16:57 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:16:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:16:57 - INFO :       DATASET: tasksource/bigbench checkmate_in_one
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]
2024-04-22 04:17:06 - INFO :       Use taylor pruner...
2024-04-22 04:17:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:17:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:17:07 - INFO :       Start Pruning
2024-04-22 04:17:08 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:17:09 - INFO :       Loss = 1.306640625
2024-04-22 04:17:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:17:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:17:13 - INFO :       checkmate_in_one: Total Sparsity 1.3542894326616245e-06
2024-04-22 04:18:04 - INFO :       checkmate_in_one: Total Accuracy (2, 50, 0.04)
2024-04-22 04:18:04 - INFO :       
==================Finish================

2024-04-22 04:18:04 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:18:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:18:04 - INFO :       DATASET: tasksource/bigbench cifar10_classification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2024-04-22 04:18:14 - INFO :       Use taylor pruner...
2024-04-22 04:18:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:18:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:18:14 - INFO :       Start Pruning
Token indices sequence length is longer than the specified maximum sequence length for this model (6970 > 4096). Running this sequence through the model will result in indexing errors
2024-04-22 04:18:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:18:18 - INFO :       Loss = 3.82421875
2024-04-22 04:18:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:18:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:18:21 - INFO :       cifar10_classification: Total Sparsity 1.3563580218549744e-06
2024-04-22 04:20:15 - INFO :       cifar10_classification: Total Accuracy (1, 50, 0.02)
2024-04-22 04:20:15 - INFO :       
==================Finish================

2024-04-22 04:20:15 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:20:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:20:15 - INFO :       DATASET: tasksource/bigbench code_line_description
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2024-04-22 04:20:25 - INFO :       Use taylor pruner...
2024-04-22 04:20:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:20:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:20:26 - INFO :       Start Pruning
2024-04-22 04:20:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:20:28 - INFO :       Loss = 11.140625
2024-04-22 04:20:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:20:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:20:31 - INFO :       code_line_description: Total Sparsity 1.358267488802682e-06
2024-04-22 04:20:45 - INFO :       code_line_description: Total Accuracy (11, 16, 0.6875)
2024-04-22 04:20:45 - INFO :       
==================Finish================

2024-04-22 04:20:45 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:20:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:20:45 - INFO :       DATASET: tasksource/bigbench color
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  2.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:06<00:00,  3.11s/it]
2024-04-22 04:20:59 - INFO :       Use taylor pruner...
2024-04-22 04:20:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:20:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:20:59 - INFO :       Start Pruning
2024-04-22 04:21:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:21:04 - INFO :       Loss = 10.59375
2024-04-22 04:21:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:21:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:21:08 - INFO :       color: Total Sparsity 1.3581083665570398e-06
2024-04-22 04:21:50 - INFO :       color: Total Accuracy (1, 50, 0.02)
2024-04-22 04:21:50 - INFO :       
==================Finish================

2024-04-22 04:21:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:21:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:21:50 - INFO :       DATASET: tasksource/bigbench common_morpheme
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.45s/it]
2024-04-22 04:22:06 - INFO :       Use taylor pruner...
2024-04-22 04:22:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:22:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:22:06 - INFO :       Start Pruning
2024-04-22 04:22:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:22:14 - INFO :       Loss = 13.328125
2024-04-22 04:22:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:22:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:22:18 - INFO :       common_morpheme: Total Sparsity 1.3620864226980974e-06
2024-04-22 04:22:32 - INFO :       common_morpheme: Total Accuracy (4, 16, 0.25)
2024-04-22 04:22:32 - INFO :       
==================Finish================

2024-04-22 04:22:32 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:22:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:22:32 - INFO :       DATASET: tasksource/bigbench conceptual_combinations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.59s/it]
2024-04-22 04:23:10 - INFO :       Use taylor pruner...
2024-04-22 04:23:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:23:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:23:11 - INFO :       Start Pruning
2024-04-22 04:25:07 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:25:08 - INFO :       Loss = 11.6171875
2024-04-22 04:25:10 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:25:10 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:25:12 - INFO :       conceptual_combinations: Total Sparsity 1.3589039777852514e-06
2024-04-22 04:25:28 - INFO :       conceptual_combinations: Total Accuracy (10, 19, 0.5263157894736842)
2024-04-22 04:25:28 - INFO :       
==================Finish================

2024-04-22 04:25:28 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:25:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:25:28 - INFO :       DATASET: tasksource/bigbench crash_blossom
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]
2024-04-22 04:26:17 - INFO :       Use taylor pruner...
2024-04-22 04:26:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:26:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:26:18 - INFO :       Start Pruning
2024-04-22 04:27:25 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:27:26 - INFO :       Loss = 13.5234375
2024-04-22 04:27:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:27:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:27:30 - INFO :       crash_blossom: Total Sparsity 1.359222222276536e-06
2024-04-22 04:27:44 - INFO :       crash_blossom: Total Accuracy (6, 16, 0.375)
2024-04-22 04:27:44 - INFO :       
==================Finish================

2024-04-22 04:27:44 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:27:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:27:44 - INFO :       DATASET: tasksource/bigbench crass_ai
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2024-04-22 04:27:54 - INFO :       Use taylor pruner...
2024-04-22 04:27:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:27:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:27:54 - INFO :       Start Pruning
2024-04-22 04:28:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:28:07 - INFO :       Loss = 11.359375
2024-04-22 04:28:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:28:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:28:10 - INFO :       crass_ai: Total Sparsity 1.356517144100617e-06
2024-04-22 04:28:24 - INFO :       crass_ai: Total Accuracy (5, 16, 0.3125)
2024-04-22 04:28:24 - INFO :       
==================Finish================

2024-04-22 04:28:24 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:28:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:28:24 - INFO :       DATASET: tasksource/bigbench cryobiology_spanish
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]
2024-04-22 04:28:56 - INFO :       Use taylor pruner...
2024-04-22 04:28:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:28:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:28:56 - INFO :       Start Pruning
2024-04-22 04:29:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:29:25 - INFO :       Loss = 13.7265625
2024-04-22 04:29:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:29:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:29:28 - INFO :       cryobiology_spanish: Total Sparsity 1.3581083665570398e-06
2024-04-22 04:29:53 - INFO :       cryobiology_spanish: Total Accuracy (24, 29, 0.8275862068965517)
2024-04-22 04:29:53 - INFO :       
==================Finish================

2024-04-22 04:29:53 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:29:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:29:53 - INFO :       DATASET: tasksource/bigbench cs_algorithms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.91s/it]
2024-04-22 04:30:03 - INFO :       Use taylor pruner...
2024-04-22 04:30:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:30:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:30:04 - INFO :       Start Pruning
2024-04-22 04:30:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:30:07 - INFO :       Loss = 14.0625
2024-04-22 04:30:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:30:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:30:10 - INFO :       cs_algorithms: Total Sparsity 1.3616090559611704e-06
2024-04-22 04:30:53 - INFO :       cs_algorithms: Total Accuracy (3, 50, 0.06)
2024-04-22 04:30:53 - INFO :       
==================Finish================

2024-04-22 04:30:53 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:30:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:30:53 - INFO :       DATASET: tasksource/bigbench dark_humor_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2024-04-22 04:31:04 - INFO :       Use taylor pruner...
2024-04-22 04:31:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:31:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:31:04 - INFO :       Start Pruning
2024-04-22 04:31:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:31:07 - INFO :       Loss = 13.1640625
2024-04-22 04:31:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:31:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:31:10 - INFO :       dark_humor_detection: Total Sparsity 1.3568353885919015e-06
2024-04-22 04:31:24 - INFO :       dark_humor_detection: Total Accuracy (9, 16, 0.5625)
2024-04-22 04:31:24 - INFO :       
==================Finish================

2024-04-22 04:31:24 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:31:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:31:24 - INFO :       DATASET: tasksource/bigbench date_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2024-04-22 04:31:34 - INFO :       Use taylor pruner...
2024-04-22 04:31:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:31:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:31:35 - INFO :       Start Pruning
2024-04-22 04:31:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:31:37 - INFO :       Loss = 10.953125
2024-04-22 04:31:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:31:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:31:41 - INFO :       date_understanding: Total Sparsity 1.358267488802682e-06
2024-04-22 04:32:24 - INFO :       date_understanding: Total Accuracy (13, 50, 0.26)
2024-04-22 04:32:24 - INFO :       
==================Finish================

2024-04-22 04:32:24 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:32:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:32:24 - INFO :       DATASET: tasksource/bigbench disambiguation_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]
2024-04-22 04:32:33 - INFO :       Use taylor pruner...
2024-04-22 04:32:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:32:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:32:34 - INFO :       Start Pruning
2024-04-22 04:32:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:32:36 - INFO :       Loss = 11.890625
2024-04-22 04:32:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:32:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:32:40 - INFO :       disambiguation_qa: Total Sparsity 1.3546076771529093e-06
2024-04-22 04:33:23 - INFO :       disambiguation_qa: Total Accuracy (24, 50, 0.48)
2024-04-22 04:33:23 - INFO :       
==================Finish================

2024-04-22 04:33:23 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:33:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:33:23 - INFO :       DATASET: tasksource/bigbench discourse_marker_prediction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.18s/it]
2024-04-22 04:33:34 - INFO :       Use taylor pruner...
2024-04-22 04:33:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:33:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:33:35 - INFO :       Start Pruning
2024-04-22 04:33:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:33:37 - INFO :       Loss = 1.212890625
2024-04-22 04:33:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:33:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:33:41 - INFO :       discourse_marker_prediction: Total Sparsity 1.3568353885919015e-06
2024-04-22 04:34:31 - INFO :       discourse_marker_prediction: Total Accuracy (12, 50, 0.24)
2024-04-22 04:34:31 - INFO :       
==================Finish================

2024-04-22 04:34:31 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:34:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:34:31 - INFO :       DATASET: tasksource/bigbench dyck_languages
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]
2024-04-22 04:34:41 - INFO :       Use taylor pruner...
2024-04-22 04:34:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:34:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:34:41 - INFO :       Start Pruning
2024-04-22 04:34:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:34:44 - INFO :       Loss = 1.107421875
2024-04-22 04:34:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:34:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:34:48 - INFO :       dyck_languages: Total Sparsity 1.3536529436790554e-06
2024-04-22 04:35:39 - INFO :       dyck_languages: Total Accuracy (0, 50, 0.0)
2024-04-22 04:35:39 - INFO :       
==================Finish================

2024-04-22 04:35:39 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:35:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:35:39 - INFO :       DATASET: tasksource/bigbench elementary_math_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]
2024-04-22 04:35:50 - INFO :       Use taylor pruner...
2024-04-22 04:35:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:35:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:35:51 - INFO :       Start Pruning
2024-04-22 04:35:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:35:53 - INFO :       Loss = 11.171875
2024-04-22 04:35:55 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:35:55 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:35:57 - INFO :       elementary_math_qa: Total Sparsity 1.3569945108375437e-06
2024-04-22 04:36:40 - INFO :       elementary_math_qa: Total Accuracy (14, 50, 0.28)
2024-04-22 04:36:40 - INFO :       
==================Finish================

2024-04-22 04:36:40 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:36:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:36:40 - INFO :       DATASET: tasksource/bigbench emoji_movie
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.13s/it]
2024-04-22 04:36:50 - INFO :       Use taylor pruner...
2024-04-22 04:36:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:36:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:36:50 - INFO :       Start Pruning
2024-04-22 04:36:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:36:53 - INFO :       Loss = 11.9453125
2024-04-22 04:36:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:36:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:36:56 - INFO :       emoji_movie: Total Sparsity 1.3549259216441938e-06
2024-04-22 04:37:14 - INFO :       emoji_movie: Total Accuracy (12, 20, 0.6)
2024-04-22 04:37:14 - INFO :       
==================Finish================

2024-04-22 04:37:14 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:37:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:37:14 - INFO :       DATASET: tasksource/bigbench empirical_judgments
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-22 04:37:23 - INFO :       Use taylor pruner...
2024-04-22 04:37:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:37:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:37:24 - INFO :       Start Pruning
2024-04-22 04:37:25 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:37:26 - INFO :       Loss = 12.75
2024-04-22 04:37:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:37:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:37:30 - INFO :       empirical_judgments: Total Sparsity 1.3600178335047475e-06
2024-04-22 04:37:46 - INFO :       empirical_judgments: Total Accuracy (5, 19, 0.2631578947368421)
2024-04-22 04:37:46 - INFO :       
==================Finish================

2024-04-22 04:37:46 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:37:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:37:46 - INFO :       DATASET: tasksource/bigbench english_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]
2024-04-22 04:37:56 - INFO :       Use taylor pruner...
2024-04-22 04:37:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:37:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:37:57 - INFO :       Start Pruning
2024-04-22 04:37:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:37:59 - INFO :       Loss = 10.71875
2024-04-22 04:38:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:38:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:38:02 - INFO :       english_proverbs: Total Sparsity 1.3577901220657553e-06
2024-04-22 04:38:17 - INFO :       english_proverbs: Total Accuracy (3, 16, 0.1875)
2024-04-22 04:38:17 - INFO :       
==================Finish================

2024-04-22 04:38:17 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:38:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:38:17 - INFO :       DATASET: tasksource/bigbench english_russian_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]
2024-04-22 04:38:28 - INFO :       Use taylor pruner...
2024-04-22 04:38:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:38:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:38:28 - INFO :       Start Pruning
2024-04-22 04:38:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:38:31 - INFO :       Loss = 11.46875
2024-04-22 04:38:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:38:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:38:34 - INFO :       english_russian_proverbs: Total Sparsity 1.3574718775744707e-06
2024-04-22 04:38:49 - INFO :       english_russian_proverbs: Total Accuracy (2, 16, 0.125)
2024-04-22 04:38:49 - INFO :       
==================Finish================

2024-04-22 04:38:49 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:38:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:38:49 - INFO :       DATASET: tasksource/bigbench entailed_polarity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  3.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]
2024-04-22 04:38:58 - INFO :       Use taylor pruner...
2024-04-22 04:38:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:38:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:38:58 - INFO :       Start Pruning
2024-04-22 04:39:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:39:01 - INFO :       Loss = 14.7578125
2024-04-22 04:39:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:39:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:39:04 - INFO :       entailed_polarity: Total Sparsity 1.360336077996032e-06
2024-04-22 04:39:30 - INFO :       entailed_polarity: Total Accuracy (28, 29, 0.9655172413793104)
2024-04-22 04:39:30 - INFO :       
==================Finish================

2024-04-22 04:39:30 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:39:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:39:30 - INFO :       DATASET: tasksource/bigbench entailed_polarity_hindi
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]
2024-04-22 04:39:41 - INFO :       Use taylor pruner...
2024-04-22 04:39:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:39:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:39:41 - INFO :       Start Pruning
2024-04-22 04:39:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:39:44 - INFO :       Loss = 9.7109375
2024-04-22 04:39:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:39:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:39:47 - INFO :       entailed_polarity_hindi: Total Sparsity 1.3563580218549744e-06
2024-04-22 04:40:12 - INFO :       entailed_polarity_hindi: Total Accuracy (20, 27, 0.7407407407407407)
2024-04-22 04:40:12 - INFO :       
==================Finish================

2024-04-22 04:40:12 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:40:12 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:40:12 - INFO :       DATASET: tasksource/bigbench epistemic_reasoning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]
2024-04-22 04:40:21 - INFO :       Use taylor pruner...
2024-04-22 04:40:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:40:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:40:22 - INFO :       Start Pruning
2024-04-22 04:40:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:40:24 - INFO :       Loss = 12.0
2024-04-22 04:40:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:40:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:40:28 - INFO :       epistemic_reasoning: Total Sparsity 1.3617681782068128e-06
2024-04-22 04:41:13 - INFO :       epistemic_reasoning: Total Accuracy (25, 50, 0.5)
2024-04-22 04:41:13 - INFO :       
==================Finish================

2024-04-22 04:41:13 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:41:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:41:13 - INFO :       DATASET: tasksource/bigbench evaluating_information_essentiality
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2024-04-22 04:41:22 - INFO :       Use taylor pruner...
2024-04-22 04:41:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:41:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:41:22 - INFO :       Start Pruning
2024-04-22 04:41:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:41:24 - INFO :       Loss = 7.953125
2024-04-22 04:41:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:41:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:41:28 - INFO :       evaluating_information_essentiality: Total Sparsity 1.3530164546964862e-06
2024-04-22 04:41:43 - INFO :       evaluating_information_essentiality: Total Accuracy (1, 16, 0.0625)
2024-04-22 04:41:43 - INFO :       
==================Finish================

2024-04-22 04:41:43 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:41:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:41:43 - INFO :       DATASET: tasksource/bigbench fact_checker
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  2.00s/it]
2024-04-22 04:41:54 - INFO :       Use taylor pruner...
2024-04-22 04:41:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:41:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:41:54 - INFO :       Start Pruning
2024-04-22 04:41:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:41:57 - INFO :       Loss = 14.3828125
2024-04-22 04:41:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:41:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:42:01 - INFO :       fact_checker: Total Sparsity 1.35603977736369e-06
2024-04-22 04:42:46 - INFO :       fact_checker: Total Accuracy (39, 50, 0.78)
2024-04-22 04:42:46 - INFO :       
==================Finish================

2024-04-22 04:42:46 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:42:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:42:46 - INFO :       DATASET: tasksource/bigbench fantasy_reasoning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-22 04:42:55 - INFO :       Use taylor pruner...
2024-04-22 04:42:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:42:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:42:56 - INFO :       Start Pruning
2024-04-22 04:42:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:42:58 - INFO :       Loss = 13.109375
2024-04-22 04:43:00 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:43:00 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:43:01 - INFO :       fantasy_reasoning: Total Sparsity 1.35397118817034e-06
2024-04-22 04:43:38 - INFO :       fantasy_reasoning: Total Accuracy (20, 40, 0.5)
2024-04-22 04:43:38 - INFO :       
==================Finish================

2024-04-22 04:43:38 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:43:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:43:38 - INFO :       DATASET: tasksource/bigbench figure_of_speech_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]
2024-04-22 04:43:47 - INFO :       Use taylor pruner...
2024-04-22 04:43:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:43:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:43:48 - INFO :       Start Pruning
2024-04-22 04:43:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:43:50 - INFO :       Loss = 11.7734375
2024-04-22 04:43:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:43:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:43:54 - INFO :       figure_of_speech_detection: Total Sparsity 1.355085043889836e-06
2024-04-22 04:44:09 - INFO :       figure_of_speech_detection: Total Accuracy (3, 16, 0.1875)
2024-04-22 04:44:09 - INFO :       
==================Finish================

2024-04-22 04:44:09 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:44:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:44:09 - INFO :       DATASET: tasksource/bigbench formal_fallacies_syllogisms_negation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-22 04:44:18 - INFO :       Use taylor pruner...
2024-04-22 04:44:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:44:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:44:19 - INFO :       Start Pruning
2024-04-22 04:44:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:44:21 - INFO :       Loss = 12.171875
2024-04-22 04:44:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:44:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:44:24 - INFO :       formal_fallacies_syllogisms_negation: Total Sparsity 1.3569945108375437e-06
2024-04-22 04:45:09 - INFO :       formal_fallacies_syllogisms_negation: Total Accuracy (23, 50, 0.46)
2024-04-22 04:45:09 - INFO :       
==================Finish================

2024-04-22 04:45:09 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:45:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:45:09 - INFO :       DATASET: tasksource/bigbench general_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2024-04-22 04:45:19 - INFO :       Use taylor pruner...
2024-04-22 04:45:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:45:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:45:19 - INFO :       Start Pruning
2024-04-22 04:45:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:45:21 - INFO :       Loss = 13.3125
2024-04-22 04:45:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:45:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:45:25 - INFO :       general_knowledge: Total Sparsity 1.3601769557503897e-06
2024-04-22 04:45:38 - INFO :       general_knowledge: Total Accuracy (12, 16, 0.75)
2024-04-22 04:45:38 - INFO :       
==================Finish================

2024-04-22 04:45:38 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:45:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:45:38 - INFO :       DATASET: tasksource/bigbench geometric_shapes
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]
2024-04-22 04:45:48 - INFO :       Use taylor pruner...
2024-04-22 04:45:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:45:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:45:48 - INFO :       Start Pruning
2024-04-22 04:45:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:45:51 - INFO :       Loss = 7.7890625
2024-04-22 04:45:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:45:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:45:54 - INFO :       geometric_shapes: Total Sparsity 1.3579492443113975e-06
2024-04-22 04:46:39 - INFO :       geometric_shapes: Total Accuracy (6, 50, 0.12)
2024-04-22 04:46:39 - INFO :       
==================Finish================

2024-04-22 04:46:39 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:46:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:46:39 - INFO :       DATASET: tasksource/bigbench goal_step_wikihow
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.57s/it]
2024-04-22 04:46:49 - INFO :       Use taylor pruner...
2024-04-22 04:46:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:46:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:46:49 - INFO :       Start Pruning
2024-04-22 04:46:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:46:52 - INFO :       Loss = 12.671875
2024-04-22 04:46:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:46:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:46:56 - INFO :       goal_step_wikihow: Total Sparsity 1.3589039777852514e-06
2024-04-22 04:47:39 - INFO :       goal_step_wikihow: Total Accuracy (18, 50, 0.36)
2024-04-22 04:47:39 - INFO :       
==================Finish================

2024-04-22 04:47:39 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:47:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:47:39 - INFO :       DATASET: tasksource/bigbench gre_reading_comprehension
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.89s/it]
2024-04-22 04:47:49 - INFO :       Use taylor pruner...
2024-04-22 04:47:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:47:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:47:49 - INFO :       Start Pruning
2024-04-22 04:47:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:47:51 - INFO :       Loss = 3.587890625
2024-04-22 04:47:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:47:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:47:54 - INFO :       gre_reading_comprehension: Total Sparsity 1.3585857332939668e-06
2024-04-22 04:48:11 - INFO :       gre_reading_comprehension: Total Accuracy (4, 16, 0.25)
2024-04-22 04:48:11 - INFO :       
==================Finish================

2024-04-22 04:48:11 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:48:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:48:11 - INFO :       DATASET: tasksource/bigbench hhh_alignment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]
2024-04-22 04:48:22 - INFO :       Use taylor pruner...
2024-04-22 04:48:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:48:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:48:23 - INFO :       Start Pruning
2024-04-22 04:48:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:48:25 - INFO :       Loss = 9.8515625
2024-04-22 04:48:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:48:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:48:28 - INFO :       hhh_alignment: Total Sparsity 1.3566762663462592e-06
2024-04-22 04:49:07 - INFO :       hhh_alignment: Total Accuracy (27, 42, 0.6428571428571429)
2024-04-22 04:49:08 - INFO :       
==================Finish================

2024-04-22 04:49:08 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:49:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:49:08 - INFO :       DATASET: tasksource/bigbench hindu_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.99s/it]
2024-04-22 04:49:18 - INFO :       Use taylor pruner...
2024-04-22 04:49:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:49:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:49:19 - INFO :       Start Pruning
2024-04-22 04:49:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:49:22 - INFO :       Loss = 13.390625
2024-04-22 04:49:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:49:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:49:25 - INFO :       hindu_knowledge: Total Sparsity 1.3622455449437396e-06
2024-04-22 04:49:55 - INFO :       hindu_knowledge: Total Accuracy (20, 35, 0.5714285714285714)
2024-04-22 04:49:55 - INFO :       
==================Finish================

2024-04-22 04:49:55 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:49:55 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:49:55 - INFO :       DATASET: tasksource/bigbench hinglish_toxicity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.31s/it]
2024-04-22 04:50:06 - INFO :       Use taylor pruner...
2024-04-22 04:50:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:50:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:50:06 - INFO :       Start Pruning
2024-04-22 04:50:08 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:50:08 - INFO :       Loss = 14.609375
2024-04-22 04:50:10 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:50:10 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:50:12 - INFO :       hinglish_toxicity: Total Sparsity 1.357630999820113e-06
2024-04-22 04:50:45 - INFO :       hinglish_toxicity: Total Accuracy (19, 40, 0.475)
2024-04-22 04:50:46 - INFO :       
==================Finish================

2024-04-22 04:50:46 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:50:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:50:46 - INFO :       DATASET: tasksource/bigbench human_organs_senses
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.98s/it]
2024-04-22 04:50:56 - INFO :       Use taylor pruner...
2024-04-22 04:50:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:50:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:50:57 - INFO :       Start Pruning
2024-04-22 04:50:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:50:59 - INFO :       Loss = 14.2109375
2024-04-22 04:51:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:51:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:51:04 - INFO :       human_organs_senses: Total Sparsity 1.357153633083186e-06
2024-04-22 04:51:18 - INFO :       human_organs_senses: Total Accuracy (9, 16, 0.5625)
2024-04-22 04:51:18 - INFO :       
==================Finish================

2024-04-22 04:51:18 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:51:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:51:18 - INFO :       DATASET: tasksource/bigbench hyperbaton
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]
2024-04-22 04:51:28 - INFO :       Use taylor pruner...
2024-04-22 04:51:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:51:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:51:28 - INFO :       Start Pruning
2024-04-22 04:51:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:51:30 - INFO :       Loss = 15.109375
2024-04-22 04:51:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:51:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:51:33 - INFO :       hyperbaton: Total Sparsity 1.356517144100617e-06
2024-04-22 04:52:15 - INFO :       hyperbaton: Total Accuracy (22, 50, 0.44)
2024-04-22 04:52:15 - INFO :       
==================Finish================

2024-04-22 04:52:15 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:52:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:52:15 - INFO :       DATASET: tasksource/bigbench identify_math_theorems
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.30s/it]
2024-04-22 04:52:27 - INFO :       Use taylor pruner...
2024-04-22 04:52:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:52:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:52:28 - INFO :       Start Pruning
2024-04-22 04:52:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:52:30 - INFO :       Loss = 1.6728515625
2024-04-22 04:52:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:52:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:52:33 - INFO :       identify_math_theorems: Total Sparsity 1.3573127553288283e-06
2024-04-22 04:52:50 - INFO :       identify_math_theorems: Total Accuracy (7, 16, 0.4375)
2024-04-22 04:52:50 - INFO :       
==================Finish================

2024-04-22 04:52:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:52:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:52:50 - INFO :       DATASET: tasksource/bigbench identify_odd_metaphor
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]
2024-04-22 04:52:59 - INFO :       Use taylor pruner...
2024-04-22 04:52:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:52:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:53:00 - INFO :       Start Pruning
2024-04-22 04:53:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:53:02 - INFO :       Loss = 10.578125
2024-04-22 04:53:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:53:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:53:06 - INFO :       identify_odd_metaphor: Total Sparsity 1.359699589013463e-06
2024-04-22 04:53:20 - INFO :       identify_odd_metaphor: Total Accuracy (10, 16, 0.625)
2024-04-22 04:53:20 - INFO :       
==================Finish================

2024-04-22 04:53:20 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:53:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:53:20 - INFO :       DATASET: tasksource/bigbench implicatures
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.84s/it]
2024-04-22 04:53:29 - INFO :       Use taylor pruner...
2024-04-22 04:53:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:53:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:53:30 - INFO :       Start Pruning
2024-04-22 04:53:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:53:32 - INFO :       Loss = 14.2421875
2024-04-22 04:53:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:53:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:53:35 - INFO :       implicatures: Total Sparsity 1.3617681782068128e-06
2024-04-22 04:54:20 - INFO :       implicatures: Total Accuracy (31, 50, 0.62)
2024-04-22 04:54:21 - INFO :       
==================Finish================

2024-04-22 04:54:21 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:54:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:54:21 - INFO :       DATASET: tasksource/bigbench implicit_relations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]
2024-04-22 04:54:34 - INFO :       Use taylor pruner...
2024-04-22 04:54:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:54:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:54:34 - INFO :       Start Pruning
2024-04-22 04:54:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:54:36 - INFO :       Loss = 6.2890625
2024-04-22 04:54:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:54:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:54:40 - INFO :       implicit_relations: Total Sparsity 1.3552441661354783e-06
2024-04-22 04:54:56 - INFO :       implicit_relations: Total Accuracy (5, 17, 0.29411764705882354)
2024-04-22 04:54:56 - INFO :       
==================Finish================

2024-04-22 04:54:56 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:54:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:54:56 - INFO :       DATASET: tasksource/bigbench indic_cause_and_effect
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.94s/it]
2024-04-22 04:55:05 - INFO :       Use taylor pruner...
2024-04-22 04:55:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:55:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:55:06 - INFO :       Start Pruning
2024-04-22 04:55:07 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:55:08 - INFO :       Loss = 1.6083984375
2024-04-22 04:55:10 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:55:10 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:55:12 - INFO :       indic_cause_and_effect: Total Sparsity 1.3534938214334132e-06
2024-04-22 04:55:58 - INFO :       indic_cause_and_effect: Total Accuracy (28, 50, 0.56)
2024-04-22 04:55:59 - INFO :       
==================Finish================

2024-04-22 04:55:59 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:55:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:55:59 - INFO :       DATASET: tasksource/bigbench intent_recognition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.87s/it]
2024-04-22 04:56:08 - INFO :       Use taylor pruner...
2024-04-22 04:56:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:56:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:56:08 - INFO :       Start Pruning
2024-04-22 04:56:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:56:10 - INFO :       Loss = 10.34375
2024-04-22 04:56:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:56:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:56:14 - INFO :       intent_recognition: Total Sparsity 1.3558806551180476e-06
2024-04-22 04:56:57 - INFO :       intent_recognition: Total Accuracy (23, 50, 0.46)
2024-04-22 04:56:57 - INFO :       
==================Finish================

2024-04-22 04:56:57 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:56:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:56:57 - INFO :       DATASET: tasksource/bigbench international_phonetic_alphabet_nli
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.86s/it]
2024-04-22 04:57:06 - INFO :       Use taylor pruner...
2024-04-22 04:57:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:57:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:57:07 - INFO :       Start Pruning
2024-04-22 04:57:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:57:10 - INFO :       Loss = 9.0
2024-04-22 04:57:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:57:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:57:13 - INFO :       international_phonetic_alphabet_nli: Total Sparsity 1.3569945108375437e-06
2024-04-22 04:57:35 - INFO :       international_phonetic_alphabet_nli: Total Accuracy (11, 25, 0.44)
2024-04-22 04:57:35 - INFO :       
==================Finish================

2024-04-22 04:57:35 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:57:35 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:57:35 - INFO :       DATASET: tasksource/bigbench intersect_geometry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.65s/it]
2024-04-22 04:57:44 - INFO :       Use taylor pruner...
2024-04-22 04:57:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:57:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:57:45 - INFO :       Start Pruning
2024-04-22 04:57:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:57:49 - INFO :       Loss = 2.94921875
2024-04-22 04:57:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:57:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:57:51 - INFO :       intersect_geometry: Total Sparsity 1.35397118817034e-06
2024-04-22 04:58:41 - INFO :       intersect_geometry: Total Accuracy (0, 50, 0.0)
2024-04-22 04:58:41 - INFO :       
==================Finish================

2024-04-22 04:58:41 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:58:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:58:41 - INFO :       DATASET: tasksource/bigbench irony_identification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.14s/it]
2024-04-22 04:58:54 - INFO :       Use taylor pruner...
2024-04-22 04:58:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:58:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:58:54 - INFO :       Start Pruning
2024-04-22 04:58:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:58:56 - INFO :       Loss = 13.9140625
2024-04-22 04:58:58 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:58:58 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:58:59 - INFO :       irony_identification: Total Sparsity 1.3563580218549744e-06
2024-04-22 04:59:16 - INFO :       irony_identification: Total Accuracy (11, 19, 0.5789473684210527)
2024-04-22 04:59:16 - INFO :       
==================Finish================

2024-04-22 04:59:16 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 04:59:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 04:59:16 - INFO :       DATASET: tasksource/bigbench kannada
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.90s/it]
2024-04-22 04:59:26 - INFO :       Use taylor pruner...
2024-04-22 04:59:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:59:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 04:59:26 - INFO :       Start Pruning
2024-04-22 04:59:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 04:59:28 - INFO :       Loss = 6.78125
2024-04-22 04:59:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 04:59:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 04:59:32 - INFO :       kannada: Total Sparsity 1.3549259216441938e-06
2024-04-22 05:00:24 - INFO :       kannada: Total Accuracy (11, 50, 0.22)
2024-04-22 05:00:26 - INFO :       
==================Finish================

2024-04-22 05:00:26 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:00:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:00:26 - INFO :       DATASET: tasksource/bigbench key_value_maps
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.15s/it]
2024-04-22 05:00:36 - INFO :       Use taylor pruner...
2024-04-22 05:00:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:00:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:00:36 - INFO :       Start Pruning
2024-04-22 05:00:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:00:39 - INFO :       Loss = 7.25390625
2024-04-22 05:00:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:00:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:00:42 - INFO :       key_value_maps: Total Sparsity 1.3574718775744707e-06
2024-04-22 05:01:03 - INFO :       key_value_maps: Total Accuracy (12, 21, 0.5714285714285714)
2024-04-22 05:01:03 - INFO :       
==================Finish================

2024-04-22 05:01:03 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:01:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:01:03 - INFO :       DATASET: tasksource/bigbench known_unknowns
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.56s/it]
2024-04-22 05:01:12 - INFO :       Use taylor pruner...
2024-04-22 05:01:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:01:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:01:13 - INFO :       Start Pruning
2024-04-22 05:01:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:01:15 - INFO :       Loss = 14.4296875
2024-04-22 05:01:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:01:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:01:19 - INFO :       known_unknowns: Total Sparsity 1.3579492443113975e-06
2024-04-22 05:01:32 - INFO :       known_unknowns: Total Accuracy (8, 16, 0.5)
2024-04-22 05:01:32 - INFO :       
==================Finish================

2024-04-22 05:01:32 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:01:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:01:32 - INFO :       DATASET: tasksource/bigbench language_identification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2024-04-22 05:01:43 - INFO :       Use taylor pruner...
2024-04-22 05:01:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:01:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:01:43 - INFO :       Start Pruning
2024-04-22 05:01:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:01:46 - INFO :       Loss = 8.46875
2024-04-22 05:01:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:01:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:01:49 - INFO :       language_identification: Total Sparsity 1.3552441661354783e-06
2024-04-22 05:02:33 - INFO :       language_identification: Total Accuracy (10, 50, 0.2)
2024-04-22 05:02:34 - INFO :       
==================Finish================

2024-04-22 05:02:34 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:02:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:02:34 - INFO :       DATASET: tasksource/bigbench logic_grid_puzzle
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]
2024-04-22 05:02:45 - INFO :       Use taylor pruner...
2024-04-22 05:02:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:02:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:02:45 - INFO :       Start Pruning
2024-04-22 05:02:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:02:48 - INFO :       Loss = 4.14453125
2024-04-22 05:02:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:02:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:02:51 - INFO :       logic_grid_puzzle: Total Sparsity 1.3554032883811208e-06
2024-04-22 05:03:38 - INFO :       logic_grid_puzzle: Total Accuracy (13, 50, 0.26)
2024-04-22 05:03:38 - INFO :       
==================Finish================

2024-04-22 05:03:38 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:03:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:03:38 - INFO :       DATASET: tasksource/bigbench logical_args
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.07s/it]
2024-04-22 05:03:49 - INFO :       Use taylor pruner...
2024-04-22 05:03:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:03:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:03:49 - INFO :       Start Pruning
2024-04-22 05:03:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:03:52 - INFO :       Loss = 8.1875
2024-04-22 05:03:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:03:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:03:55 - INFO :       logical_args: Total Sparsity 1.3563580218549744e-06
2024-04-22 05:04:10 - INFO :       logical_args: Total Accuracy (10, 16, 0.625)
2024-04-22 05:04:10 - INFO :       
==================Finish================

2024-04-22 05:04:10 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:04:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:04:10 - INFO :       DATASET: tasksource/bigbench logical_deduction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:03<00:03,  3.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.25s/it]
2024-04-22 05:04:21 - INFO :       Use taylor pruner...
2024-04-22 05:04:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:04:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:04:22 - INFO :       Start Pruning
2024-04-22 05:04:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:04:24 - INFO :       Loss = 10.3828125
2024-04-22 05:04:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:04:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:04:28 - INFO :       logical_deduction: Total Sparsity 1.3579492443113975e-06
2024-04-22 05:05:12 - INFO :       logical_deduction: Total Accuracy (13, 50, 0.26)
2024-04-22 05:05:12 - INFO :       
==================Finish================

2024-04-22 05:05:12 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:05:12 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:05:12 - INFO :       DATASET: tasksource/bigbench logical_fallacy_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.85s/it]
2024-04-22 05:05:21 - INFO :       Use taylor pruner...
2024-04-22 05:05:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:05:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:05:21 - INFO :       Start Pruning
2024-04-22 05:05:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:05:24 - INFO :       Loss = 13.546875
2024-04-22 05:05:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:05:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:05:28 - INFO :       logical_fallacy_detection: Total Sparsity 1.3598587112591052e-06
2024-04-22 05:06:15 - INFO :       logical_fallacy_detection: Total Accuracy (29, 50, 0.58)
2024-04-22 05:06:16 - INFO :       
==================Finish================

2024-04-22 05:06:16 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:06:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:06:16 - INFO :       DATASET: tasksource/bigbench logical_sequence
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.03s/it]
2024-04-22 05:06:27 - INFO :       Use taylor pruner...
2024-04-22 05:06:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:06:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:06:27 - INFO :       Start Pruning
2024-04-22 05:06:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:06:30 - INFO :       Loss = 11.1015625
2024-04-22 05:06:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:06:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:06:33 - INFO :       logical_sequence: Total Sparsity 1.3606543224873167e-06
2024-04-22 05:06:47 - INFO :       logical_sequence: Total Accuracy (4, 16, 0.25)
2024-04-22 05:06:47 - INFO :       
==================Finish================

2024-04-22 05:06:47 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:06:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:06:47 - INFO :       DATASET: tasksource/bigbench mathematical_induction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.67s/it]
2024-04-22 05:06:56 - INFO :       Use taylor pruner...
2024-04-22 05:06:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:06:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:06:57 - INFO :       Start Pruning
2024-04-22 05:06:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:07:00 - INFO :       Loss = 14.1953125
2024-04-22 05:07:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:07:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:07:03 - INFO :       mathematical_induction: Total Sparsity 1.358744855539609e-06
2024-04-22 05:07:17 - INFO :       mathematical_induction: Total Accuracy (10, 16, 0.625)
2024-04-22 05:07:17 - INFO :       
==================Finish================

2024-04-22 05:07:17 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:07:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:07:17 - INFO :       DATASET: tasksource/bigbench medical_questions_russian
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-22 05:07:28 - INFO :       Use taylor pruner...
2024-04-22 05:07:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:07:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:07:28 - INFO :       Start Pruning
2024-04-22 05:07:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:07:31 - INFO :       Loss = 10.53125
2024-04-22 05:07:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:07:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:07:35 - INFO :       medical_questions_russian: Total Sparsity 1.3561988996093322e-06
2024-04-22 05:08:20 - INFO :       medical_questions_russian: Total Accuracy (14, 50, 0.28)
2024-04-22 05:08:21 - INFO :       
==================Finish================

2024-04-22 05:08:21 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:08:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:08:21 - INFO :       DATASET: tasksource/bigbench metaphor_boolean
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.58s/it]
2024-04-22 05:08:30 - INFO :       Use taylor pruner...
2024-04-22 05:08:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:08:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:08:31 - INFO :       Start Pruning
2024-04-22 05:08:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:08:33 - INFO :       Loss = 13.3984375
2024-04-22 05:08:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:08:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:08:36 - INFO :       metaphor_boolean: Total Sparsity 1.3598587112591052e-06
2024-04-22 05:09:20 - INFO :       metaphor_boolean: Total Accuracy (18, 50, 0.36)
2024-04-22 05:09:20 - INFO :       
==================Finish================

2024-04-22 05:09:20 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:09:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:09:20 - INFO :       DATASET: tasksource/bigbench metaphor_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]
2024-04-22 05:09:30 - INFO :       Use taylor pruner...
2024-04-22 05:09:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:09:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:09:31 - INFO :       Start Pruning
2024-04-22 05:09:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:09:33 - INFO :       Loss = 7.9609375
2024-04-22 05:09:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:09:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:09:36 - INFO :       metaphor_understanding: Total Sparsity 1.3552441661354783e-06
2024-04-22 05:10:17 - INFO :       metaphor_understanding: Total Accuracy (31, 46, 0.6739130434782609)
2024-04-22 05:10:17 - INFO :       
==================Finish================

2024-04-22 05:10:17 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:10:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:10:17 - INFO :       DATASET: tasksource/bigbench misconceptions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.88s/it]
2024-04-22 05:10:27 - INFO :       Use taylor pruner...
2024-04-22 05:10:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:10:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:10:27 - INFO :       Start Pruning
2024-04-22 05:10:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:10:29 - INFO :       Loss = 14.078125
2024-04-22 05:10:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:10:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:10:33 - INFO :       misconceptions: Total Sparsity 1.357153633083186e-06
2024-04-22 05:11:09 - INFO :       misconceptions: Total Accuracy (21, 43, 0.4883720930232558)
2024-04-22 05:11:10 - INFO :       
==================Finish================

2024-04-22 05:11:10 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:11:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:11:10 - INFO :       DATASET: tasksource/bigbench mnist_ascii
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.12s/it]
2024-04-22 05:11:19 - INFO :       Use taylor pruner...
2024-04-22 05:11:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:11:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:11:20 - INFO :       Start Pruning
2024-04-22 05:11:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:11:24 - INFO :       Loss = 5.18359375
2024-04-22 05:11:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:11:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:11:27 - INFO :       mnist_ascii: Total Sparsity 1.357630999820113e-06
2024-04-22 05:12:50 - INFO :       mnist_ascii: Total Accuracy (6, 50, 0.12)
2024-04-22 05:12:51 - INFO :       
==================Finish================

2024-04-22 05:12:51 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:12:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:12:51 - INFO :       DATASET: tasksource/bigbench moral_permissibility
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.91s/it]
2024-04-22 05:13:01 - INFO :       Use taylor pruner...
2024-04-22 05:13:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:13:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:13:01 - INFO :       Start Pruning
2024-04-22 05:13:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:13:03 - INFO :       Loss = 12.7421875
2024-04-22 05:13:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:13:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:13:07 - INFO :       moral_permissibility: Total Sparsity 1.3554032883811208e-06
2024-04-22 05:13:52 - INFO :       moral_permissibility: Total Accuracy (26, 50, 0.52)
2024-04-22 05:13:52 - INFO :       
==================Finish================

2024-04-22 05:13:52 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:13:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:13:52 - INFO :       DATASET: tasksource/bigbench movie_dialog_same_or_different
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.97s/it]
2024-04-22 05:14:01 - INFO :       Use taylor pruner...
2024-04-22 05:14:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:14:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:14:02 - INFO :       Start Pruning
2024-04-22 05:14:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:14:04 - INFO :       Loss = 12.4375
2024-04-22 05:14:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:14:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:14:07 - INFO :       movie_dialog_same_or_different: Total Sparsity 1.3584266110483244e-06
2024-04-22 05:14:52 - INFO :       movie_dialog_same_or_different: Total Accuracy (23, 50, 0.46)
2024-04-22 05:14:52 - INFO :       
==================Finish================

2024-04-22 05:14:52 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:14:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:14:52 - INFO :       DATASET: tasksource/bigbench movie_recommendation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.93s/it]
2024-04-22 05:15:04 - INFO :       Use taylor pruner...
2024-04-22 05:15:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:15:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:15:05 - INFO :       Start Pruning
2024-04-22 05:15:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:15:07 - INFO :       Loss = 13.328125
2024-04-22 05:15:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:15:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:15:11 - INFO :       movie_recommendation: Total Sparsity 1.3568353885919015e-06
2024-04-22 05:15:53 - INFO :       movie_recommendation: Total Accuracy (21, 50, 0.42)
2024-04-22 05:15:53 - INFO :       
==================Finish================

2024-04-22 05:15:53 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:15:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:15:53 - INFO :       DATASET: tasksource/bigbench navigate
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.17s/it]
2024-04-22 05:16:07 - INFO :       Use taylor pruner...
2024-04-22 05:16:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:16:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:16:07 - INFO :       Start Pruning
2024-04-22 05:16:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:16:10 - INFO :       Loss = 14.4375
2024-04-22 05:16:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:16:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:16:14 - INFO :       navigate: Total Sparsity 1.3581083665570398e-06
2024-04-22 05:16:59 - INFO :       navigate: Total Accuracy (30, 50, 0.6)
2024-04-22 05:16:59 - INFO :       
==================Finish================

2024-04-22 05:16:59 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:16:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:16:59 - INFO :       DATASET: tasksource/bigbench nonsense_words_grammar
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.74s/it]
2024-04-22 05:17:11 - INFO :       Use taylor pruner...
2024-04-22 05:17:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:17:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:17:11 - INFO :       Start Pruning
2024-04-22 05:17:12 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:17:13 - INFO :       Loss = 13.5390625
2024-04-22 05:17:15 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:17:15 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:17:16 - INFO :       nonsense_words_grammar: Total Sparsity 1.3573127553288283e-06
2024-04-22 05:17:30 - INFO :       nonsense_words_grammar: Total Accuracy (6, 16, 0.375)
2024-04-22 05:17:30 - INFO :       
==================Finish================

2024-04-22 05:17:30 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:17:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:17:30 - INFO :       DATASET: tasksource/bigbench novel_concepts
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  1.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:04<00:00,  2.08s/it]
2024-04-22 05:17:41 - INFO :       Use taylor pruner...
2024-04-22 05:17:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:17:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:17:41 - INFO :       Start Pruning
2024-04-22 05:17:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:17:44 - INFO :       Loss = 11.578125
2024-04-22 05:17:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:17:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:17:47 - INFO :       novel_concepts: Total Sparsity 1.3598587112591052e-06
2024-04-22 05:18:02 - INFO :       novel_concepts: Total Accuracy (5, 16, 0.3125)
2024-04-22 05:18:02 - INFO :       
==================Finish================

2024-04-22 05:18:02 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:18:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:18:02 - INFO :       DATASET: tasksource/bigbench odd_one_out
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:03<00:00,  1.81s/it]
2024-04-22 05:18:16 - INFO :       Use taylor pruner...
2024-04-22 05:18:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:18:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:18:17 - INFO :       Start Pruning
2024-04-22 05:18:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:18:19 - INFO :       Loss = 14.0625
2024-04-22 05:18:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:18:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:18:22 - INFO :       odd_one_out: Total Sparsity 1.3574718775744707e-06
2024-04-22 05:18:37 - INFO :       odd_one_out: Total Accuracy (3, 17, 0.17647058823529413)
2024-04-22 05:18:37 - INFO :       
==================Finish================

2024-04-22 05:18:37 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:18:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:18:37 - INFO :       DATASET: tasksource/bigbench parsinlu_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.12s/it]
2024-04-22 05:18:58 - INFO :       Use taylor pruner...
2024-04-22 05:18:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:18:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:18:59 - INFO :       Start Pruning
2024-04-22 05:19:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:19:01 - INFO :       Loss = 9.375
2024-04-22 05:19:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:19:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:19:05 - INFO :       parsinlu_qa: Total Sparsity 1.3577901220657553e-06
2024-04-22 05:19:49 - INFO :       parsinlu_qa: Total Accuracy (15, 50, 0.3)
2024-04-22 05:19:49 - INFO :       
==================Finish================

2024-04-22 05:19:49 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:19:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:19:49 - INFO :       DATASET: tasksource/bigbench penguins_in_a_table
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:02<00:02,  2.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.52s/it]
2024-04-22 05:20:06 - INFO :       Use taylor pruner...
2024-04-22 05:20:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:20:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:20:07 - INFO :       Start Pruning
2024-04-22 05:20:08 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:20:09 - INFO :       Loss = 8.65625
2024-04-22 05:20:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:20:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:20:14 - INFO :       penguins_in_a_table: Total Sparsity 1.3542894326616245e-06
2024-04-22 05:20:45 - INFO :       penguins_in_a_table: Total Accuracy (10, 29, 0.3448275862068966)
2024-04-22 05:20:45 - INFO :       
==================Finish================

2024-04-22 05:20:45 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:20:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:20:45 - INFO :       DATASET: tasksource/bigbench persian_idioms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.76s/it]
2024-04-22 05:21:09 - INFO :       Use taylor pruner...
2024-04-22 05:21:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:21:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:21:09 - INFO :       Start Pruning
2024-04-22 05:21:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:21:12 - INFO :       Loss = 11.734375
2024-04-22 05:21:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:21:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:21:17 - INFO :       persian_idioms: Total Sparsity 1.3566762663462592e-06
2024-04-22 05:21:33 - INFO :       persian_idioms: Total Accuracy (4, 16, 0.25)
2024-04-22 05:21:33 - INFO :       
==================Finish================

2024-04-22 05:21:33 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:21:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:21:33 - INFO :       DATASET: tasksource/bigbench phrase_relatedness
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.20s/it]
2024-04-22 05:21:58 - INFO :       Use taylor pruner...
2024-04-22 05:21:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:21:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:21:58 - INFO :       Start Pruning
2024-04-22 05:22:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:22:01 - INFO :       Loss = 13.3515625
2024-04-22 05:22:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:22:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:22:05 - INFO :       phrase_relatedness: Total Sparsity 1.3589039777852514e-06
2024-04-22 05:22:27 - INFO :       phrase_relatedness: Total Accuracy (11, 20, 0.55)
2024-04-22 05:22:27 - INFO :       
==================Finish================

2024-04-22 05:22:27 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:22:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:22:27 - INFO :       DATASET: tasksource/bigbench physical_intuition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.39s/it]
2024-04-22 05:22:52 - INFO :       Use taylor pruner...
2024-04-22 05:22:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:22:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:22:53 - INFO :       Start Pruning
2024-04-22 05:22:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:22:57 - INFO :       Loss = 12.53125
2024-04-22 05:22:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:22:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:23:01 - INFO :       physical_intuition: Total Sparsity 1.3573127553288283e-06
2024-04-22 05:23:17 - INFO :       physical_intuition: Total Accuracy (5, 16, 0.3125)
2024-04-22 05:23:17 - INFO :       
==================Finish================

2024-04-22 05:23:17 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:23:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:23:17 - INFO :       DATASET: tasksource/bigbench physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.93s/it]
2024-04-22 05:23:38 - INFO :       Use taylor pruner...
2024-04-22 05:23:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:23:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:23:39 - INFO :       Start Pruning
2024-04-22 05:23:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:23:42 - INFO :       Loss = 9.6875
2024-04-22 05:23:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:23:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:23:47 - INFO :       physics: Total Sparsity 1.3598587112591052e-06
2024-04-22 05:24:37 - INFO :       physics: Total Accuracy (40, 45, 0.8888888888888888)
2024-04-22 05:24:37 - INFO :       
==================Finish================

2024-04-22 05:24:37 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:24:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:24:37 - INFO :       DATASET: tasksource/bigbench play_dialog_same_or_different
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.92s/it]
2024-04-22 05:24:57 - INFO :       Use taylor pruner...
2024-04-22 05:24:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:24:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:24:58 - INFO :       Start Pruning
2024-04-22 05:24:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:25:00 - INFO :       Loss = 9.1953125
2024-04-22 05:25:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:25:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:25:04 - INFO :       play_dialog_same_or_different: Total Sparsity 1.3541303104159823e-06
2024-04-22 05:26:02 - INFO :       play_dialog_same_or_different: Total Accuracy (16, 50, 0.32)
2024-04-22 05:26:02 - INFO :       
==================Finish================

2024-04-22 05:26:02 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:26:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:26:02 - INFO :       DATASET: tasksource/bigbench presuppositions_as_nli
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.25s/it]
2024-04-22 05:26:24 - INFO :       Use taylor pruner...
2024-04-22 05:26:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:26:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:26:25 - INFO :       Start Pruning
2024-04-22 05:26:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:26:28 - INFO :       Loss = 10.78125
2024-04-22 05:26:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:26:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:26:32 - INFO :       presuppositions_as_nli: Total Sparsity 1.3574718775744707e-06
2024-04-22 05:27:25 - INFO :       presuppositions_as_nli: Total Accuracy (17, 50, 0.34)
2024-04-22 05:27:25 - INFO :       
==================Finish================

2024-04-22 05:27:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:27:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:27:25 - INFO :       DATASET: tasksource/bigbench question_selection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.12s/it]
2024-04-22 05:27:47 - INFO :       Use taylor pruner...
2024-04-22 05:27:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:27:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:27:48 - INFO :       Start Pruning
2024-04-22 05:27:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:27:52 - INFO :       Loss = 6.015625
2024-04-22 05:27:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:27:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:27:56 - INFO :       question_selection: Total Sparsity 1.3534938214334132e-06
2024-04-22 05:28:57 - INFO :       question_selection: Total Accuracy (32, 50, 0.64)
2024-04-22 05:28:58 - INFO :       
==================Finish================

2024-04-22 05:28:58 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:28:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:28:58 - INFO :       DATASET: tasksource/bigbench reasoning_about_colored_objects
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.26s/it]
2024-04-22 05:29:19 - INFO :       Use taylor pruner...
2024-04-22 05:29:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:29:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:29:20 - INFO :       Start Pruning
2024-04-22 05:29:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:29:23 - INFO :       Loss = 11.0546875
2024-04-22 05:29:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:29:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:29:27 - INFO :       reasoning_about_colored_objects: Total Sparsity 1.3574718775744707e-06
2024-04-22 05:30:23 - INFO :       reasoning_about_colored_objects: Total Accuracy (12, 50, 0.24)
2024-04-22 05:30:23 - INFO :       
==================Finish================

2024-04-22 05:30:23 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:30:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:30:23 - INFO :       DATASET: tasksource/bigbench riddle_sense
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.97s/it]
2024-04-22 05:30:44 - INFO :       Use taylor pruner...
2024-04-22 05:30:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:30:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:30:45 - INFO :       Start Pruning
2024-04-22 05:30:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:30:48 - INFO :       Loss = 13.4140625
2024-04-22 05:30:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:30:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:30:52 - INFO :       riddle_sense: Total Sparsity 1.359699589013463e-06
2024-04-22 05:31:09 - INFO :       riddle_sense: Total Accuracy (2, 16, 0.125)
2024-04-22 05:31:09 - INFO :       
==================Finish================

2024-04-22 05:31:09 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:31:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:31:09 - INFO :       DATASET: tasksource/bigbench ruin_names
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.65s/it]
2024-04-22 05:31:34 - INFO :       Use taylor pruner...
2024-04-22 05:31:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:31:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:31:35 - INFO :       Start Pruning
2024-04-22 05:31:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:31:42 - INFO :       Loss = 12.4765625
2024-04-22 05:31:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:31:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:31:46 - INFO :       ruin_names: Total Sparsity 1.357630999820113e-06
2024-04-22 05:32:40 - INFO :       ruin_names: Total Accuracy (6, 50, 0.12)
2024-04-22 05:32:40 - INFO :       
==================Finish================

2024-04-22 05:32:40 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:32:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:32:40 - INFO :       DATASET: tasksource/bigbench salient_translation_error_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.53s/it]
2024-04-22 05:33:07 - INFO :       Use taylor pruner...
2024-04-22 05:33:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:33:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:33:07 - INFO :       Start Pruning
2024-04-22 05:33:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:33:17 - INFO :       Loss = 8.140625
2024-04-22 05:33:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:33:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:33:21 - INFO :       salient_translation_error_detection: Total Sparsity 1.3577901220657553e-06
2024-04-22 05:34:19 - INFO :       salient_translation_error_detection: Total Accuracy (11, 50, 0.22)
2024-04-22 05:34:19 - INFO :       
==================Finish================

2024-04-22 05:34:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:34:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:34:19 - INFO :       DATASET: tasksource/bigbench sentence_ambiguity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.03s/it]
2024-04-22 05:34:47 - INFO :       Use taylor pruner...
2024-04-22 05:34:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:34:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:34:47 - INFO :       Start Pruning
2024-04-22 05:34:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:34:51 - INFO :       Loss = 14.3125
2024-04-22 05:34:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:34:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:34:55 - INFO :       sentence_ambiguity: Total Sparsity 1.357630999820113e-06
2024-04-22 05:35:11 - INFO :       sentence_ambiguity: Total Accuracy (10, 16, 0.625)
2024-04-22 05:35:11 - INFO :       
==================Finish================

2024-04-22 05:35:11 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:35:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:35:11 - INFO :       DATASET: tasksource/bigbench similarities_abstraction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.09s/it]
2024-04-22 05:35:33 - INFO :       Use taylor pruner...
2024-04-22 05:35:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:35:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:35:34 - INFO :       Start Pruning
2024-04-22 05:35:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:35:36 - INFO :       Loss = 13.109375
2024-04-22 05:35:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:35:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:35:41 - INFO :       similarities_abstraction: Total Sparsity 1.3604952002416743e-06
2024-04-22 05:35:58 - INFO :       similarities_abstraction: Total Accuracy (9, 16, 0.5625)
2024-04-22 05:35:58 - INFO :       
==================Finish================

2024-04-22 05:35:58 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:35:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:35:58 - INFO :       DATASET: tasksource/bigbench simple_ethical_questions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.17s/it]
2024-04-22 05:36:21 - INFO :       Use taylor pruner...
2024-04-22 05:36:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:36:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:36:22 - INFO :       Start Pruning
2024-04-22 05:36:25 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:36:26 - INFO :       Loss = 11.203125
2024-04-22 05:36:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:36:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:36:31 - INFO :       simple_ethical_questions: Total Sparsity 1.3552441661354783e-06
2024-04-22 05:36:56 - INFO :       simple_ethical_questions: Total Accuracy (19, 23, 0.8260869565217391)
2024-04-22 05:36:56 - INFO :       
==================Finish================

2024-04-22 05:36:56 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:36:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:36:56 - INFO :       DATASET: tasksource/bigbench snarks
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.19s/it]
2024-04-22 05:37:18 - INFO :       Use taylor pruner...
2024-04-22 05:37:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:37:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:37:19 - INFO :       Start Pruning
2024-04-22 05:37:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:37:24 - INFO :       Loss = 13.7578125
2024-04-22 05:37:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:37:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:37:28 - INFO :       snarks: Total Sparsity 1.3598587112591052e-06
2024-04-22 05:38:08 - INFO :       snarks: Total Accuracy (11, 36, 0.3055555555555556)
2024-04-22 05:38:09 - INFO :       
==================Finish================

2024-04-22 05:38:09 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:38:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:38:09 - INFO :       DATASET: tasksource/bigbench social_iqa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.36s/it]
2024-04-22 05:38:33 - INFO :       Use taylor pruner...
2024-04-22 05:38:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:38:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:38:34 - INFO :       Start Pruning
2024-04-22 05:38:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:38:41 - INFO :       Loss = 13.3125
2024-04-22 05:38:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:38:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:38:46 - INFO :       social_iqa: Total Sparsity 1.3574718775744707e-06
2024-04-22 05:39:36 - INFO :       social_iqa: Total Accuracy (21, 50, 0.42)
2024-04-22 05:39:36 - INFO :       
==================Finish================

2024-04-22 05:39:36 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:39:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:39:36 - INFO :       DATASET: tasksource/bigbench social_support
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.05s/it]
2024-04-22 05:39:59 - INFO :       Use taylor pruner...
2024-04-22 05:39:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:39:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:40:00 - INFO :       Start Pruning
2024-04-22 05:40:08 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:40:09 - INFO :       Loss = 13.234375
2024-04-22 05:40:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:40:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:40:14 - INFO :       social_support: Total Sparsity 1.3589039777852514e-06
2024-04-22 05:41:07 - INFO :       social_support: Total Accuracy (29, 50, 0.58)
2024-04-22 05:41:07 - INFO :       
==================Finish================

2024-04-22 05:41:07 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:41:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:41:07 - INFO :       DATASET: tasksource/bigbench sports_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.80s/it]
2024-04-22 05:41:34 - INFO :       Use taylor pruner...
2024-04-22 05:41:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:41:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:41:35 - INFO :       Start Pruning
2024-04-22 05:42:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:42:10 - INFO :       Loss = 15.15625
2024-04-22 05:42:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:42:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:42:14 - INFO :       sports_understanding: Total Sparsity 1.355562410626763e-06
2024-04-22 05:43:05 - INFO :       sports_understanding: Total Accuracy (29, 50, 0.58)
2024-04-22 05:43:05 - INFO :       
==================Finish================

2024-04-22 05:43:05 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:43:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:43:05 - INFO :       DATASET: tasksource/bigbench strange_stories
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.01s/it]
2024-04-22 05:43:29 - INFO :       Use taylor pruner...
2024-04-22 05:43:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:43:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:43:30 - INFO :       Start Pruning
2024-04-22 05:43:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:43:43 - INFO :       Loss = 10.8828125
2024-04-22 05:43:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:43:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:43:47 - INFO :       strange_stories: Total Sparsity 1.3573127553288283e-06
2024-04-22 05:44:22 - INFO :       strange_stories: Total Accuracy (18, 34, 0.5294117647058824)
2024-04-22 05:44:22 - INFO :       
==================Finish================

2024-04-22 05:44:22 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:44:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:44:22 - INFO :       DATASET: tasksource/bigbench strategyqa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.49s/it]
2024-04-22 05:44:49 - INFO :       Use taylor pruner...
2024-04-22 05:44:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:44:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:44:50 - INFO :       Start Pruning
2024-04-22 05:45:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:45:04 - INFO :       Loss = 14.515625
2024-04-22 05:45:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:45:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:45:09 - INFO :       strategyqa: Total Sparsity 1.35397118817034e-06
2024-04-22 05:46:02 - INFO :       strategyqa: Total Accuracy (29, 50, 0.58)
2024-04-22 05:46:02 - INFO :       
==================Finish================

2024-04-22 05:46:02 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:46:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:46:02 - INFO :       DATASET: tasksource/bigbench suicide_risk
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.80s/it]
2024-04-22 05:46:25 - INFO :       Use taylor pruner...
2024-04-22 05:46:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:46:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:46:26 - INFO :       Start Pruning
2024-04-22 05:46:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:46:32 - INFO :       Loss = 8.953125
2024-04-22 05:46:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:46:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:46:36 - INFO :       suicide_risk: Total Sparsity 1.3557215328724054e-06
2024-04-22 05:46:53 - INFO :       suicide_risk: Total Accuracy (4, 16, 0.25)
2024-04-22 05:46:53 - INFO :       
==================Finish================

2024-04-22 05:46:53 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:46:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:46:53 - INFO :       DATASET: tasksource/bigbench swahili_english_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.33s/it]
2024-04-22 05:47:16 - INFO :       Use taylor pruner...
2024-04-22 05:47:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:47:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:47:17 - INFO :       Start Pruning
2024-04-22 05:47:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:47:23 - INFO :       Loss = 10.7734375
2024-04-22 05:47:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:47:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:47:27 - INFO :       swahili_english_proverbs: Total Sparsity 1.355562410626763e-06
2024-04-22 05:48:00 - INFO :       swahili_english_proverbs: Total Accuracy (16, 30, 0.5333333333333333)
2024-04-22 05:48:00 - INFO :       
==================Finish================

2024-04-22 05:48:00 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:48:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:48:00 - INFO :       DATASET: tasksource/bigbench swedish_to_german_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.02s/it]
2024-04-22 05:48:24 - INFO :       Use taylor pruner...
2024-04-22 05:48:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:48:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:48:24 - INFO :       Start Pruning
2024-04-22 05:48:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:48:30 - INFO :       Loss = 11.203125
2024-04-22 05:48:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:48:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:48:35 - INFO :       swedish_to_german_proverbs: Total Sparsity 1.3569945108375437e-06
2024-04-22 05:48:51 - INFO :       swedish_to_german_proverbs: Total Accuracy (7, 16, 0.4375)
2024-04-22 05:48:51 - INFO :       
==================Finish================

2024-04-22 05:48:51 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:48:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:48:51 - INFO :       DATASET: tasksource/bigbench symbol_interpretation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.85s/it]
2024-04-22 05:49:16 - INFO :       Use taylor pruner...
2024-04-22 05:49:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:49:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:49:16 - INFO :       Start Pruning
2024-04-22 05:49:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:49:23 - INFO :       Loss = 4.46484375
2024-04-22 05:49:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:49:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:49:28 - INFO :       symbol_interpretation: Total Sparsity 1.3577901220657553e-06
2024-04-22 05:50:43 - INFO :       symbol_interpretation: Total Accuracy (16, 50, 0.32)
2024-04-22 05:50:43 - INFO :       
==================Finish================

2024-04-22 05:50:43 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:50:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:50:43 - INFO :       DATASET: tasksource/bigbench temporal_sequences
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.61s/it]
2024-04-22 05:51:08 - INFO :       Use taylor pruner...
2024-04-22 05:51:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:51:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:51:09 - INFO :       Start Pruning
2024-04-22 05:51:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:51:15 - INFO :       Loss = 7.87109375
2024-04-22 05:51:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:51:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:51:20 - INFO :       temporal_sequences: Total Sparsity 1.3601769557503897e-06
2024-04-22 05:52:14 - INFO :       temporal_sequences: Total Accuracy (13, 50, 0.26)
2024-04-22 05:52:14 - INFO :       
==================Finish================

2024-04-22 05:52:14 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:52:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:52:14 - INFO :       DATASET: tasksource/bigbench timedial
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.98s/it]
2024-04-22 05:52:38 - INFO :       Use taylor pruner...
2024-04-22 05:52:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:52:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:52:39 - INFO :       Start Pruning
2024-04-22 05:52:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:52:51 - INFO :       Loss = 7.140625
2024-04-22 05:52:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:52:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:52:56 - INFO :       timedial: Total Sparsity 1.3573127553288283e-06
2024-04-22 05:53:54 - INFO :       timedial: Total Accuracy (11, 50, 0.22)
2024-04-22 05:53:55 - INFO :       
==================Finish================

2024-04-22 05:53:55 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:53:55 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:53:55 - INFO :       DATASET: tasksource/bigbench tracking_shuffled_objects
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.28s/it]
2024-04-22 05:54:27 - INFO :       Use taylor pruner...
2024-04-22 05:54:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:54:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:54:28 - INFO :       Start Pruning
2024-04-22 05:54:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:54:46 - INFO :       Loss = 7.94140625
2024-04-22 05:54:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:54:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:54:50 - INFO :       tracking_shuffled_objects: Total Sparsity 1.3526982102052016e-06
2024-04-22 05:55:43 - INFO :       tracking_shuffled_objects: Total Accuracy (6, 50, 0.12)
2024-04-22 05:55:43 - INFO :       
==================Finish================

2024-04-22 05:55:43 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:55:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:55:43 - INFO :       DATASET: tasksource/bigbench understanding_fables
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.83s/it]
2024-04-22 05:56:11 - INFO :       Use taylor pruner...
2024-04-22 05:56:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:56:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:56:11 - INFO :       Start Pruning
2024-04-22 05:56:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:56:29 - INFO :       Loss = 7.1171875
2024-04-22 05:56:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:56:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:56:33 - INFO :       understanding_fables: Total Sparsity 1.3557215328724054e-06
2024-04-22 05:57:14 - INFO :       understanding_fables: Total Accuracy (11, 37, 0.2972972972972973)
2024-04-22 05:57:15 - INFO :       
==================Finish================

2024-04-22 05:57:15 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:57:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:57:15 - INFO :       DATASET: tasksource/bigbench undo_permutation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.88s/it]
2024-04-22 05:57:38 - INFO :       Use taylor pruner...
2024-04-22 05:57:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:57:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:57:39 - INFO :       Start Pruning
2024-04-22 05:57:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:57:46 - INFO :       Loss = 5.046875
2024-04-22 05:57:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:57:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:57:51 - INFO :       undo_permutation: Total Sparsity 1.3541303104159823e-06
2024-04-22 05:58:47 - INFO :       undo_permutation: Total Accuracy (23, 50, 0.46)
2024-04-22 05:58:47 - INFO :       
==================Finish================

2024-04-22 05:58:47 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:58:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:58:47 - INFO :       DATASET: tasksource/bigbench unit_interpretation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.91s/it]
2024-04-22 05:59:12 - INFO :       Use taylor pruner...
2024-04-22 05:59:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:59:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 05:59:13 - INFO :       Start Pruning
2024-04-22 05:59:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 05:59:20 - INFO :       Loss = 10.90625
2024-04-22 05:59:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 05:59:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 05:59:24 - INFO :       unit_interpretation: Total Sparsity 1.3589039777852514e-06
2024-04-22 05:59:44 - INFO :       unit_interpretation: Total Accuracy (4, 20, 0.2)
2024-04-22 05:59:44 - INFO :       
==================Finish================

2024-04-22 05:59:44 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 05:59:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 05:59:44 - INFO :       DATASET: tasksource/bigbench vitaminc_fact_verification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.77s/it]
2024-04-22 06:00:06 - INFO :       Use taylor pruner...
2024-04-22 06:00:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:00:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:00:07 - INFO :       Start Pruning
2024-04-22 06:00:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:00:12 - INFO :       Loss = 11.3359375
2024-04-22 06:00:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:00:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:00:16 - INFO :       vitaminc_fact_verification: Total Sparsity 1.3561988996093322e-06
2024-04-22 06:01:07 - INFO :       vitaminc_fact_verification: Total Accuracy (19, 50, 0.38)
2024-04-22 06:01:07 - INFO :       
==================Finish================

2024-04-22 06:01:07 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 06:01:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:01:07 - INFO :       DATASET: tasksource/bigbench what_is_the_tao
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.47s/it]
2024-04-22 06:01:32 - INFO :       Use taylor pruner...
2024-04-22 06:01:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:01:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:01:33 - INFO :       Start Pruning
2024-04-22 06:01:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:01:39 - INFO :       Loss = 12.328125
2024-04-22 06:01:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:01:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:01:43 - INFO :       what_is_the_tao: Total Sparsity 1.3589039777852514e-06
2024-04-22 06:02:00 - INFO :       what_is_the_tao: Total Accuracy (6, 16, 0.375)
2024-04-22 06:02:01 - INFO :       
==================Finish================

2024-04-22 06:02:01 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 06:02:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:02:01 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  6.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.23s/it]
2024-04-22 06:02:23 - INFO :       Use taylor pruner...
2024-04-22 06:02:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:02:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:02:24 - INFO :       Start Pruning
2024-04-22 06:02:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:02:29 - INFO :       Loss = 1.44921875
2024-04-22 06:02:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:02:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:02:33 - INFO :       which_wiki_edit: Total Sparsity 1.35190259897699e-06
2024-04-22 06:04:23 - INFO :       which_wiki_edit: Total Accuracy (27, 50, 0.54)
2024-04-22 06:04:24 - INFO :       
==================Finish================

2024-04-22 06:04:24 - INFO :       Memory Requirement: 16809.46826171875 MiB

2024-04-22 06:04:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:04:24 - INFO :       DATASET: tasksource/bigbench winowhy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.92s/it]
2024-04-22 06:04:47 - INFO :       Use taylor pruner...
2024-04-22 06:04:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:04:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:04:48 - INFO :       Start Pruning
2024-04-22 06:04:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:04:56 - INFO :       Loss = 14.015625
2024-04-22 06:04:58 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:04:58 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:05:00 - INFO :       winowhy: Total Sparsity 1.358744855539609e-06
2024-04-22 06:05:51 - INFO :       winowhy: Total Accuracy (25, 50, 0.5)
2024-04-22 06:05:51 - INFO :       
==================Finish================

2024-04-22 06:05:51 - INFO :       Memory Requirement: 16777.79052734375 MiB

2024-04-22 06:05:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:05:51 - INFO :       DATASET: tasksource/mmlu abstract_algebra
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.34s/it]
2024-04-22 06:06:18 - INFO :       Use taylor pruner...
2024-04-22 06:06:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:06:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:06:19 - INFO :       Start Pruning
2024-04-22 06:06:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:06:45 - INFO :       Loss = 13.75
2024-04-22 06:06:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:06:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:06:49 - INFO :       abstract_algebra: Total Sparsity 1.357153633083186e-06
2024-04-22 06:07:02 - INFO :       abstract_algebra: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-22 06:07:02 - INFO :       
==================Finish================

2024-04-22 06:07:02 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:07:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:07:02 - INFO :       DATASET: tasksource/mmlu anatomy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.79s/it]
2024-04-22 06:07:27 - INFO :       Use taylor pruner...
2024-04-22 06:07:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:07:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:07:28 - INFO :       Start Pruning
2024-04-22 06:07:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:07:39 - INFO :       Loss = 14.4296875
2024-04-22 06:07:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:07:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:07:43 - INFO :       anatomy: Total Sparsity 1.358744855539609e-06
2024-04-22 06:07:58 - INFO :       anatomy: Total Accuracy (8, 14, 0.5714285714285714)
2024-04-22 06:07:58 - INFO :       
==================Finish================

2024-04-22 06:07:58 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:07:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:07:58 - INFO :       DATASET: tasksource/mmlu astronomy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.11s/it]
2024-04-22 06:08:22 - INFO :       Use taylor pruner...
2024-04-22 06:08:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:08:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:08:23 - INFO :       Start Pruning
2024-04-22 06:08:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:08:31 - INFO :       Loss = 14.4296875
2024-04-22 06:08:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:08:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:08:36 - INFO :       astronomy: Total Sparsity 1.357630999820113e-06
2024-04-22 06:08:53 - INFO :       astronomy: Total Accuracy (5, 16, 0.3125)
2024-04-22 06:08:53 - INFO :       
==================Finish================

2024-04-22 06:08:53 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:08:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:08:53 - INFO :       DATASET: tasksource/mmlu business_ethics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.79s/it]
2024-04-22 06:09:18 - INFO :       Use taylor pruner...
2024-04-22 06:09:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:09:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:09:19 - INFO :       Start Pruning
2024-04-22 06:09:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:09:45 - INFO :       Loss = 13.8984375
2024-04-22 06:09:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:09:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:09:50 - INFO :       business_ethics: Total Sparsity 1.359699589013463e-06
2024-04-22 06:10:03 - INFO :       business_ethics: Total Accuracy (7, 11, 0.6363636363636364)
2024-04-22 06:10:03 - INFO :       
==================Finish================

2024-04-22 06:10:03 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:10:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:10:03 - INFO :       DATASET: tasksource/mmlu clinical_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.60s/it]
2024-04-22 06:10:26 - INFO :       Use taylor pruner...
2024-04-22 06:10:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:10:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:10:27 - INFO :       Start Pruning
2024-04-22 06:10:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:10:34 - INFO :       Loss = 13.7734375
2024-04-22 06:10:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:10:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:10:37 - INFO :       clinical_knowledge: Total Sparsity 1.3566762663462592e-06
2024-04-22 06:11:10 - INFO :       clinical_knowledge: Total Accuracy (13, 29, 0.4482758620689655)
2024-04-22 06:11:10 - INFO :       
==================Finish================

2024-04-22 06:11:10 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:11:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:11:10 - INFO :       DATASET: tasksource/mmlu college_biology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.58s/it]
2024-04-22 06:11:35 - INFO :       Use taylor pruner...
2024-04-22 06:11:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:11:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:11:36 - INFO :       Start Pruning
2024-04-22 06:11:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:11:42 - INFO :       Loss = 14.1640625
2024-04-22 06:11:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:11:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:11:47 - INFO :       college_biology: Total Sparsity 1.358267488802682e-06
2024-04-22 06:12:04 - INFO :       college_biology: Total Accuracy (10, 16, 0.625)
2024-04-22 06:12:04 - INFO :       
==================Finish================

2024-04-22 06:12:04 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:12:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:12:04 - INFO :       DATASET: tasksource/mmlu college_chemistry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.59s/it]
2024-04-22 06:12:28 - INFO :       Use taylor pruner...
2024-04-22 06:12:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:12:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:12:29 - INFO :       Start Pruning
num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-22 06:12:35 - WARNING :       num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-22 06:12:35 - WARNING :       num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-22 06:12:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:12:36 - INFO :       Loss = 14.1953125
2024-04-22 06:12:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:12:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:12:40 - INFO :       college_chemistry: Total Sparsity 1.3547667993985515e-06
2024-04-22 06:12:48 - INFO :       college_chemistry: Total Accuracy (2, 8, 0.25)
2024-04-22 06:12:48 - INFO :       
==================Finish================

2024-04-22 06:12:48 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:12:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:12:48 - INFO :       DATASET: tasksource/mmlu college_computer_science
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.06s/it]
2024-04-22 06:13:12 - INFO :       Use taylor pruner...
2024-04-22 06:13:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:13:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:13:13 - INFO :       Start Pruning
2024-04-22 06:13:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:13:27 - INFO :       Loss = 13.9296875
2024-04-22 06:13:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:13:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:13:32 - INFO :       college_computer_science: Total Sparsity 1.358744855539609e-06
2024-04-22 06:13:44 - INFO :       college_computer_science: Total Accuracy (2, 11, 0.18181818181818182)
2024-04-22 06:13:44 - INFO :       
==================Finish================

2024-04-22 06:13:44 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:13:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:13:44 - INFO :       DATASET: tasksource/mmlu college_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.47s/it]
2024-04-22 06:14:10 - INFO :       Use taylor pruner...
2024-04-22 06:14:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:14:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:14:11 - INFO :       Start Pruning
2024-04-22 06:14:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:14:20 - INFO :       Loss = 12.9140625
2024-04-22 06:14:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:14:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:14:24 - INFO :       college_mathematics: Total Sparsity 1.3617681782068128e-06
2024-04-22 06:14:36 - INFO :       college_mathematics: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-22 06:14:36 - INFO :       
==================Finish================

2024-04-22 06:14:36 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:14:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:14:36 - INFO :       DATASET: tasksource/mmlu college_medicine
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.36s/it]
2024-04-22 06:15:02 - INFO :       Use taylor pruner...
2024-04-22 06:15:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:15:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:15:03 - INFO :       Start Pruning
2024-04-22 06:15:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:15:12 - INFO :       Loss = 12.7734375
2024-04-22 06:15:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:15:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:15:16 - INFO :       college_medicine: Total Sparsity 1.3563580218549744e-06
2024-04-22 06:15:41 - INFO :       college_medicine: Total Accuracy (9, 22, 0.4090909090909091)
2024-04-22 06:15:41 - INFO :       
==================Finish================

2024-04-22 06:15:41 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:15:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:15:41 - INFO :       DATASET: tasksource/mmlu college_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.83s/it]
2024-04-22 06:16:09 - INFO :       Use taylor pruner...
2024-04-22 06:16:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:16:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:16:10 - INFO :       Start Pruning
2024-04-22 06:16:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:16:18 - INFO :       Loss = 13.03125
2024-04-22 06:16:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:16:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:16:23 - INFO :       college_physics: Total Sparsity 1.3584266110483244e-06
2024-04-22 06:16:35 - INFO :       college_physics: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-22 06:16:35 - INFO :       
==================Finish================

2024-04-22 06:16:35 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:16:35 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:16:35 - INFO :       DATASET: tasksource/mmlu computer_security
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.15s/it]
2024-04-22 06:16:59 - INFO :       Use taylor pruner...
2024-04-22 06:16:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:16:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:17:00 - INFO :       Start Pruning
2024-04-22 06:17:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:17:07 - INFO :       Loss = 13.8125
2024-04-22 06:17:10 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:17:10 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:17:12 - INFO :       computer_security: Total Sparsity 1.3581083665570398e-06
2024-04-22 06:17:22 - INFO :       computer_security: Total Accuracy (5, 11, 0.45454545454545453)
2024-04-22 06:17:22 - INFO :       
==================Finish================

2024-04-22 06:17:22 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:17:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:17:22 - INFO :       DATASET: tasksource/mmlu conceptual_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.65s/it]
2024-04-22 06:17:47 - INFO :       Use taylor pruner...
2024-04-22 06:17:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:17:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:17:48 - INFO :       Start Pruning
2024-04-22 06:17:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:17:55 - INFO :       Loss = 14.3984375
2024-04-22 06:17:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:17:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:17:59 - INFO :       conceptual_physics: Total Sparsity 1.3619273004524551e-06
2024-04-22 06:18:28 - INFO :       conceptual_physics: Total Accuracy (9, 26, 0.34615384615384615)
2024-04-22 06:18:28 - INFO :       
==================Finish================

2024-04-22 06:18:28 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:18:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:18:28 - INFO :       DATASET: tasksource/mmlu econometrics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.43s/it]
2024-04-22 06:18:53 - INFO :       Use taylor pruner...
2024-04-22 06:18:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:18:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:18:54 - INFO :       Start Pruning
2024-04-22 06:19:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:19:01 - INFO :       Loss = 13.0
2024-04-22 06:19:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:19:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:19:06 - INFO :       econometrics: Total Sparsity 1.3611316892242436e-06
2024-04-22 06:19:19 - INFO :       econometrics: Total Accuracy (2, 12, 0.16666666666666666)
2024-04-22 06:19:19 - INFO :       
==================Finish================

2024-04-22 06:19:19 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:19:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:19:19 - INFO :       DATASET: tasksource/mmlu electrical_engineering
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.00s/it]
2024-04-22 06:19:41 - INFO :       Use taylor pruner...
2024-04-22 06:19:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:19:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:19:41 - INFO :       Start Pruning
2024-04-22 06:19:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:19:49 - INFO :       Loss = 14.53125
2024-04-22 06:19:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:19:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:19:53 - INFO :       electrical_engineering: Total Sparsity 1.358744855539609e-06
2024-04-22 06:20:10 - INFO :       electrical_engineering: Total Accuracy (4, 16, 0.25)
2024-04-22 06:20:10 - INFO :       
==================Finish================

2024-04-22 06:20:10 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:20:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:20:10 - INFO :       DATASET: tasksource/mmlu elementary_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.32s/it]
2024-04-22 06:20:35 - INFO :       Use taylor pruner...
2024-04-22 06:20:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:20:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:20:36 - INFO :       Start Pruning
2024-04-22 06:20:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:20:42 - INFO :       Loss = 13.5390625
2024-04-22 06:20:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:20:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:20:47 - INFO :       elementary_mathematics: Total Sparsity 1.356517144100617e-06
2024-04-22 06:21:30 - INFO :       elementary_mathematics: Total Accuracy (12, 41, 0.2926829268292683)
2024-04-22 06:21:30 - INFO :       
==================Finish================

2024-04-22 06:21:30 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:21:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:21:30 - INFO :       DATASET: tasksource/mmlu formal_logic
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.23s/it]
2024-04-22 06:21:56 - INFO :       Use taylor pruner...
2024-04-22 06:21:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:21:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:21:57 - INFO :       Start Pruning
2024-04-22 06:22:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:22:04 - INFO :       Loss = 11.6875
2024-04-22 06:22:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:22:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:22:08 - INFO :       formal_logic: Total Sparsity 1.3593813445221782e-06
2024-04-22 06:22:24 - INFO :       formal_logic: Total Accuracy (2, 14, 0.14285714285714285)
2024-04-22 06:22:24 - INFO :       
==================Finish================

2024-04-22 06:22:24 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:22:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:22:24 - INFO :       DATASET: tasksource/mmlu global_facts
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.13s/it]
2024-04-22 06:22:47 - INFO :       Use taylor pruner...
2024-04-22 06:22:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:22:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:22:48 - INFO :       Start Pruning
2024-04-22 06:22:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:22:54 - INFO :       Loss = 13.546875
2024-04-22 06:22:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:22:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:22:58 - INFO :       global_facts: Total Sparsity 1.3593813445221782e-06
2024-04-22 06:23:09 - INFO :       global_facts: Total Accuracy (1, 10, 0.1)
2024-04-22 06:23:09 - INFO :       
==================Finish================

2024-04-22 06:23:09 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:23:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:23:09 - INFO :       DATASET: tasksource/mmlu high_school_biology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.42s/it]
2024-04-22 06:23:33 - INFO :       Use taylor pruner...
2024-04-22 06:23:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:23:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:23:33 - INFO :       Start Pruning
2024-04-22 06:23:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:23:40 - INFO :       Loss = 13.84375
2024-04-22 06:23:42 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:23:42 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:23:44 - INFO :       high_school_biology: Total Sparsity 1.3585857332939668e-06
2024-04-22 06:24:17 - INFO :       high_school_biology: Total Accuracy (13, 32, 0.40625)
2024-04-22 06:24:17 - INFO :       
==================Finish================

2024-04-22 06:24:17 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:24:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:24:17 - INFO :       DATASET: tasksource/mmlu high_school_chemistry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.63s/it]
2024-04-22 06:24:42 - INFO :       Use taylor pruner...
2024-04-22 06:24:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:24:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:24:42 - INFO :       Start Pruning
2024-04-22 06:24:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:24:49 - INFO :       Loss = 13.0234375
2024-04-22 06:24:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:24:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:24:54 - INFO :       high_school_chemistry: Total Sparsity 1.3561988996093322e-06
2024-04-22 06:25:18 - INFO :       high_school_chemistry: Total Accuracy (4, 22, 0.18181818181818182)
2024-04-22 06:25:18 - INFO :       
==================Finish================

2024-04-22 06:25:18 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:25:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:25:18 - INFO :       DATASET: tasksource/mmlu high_school_computer_science
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.54s/it]
2024-04-22 06:25:43 - INFO :       Use taylor pruner...
2024-04-22 06:25:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:25:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:25:44 - INFO :       Start Pruning
num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-22 06:25:50 - WARNING :       num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-22 06:25:50 - WARNING :       num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-22 06:25:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:25:51 - INFO :       Loss = 13.1484375
2024-04-22 06:25:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:25:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:25:55 - INFO :       high_school_computer_science: Total Sparsity 1.3554032883811208e-06
2024-04-22 06:26:04 - INFO :       high_school_computer_science: Total Accuracy (5, 9, 0.5555555555555556)
2024-04-22 06:26:04 - INFO :       
==================Finish================

2024-04-22 06:26:04 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:26:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:26:04 - INFO :       DATASET: tasksource/mmlu high_school_european_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.85s/it]
2024-04-22 06:26:27 - INFO :       Use taylor pruner...
2024-04-22 06:26:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:26:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:26:28 - INFO :       Start Pruning
2024-04-22 06:26:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:26:34 - INFO :       Loss = 6.47265625
2024-04-22 06:26:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:26:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:26:39 - INFO :       high_school_european_history: Total Sparsity 1.3552441661354783e-06
2024-04-22 06:26:59 - INFO :       high_school_european_history: Total Accuracy (10, 18, 0.5555555555555556)
2024-04-22 06:26:59 - INFO :       
==================Finish================

2024-04-22 06:26:59 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:26:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:26:59 - INFO :       DATASET: tasksource/mmlu high_school_geography
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.09s/it]
2024-04-22 06:27:22 - INFO :       Use taylor pruner...
2024-04-22 06:27:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:27:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:27:23 - INFO :       Start Pruning
2024-04-22 06:27:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:27:31 - INFO :       Loss = 14.0859375
2024-04-22 06:27:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:27:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:27:36 - INFO :       high_school_geography: Total Sparsity 1.3568353885919015e-06
2024-04-22 06:28:01 - INFO :       high_school_geography: Total Accuracy (14, 22, 0.6363636363636364)
2024-04-22 06:28:01 - INFO :       
==================Finish================

2024-04-22 06:28:01 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:28:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:28:01 - INFO :       DATASET: tasksource/mmlu high_school_government_and_politics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.03s/it]
2024-04-22 06:28:25 - INFO :       Use taylor pruner...
2024-04-22 06:28:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:28:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:28:25 - INFO :       Start Pruning
2024-04-22 06:28:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:28:34 - INFO :       Loss = 14.0390625
2024-04-22 06:28:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:28:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:28:39 - INFO :       high_school_government_and_politics: Total Sparsity 1.3609725669786013e-06
2024-04-22 06:29:02 - INFO :       high_school_government_and_politics: Total Accuracy (9, 21, 0.42857142857142855)
2024-04-22 06:29:02 - INFO :       
==================Finish================

2024-04-22 06:29:02 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:29:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:29:02 - INFO :       DATASET: tasksource/mmlu high_school_macroeconomics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.30s/it]
2024-04-22 06:29:25 - INFO :       Use taylor pruner...
2024-04-22 06:29:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:29:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:29:26 - INFO :       Start Pruning
2024-04-22 06:29:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:29:32 - INFO :       Loss = 13.1015625
2024-04-22 06:29:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:29:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:29:37 - INFO :       high_school_macroeconomics: Total Sparsity 1.3561988996093322e-06
2024-04-22 06:30:24 - INFO :       high_school_macroeconomics: Total Accuracy (15, 43, 0.3488372093023256)
2024-04-22 06:30:24 - INFO :       
==================Finish================

2024-04-22 06:30:24 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:30:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:30:24 - INFO :       DATASET: tasksource/mmlu high_school_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.58s/it]
2024-04-22 06:30:49 - INFO :       Use taylor pruner...
2024-04-22 06:30:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:30:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:30:50 - INFO :       Start Pruning
2024-04-22 06:30:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:30:56 - INFO :       Loss = 12.7421875
2024-04-22 06:30:58 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:30:58 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:31:00 - INFO :       high_school_mathematics: Total Sparsity 1.3568353885919015e-06
2024-04-22 06:31:31 - INFO :       high_school_mathematics: Total Accuracy (6, 29, 0.20689655172413793)
2024-04-22 06:31:31 - INFO :       
==================Finish================

2024-04-22 06:31:31 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:31:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:31:31 - INFO :       DATASET: tasksource/mmlu high_school_microeconomics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.20s/it]
2024-04-22 06:31:55 - INFO :       Use taylor pruner...
2024-04-22 06:31:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:31:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:31:56 - INFO :       Start Pruning
2024-04-22 06:32:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:32:04 - INFO :       Loss = 13.765625
2024-04-22 06:32:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:32:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:32:09 - INFO :       high_school_microeconomics: Total Sparsity 1.3598587112591052e-06
2024-04-22 06:32:37 - INFO :       high_school_microeconomics: Total Accuracy (9, 26, 0.34615384615384615)
2024-04-22 06:32:37 - INFO :       
==================Finish================

2024-04-22 06:32:37 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:32:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:32:37 - INFO :       DATASET: tasksource/mmlu high_school_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.67s/it]
2024-04-22 06:33:00 - INFO :       Use taylor pruner...
2024-04-22 06:33:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:33:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:33:01 - INFO :       Start Pruning
2024-04-22 06:33:08 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:33:09 - INFO :       Loss = 11.984375
2024-04-22 06:33:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:33:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:33:14 - INFO :       high_school_physics: Total Sparsity 1.3573127553288283e-06
2024-04-22 06:33:33 - INFO :       high_school_physics: Total Accuracy (5, 17, 0.29411764705882354)
2024-04-22 06:33:33 - INFO :       
==================Finish================

2024-04-22 06:33:33 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:33:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:33:33 - INFO :       DATASET: tasksource/mmlu high_school_psychology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.91s/it]
2024-04-22 06:33:54 - INFO :       Use taylor pruner...
2024-04-22 06:33:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:33:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:33:55 - INFO :       Start Pruning
2024-04-22 06:34:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:34:02 - INFO :       Loss = 13.6015625
2024-04-22 06:34:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:34:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:34:07 - INFO :       high_school_psychology: Total Sparsity 1.3569945108375437e-06
2024-04-22 06:35:01 - INFO :       high_school_psychology: Total Accuracy (32, 50, 0.64)
2024-04-22 06:35:01 - INFO :       
==================Finish================

2024-04-22 06:35:01 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:35:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:35:01 - INFO :       DATASET: tasksource/mmlu high_school_statistics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.87s/it]
2024-04-22 06:35:25 - INFO :       Use taylor pruner...
2024-04-22 06:35:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:35:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:35:26 - INFO :       Start Pruning
2024-04-22 06:35:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:35:35 - INFO :       Loss = 12.3671875
2024-04-22 06:35:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:35:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:35:39 - INFO :       high_school_statistics: Total Sparsity 1.359699589013463e-06
2024-04-22 06:36:05 - INFO :       high_school_statistics: Total Accuracy (7, 23, 0.30434782608695654)
2024-04-22 06:36:05 - INFO :       
==================Finish================

2024-04-22 06:36:05 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:36:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:36:05 - INFO :       DATASET: tasksource/mmlu high_school_us_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.86s/it]
2024-04-22 06:36:31 - INFO :       Use taylor pruner...
2024-04-22 06:36:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:36:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:36:32 - INFO :       Start Pruning
2024-04-22 06:36:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:36:56 - INFO :       Loss = 8.1640625
2024-04-22 06:36:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:36:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:37:01 - INFO :       high_school_us_history: Total Sparsity 1.3569945108375437e-06
2024-04-22 06:37:26 - INFO :       high_school_us_history: Total Accuracy (12, 22, 0.5454545454545454)
2024-04-22 06:37:26 - INFO :       
==================Finish================

2024-04-22 06:37:26 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:37:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:37:26 - INFO :       DATASET: tasksource/mmlu high_school_world_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.09s/it]
2024-04-22 06:37:52 - INFO :       Use taylor pruner...
2024-04-22 06:37:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:37:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:37:53 - INFO :       Start Pruning
2024-04-22 06:37:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:38:00 - INFO :       Loss = 6.7890625
2024-04-22 06:38:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:38:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:38:05 - INFO :       high_school_world_history: Total Sparsity 1.3581083665570398e-06
2024-04-22 06:38:35 - INFO :       high_school_world_history: Total Accuracy (12, 26, 0.46153846153846156)
2024-04-22 06:38:35 - INFO :       
==================Finish================

2024-04-22 06:38:35 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:38:35 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:38:35 - INFO :       DATASET: tasksource/mmlu human_aging
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.55s/it]
2024-04-22 06:39:01 - INFO :       Use taylor pruner...
2024-04-22 06:39:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:39:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:39:02 - INFO :       Start Pruning
2024-04-22 06:39:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:39:06 - INFO :       Loss = 14.296875
2024-04-22 06:39:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:39:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:39:11 - INFO :       human_aging: Total Sparsity 1.3598587112591052e-06
2024-04-22 06:39:35 - INFO :       human_aging: Total Accuracy (10, 23, 0.43478260869565216)
2024-04-22 06:39:35 - INFO :       
==================Finish================

2024-04-22 06:39:35 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:39:35 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:39:35 - INFO :       DATASET: tasksource/mmlu human_sexuality
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.10s/it]
2024-04-22 06:39:59 - INFO :       Use taylor pruner...
2024-04-22 06:39:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:39:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:39:59 - INFO :       Start Pruning
2024-04-22 06:40:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:40:05 - INFO :       Loss = 13.75
2024-04-22 06:40:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:40:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:40:10 - INFO :       human_sexuality: Total Sparsity 1.3612908114698858e-06
2024-04-22 06:40:23 - INFO :       human_sexuality: Total Accuracy (4, 12, 0.3333333333333333)
2024-04-22 06:40:23 - INFO :       
==================Finish================

2024-04-22 06:40:23 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:40:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:40:23 - INFO :       DATASET: tasksource/mmlu international_law
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.77s/it]
2024-04-22 06:40:48 - INFO :       Use taylor pruner...
2024-04-22 06:40:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:40:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:40:49 - INFO :       Start Pruning
2024-04-22 06:41:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:41:57 - INFO :       Loss = 13.8125
2024-04-22 06:41:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:41:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:42:01 - INFO :       international_law: Total Sparsity 1.3579492443113975e-06
2024-04-22 06:42:15 - INFO :       international_law: Total Accuracy (11, 13, 0.8461538461538461)
2024-04-22 06:42:15 - INFO :       
==================Finish================

2024-04-22 06:42:15 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:42:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:42:15 - INFO :       DATASET: tasksource/mmlu jurisprudence
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.69s/it]
2024-04-22 06:43:14 - INFO :       Use taylor pruner...
2024-04-22 06:43:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:43:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:43:15 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-22 06:44:55 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-22 06:46:35 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-22 06:46:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:46:36 - INFO :       Loss = 14.375
2024-04-22 06:46:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:46:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:46:41 - INFO :       jurisprudence: Total Sparsity 1.359699589013463e-06
2024-04-22 06:46:53 - INFO :       jurisprudence: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-22 06:46:53 - INFO :       
==================Finish================

2024-04-22 06:46:53 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:46:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:46:53 - INFO :       DATASET: tasksource/mmlu logical_fallacies
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.08s/it]
2024-04-22 06:47:55 - INFO :       Use taylor pruner...
2024-04-22 06:47:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:47:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:47:55 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-22 06:49:35 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-22 06:51:16 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-22 06:51:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:51:17 - INFO :       Loss = 13.1953125
2024-04-22 06:51:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:51:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:51:21 - INFO :       logical_fallacies: Total Sparsity 1.3593813445221782e-06
2024-04-22 06:51:39 - INFO :       logical_fallacies: Total Accuracy (11, 18, 0.6111111111111112)
2024-04-22 06:51:39 - INFO :       
==================Finish================

2024-04-22 06:51:39 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:51:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:51:39 - INFO :       DATASET: tasksource/mmlu machine_learning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.37s/it]
2024-04-22 06:52:44 - INFO :       Use taylor pruner...
2024-04-22 06:52:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:52:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:52:44 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-22 06:54:25 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-22 06:58:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 06:58:07 - INFO :       Loss = 14.421875
2024-04-22 06:58:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 06:58:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 06:58:11 - INFO :       machine_learning: Total Sparsity 1.3584266110483244e-06
2024-04-22 06:58:22 - INFO :       machine_learning: Total Accuracy (2, 11, 0.18181818181818182)
2024-04-22 06:58:22 - INFO :       
==================Finish================

2024-04-22 06:58:22 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 06:58:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 06:58:22 - INFO :       DATASET: tasksource/mmlu management
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.52s/it]
2024-04-22 06:59:21 - INFO :       Use taylor pruner...
2024-04-22 06:59:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:59:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 06:59:22 - INFO :       Start Pruning
2024-04-22 07:01:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:01:48 - INFO :       Loss = 14.390625
2024-04-22 07:01:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:01:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:01:53 - INFO :       management: Total Sparsity 1.359222222276536e-06
2024-04-22 07:02:03 - INFO :       management: Total Accuracy (7, 11, 0.6363636363636364)
2024-04-22 07:02:03 - INFO :       
==================Finish================

2024-04-22 07:02:03 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:02:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:02:03 - INFO :       DATASET: tasksource/mmlu marketing
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.59s/it]
2024-04-22 07:02:47 - INFO :       Use taylor pruner...
2024-04-22 07:02:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:02:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:02:48 - INFO :       Start Pruning
2024-04-22 07:03:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:03:24 - INFO :       Loss = 14.3359375
2024-04-22 07:03:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:03:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:03:27 - INFO :       marketing: Total Sparsity 1.3579492443113975e-06
2024-04-22 07:03:53 - INFO :       marketing: Total Accuracy (19, 25, 0.76)
2024-04-22 07:03:53 - INFO :       
==================Finish================

2024-04-22 07:03:53 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:03:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:03:53 - INFO :       DATASET: tasksource/mmlu medical_genetics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.31s/it]
2024-04-22 07:04:30 - INFO :       Use taylor pruner...
2024-04-22 07:04:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:04:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:04:31 - INFO :       Start Pruning
2024-04-22 07:04:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:05:00 - INFO :       Loss = 14.0703125
2024-04-22 07:05:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:05:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:05:04 - INFO :       medical_genetics: Total Sparsity 1.3563580218549744e-06
2024-04-22 07:05:16 - INFO :       medical_genetics: Total Accuracy (8, 11, 0.7272727272727273)
2024-04-22 07:05:16 - INFO :       
==================Finish================

2024-04-22 07:05:16 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:05:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:05:16 - INFO :       DATASET: tasksource/mmlu miscellaneous
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.73s/it]
2024-04-22 07:05:56 - INFO :       Use taylor pruner...
2024-04-22 07:05:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:05:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:05:57 - INFO :       Start Pruning
2024-04-22 07:06:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:06:32 - INFO :       Loss = 11.8671875
2024-04-22 07:06:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:06:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:06:37 - INFO :       miscellaneous: Total Sparsity 1.3617681782068128e-06
2024-04-22 07:07:30 - INFO :       miscellaneous: Total Accuracy (30, 50, 0.6)
2024-04-22 07:07:30 - INFO :       
==================Finish================

2024-04-22 07:07:30 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:07:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:07:30 - INFO :       DATASET: tasksource/mmlu moral_disputes
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.47s/it]
2024-04-22 07:07:58 - INFO :       Use taylor pruner...
2024-04-22 07:07:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:07:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:07:59 - INFO :       Start Pruning
2024-04-22 07:08:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:08:11 - INFO :       Loss = 13.609375
2024-04-22 07:08:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:08:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:08:16 - INFO :       moral_disputes: Total Sparsity 1.358267488802682e-06
2024-04-22 07:08:58 - INFO :       moral_disputes: Total Accuracy (16, 38, 0.42105263157894735)
2024-04-22 07:08:58 - INFO :       
==================Finish================

2024-04-22 07:08:58 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:08:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:08:58 - INFO :       DATASET: tasksource/mmlu moral_scenarios
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.01s/it]
2024-04-22 07:09:20 - INFO :       Use taylor pruner...
2024-04-22 07:09:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:09:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:09:21 - INFO :       Start Pruning
2024-04-22 07:09:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:09:30 - INFO :       Loss = 12.2265625
2024-04-22 07:09:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:09:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:09:35 - INFO :       moral_scenarios: Total Sparsity 1.3577901220657553e-06
2024-04-22 07:10:29 - INFO :       moral_scenarios: Total Accuracy (0, 50, 0.0)
2024-04-22 07:10:29 - INFO :       
==================Finish================

2024-04-22 07:10:29 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:10:29 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:10:29 - INFO :       DATASET: tasksource/mmlu nutrition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.03s/it]
2024-04-22 07:10:56 - INFO :       Use taylor pruner...
2024-04-22 07:10:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:10:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:10:57 - INFO :       Start Pruning
2024-04-22 07:11:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:11:08 - INFO :       Loss = 13.9765625
2024-04-22 07:11:10 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:11:10 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:11:12 - INFO :       nutrition: Total Sparsity 1.3574718775744707e-06
2024-04-22 07:11:47 - INFO :       nutrition: Total Accuracy (18, 33, 0.5454545454545454)
2024-04-22 07:11:47 - INFO :       
==================Finish================

2024-04-22 07:11:47 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:11:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:11:47 - INFO :       DATASET: tasksource/mmlu philosophy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.84s/it]
2024-04-22 07:12:12 - INFO :       Use taylor pruner...
2024-04-22 07:12:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:12:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:12:13 - INFO :       Start Pruning
2024-04-22 07:12:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:12:24 - INFO :       Loss = 14.328125
2024-04-22 07:12:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:12:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:12:29 - INFO :       philosophy: Total Sparsity 1.359699589013463e-06
2024-04-22 07:13:04 - INFO :       philosophy: Total Accuracy (17, 34, 0.5)
2024-04-22 07:13:04 - INFO :       
==================Finish================

2024-04-22 07:13:04 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:13:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:13:04 - INFO :       DATASET: tasksource/mmlu prehistory
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.93s/it]
2024-04-22 07:13:30 - INFO :       Use taylor pruner...
2024-04-22 07:13:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:13:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:13:31 - INFO :       Start Pruning
2024-04-22 07:13:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:13:46 - INFO :       Loss = 13.5625
2024-04-22 07:13:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:13:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:13:51 - INFO :       prehistory: Total Sparsity 1.3558806551180476e-06
2024-04-22 07:14:26 - INFO :       prehistory: Total Accuracy (17, 35, 0.4857142857142857)
2024-04-22 07:14:26 - INFO :       
==================Finish================

2024-04-22 07:14:26 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:14:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:14:26 - INFO :       DATASET: tasksource/mmlu professional_accounting
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.91s/it]
2024-04-22 07:14:53 - INFO :       Use taylor pruner...
2024-04-22 07:14:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:14:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:14:53 - INFO :       Start Pruning
2024-04-22 07:15:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:15:03 - INFO :       Loss = 13.0390625
2024-04-22 07:15:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:15:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:15:07 - INFO :       professional_accounting: Total Sparsity 1.359699589013463e-06
2024-04-22 07:15:42 - INFO :       professional_accounting: Total Accuracy (11, 31, 0.3548387096774194)
2024-04-22 07:15:42 - INFO :       
==================Finish================

2024-04-22 07:15:42 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:15:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:15:42 - INFO :       DATASET: tasksource/mmlu professional_law
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.94s/it]
2024-04-22 07:16:06 - INFO :       Use taylor pruner...
2024-04-22 07:16:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:16:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:16:07 - INFO :       Start Pruning
2024-04-22 07:16:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:16:16 - INFO :       Loss = 10.3046875
2024-04-22 07:16:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:16:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:16:21 - INFO :       professional_law: Total Sparsity 1.3547667993985515e-06
2024-04-22 07:17:14 - INFO :       professional_law: Total Accuracy (12, 50, 0.24)
2024-04-22 07:17:14 - INFO :       
==================Finish================

2024-04-22 07:17:14 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:17:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:17:14 - INFO :       DATASET: tasksource/mmlu professional_medicine
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.05s/it]
2024-04-22 07:17:39 - INFO :       Use taylor pruner...
2024-04-22 07:17:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:17:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:17:40 - INFO :       Start Pruning
2024-04-22 07:17:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:17:48 - INFO :       Loss = 9.0390625
2024-04-22 07:17:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:17:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:17:53 - INFO :       professional_medicine: Total Sparsity 1.3609725669786013e-06
2024-04-22 07:18:27 - INFO :       professional_medicine: Total Accuracy (17, 31, 0.5483870967741935)
2024-04-22 07:18:27 - INFO :       
==================Finish================

2024-04-22 07:18:27 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:18:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:18:27 - INFO :       DATASET: tasksource/mmlu professional_psychology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.04s/it]
2024-04-22 07:18:53 - INFO :       Use taylor pruner...
2024-04-22 07:18:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:18:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:18:54 - INFO :       Start Pruning
2024-04-22 07:19:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:19:02 - INFO :       Loss = 13.9609375
2024-04-22 07:19:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:19:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:19:06 - INFO :       professional_psychology: Total Sparsity 1.3557215328724054e-06
2024-04-22 07:20:01 - INFO :       professional_psychology: Total Accuracy (21, 50, 0.42)
2024-04-22 07:20:01 - INFO :       
==================Finish================

2024-04-22 07:20:01 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:20:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:20:01 - INFO :       DATASET: tasksource/mmlu public_relations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.95s/it]
2024-04-22 07:20:26 - INFO :       Use taylor pruner...
2024-04-22 07:20:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:20:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:20:27 - INFO :       Start Pruning
2024-04-22 07:20:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:20:34 - INFO :       Loss = 12.90625
2024-04-22 07:20:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:20:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:20:38 - INFO :       public_relations: Total Sparsity 1.3581083665570398e-06
2024-04-22 07:20:51 - INFO :       public_relations: Total Accuracy (8, 12, 0.6666666666666666)
2024-04-22 07:20:52 - INFO :       
==================Finish================

2024-04-22 07:20:52 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:20:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:20:52 - INFO :       DATASET: tasksource/mmlu security_studies
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.18s/it]
2024-04-22 07:21:16 - INFO :       Use taylor pruner...
2024-04-22 07:21:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:21:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:21:17 - INFO :       Start Pruning
2024-04-22 07:21:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:21:24 - INFO :       Loss = 11.7734375
2024-04-22 07:21:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:21:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:21:28 - INFO :       security_studies: Total Sparsity 1.3585857332939668e-06
2024-04-22 07:22:00 - INFO :       security_studies: Total Accuracy (11, 27, 0.4074074074074074)
2024-04-22 07:22:00 - INFO :       
==================Finish================

2024-04-22 07:22:00 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:22:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:22:00 - INFO :       DATASET: tasksource/mmlu sociology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.92s/it]
2024-04-22 07:22:22 - INFO :       Use taylor pruner...
2024-04-22 07:22:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:22:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:22:23 - INFO :       Start Pruning
2024-04-22 07:22:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:22:30 - INFO :       Loss = 13.8125
2024-04-22 07:22:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:22:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:22:35 - INFO :       sociology: Total Sparsity 1.3566762663462592e-06
2024-04-22 07:23:00 - INFO :       sociology: Total Accuracy (11, 22, 0.5)
2024-04-22 07:23:00 - INFO :       
==================Finish================

2024-04-22 07:23:00 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:23:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:23:00 - INFO :       DATASET: tasksource/mmlu us_foreign_policy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  4.00s/it]
2024-04-22 07:23:23 - INFO :       Use taylor pruner...
2024-04-22 07:23:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:23:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:23:24 - INFO :       Start Pruning
2024-04-22 07:23:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:23:30 - INFO :       Loss = 13.65625
2024-04-22 07:23:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:23:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:23:34 - INFO :       us_foreign_policy: Total Sparsity 1.3590631000308936e-06
2024-04-22 07:23:46 - INFO :       us_foreign_policy: Total Accuracy (6, 11, 0.5454545454545454)
2024-04-22 07:23:47 - INFO :       
==================Finish================

2024-04-22 07:23:47 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:23:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:23:47 - INFO :       DATASET: tasksource/mmlu virology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.97s/it]
2024-04-22 07:24:10 - INFO :       Use taylor pruner...
2024-04-22 07:24:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:24:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:24:11 - INFO :       Start Pruning
2024-04-22 07:24:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:24:17 - INFO :       Loss = 10.9296875
2024-04-22 07:24:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:24:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:24:21 - INFO :       virology: Total Sparsity 1.3573127553288283e-06
2024-04-22 07:24:40 - INFO :       virology: Total Accuracy (9, 18, 0.5)
2024-04-22 07:24:41 - INFO :       
==================Finish================

2024-04-22 07:24:41 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:24:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:24:41 - INFO :       DATASET: tasksource/mmlu world_religions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.64s/it]
2024-04-22 07:25:03 - INFO :       Use taylor pruner...
2024-04-22 07:25:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:25:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:25:04 - INFO :       Start Pruning
2024-04-22 07:25:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:25:12 - INFO :       Loss = 14.4921875
2024-04-22 07:25:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:25:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:25:16 - INFO :       world_religions: Total Sparsity 1.3581083665570398e-06
2024-04-22 07:25:37 - INFO :       world_religions: Total Accuracy (14, 19, 0.7368421052631579)
2024-04-22 07:25:37 - INFO :       
==================Finish================

2024-04-22 07:25:37 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:25:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:25:37 - INFO :       DATASET: math_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.87s/it]
2024-04-22 07:26:00 - INFO :       Use taylor pruner...
2024-04-22 07:26:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:26:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:26:00 - INFO :       Start Pruning
2024-04-22 07:26:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:26:11 - INFO :       Loss = 12.9453125
2024-04-22 07:26:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:26:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:26:15 - INFO :       math_qa: Total Sparsity 1.3554032883811208e-06
2024-04-22 07:27:03 - INFO :       math_qa: Accuracy (10, 50, 0.2)
2024-04-22 07:27:03 - INFO :       
==================Finish================

2024-04-22 07:27:03 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:27:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:27:03 - INFO :       DATASET: EleutherAI/truthful_qa_mc
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.47s/it]
2024-04-22 07:27:28 - INFO :       Use taylor pruner...
2024-04-22 07:27:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:27:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:27:29 - INFO :       Start Pruning
2024-04-22 07:27:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:27:38 - INFO :       Loss = 13.8359375
2024-04-22 07:27:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:27:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:27:42 - INFO :       truthful_qa_mc: Total Sparsity 1.3569945108375437e-06
2024-04-22 07:28:28 - INFO :       truthful_qa_mc: Accuracy (15, 50, 0.3)
2024-04-22 07:28:28 - INFO :       
==================Finish================

2024-04-22 07:28:28 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:28:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:28:28 - INFO :       DATASET: derek-thomas/ScienceQA
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.20s/it]
2024-04-22 07:28:53 - INFO :       Use taylor pruner...
2024-04-22 07:28:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:28:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:28:54 - INFO :       Start Pruning
2024-04-22 07:29:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:29:04 - INFO :       Loss = 14.1328125
2024-04-22 07:29:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:29:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:29:08 - INFO :       ScienceQA: Total Sparsity 1.3611316892242436e-06
2024-04-22 07:29:55 - INFO :       ScienceQA: Accuracy (23, 50, 0.46)
2024-04-22 07:29:55 - INFO :       
==================Finish================

2024-04-22 07:29:55 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 07:29:55 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:29:55 - INFO :       DATASET: commonsense_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.84s/it]
2024-04-22 07:30:22 - INFO :       Use taylor pruner...
2024-04-22 07:30:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:30:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:30:23 - INFO :       Start Pruning
2024-04-22 07:30:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:30:44 - INFO :       Loss = 14.2421875
2024-04-22 07:30:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:30:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:30:48 - INFO :       commonsense_qa: Total Sparsity 1.3595404667678207e-06
2024-04-22 07:31:36 - INFO :       commonsense_qa: Accuracy (26, 50, 0.52)
2024-04-22 07:31:36 - INFO :       
==================Finish================

2024-04-22 07:31:36 - INFO :       Memory Requirement: 16770.79052734375 MiB

End: Memory Requirement: 3979.2666015625 MiB

Begin: Memory Requirement: 3979.2666015625 MiB

2024-04-22 07:31:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:31:36 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Index 3
Sparsity 3.5000000000000004 %
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.24s/it]
2024-04-22 07:32:01 - INFO :       Use taylor pruner...
2024-04-22 07:32:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:32:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:32:01 - INFO :       Start Pruning
2024-04-22 07:32:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:32:12 - INFO :       Loss = 1.2587890625
2024-04-22 07:32:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:32:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:32:16 - INFO :       which_wiki_edit: Total Sparsity 1.354448554907267e-06
2024-04-22 07:34:05 - INFO :       which_wiki_edit: Total Accuracy (29, 50, 0.58)
2024-04-22 07:34:05 - INFO :       
==================Finish================

2024-04-22 07:34:05 - INFO :       Memory Requirement: 16849.60302734375 MiB

2024-04-22 07:34:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:34:05 - INFO :       DATASET: tasksource/bigbench abstract_narrative_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.97s/it]
2024-04-22 07:34:31 - INFO :       Use taylor pruner...
2024-04-22 07:34:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:34:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:34:32 - INFO :       Start Pruning
2024-04-22 07:34:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:34:43 - INFO :       Loss = 7.84375
2024-04-22 07:34:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:34:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:34:48 - INFO :       abstract_narrative_understanding: Total Sparsity 1.3558806551180476e-06
2024-04-22 07:35:43 - INFO :       abstract_narrative_understanding: Total Accuracy (18, 50, 0.36)
2024-04-22 07:35:43 - INFO :       
==================Finish================

2024-04-22 07:35:43 - INFO :       Memory Requirement: 16772.79052734375 MiB

2024-04-22 07:35:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:35:43 - INFO :       DATASET: tasksource/bigbench anachronisms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.00s/it]
2024-04-22 07:36:07 - INFO :       Use taylor pruner...
2024-04-22 07:36:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:36:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:36:08 - INFO :       Start Pruning
2024-04-22 07:36:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:36:18 - INFO :       Loss = 14.71875
2024-04-22 07:36:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:36:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:36:23 - INFO :       anachronisms: Total Sparsity 1.35603977736369e-06
2024-04-22 07:37:10 - INFO :       anachronisms: Total Accuracy (30, 46, 0.6521739130434783)
2024-04-22 07:37:10 - INFO :       
==================Finish================

2024-04-22 07:37:10 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-22 07:37:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:37:10 - INFO :       DATASET: tasksource/bigbench analogical_similarity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.50s/it]
2024-04-22 07:37:33 - INFO :       Use taylor pruner...
2024-04-22 07:37:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:37:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:37:33 - INFO :       Start Pruning
2024-04-22 07:37:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:37:44 - INFO :       Loss = 1.3515625
2024-04-22 07:37:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:37:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:37:48 - INFO :       analogical_similarity: Total Sparsity 1.3557215328724054e-06
2024-04-22 07:38:54 - INFO :       analogical_similarity: Total Accuracy (3, 50, 0.06)
2024-04-22 07:38:55 - INFO :       
==================Finish================

2024-04-22 07:38:55 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-22 07:38:55 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:38:55 - INFO :       DATASET: tasksource/bigbench analytic_entailment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.02s/it]
2024-04-22 07:39:18 - INFO :       Use taylor pruner...
2024-04-22 07:39:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:39:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:39:19 - INFO :       Start Pruning
2024-04-22 07:39:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:39:27 - INFO :       Loss = 14.125
2024-04-22 07:39:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:39:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:39:31 - INFO :       analytic_entailment: Total Sparsity 1.3573127553288283e-06
2024-04-22 07:39:48 - INFO :       analytic_entailment: Total Accuracy (8, 16, 0.5)
2024-04-22 07:39:49 - INFO :       
==================Finish================

2024-04-22 07:39:49 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-22 07:39:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:39:49 - INFO :       DATASET: tasksource/bigbench arithmetic
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.85s/it]
2024-04-22 07:40:12 - INFO :       Use taylor pruner...
2024-04-22 07:40:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:40:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:40:13 - INFO :       Start Pruning
2024-04-22 07:40:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:40:21 - INFO :       Loss = 11.2578125
2024-04-22 07:40:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:40:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:40:27 - INFO :       arithmetic: Total Sparsity 1.355562410626763e-06
2024-04-22 07:41:20 - INFO :       arithmetic: Total Accuracy (0, 50, 0.0)
2024-04-22 07:41:20 - INFO :       
==================Finish================

2024-04-22 07:41:20 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-22 07:41:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:41:20 - INFO :       DATASET: tasksource/bigbench authorship_verification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.87s/it]
2024-04-22 07:41:43 - INFO :       Use taylor pruner...
2024-04-22 07:41:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:41:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:41:43 - INFO :       Start Pruning
2024-04-22 07:41:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:41:54 - INFO :       Loss = 2.75
2024-04-22 07:41:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:41:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:41:58 - INFO :       authorship_verification: Total Sparsity 1.3542894326616245e-06
2024-04-22 07:44:18 - INFO :       authorship_verification: Total Accuracy (26, 50, 0.52)
2024-04-22 07:44:19 - INFO :       
==================Finish================

2024-04-22 07:44:19 - INFO :       Memory Requirement: 16794.029296875 MiB

2024-04-22 07:44:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:44:19 - INFO :       DATASET: tasksource/bigbench bbq_lite_json
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.47s/it]
2024-04-22 07:44:42 - INFO :       Use taylor pruner...
2024-04-22 07:44:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:44:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:44:43 - INFO :       Start Pruning
2024-04-22 07:44:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:44:51 - INFO :       Loss = 13.265625
2024-04-22 07:44:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:44:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:44:55 - INFO :       bbq_lite_json: Total Sparsity 1.3584266110483244e-06
2024-04-22 07:45:48 - INFO :       bbq_lite_json: Total Accuracy (4, 50, 0.08)
2024-04-22 07:45:48 - INFO :       
==================Finish================

2024-04-22 07:45:48 - INFO :       Memory Requirement: 16771.79052734375 MiB

2024-04-22 07:45:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:45:48 - INFO :       DATASET: tasksource/bigbench causal_judgment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.24s/it]
2024-04-22 07:46:13 - INFO :       Use taylor pruner...
2024-04-22 07:46:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:46:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:46:14 - INFO :       Start Pruning
2024-04-22 07:46:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:46:24 - INFO :       Loss = 9.828125
2024-04-22 07:46:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:46:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:46:29 - INFO :       causal_judgment: Total Sparsity 1.356517144100617e-06
2024-04-22 07:47:11 - INFO :       causal_judgment: Total Accuracy (17, 38, 0.4473684210526316)
2024-04-22 07:47:11 - INFO :       
==================Finish================

2024-04-22 07:47:11 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 07:47:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:47:11 - INFO :       DATASET: tasksource/bigbench cause_and_effect
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.46s/it]
2024-04-22 07:47:37 - INFO :       Use taylor pruner...
2024-04-22 07:47:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:47:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:47:38 - INFO :       Start Pruning
2024-04-22 07:47:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:47:48 - INFO :       Loss = 13.328125
2024-04-22 07:47:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:47:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:47:53 - INFO :       cause_and_effect: Total Sparsity 1.3566762663462592e-06
2024-04-22 07:48:26 - INFO :       cause_and_effect: Total Accuracy (23, 30, 0.7666666666666667)
2024-04-22 07:48:26 - INFO :       
==================Finish================

2024-04-22 07:48:26 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 07:48:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:48:26 - INFO :       DATASET: tasksource/bigbench checkmate_in_one
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.95s/it]
2024-04-22 07:48:49 - INFO :       Use taylor pruner...
2024-04-22 07:48:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:48:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:48:50 - INFO :       Start Pruning
2024-04-22 07:49:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:49:02 - INFO :       Loss = 1.166015625
2024-04-22 07:49:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:49:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:49:07 - INFO :       checkmate_in_one: Total Sparsity 1.3528573324508439e-06
2024-04-22 07:50:07 - INFO :       checkmate_in_one: Total Accuracy (2, 50, 0.04)
2024-04-22 07:50:07 - INFO :       
==================Finish================

2024-04-22 07:50:07 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 07:50:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:50:07 - INFO :       DATASET: tasksource/bigbench cifar10_classification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.52s/it]
2024-04-22 07:50:33 - INFO :       Use taylor pruner...
2024-04-22 07:50:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:50:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:50:34 - INFO :       Start Pruning
Token indices sequence length is longer than the specified maximum sequence length for this model (7170 > 4096). Running this sequence through the model will result in indexing errors
2024-04-22 07:50:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:50:46 - INFO :       Loss = 2.85546875
2024-04-22 07:50:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:50:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:50:50 - INFO :       cifar10_classification: Total Sparsity 1.3495157652923556e-06
2024-04-22 07:52:57 - INFO :       cifar10_classification: Total Accuracy (2, 50, 0.04)
2024-04-22 07:52:57 - INFO :       
==================Finish================

2024-04-22 07:52:57 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 07:52:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:52:57 - INFO :       DATASET: tasksource/bigbench code_line_description
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.63s/it]
2024-04-22 07:53:20 - INFO :       Use taylor pruner...
2024-04-22 07:53:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:53:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:53:21 - INFO :       Start Pruning
2024-04-22 07:53:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:53:29 - INFO :       Loss = 10.3671875
2024-04-22 07:53:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:53:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:53:33 - INFO :       code_line_description: Total Sparsity 1.3561988996093322e-06
2024-04-22 07:53:50 - INFO :       code_line_description: Total Accuracy (11, 16, 0.6875)
2024-04-22 07:53:50 - INFO :       
==================Finish================

2024-04-22 07:53:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 07:53:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:53:50 - INFO :       DATASET: tasksource/bigbench color
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.90s/it]
2024-04-22 07:54:13 - INFO :       Use taylor pruner...
2024-04-22 07:54:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:54:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:54:14 - INFO :       Start Pruning
2024-04-22 07:54:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:54:22 - INFO :       Loss = 10.578125
2024-04-22 07:54:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:54:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:54:26 - INFO :       color: Total Sparsity 1.3561988996093322e-06
2024-04-22 07:55:19 - INFO :       color: Total Accuracy (1, 50, 0.02)
2024-04-22 07:55:19 - INFO :       
==================Finish================

2024-04-22 07:55:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 07:55:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:55:19 - INFO :       DATASET: tasksource/bigbench common_morpheme
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.56s/it]
2024-04-22 07:55:44 - INFO :       Use taylor pruner...
2024-04-22 07:55:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:55:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:55:45 - INFO :       Start Pruning
2024-04-22 07:55:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:55:55 - INFO :       Loss = 13.140625
2024-04-22 07:55:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:55:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:56:00 - INFO :       common_morpheme: Total Sparsity 1.3622455449437396e-06
2024-04-22 07:56:18 - INFO :       common_morpheme: Total Accuracy (4, 16, 0.25)
2024-04-22 07:56:18 - INFO :       
==================Finish================

2024-04-22 07:56:18 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 07:56:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:56:18 - INFO :       DATASET: tasksource/bigbench conceptual_combinations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.91s/it]
2024-04-22 07:56:42 - INFO :       Use taylor pruner...
2024-04-22 07:56:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:56:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:56:43 - INFO :       Start Pruning
2024-04-22 07:56:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:56:52 - INFO :       Loss = 11.25
2024-04-22 07:56:55 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:56:55 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:56:57 - INFO :       conceptual_combinations: Total Sparsity 1.3573127553288283e-06
2024-04-22 07:57:17 - INFO :       conceptual_combinations: Total Accuracy (14, 19, 0.7368421052631579)
2024-04-22 07:57:17 - INFO :       
==================Finish================

2024-04-22 07:57:17 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 07:57:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:57:17 - INFO :       DATASET: tasksource/bigbench crash_blossom
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.38s/it]
2024-04-22 07:57:41 - INFO :       Use taylor pruner...
2024-04-22 07:57:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:57:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:57:42 - INFO :       Start Pruning
2024-04-22 07:57:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:57:54 - INFO :       Loss = 13.359375
2024-04-22 07:57:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:57:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:57:58 - INFO :       crash_blossom: Total Sparsity 1.3574718775744707e-06
2024-04-22 07:58:15 - INFO :       crash_blossom: Total Accuracy (6, 16, 0.375)
2024-04-22 07:58:15 - INFO :       
==================Finish================

2024-04-22 07:58:15 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 07:58:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:58:15 - INFO :       DATASET: tasksource/bigbench crass_ai
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.88s/it]
2024-04-22 07:58:37 - INFO :       Use taylor pruner...
2024-04-22 07:58:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:58:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 07:58:38 - INFO :       Start Pruning
2024-04-22 07:58:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 07:58:46 - INFO :       Loss = 11.15625
2024-04-22 07:58:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 07:58:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 07:58:50 - INFO :       crass_ai: Total Sparsity 1.357630999820113e-06
2024-04-22 07:59:06 - INFO :       crass_ai: Total Accuracy (5, 16, 0.3125)
2024-04-22 07:59:06 - INFO :       
==================Finish================

2024-04-22 07:59:06 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 07:59:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 07:59:06 - INFO :       DATASET: tasksource/bigbench cryobiology_spanish
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.84s/it]
2024-04-22 08:00:07 - INFO :       Use taylor pruner...
2024-04-22 08:00:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:00:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:00:07 - INFO :       Start Pruning
2024-04-22 08:03:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 08:03:17 - INFO :       Loss = 13.7734375
2024-04-22 08:03:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 08:03:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 08:03:21 - INFO :       cryobiology_spanish: Total Sparsity 1.3604952002416743e-06
2024-04-22 08:03:51 - INFO :       cryobiology_spanish: Total Accuracy (24, 29, 0.8275862068965517)
2024-04-22 08:03:51 - INFO :       
==================Finish================

2024-04-22 08:03:51 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 08:03:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 08:03:51 - INFO :       DATASET: tasksource/bigbench cs_algorithms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.74s/it]
2024-04-22 08:04:51 - INFO :       Use taylor pruner...
2024-04-22 08:04:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:04:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:04:52 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:06:32 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:08:13 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:08:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 08:08:14 - INFO :       Loss = 13.4453125
2024-04-22 08:08:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 08:08:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 08:08:19 - INFO :       cs_algorithms: Total Sparsity 1.358744855539609e-06
2024-04-22 08:09:10 - INFO :       cs_algorithms: Total Accuracy (4, 50, 0.08)
2024-04-22 08:09:10 - INFO :       
==================Finish================

2024-04-22 08:09:10 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 08:09:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 08:09:10 - INFO :       DATASET: tasksource/bigbench dark_humor_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.84s/it]
2024-04-22 08:10:10 - INFO :       Use taylor pruner...
2024-04-22 08:10:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:10:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:10:11 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:12:03 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:13:43 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:13:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 08:13:44 - INFO :       Loss = 12.6953125
2024-04-22 08:13:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 08:13:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 08:13:49 - INFO :       dark_humor_detection: Total Sparsity 1.3568353885919015e-06
2024-04-22 08:14:06 - INFO :       dark_humor_detection: Total Accuracy (6, 16, 0.375)
2024-04-22 08:14:06 - INFO :       
==================Finish================

2024-04-22 08:14:06 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 08:14:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 08:14:06 - INFO :       DATASET: tasksource/bigbench date_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.72s/it]
2024-04-22 08:15:06 - INFO :       Use taylor pruner...
2024-04-22 08:15:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:15:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:15:07 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:20:47 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:20:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 08:20:49 - INFO :       Loss = 11.484375
2024-04-22 08:20:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 08:20:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 08:20:53 - INFO :       date_understanding: Total Sparsity 1.3581083665570398e-06
2024-04-22 08:21:45 - INFO :       date_understanding: Total Accuracy (8, 50, 0.16)
2024-04-22 08:21:45 - INFO :       
==================Finish================

2024-04-22 08:21:45 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 08:21:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 08:21:45 - INFO :       DATASET: tasksource/bigbench disambiguation_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.99s/it]
2024-04-22 08:22:45 - INFO :       Use taylor pruner...
2024-04-22 08:22:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:22:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:22:46 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:24:26 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:26:06 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:26:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 08:26:07 - INFO :       Loss = 11.875
2024-04-22 08:26:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 08:26:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 08:26:12 - INFO :       disambiguation_qa: Total Sparsity 1.357630999820113e-06
2024-04-22 08:27:03 - INFO :       disambiguation_qa: Total Accuracy (23, 50, 0.46)
2024-04-22 08:27:03 - INFO :       
==================Finish================

2024-04-22 08:27:03 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 08:27:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 08:27:03 - INFO :       DATASET: tasksource/bigbench discourse_marker_prediction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.52s/it]
2024-04-22 08:28:01 - INFO :       Use taylor pruner...
2024-04-22 08:28:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:28:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:28:02 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:29:42 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:31:22 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:31:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 08:31:24 - INFO :       Loss = 0.69970703125
2024-04-22 08:31:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 08:31:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 08:31:28 - INFO :       discourse_marker_prediction: Total Sparsity 1.3534938214334132e-06
2024-04-22 08:32:25 - INFO :       discourse_marker_prediction: Total Accuracy (11, 50, 0.22)
2024-04-22 08:32:25 - INFO :       
==================Finish================

2024-04-22 08:32:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 08:32:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 08:32:25 - INFO :       DATASET: tasksource/bigbench dyck_languages
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.98s/it]
2024-04-22 08:33:26 - INFO :       Use taylor pruner...
2024-04-22 08:33:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:33:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:33:27 - INFO :       Start Pruning
2024-04-22 08:37:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 08:37:47 - INFO :       Loss = 1.078125
2024-04-22 08:37:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 08:37:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 08:37:51 - INFO :       dyck_languages: Total Sparsity 1.3534938214334132e-06
2024-04-22 08:38:50 - INFO :       dyck_languages: Total Accuracy (1, 50, 0.02)
2024-04-22 08:38:50 - INFO :       
==================Finish================

2024-04-22 08:38:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 08:38:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 08:38:50 - INFO :       DATASET: tasksource/bigbench elementary_math_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.65s/it]
2024-04-22 08:39:49 - INFO :       Use taylor pruner...
2024-04-22 08:39:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:39:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:39:50 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:41:30 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:43:10 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:43:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 08:43:12 - INFO :       Loss = 12.4921875
2024-04-22 08:43:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 08:43:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 08:43:16 - INFO :       elementary_math_qa: Total Sparsity 1.3574718775744707e-06
2024-04-22 08:44:08 - INFO :       elementary_math_qa: Total Accuracy (12, 50, 0.24)
2024-04-22 08:44:08 - INFO :       
==================Finish================

2024-04-22 08:44:08 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 08:44:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 08:44:08 - INFO :       DATASET: tasksource/bigbench emoji_movie
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.22s/it]
2024-04-22 08:45:10 - INFO :       Use taylor pruner...
2024-04-22 08:45:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:45:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:45:10 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:46:50 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:48:31 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:48:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 08:48:32 - INFO :       Loss = 12.7578125
2024-04-22 08:48:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 08:48:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 08:48:36 - INFO :       emoji_movie: Total Sparsity 1.360336077996032e-06
2024-04-22 08:48:56 - INFO :       emoji_movie: Total Accuracy (9, 20, 0.45)
2024-04-22 08:48:56 - INFO :       
==================Finish================

2024-04-22 08:48:56 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 08:48:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 08:48:56 - INFO :       DATASET: tasksource/bigbench empirical_judgments
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.70s/it]
2024-04-22 08:49:55 - INFO :       Use taylor pruner...
2024-04-22 08:49:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:49:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:49:56 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:49:56 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:49:56 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:49:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 08:49:58 - INFO :       Loss = 12.71875
2024-04-22 08:50:00 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 08:50:00 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 08:50:02 - INFO :       empirical_judgments: Total Sparsity 1.3584266110483244e-06
2024-04-22 08:50:22 - INFO :       empirical_judgments: Total Accuracy (5, 19, 0.2631578947368421)
2024-04-22 08:50:22 - INFO :       
==================Finish================

2024-04-22 08:50:22 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 08:50:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 08:50:22 - INFO :       DATASET: tasksource/bigbench english_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.75s/it]
2024-04-22 08:50:43 - INFO :       Use taylor pruner...
2024-04-22 08:50:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:50:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:50:44 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:50:44 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:50:44 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:50:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 08:50:45 - INFO :       Loss = 10.484375
2024-04-22 08:50:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 08:50:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 08:50:49 - INFO :       english_proverbs: Total Sparsity 1.3554032883811208e-06
2024-04-22 08:51:06 - INFO :       english_proverbs: Total Accuracy (5, 16, 0.3125)
2024-04-22 08:51:06 - INFO :       
==================Finish================

2024-04-22 08:51:06 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 08:51:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 08:51:06 - INFO :       DATASET: tasksource/bigbench english_russian_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.39s/it]
2024-04-22 08:51:29 - INFO :       Use taylor pruner...
2024-04-22 08:51:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:51:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:51:30 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:51:30 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:51:30 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:51:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 08:51:32 - INFO :       Loss = 11.2734375
2024-04-22 08:51:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 08:51:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 08:51:36 - INFO :       english_russian_proverbs: Total Sparsity 1.3584266110483244e-06
2024-04-22 08:51:53 - INFO :       english_russian_proverbs: Total Accuracy (2, 16, 0.125)
2024-04-22 08:51:53 - INFO :       
==================Finish================

2024-04-22 08:51:53 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 08:51:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 08:51:53 - INFO :       DATASET: tasksource/bigbench entailed_polarity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.07s/it]
2024-04-22 08:52:14 - INFO :       Use taylor pruner...
2024-04-22 08:52:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:52:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:52:15 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:52:15 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:52:15 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:52:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 08:52:17 - INFO :       Loss = 14.4609375
2024-04-22 08:52:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 08:52:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 08:52:22 - INFO :       entailed_polarity: Total Sparsity 1.359699589013463e-06
2024-04-22 08:52:54 - INFO :       entailed_polarity: Total Accuracy (28, 29, 0.9655172413793104)
2024-04-22 08:52:54 - INFO :       
==================Finish================

2024-04-22 08:52:54 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 08:52:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 08:52:54 - INFO :       DATASET: tasksource/bigbench entailed_polarity_hindi
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.19s/it]
2024-04-22 08:53:15 - INFO :       Use taylor pruner...
2024-04-22 08:53:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:53:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:53:16 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:53:16 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:53:16 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:53:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 08:53:17 - INFO :       Loss = 9.59375
2024-04-22 08:53:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 08:53:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 08:53:23 - INFO :       entailed_polarity_hindi: Total Sparsity 1.357630999820113e-06
2024-04-22 08:53:53 - INFO :       entailed_polarity_hindi: Total Accuracy (18, 27, 0.6666666666666666)
2024-04-22 08:53:53 - INFO :       
==================Finish================

2024-04-22 08:53:53 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 08:53:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 08:53:53 - INFO :       DATASET: tasksource/bigbench epistemic_reasoning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.34s/it]
2024-04-22 08:54:17 - INFO :       Use taylor pruner...
2024-04-22 08:54:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:54:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:54:18 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:54:18 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:54:18 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:54:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 08:54:19 - INFO :       Loss = 13.171875
2024-04-22 08:54:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 08:54:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 08:54:24 - INFO :       epistemic_reasoning: Total Sparsity 1.3577901220657553e-06
2024-04-22 08:55:16 - INFO :       epistemic_reasoning: Total Accuracy (30, 50, 0.6)
2024-04-22 08:55:16 - INFO :       
==================Finish================

2024-04-22 08:55:16 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 08:55:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 08:55:16 - INFO :       DATASET: tasksource/bigbench evaluating_information_essentiality
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.66s/it]
2024-04-22 08:55:40 - INFO :       Use taylor pruner...
2024-04-22 08:55:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:55:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:55:40 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:55:40 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:55:40 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:55:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 08:55:42 - INFO :       Loss = 6.0078125
2024-04-22 08:55:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 08:55:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 08:55:47 - INFO :       evaluating_information_essentiality: Total Sparsity 1.35603977736369e-06
2024-04-22 08:56:04 - INFO :       evaluating_information_essentiality: Total Accuracy (1, 16, 0.0625)
2024-04-22 08:56:04 - INFO :       
==================Finish================

2024-04-22 08:56:04 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 08:56:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 08:56:04 - INFO :       DATASET: tasksource/bigbench fact_checker
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.44s/it]
2024-04-22 08:56:34 - INFO :       Use taylor pruner...
2024-04-22 08:56:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:56:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:56:35 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:56:35 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:56:35 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:56:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 08:56:36 - INFO :       Loss = 14.5703125
2024-04-22 08:56:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 08:56:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 08:56:41 - INFO :       fact_checker: Total Sparsity 1.3585857332939668e-06
2024-04-22 08:57:35 - INFO :       fact_checker: Total Accuracy (42, 50, 0.84)
2024-04-22 08:57:36 - INFO :       
==================Finish================

2024-04-22 08:57:36 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 08:57:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 08:57:36 - INFO :       DATASET: tasksource/bigbench fantasy_reasoning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.82s/it]
2024-04-22 08:58:02 - INFO :       Use taylor pruner...
2024-04-22 08:58:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:58:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:58:03 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:58:03 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:58:03 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:58:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 08:58:04 - INFO :       Loss = 13.3359375
2024-04-22 08:58:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 08:58:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 08:58:09 - INFO :       fantasy_reasoning: Total Sparsity 1.3585857332939668e-06
2024-04-22 08:58:55 - INFO :       fantasy_reasoning: Total Accuracy (22, 40, 0.55)
2024-04-22 08:58:55 - INFO :       
==================Finish================

2024-04-22 08:58:55 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 08:58:55 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 08:58:55 - INFO :       DATASET: tasksource/bigbench figure_of_speech_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.66s/it]
2024-04-22 08:59:20 - INFO :       Use taylor pruner...
2024-04-22 08:59:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:59:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 08:59:21 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:59:21 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:59:21 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 08:59:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 08:59:22 - INFO :       Loss = 11.7109375
2024-04-22 08:59:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 08:59:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 08:59:28 - INFO :       figure_of_speech_detection: Total Sparsity 1.355562410626763e-06
2024-04-22 08:59:48 - INFO :       figure_of_speech_detection: Total Accuracy (3, 16, 0.1875)
2024-04-22 08:59:48 - INFO :       
==================Finish================

2024-04-22 08:59:48 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 08:59:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 08:59:48 - INFO :       DATASET: tasksource/bigbench formal_fallacies_syllogisms_negation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.97s/it]
2024-04-22 09:00:10 - INFO :       Use taylor pruner...
2024-04-22 09:00:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:00:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:00:11 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:00:11 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:00:11 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:00:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:00:12 - INFO :       Loss = 12.2109375
2024-04-22 09:00:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:00:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:00:16 - INFO :       formal_fallacies_syllogisms_negation: Total Sparsity 1.3574718775744707e-06
2024-04-22 09:01:13 - INFO :       formal_fallacies_syllogisms_negation: Total Accuracy (23, 50, 0.46)
2024-04-22 09:01:13 - INFO :       
==================Finish================

2024-04-22 09:01:13 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:01:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:01:13 - INFO :       DATASET: tasksource/bigbench general_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.94s/it]
2024-04-22 09:01:38 - INFO :       Use taylor pruner...
2024-04-22 09:01:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:01:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:01:39 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:01:39 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:01:39 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:01:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:01:40 - INFO :       Loss = 11.2109375
2024-04-22 09:01:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:01:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:01:45 - INFO :       general_knowledge: Total Sparsity 1.3577901220657553e-06
2024-04-22 09:02:03 - INFO :       general_knowledge: Total Accuracy (12, 16, 0.75)
2024-04-22 09:02:03 - INFO :       
==================Finish================

2024-04-22 09:02:03 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:02:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:02:03 - INFO :       DATASET: tasksource/bigbench geometric_shapes
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.72s/it]
2024-04-22 09:02:29 - INFO :       Use taylor pruner...
2024-04-22 09:02:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:02:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:02:30 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:02:30 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:02:30 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:02:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:02:32 - INFO :       Loss = 8.6640625
2024-04-22 09:02:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:02:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:02:36 - INFO :       geometric_shapes: Total Sparsity 1.3581083665570398e-06
2024-04-22 09:03:33 - INFO :       geometric_shapes: Total Accuracy (6, 50, 0.12)
2024-04-22 09:03:33 - INFO :       
==================Finish================

2024-04-22 09:03:33 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:03:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:03:33 - INFO :       DATASET: tasksource/bigbench goal_step_wikihow
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.34s/it]
2024-04-22 09:03:57 - INFO :       Use taylor pruner...
2024-04-22 09:03:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:03:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:03:58 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:03:58 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:03:58 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:03:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:03:59 - INFO :       Loss = 12.0859375
2024-04-22 09:04:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:04:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:04:04 - INFO :       goal_step_wikihow: Total Sparsity 1.3601769557503897e-06
2024-04-22 09:05:02 - INFO :       goal_step_wikihow: Total Accuracy (23, 50, 0.46)
2024-04-22 09:05:02 - INFO :       
==================Finish================

2024-04-22 09:05:02 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:05:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:05:02 - INFO :       DATASET: tasksource/bigbench gre_reading_comprehension
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.21s/it]
2024-04-22 09:05:25 - INFO :       Use taylor pruner...
2024-04-22 09:05:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:05:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:05:26 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:05:26 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:05:26 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:05:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:05:31 - INFO :       Loss = 2.45703125
2024-04-22 09:05:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:05:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:05:36 - INFO :       gre_reading_comprehension: Total Sparsity 1.3520617212226323e-06
2024-04-22 09:05:58 - INFO :       gre_reading_comprehension: Total Accuracy (5, 16, 0.3125)
2024-04-22 09:05:58 - INFO :       
==================Finish================

2024-04-22 09:05:58 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:05:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:05:58 - INFO :       DATASET: tasksource/bigbench hhh_alignment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.57s/it]
2024-04-22 09:06:24 - INFO :       Use taylor pruner...
2024-04-22 09:06:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:06:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:06:25 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:06:25 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:06:25 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:06:25 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:06:27 - INFO :       Loss = 11.015625
2024-04-22 09:06:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:06:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:06:32 - INFO :       hhh_alignment: Total Sparsity 1.3574718775744707e-06
2024-04-22 09:07:25 - INFO :       hhh_alignment: Total Accuracy (27, 42, 0.6428571428571429)
2024-04-22 09:07:25 - INFO :       
==================Finish================

2024-04-22 09:07:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:07:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:07:25 - INFO :       DATASET: tasksource/bigbench hindu_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.75s/it]
2024-04-22 09:07:49 - INFO :       Use taylor pruner...
2024-04-22 09:07:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:07:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:07:50 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:07:50 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:07:50 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:07:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:07:52 - INFO :       Loss = 13.2890625
2024-04-22 09:07:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:07:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:07:57 - INFO :       hindu_knowledge: Total Sparsity 1.359699589013463e-06
2024-04-22 09:08:37 - INFO :       hindu_knowledge: Total Accuracy (23, 35, 0.6571428571428571)
2024-04-22 09:08:38 - INFO :       
==================Finish================

2024-04-22 09:08:38 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:08:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:08:38 - INFO :       DATASET: tasksource/bigbench hinglish_toxicity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.00s/it]
2024-04-22 09:09:04 - INFO :       Use taylor pruner...
2024-04-22 09:09:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:09:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:09:05 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:09:05 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:09:05 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:09:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:09:06 - INFO :       Loss = 14.28125
2024-04-22 09:09:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:09:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:09:11 - INFO :       hinglish_toxicity: Total Sparsity 1.3577901220657553e-06
2024-04-22 09:10:03 - INFO :       hinglish_toxicity: Total Accuracy (19, 40, 0.475)
2024-04-22 09:10:03 - INFO :       
==================Finish================

2024-04-22 09:10:03 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:10:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:10:03 - INFO :       DATASET: tasksource/bigbench human_organs_senses
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.40s/it]
2024-04-22 09:10:30 - INFO :       Use taylor pruner...
2024-04-22 09:10:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:10:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:10:31 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:10:31 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:10:31 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:10:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:10:33 - INFO :       Loss = 13.734375
2024-04-22 09:10:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:10:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:10:38 - INFO :       human_organs_senses: Total Sparsity 1.3589039777852514e-06
2024-04-22 09:10:56 - INFO :       human_organs_senses: Total Accuracy (9, 16, 0.5625)
2024-04-22 09:10:57 - INFO :       
==================Finish================

2024-04-22 09:10:57 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:10:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:10:57 - INFO :       DATASET: tasksource/bigbench hyperbaton
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.08s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.30s/it]
2024-04-22 09:11:21 - INFO :       Use taylor pruner...
2024-04-22 09:11:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:11:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:11:22 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:11:22 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:11:22 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:11:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:11:23 - INFO :       Loss = 14.7578125
2024-04-22 09:11:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:11:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:11:28 - INFO :       hyperbaton: Total Sparsity 1.3558806551180476e-06
2024-04-22 09:12:26 - INFO :       hyperbaton: Total Accuracy (22, 50, 0.44)
2024-04-22 09:12:26 - INFO :       
==================Finish================

2024-04-22 09:12:26 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:12:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:12:26 - INFO :       DATASET: tasksource/bigbench identify_math_theorems
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.74s/it]
2024-04-22 09:12:50 - INFO :       Use taylor pruner...
2024-04-22 09:12:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:12:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:12:51 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:12:51 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:12:51 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:12:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:12:53 - INFO :       Loss = 1.658203125
2024-04-22 09:12:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:12:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:12:59 - INFO :       identify_math_theorems: Total Sparsity 1.359699589013463e-06
2024-04-22 09:13:22 - INFO :       identify_math_theorems: Total Accuracy (9, 16, 0.5625)
2024-04-22 09:13:22 - INFO :       
==================Finish================

2024-04-22 09:13:22 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:13:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:13:22 - INFO :       DATASET: tasksource/bigbench identify_odd_metaphor
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.58s/it]
2024-04-22 09:13:46 - INFO :       Use taylor pruner...
2024-04-22 09:13:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:13:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:13:47 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:13:47 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:13:47 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:13:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:13:48 - INFO :       Loss = 10.6640625
2024-04-22 09:13:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:13:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:13:53 - INFO :       identify_odd_metaphor: Total Sparsity 1.3574718775744707e-06
2024-04-22 09:14:14 - INFO :       identify_odd_metaphor: Total Accuracy (10, 16, 0.625)
2024-04-22 09:14:15 - INFO :       
==================Finish================

2024-04-22 09:14:15 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:14:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:14:15 - INFO :       DATASET: tasksource/bigbench implicatures
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.99s/it]
2024-04-22 09:14:40 - INFO :       Use taylor pruner...
2024-04-22 09:14:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:14:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:14:41 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:14:41 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:14:41 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:14:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:14:43 - INFO :       Loss = 14.140625
2024-04-22 09:14:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:14:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:14:49 - INFO :       implicatures: Total Sparsity 1.3581083665570398e-06
2024-04-22 09:15:50 - INFO :       implicatures: Total Accuracy (37, 50, 0.74)
2024-04-22 09:15:51 - INFO :       
==================Finish================

2024-04-22 09:15:51 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:15:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:15:51 - INFO :       DATASET: tasksource/bigbench implicit_relations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.11s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.49s/it]
2024-04-22 09:16:17 - INFO :       Use taylor pruner...
2024-04-22 09:16:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:16:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:16:18 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:16:18 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:16:18 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:16:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:16:19 - INFO :       Loss = 6.08203125
2024-04-22 09:16:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:16:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:16:24 - INFO :       implicit_relations: Total Sparsity 1.3534938214334132e-06
2024-04-22 09:16:46 - INFO :       implicit_relations: Total Accuracy (5, 17, 0.29411764705882354)
2024-04-22 09:16:47 - INFO :       
==================Finish================

2024-04-22 09:16:47 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:16:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:16:47 - INFO :       DATASET: tasksource/bigbench indic_cause_and_effect
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.44s/it]
2024-04-22 09:17:16 - INFO :       Use taylor pruner...
2024-04-22 09:17:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:17:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:17:17 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:17:17 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:17:17 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:17:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:17:19 - INFO :       Loss = 7.296875
2024-04-22 09:17:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:17:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:17:24 - INFO :       indic_cause_and_effect: Total Sparsity 1.3552441661354783e-06
2024-04-22 09:18:26 - INFO :       indic_cause_and_effect: Total Accuracy (28, 50, 0.56)
2024-04-22 09:18:27 - INFO :       
==================Finish================

2024-04-22 09:18:27 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:18:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:18:27 - INFO :       DATASET: tasksource/bigbench intent_recognition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.42s/it]
2024-04-22 09:18:52 - INFO :       Use taylor pruner...
2024-04-22 09:18:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:18:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:18:53 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:18:53 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:18:53 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:18:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:18:55 - INFO :       Loss = 10.4296875
2024-04-22 09:18:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:18:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:19:00 - INFO :       intent_recognition: Total Sparsity 1.3566762663462592e-06
2024-04-22 09:20:02 - INFO :       intent_recognition: Total Accuracy (23, 50, 0.46)
2024-04-22 09:20:02 - INFO :       
==================Finish================

2024-04-22 09:20:02 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:20:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:20:02 - INFO :       DATASET: tasksource/bigbench international_phonetic_alphabet_nli
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.97s/it]
2024-04-22 09:20:27 - INFO :       Use taylor pruner...
2024-04-22 09:20:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:20:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:20:28 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:20:28 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:20:28 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:20:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:20:30 - INFO :       Loss = 9.109375
2024-04-22 09:20:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:20:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:20:35 - INFO :       international_phonetic_alphabet_nli: Total Sparsity 1.3552441661354783e-06
2024-04-22 09:21:06 - INFO :       international_phonetic_alphabet_nli: Total Accuracy (9, 25, 0.36)
2024-04-22 09:21:06 - INFO :       
==================Finish================

2024-04-22 09:21:06 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:21:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:21:06 - INFO :       DATASET: tasksource/bigbench intersect_geometry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.98s/it]
2024-04-22 09:21:33 - INFO :       Use taylor pruner...
2024-04-22 09:21:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:21:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:21:34 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:21:34 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:21:34 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:21:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:21:35 - INFO :       Loss = 2.9140625
2024-04-22 09:21:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:21:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:21:41 - INFO :       intersect_geometry: Total Sparsity 1.355085043889836e-06
2024-04-22 09:22:47 - INFO :       intersect_geometry: Total Accuracy (0, 50, 0.0)
2024-04-22 09:22:47 - INFO :       
==================Finish================

2024-04-22 09:22:47 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:22:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:22:47 - INFO :       DATASET: tasksource/bigbench irony_identification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.27s/it]
2024-04-22 09:23:12 - INFO :       Use taylor pruner...
2024-04-22 09:23:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:23:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:23:13 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:23:13 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:23:13 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:23:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:23:16 - INFO :       Loss = 13.8828125
2024-04-22 09:23:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:23:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:23:21 - INFO :       irony_identification: Total Sparsity 1.3589039777852514e-06
2024-04-22 09:23:45 - INFO :       irony_identification: Total Accuracy (11, 19, 0.5789473684210527)
2024-04-22 09:23:45 - INFO :       
==================Finish================

2024-04-22 09:23:45 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:23:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:23:45 - INFO :       DATASET: tasksource/bigbench kannada
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.71s/it]
2024-04-22 09:24:11 - INFO :       Use taylor pruner...
2024-04-22 09:24:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:24:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:24:11 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:24:11 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:24:11 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:24:12 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:24:13 - INFO :       Loss = 4.0390625
2024-04-22 09:24:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:24:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:24:18 - INFO :       kannada: Total Sparsity 1.3542894326616245e-06
2024-04-22 09:25:30 - INFO :       kannada: Total Accuracy (12, 50, 0.24)
2024-04-22 09:25:31 - INFO :       
==================Finish================

2024-04-22 09:25:31 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:25:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:25:31 - INFO :       DATASET: tasksource/bigbench key_value_maps
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.22s/it]
2024-04-22 09:25:57 - INFO :       Use taylor pruner...
2024-04-22 09:25:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:25:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:25:58 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:25:58 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:25:58 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:25:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:26:00 - INFO :       Loss = 7.0546875
2024-04-22 09:26:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:26:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:26:05 - INFO :       key_value_maps: Total Sparsity 1.3579492443113975e-06
2024-04-22 09:26:32 - INFO :       key_value_maps: Total Accuracy (12, 21, 0.5714285714285714)
2024-04-22 09:26:32 - INFO :       
==================Finish================

2024-04-22 09:26:32 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:26:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:26:32 - INFO :       DATASET: tasksource/bigbench known_unknowns
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.38s/it]
2024-04-22 09:26:58 - INFO :       Use taylor pruner...
2024-04-22 09:26:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:26:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:26:59 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:26:59 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:26:59 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:26:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:27:01 - INFO :       Loss = 14.53125
2024-04-22 09:27:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:27:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:27:06 - INFO :       known_unknowns: Total Sparsity 1.3579492443113975e-06
2024-04-22 09:27:27 - INFO :       known_unknowns: Total Accuracy (10, 16, 0.625)
2024-04-22 09:27:27 - INFO :       
==================Finish================

2024-04-22 09:27:27 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:27:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:27:27 - INFO :       DATASET: tasksource/bigbench language_identification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  5.00s/it]
2024-04-22 09:27:55 - INFO :       Use taylor pruner...
2024-04-22 09:27:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:27:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:27:56 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:27:56 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:27:56 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:27:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:27:58 - INFO :       Loss = 7.98828125
2024-04-22 09:28:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:28:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:28:04 - INFO :       language_identification: Total Sparsity 1.3573127553288283e-06
2024-04-22 09:29:09 - INFO :       language_identification: Total Accuracy (11, 50, 0.22)
2024-04-22 09:29:10 - INFO :       
==================Finish================

2024-04-22 09:29:10 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:29:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:29:10 - INFO :       DATASET: tasksource/bigbench logic_grid_puzzle
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.06s/it]
2024-04-22 09:29:37 - INFO :       Use taylor pruner...
2024-04-22 09:29:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:29:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:29:38 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:29:38 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:29:38 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:29:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:29:40 - INFO :       Loss = 3.150390625
2024-04-22 09:29:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:29:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:29:45 - INFO :       logic_grid_puzzle: Total Sparsity 1.3542894326616245e-06
2024-04-22 09:30:49 - INFO :       logic_grid_puzzle: Total Accuracy (18, 50, 0.36)
2024-04-22 09:30:49 - INFO :       
==================Finish================

2024-04-22 09:30:49 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:30:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:30:49 - INFO :       DATASET: tasksource/bigbench logical_args
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.72s/it]
2024-04-22 09:31:14 - INFO :       Use taylor pruner...
2024-04-22 09:31:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:31:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:31:15 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:31:15 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:31:15 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:31:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:31:17 - INFO :       Loss = 7.9609375
2024-04-22 09:31:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:31:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:31:22 - INFO :       logical_args: Total Sparsity 1.3577901220657553e-06
2024-04-22 09:31:43 - INFO :       logical_args: Total Accuracy (8, 16, 0.5)
2024-04-22 09:31:44 - INFO :       
==================Finish================

2024-04-22 09:31:44 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:31:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:31:44 - INFO :       DATASET: tasksource/bigbench logical_deduction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.81s/it]
2024-04-22 09:32:11 - INFO :       Use taylor pruner...
2024-04-22 09:32:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:32:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:32:12 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:32:12 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:32:12 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:32:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:32:14 - INFO :       Loss = 11.2578125
2024-04-22 09:32:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:32:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:32:19 - INFO :       logical_deduction: Total Sparsity 1.3579492443113975e-06
2024-04-22 09:33:19 - INFO :       logical_deduction: Total Accuracy (11, 50, 0.22)
2024-04-22 09:33:19 - INFO :       
==================Finish================

2024-04-22 09:33:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:33:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:33:19 - INFO :       DATASET: tasksource/bigbench logical_fallacy_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.53s/it]
2024-04-22 09:33:44 - INFO :       Use taylor pruner...
2024-04-22 09:33:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:33:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:33:45 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:33:45 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:33:45 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:33:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:33:46 - INFO :       Loss = 13.8515625
2024-04-22 09:33:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:33:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:33:53 - INFO :       logical_fallacy_detection: Total Sparsity 1.3577901220657553e-06
2024-04-22 09:35:02 - INFO :       logical_fallacy_detection: Total Accuracy (32, 50, 0.64)
2024-04-22 09:35:02 - INFO :       
==================Finish================

2024-04-22 09:35:02 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:35:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:35:02 - INFO :       DATASET: tasksource/bigbench logical_sequence
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.80s/it]
2024-04-22 09:35:28 - INFO :       Use taylor pruner...
2024-04-22 09:35:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:35:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:35:29 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:35:29 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:35:29 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:35:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:35:31 - INFO :       Loss = 11.234375
2024-04-22 09:35:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:35:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:35:36 - INFO :       logical_sequence: Total Sparsity 1.359699589013463e-06
2024-04-22 09:35:55 - INFO :       logical_sequence: Total Accuracy (6, 16, 0.375)
2024-04-22 09:35:55 - INFO :       
==================Finish================

2024-04-22 09:35:55 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:35:55 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:35:55 - INFO :       DATASET: tasksource/bigbench mathematical_induction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.50s/it]
2024-04-22 09:36:23 - INFO :       Use taylor pruner...
2024-04-22 09:36:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:36:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:36:24 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:36:24 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:36:24 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:36:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:36:26 - INFO :       Loss = 14.28125
2024-04-22 09:36:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:36:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:36:33 - INFO :       mathematical_induction: Total Sparsity 1.360336077996032e-06
2024-04-22 09:36:56 - INFO :       mathematical_induction: Total Accuracy (10, 16, 0.625)
2024-04-22 09:36:57 - INFO :       
==================Finish================

2024-04-22 09:36:57 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:36:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:36:57 - INFO :       DATASET: tasksource/bigbench medical_questions_russian
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.06s/it]
2024-04-22 09:37:23 - INFO :       Use taylor pruner...
2024-04-22 09:37:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:37:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:37:24 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:37:24 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:37:24 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:37:24 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:37:26 - INFO :       Loss = 13.0234375
2024-04-22 09:37:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:37:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:37:30 - INFO :       medical_questions_russian: Total Sparsity 1.3554032883811208e-06
2024-04-22 09:38:36 - INFO :       medical_questions_russian: Total Accuracy (13, 50, 0.26)
2024-04-22 09:38:36 - INFO :       
==================Finish================

2024-04-22 09:38:36 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:38:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:38:36 - INFO :       DATASET: tasksource/bigbench metaphor_boolean
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.91s/it]
2024-04-22 09:39:03 - INFO :       Use taylor pruner...
2024-04-22 09:39:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:39:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:39:04 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:39:04 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:39:04 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:39:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:39:05 - INFO :       Loss = 13.6640625
2024-04-22 09:39:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:39:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:39:10 - INFO :       metaphor_boolean: Total Sparsity 1.358744855539609e-06
2024-04-22 09:40:13 - INFO :       metaphor_boolean: Total Accuracy (18, 50, 0.36)
2024-04-22 09:40:14 - INFO :       
==================Finish================

2024-04-22 09:40:14 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:40:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:40:14 - INFO :       DATASET: tasksource/bigbench metaphor_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.18s/it]
2024-04-22 09:40:43 - INFO :       Use taylor pruner...
2024-04-22 09:40:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:40:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:40:44 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:40:44 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:40:44 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:40:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:40:46 - INFO :       Loss = 11.3828125
2024-04-22 09:40:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:40:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:40:51 - INFO :       metaphor_understanding: Total Sparsity 1.35397118817034e-06
2024-04-22 09:41:50 - INFO :       metaphor_understanding: Total Accuracy (26, 46, 0.5652173913043478)
2024-04-22 09:41:50 - INFO :       
==================Finish================

2024-04-22 09:41:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:41:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:41:50 - INFO :       DATASET: tasksource/bigbench misconceptions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.87s/it]
2024-04-22 09:42:17 - INFO :       Use taylor pruner...
2024-04-22 09:42:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:42:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:42:18 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:42:18 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:42:18 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:42:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:42:19 - INFO :       Loss = 14.359375
2024-04-22 09:42:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:42:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:42:24 - INFO :       misconceptions: Total Sparsity 1.3589039777852514e-06
2024-04-22 09:43:19 - INFO :       misconceptions: Total Accuracy (21, 43, 0.4883720930232558)
2024-04-22 09:43:19 - INFO :       
==================Finish================

2024-04-22 09:43:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:43:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:43:19 - INFO :       DATASET: tasksource/bigbench mnist_ascii
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.94s/it]
2024-04-22 09:43:47 - INFO :       Use taylor pruner...
2024-04-22 09:43:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:43:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:43:48 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:43:48 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:43:48 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:43:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:43:49 - INFO :       Loss = 5.734375
2024-04-22 09:43:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:43:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:43:56 - INFO :       mnist_ascii: Total Sparsity 1.3528573324508439e-06
2024-04-22 09:45:43 - INFO :       mnist_ascii: Total Accuracy (6, 50, 0.12)
2024-04-22 09:45:44 - INFO :       
==================Finish================

2024-04-22 09:45:44 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:45:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:45:44 - INFO :       DATASET: tasksource/bigbench moral_permissibility
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.25s/it]
2024-04-22 09:46:15 - INFO :       Use taylor pruner...
2024-04-22 09:46:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:46:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:46:17 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:46:17 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:46:17 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:46:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:46:18 - INFO :       Loss = 11.796875
2024-04-22 09:46:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:46:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:46:24 - INFO :       moral_permissibility: Total Sparsity 1.3538120659246977e-06
2024-04-22 09:47:28 - INFO :       moral_permissibility: Total Accuracy (26, 50, 0.52)
2024-04-22 09:47:28 - INFO :       
==================Finish================

2024-04-22 09:47:28 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:47:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:47:28 - INFO :       DATASET: tasksource/bigbench movie_dialog_same_or_different
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.15s/it]
2024-04-22 09:47:58 - INFO :       Use taylor pruner...
2024-04-22 09:47:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:47:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:47:59 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:47:59 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:47:59 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:48:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:48:01 - INFO :       Loss = 12.109375
2024-04-22 09:48:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:48:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:48:06 - INFO :       movie_dialog_same_or_different: Total Sparsity 1.3566762663462592e-06
2024-04-22 09:49:15 - INFO :       movie_dialog_same_or_different: Total Accuracy (23, 50, 0.46)
2024-04-22 09:49:16 - INFO :       
==================Finish================

2024-04-22 09:49:16 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:49:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:49:16 - INFO :       DATASET: tasksource/bigbench movie_recommendation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.29s/it]
2024-04-22 09:49:42 - INFO :       Use taylor pruner...
2024-04-22 09:49:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:49:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:49:43 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:49:43 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:49:43 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:49:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:49:44 - INFO :       Loss = 12.9609375
2024-04-22 09:49:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:49:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:49:50 - INFO :       movie_recommendation: Total Sparsity 1.358267488802682e-06
2024-04-22 09:50:50 - INFO :       movie_recommendation: Total Accuracy (24, 50, 0.48)
2024-04-22 09:50:50 - INFO :       
==================Finish================

2024-04-22 09:50:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:50:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:50:50 - INFO :       DATASET: tasksource/bigbench navigate
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.69s/it]
2024-04-22 09:51:18 - INFO :       Use taylor pruner...
2024-04-22 09:51:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:51:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:51:19 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:51:19 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:51:19 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--bigbench/c5da5ac497141c7435da10444495b8577405d4ed01e524265b144a7063718c0c (last modified on Sun Sep 24 17:46:45 2023) since it couldn't be found locally at tasksource/bigbench, or remotely on the Hugging Face Hub.
2024-04-22 09:51:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:51:21 - INFO :       Loss = 14.4921875
2024-04-22 09:51:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:51:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:51:26 - INFO :       navigate: Total Sparsity 1.3601769557503897e-06
2024-04-22 09:52:33 - INFO :       navigate: Total Accuracy (27, 50, 0.54)
2024-04-22 09:52:34 - INFO :       
==================Finish================

2024-04-22 09:52:34 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:52:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:52:34 - INFO :       DATASET: tasksource/bigbench nonsense_words_grammar
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.11s/it]
2024-04-22 09:53:00 - INFO :       Use taylor pruner...
2024-04-22 09:53:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:53:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:53:01 - INFO :       Start Pruning
2024-04-22 09:53:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:53:24 - INFO :       Loss = 13.9296875
2024-04-22 09:53:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:53:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:53:29 - INFO :       nonsense_words_grammar: Total Sparsity 1.354448554907267e-06
2024-04-22 09:53:50 - INFO :       nonsense_words_grammar: Total Accuracy (7, 16, 0.4375)
2024-04-22 09:53:50 - INFO :       
==================Finish================

2024-04-22 09:53:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:53:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:53:50 - INFO :       DATASET: tasksource/bigbench novel_concepts
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.56s/it]
2024-04-22 09:54:19 - INFO :       Use taylor pruner...
2024-04-22 09:54:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:54:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:54:20 - INFO :       Start Pruning
2024-04-22 09:54:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:54:42 - INFO :       Loss = 11.4453125
2024-04-22 09:54:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:54:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:54:48 - INFO :       novel_concepts: Total Sparsity 1.3600178335047475e-06
2024-04-22 09:55:07 - INFO :       novel_concepts: Total Accuracy (6, 16, 0.375)
2024-04-22 09:55:07 - INFO :       
==================Finish================

2024-04-22 09:55:07 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:55:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:55:07 - INFO :       DATASET: tasksource/bigbench odd_one_out
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.85s/it]
2024-04-22 09:55:39 - INFO :       Use taylor pruner...
2024-04-22 09:55:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:55:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:55:40 - INFO :       Start Pruning
2024-04-22 09:55:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:55:54 - INFO :       Loss = 14.03125
2024-04-22 09:55:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:55:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:55:59 - INFO :       odd_one_out: Total Sparsity 1.3561988996093322e-06
2024-04-22 09:56:21 - INFO :       odd_one_out: Total Accuracy (2, 17, 0.11764705882352941)
2024-04-22 09:56:21 - INFO :       
==================Finish================

2024-04-22 09:56:21 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:56:21 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:56:21 - INFO :       DATASET: tasksource/bigbench parsinlu_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.68s/it]
2024-04-22 09:56:50 - INFO :       Use taylor pruner...
2024-04-22 09:56:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:56:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:56:51 - INFO :       Start Pruning
2024-04-22 09:57:12 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:57:14 - INFO :       Loss = 8.0859375
2024-04-22 09:57:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:57:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:57:20 - INFO :       parsinlu_qa: Total Sparsity 1.35603977736369e-06
2024-04-22 09:58:30 - INFO :       parsinlu_qa: Total Accuracy (15, 50, 0.3)
2024-04-22 09:58:30 - INFO :       
==================Finish================

2024-04-22 09:58:30 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 09:58:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 09:58:30 - INFO :       DATASET: tasksource/bigbench penguins_in_a_table
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.45s/it]
2024-04-22 09:59:02 - INFO :       Use taylor pruner...
2024-04-22 09:59:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:59:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 09:59:03 - INFO :       Start Pruning
2024-04-22 09:59:25 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 09:59:26 - INFO :       Loss = 9.828125
2024-04-22 09:59:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 09:59:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 09:59:31 - INFO :       penguins_in_a_table: Total Sparsity 1.3561988996093322e-06
2024-04-22 10:00:09 - INFO :       penguins_in_a_table: Total Accuracy (6, 29, 0.20689655172413793)
2024-04-22 10:00:09 - INFO :       
==================Finish================

2024-04-22 10:00:09 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:00:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:00:09 - INFO :       DATASET: tasksource/bigbench persian_idioms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.36s/it]
2024-04-22 10:00:38 - INFO :       Use taylor pruner...
2024-04-22 10:00:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:00:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:00:39 - INFO :       Start Pruning
2024-04-22 10:00:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:00:52 - INFO :       Loss = 10.78125
2024-04-22 10:00:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:00:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:00:59 - INFO :       persian_idioms: Total Sparsity 1.3568353885919015e-06
2024-04-22 10:01:23 - INFO :       persian_idioms: Total Accuracy (6, 16, 0.375)
2024-04-22 10:01:23 - INFO :       
==================Finish================

2024-04-22 10:01:23 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:01:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:01:23 - INFO :       DATASET: tasksource/bigbench phrase_relatedness
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  6.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  7.32s/it]
2024-04-22 10:02:00 - INFO :       Use taylor pruner...
2024-04-22 10:02:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:02:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:02:01 - INFO :       Start Pruning
2024-04-22 10:02:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:02:23 - INFO :       Loss = 13.609375
2024-04-22 10:02:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:02:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:02:29 - INFO :       phrase_relatedness: Total Sparsity 1.3585857332939668e-06
2024-04-22 10:03:00 - INFO :       phrase_relatedness: Total Accuracy (10, 20, 0.5)
2024-04-22 10:03:00 - INFO :       
==================Finish================

2024-04-22 10:03:00 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:03:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:03:00 - INFO :       DATASET: tasksource/bigbench physical_intuition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.74s/it]
2024-04-22 10:03:30 - INFO :       Use taylor pruner...
2024-04-22 10:03:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:03:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:03:31 - INFO :       Start Pruning
2024-04-22 10:03:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:03:50 - INFO :       Loss = 13.3515625
2024-04-22 10:03:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:03:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:03:56 - INFO :       physical_intuition: Total Sparsity 1.3606543224873167e-06
2024-04-22 10:04:17 - INFO :       physical_intuition: Total Accuracy (5, 16, 0.3125)
2024-04-22 10:04:18 - INFO :       
==================Finish================

2024-04-22 10:04:18 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:04:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:04:18 - INFO :       DATASET: tasksource/bigbench physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.13s/it]
2024-04-22 10:04:49 - INFO :       Use taylor pruner...
2024-04-22 10:04:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:04:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:04:50 - INFO :       Start Pruning
2024-04-22 10:04:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:04:53 - INFO :       Loss = 10.3125
2024-04-22 10:04:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:04:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:04:59 - INFO :       physics: Total Sparsity 1.3569945108375437e-06
2024-04-22 10:06:04 - INFO :       physics: Total Accuracy (39, 45, 0.8666666666666667)
2024-04-22 10:06:04 - INFO :       
==================Finish================

2024-04-22 10:06:04 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:06:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:06:04 - INFO :       DATASET: tasksource/bigbench play_dialog_same_or_different
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.17s/it]
2024-04-22 10:06:40 - INFO :       Use taylor pruner...
2024-04-22 10:06:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:06:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:06:41 - INFO :       Start Pruning
2024-04-22 10:06:43 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:06:44 - INFO :       Loss = 8.6484375
2024-04-22 10:06:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:06:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:06:49 - INFO :       play_dialog_same_or_different: Total Sparsity 1.35603977736369e-06
2024-04-22 10:07:58 - INFO :       play_dialog_same_or_different: Total Accuracy (16, 50, 0.32)
2024-04-22 10:07:58 - INFO :       
==================Finish================

2024-04-22 10:07:58 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:07:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:07:58 - INFO :       DATASET: tasksource/bigbench presuppositions_as_nli
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.73s/it]
2024-04-22 10:08:29 - INFO :       Use taylor pruner...
2024-04-22 10:08:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:08:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:08:30 - INFO :       Start Pruning
2024-04-22 10:08:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:08:34 - INFO :       Loss = 10.34375
2024-04-22 10:08:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:08:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:08:39 - INFO :       presuppositions_as_nli: Total Sparsity 1.35603977736369e-06
2024-04-22 10:09:56 - INFO :       presuppositions_as_nli: Total Accuracy (15, 50, 0.3)
2024-04-22 10:09:56 - INFO :       
==================Finish================

2024-04-22 10:09:56 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:09:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:09:56 - INFO :       DATASET: tasksource/bigbench question_selection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  6.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  7.22s/it]
2024-04-22 10:10:31 - INFO :       Use taylor pruner...
2024-04-22 10:10:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:10:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:10:32 - INFO :       Start Pruning
2024-04-22 10:10:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:10:35 - INFO :       Loss = 6.1015625
2024-04-22 10:10:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:10:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:10:40 - INFO :       question_selection: Total Sparsity 1.35397118817034e-06
2024-04-22 10:11:53 - INFO :       question_selection: Total Accuracy (31, 50, 0.62)
2024-04-22 10:11:54 - INFO :       
==================Finish================

2024-04-22 10:11:54 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:11:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:11:54 - INFO :       DATASET: tasksource/bigbench reasoning_about_colored_objects
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.10s/it]
2024-04-22 10:12:20 - INFO :       Use taylor pruner...
2024-04-22 10:12:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:12:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:12:21 - INFO :       Start Pruning
2024-04-22 10:12:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:12:23 - INFO :       Loss = 10.0859375
2024-04-22 10:12:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:12:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:12:28 - INFO :       reasoning_about_colored_objects: Total Sparsity 1.356517144100617e-06
2024-04-22 10:13:49 - INFO :       reasoning_about_colored_objects: Total Accuracy (15, 50, 0.3)
2024-04-22 10:13:49 - INFO :       
==================Finish================

2024-04-22 10:13:49 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:13:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:13:49 - INFO :       DATASET: tasksource/bigbench riddle_sense
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:11<00:11, 11.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  6.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  7.47s/it]
2024-04-22 10:14:28 - INFO :       Use taylor pruner...
2024-04-22 10:14:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:14:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:14:29 - INFO :       Start Pruning
2024-04-22 10:14:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:14:32 - INFO :       Loss = 13.0234375
2024-04-22 10:14:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:14:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:14:37 - INFO :       riddle_sense: Total Sparsity 1.3612908114698858e-06
2024-04-22 10:14:59 - INFO :       riddle_sense: Total Accuracy (2, 16, 0.125)
2024-04-22 10:14:59 - INFO :       
==================Finish================

2024-04-22 10:14:59 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:14:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:14:59 - INFO :       DATASET: tasksource/bigbench ruin_names
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.64s/it]
2024-04-22 10:15:30 - INFO :       Use taylor pruner...
2024-04-22 10:15:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:15:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:15:30 - INFO :       Start Pruning
2024-04-22 10:15:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:15:33 - INFO :       Loss = 13.1875
2024-04-22 10:15:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:15:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:15:38 - INFO :       ruin_names: Total Sparsity 1.3568353885919015e-06
2024-04-22 10:16:43 - INFO :       ruin_names: Total Accuracy (8, 50, 0.16)
2024-04-22 10:16:43 - INFO :       
==================Finish================

2024-04-22 10:16:43 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:16:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:16:43 - INFO :       DATASET: tasksource/bigbench salient_translation_error_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  6.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  7.05s/it]
2024-04-22 10:17:17 - INFO :       Use taylor pruner...
2024-04-22 10:17:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:17:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:17:18 - INFO :       Start Pruning
2024-04-22 10:17:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:17:21 - INFO :       Loss = 7.953125
2024-04-22 10:17:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:17:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:17:26 - INFO :       salient_translation_error_detection: Total Sparsity 1.3563580218549744e-06
2024-04-22 10:18:47 - INFO :       salient_translation_error_detection: Total Accuracy (11, 50, 0.22)
2024-04-22 10:18:47 - INFO :       
==================Finish================

2024-04-22 10:18:47 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:18:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:18:47 - INFO :       DATASET: tasksource/bigbench sentence_ambiguity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.28s/it]
2024-04-22 10:19:18 - INFO :       Use taylor pruner...
2024-04-22 10:19:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:19:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:19:19 - INFO :       Start Pruning
2024-04-22 10:19:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:19:24 - INFO :       Loss = 14.25
2024-04-22 10:19:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:19:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:19:30 - INFO :       sentence_ambiguity: Total Sparsity 1.3569945108375437e-06
2024-04-22 10:19:57 - INFO :       sentence_ambiguity: Total Accuracy (8, 16, 0.5)
2024-04-22 10:19:57 - INFO :       
==================Finish================

2024-04-22 10:19:57 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:19:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:19:57 - INFO :       DATASET: tasksource/bigbench similarities_abstraction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.61s/it]
2024-04-22 10:20:26 - INFO :       Use taylor pruner...
2024-04-22 10:20:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:20:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:20:27 - INFO :       Start Pruning
2024-04-22 10:20:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:20:30 - INFO :       Loss = 13.0234375
2024-04-22 10:20:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:20:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:20:36 - INFO :       similarities_abstraction: Total Sparsity 1.358267488802682e-06
2024-04-22 10:20:54 - INFO :       similarities_abstraction: Total Accuracy (9, 16, 0.5625)
2024-04-22 10:20:54 - INFO :       
==================Finish================

2024-04-22 10:20:54 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:20:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:20:54 - INFO :       DATASET: tasksource/bigbench simple_ethical_questions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.00s/it]
2024-04-22 10:21:27 - INFO :       Use taylor pruner...
2024-04-22 10:21:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:21:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:21:28 - INFO :       Start Pruning
2024-04-22 10:21:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:21:31 - INFO :       Loss = 10.9609375
2024-04-22 10:21:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:21:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:21:36 - INFO :       simple_ethical_questions: Total Sparsity 1.3547667993985515e-06
2024-04-22 10:22:05 - INFO :       simple_ethical_questions: Total Accuracy (17, 23, 0.7391304347826086)
2024-04-22 10:22:05 - INFO :       
==================Finish================

2024-04-22 10:22:05 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:22:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:22:05 - INFO :       DATASET: tasksource/bigbench snarks
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.64s/it]
2024-04-22 10:22:29 - INFO :       Use taylor pruner...
2024-04-22 10:22:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:22:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:22:30 - INFO :       Start Pruning
2024-04-22 10:22:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:22:33 - INFO :       Loss = 13.9921875
2024-04-22 10:22:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:22:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:22:38 - INFO :       snarks: Total Sparsity 1.3561988996093322e-06
2024-04-22 10:23:28 - INFO :       snarks: Total Accuracy (12, 36, 0.3333333333333333)
2024-04-22 10:23:30 - INFO :       
==================Finish================

2024-04-22 10:23:30 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:23:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:23:30 - INFO :       DATASET: tasksource/bigbench social_iqa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.92s/it]
2024-04-22 10:23:55 - INFO :       Use taylor pruner...
2024-04-22 10:23:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:23:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:23:56 - INFO :       Start Pruning
2024-04-22 10:23:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:23:59 - INFO :       Loss = 13.1953125
2024-04-22 10:24:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:24:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:24:04 - INFO :       social_iqa: Total Sparsity 1.3598587112591052e-06
2024-04-22 10:25:10 - INFO :       social_iqa: Total Accuracy (23, 50, 0.46)
2024-04-22 10:25:10 - INFO :       
==================Finish================

2024-04-22 10:25:10 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:25:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:25:10 - INFO :       DATASET: tasksource/bigbench social_support
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.49s/it]
2024-04-22 10:25:37 - INFO :       Use taylor pruner...
2024-04-22 10:25:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:25:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:25:38 - INFO :       Start Pruning
2024-04-22 10:25:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:25:40 - INFO :       Loss = 12.5
2024-04-22 10:25:42 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:25:42 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:25:45 - INFO :       social_support: Total Sparsity 1.357153633083186e-06
2024-04-22 10:26:47 - INFO :       social_support: Total Accuracy (20, 50, 0.4)
2024-04-22 10:26:47 - INFO :       
==================Finish================

2024-04-22 10:26:47 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:26:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:26:47 - INFO :       DATASET: tasksource/bigbench sports_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.63s/it]
2024-04-22 10:27:12 - INFO :       Use taylor pruner...
2024-04-22 10:27:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:27:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:27:13 - INFO :       Start Pruning
2024-04-22 10:27:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:27:16 - INFO :       Loss = 14.6953125
2024-04-22 10:27:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:27:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:27:21 - INFO :       sports_understanding: Total Sparsity 1.3574718775744707e-06
2024-04-22 10:28:24 - INFO :       sports_understanding: Total Accuracy (29, 50, 0.58)
2024-04-22 10:28:25 - INFO :       
==================Finish================

2024-04-22 10:28:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:28:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:28:25 - INFO :       DATASET: tasksource/bigbench strange_stories
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.19s/it]
2024-04-22 10:28:53 - INFO :       Use taylor pruner...
2024-04-22 10:28:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:28:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:28:54 - INFO :       Start Pruning
2024-04-22 10:28:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:28:57 - INFO :       Loss = 10.03125
2024-04-22 10:28:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:28:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:29:03 - INFO :       strange_stories: Total Sparsity 1.3552441661354783e-06
2024-04-22 10:29:49 - INFO :       strange_stories: Total Accuracy (16, 34, 0.47058823529411764)
2024-04-22 10:29:49 - INFO :       
==================Finish================

2024-04-22 10:29:49 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:29:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:29:49 - INFO :       DATASET: tasksource/bigbench strategyqa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.91s/it]
2024-04-22 10:30:14 - INFO :       Use taylor pruner...
2024-04-22 10:30:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:30:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:30:15 - INFO :       Start Pruning
2024-04-22 10:30:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:30:18 - INFO :       Loss = 14.3203125
2024-04-22 10:30:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:30:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:30:23 - INFO :       strategyqa: Total Sparsity 1.357630999820113e-06
2024-04-22 10:31:20 - INFO :       strategyqa: Total Accuracy (30, 50, 0.6)
2024-04-22 10:31:20 - INFO :       
==================Finish================

2024-04-22 10:31:20 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:31:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:31:20 - INFO :       DATASET: tasksource/bigbench suicide_risk
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.80s/it]
2024-04-22 10:31:46 - INFO :       Use taylor pruner...
2024-04-22 10:31:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:31:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:31:47 - INFO :       Start Pruning
2024-04-22 10:31:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:31:49 - INFO :       Loss = 11.8203125
2024-04-22 10:31:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:31:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:31:53 - INFO :       suicide_risk: Total Sparsity 1.357630999820113e-06
2024-04-22 10:32:14 - INFO :       suicide_risk: Total Accuracy (5, 16, 0.3125)
2024-04-22 10:32:14 - INFO :       
==================Finish================

2024-04-22 10:32:14 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:32:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:32:14 - INFO :       DATASET: tasksource/bigbench swahili_english_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.47s/it]
2024-04-22 10:32:46 - INFO :       Use taylor pruner...
2024-04-22 10:32:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:32:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:32:47 - INFO :       Start Pruning
2024-04-22 10:32:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:32:51 - INFO :       Loss = 11.1796875
2024-04-22 10:32:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:32:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:32:56 - INFO :       swahili_english_proverbs: Total Sparsity 1.3577901220657553e-06
2024-04-22 10:33:37 - INFO :       swahili_english_proverbs: Total Accuracy (17, 30, 0.5666666666666667)
2024-04-22 10:33:37 - INFO :       
==================Finish================

2024-04-22 10:33:37 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:33:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:33:37 - INFO :       DATASET: tasksource/bigbench swedish_to_german_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.14s/it]
2024-04-22 10:34:08 - INFO :       Use taylor pruner...
2024-04-22 10:34:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:34:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:34:11 - INFO :       Start Pruning
2024-04-22 10:34:12 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:34:13 - INFO :       Loss = 11.6015625
2024-04-22 10:34:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:34:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:34:20 - INFO :       swedish_to_german_proverbs: Total Sparsity 1.3585857332939668e-06
2024-04-22 10:34:41 - INFO :       swedish_to_german_proverbs: Total Accuracy (8, 16, 0.5)
2024-04-22 10:34:41 - INFO :       
==================Finish================

2024-04-22 10:34:41 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:34:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:34:41 - INFO :       DATASET: tasksource/bigbench symbol_interpretation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.64s/it]
2024-04-22 10:35:07 - INFO :       Use taylor pruner...
2024-04-22 10:35:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:35:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:35:08 - INFO :       Start Pruning
2024-04-22 10:35:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:35:10 - INFO :       Loss = 4.9140625
2024-04-22 10:35:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:35:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:35:15 - INFO :       symbol_interpretation: Total Sparsity 1.3577901220657553e-06
2024-04-22 10:36:40 - INFO :       symbol_interpretation: Total Accuracy (16, 50, 0.32)
2024-04-22 10:36:40 - INFO :       
==================Finish================

2024-04-22 10:36:40 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:36:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:36:40 - INFO :       DATASET: tasksource/bigbench temporal_sequences
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.73s/it]
2024-04-22 10:37:12 - INFO :       Use taylor pruner...
2024-04-22 10:37:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:37:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:37:14 - INFO :       Start Pruning
2024-04-22 10:37:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:37:16 - INFO :       Loss = 8.078125
2024-04-22 10:37:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:37:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:37:22 - INFO :       temporal_sequences: Total Sparsity 1.358267488802682e-06
2024-04-22 10:38:25 - INFO :       temporal_sequences: Total Accuracy (11, 50, 0.22)
2024-04-22 10:38:25 - INFO :       
==================Finish================

2024-04-22 10:38:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:38:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:38:25 - INFO :       DATASET: tasksource/bigbench timedial
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.58s/it]
2024-04-22 10:38:53 - INFO :       Use taylor pruner...
2024-04-22 10:38:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:38:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:38:54 - INFO :       Start Pruning
2024-04-22 10:38:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:38:56 - INFO :       Loss = 7.07421875
2024-04-22 10:38:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:38:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:39:02 - INFO :       timedial: Total Sparsity 1.3574718775744707e-06
2024-04-22 10:40:06 - INFO :       timedial: Total Accuracy (11, 50, 0.22)
2024-04-22 10:40:07 - INFO :       
==================Finish================

2024-04-22 10:40:07 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:40:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:40:07 - INFO :       DATASET: tasksource/bigbench tracking_shuffled_objects
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.93s/it]
2024-04-22 10:40:33 - INFO :       Use taylor pruner...
2024-04-22 10:40:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:40:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:40:34 - INFO :       Start Pruning
2024-04-22 10:40:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:40:36 - INFO :       Loss = 8.1796875
2024-04-22 10:40:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:40:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:40:42 - INFO :       tracking_shuffled_objects: Total Sparsity 1.35190259897699e-06
2024-04-22 10:41:41 - INFO :       tracking_shuffled_objects: Total Accuracy (6, 50, 0.12)
2024-04-22 10:41:41 - INFO :       
==================Finish================

2024-04-22 10:41:41 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:41:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:41:41 - INFO :       DATASET: tasksource/bigbench understanding_fables
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.88s/it]
2024-04-22 10:42:07 - INFO :       Use taylor pruner...
2024-04-22 10:42:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:42:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:42:08 - INFO :       Start Pruning
2024-04-22 10:42:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:42:10 - INFO :       Loss = 7.50390625
2024-04-22 10:42:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:42:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:42:16 - INFO :       understanding_fables: Total Sparsity 1.35603977736369e-06
2024-04-22 10:43:03 - INFO :       understanding_fables: Total Accuracy (10, 37, 0.2702702702702703)
2024-04-22 10:43:03 - INFO :       
==================Finish================

2024-04-22 10:43:03 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:43:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:43:03 - INFO :       DATASET: tasksource/bigbench undo_permutation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.61s/it]
2024-04-22 10:43:28 - INFO :       Use taylor pruner...
2024-04-22 10:43:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:43:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:43:29 - INFO :       Start Pruning
2024-04-22 10:43:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:43:32 - INFO :       Loss = 7.3515625
2024-04-22 10:43:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:43:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:43:36 - INFO :       undo_permutation: Total Sparsity 1.3542894326616245e-06
2024-04-22 10:44:40 - INFO :       undo_permutation: Total Accuracy (29, 50, 0.58)
2024-04-22 10:44:40 - INFO :       
==================Finish================

2024-04-22 10:44:40 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:44:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:44:40 - INFO :       DATASET: tasksource/bigbench unit_interpretation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.75s/it]
2024-04-22 10:45:06 - INFO :       Use taylor pruner...
2024-04-22 10:45:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:45:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:45:07 - INFO :       Start Pruning
2024-04-22 10:45:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:45:10 - INFO :       Loss = 11.1328125
2024-04-22 10:45:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:45:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:45:14 - INFO :       unit_interpretation: Total Sparsity 1.358267488802682e-06
2024-04-22 10:45:38 - INFO :       unit_interpretation: Total Accuracy (6, 20, 0.3)
2024-04-22 10:45:38 - INFO :       
==================Finish================

2024-04-22 10:45:38 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:45:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:45:38 - INFO :       DATASET: tasksource/bigbench vitaminc_fact_verification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.43s/it]
2024-04-22 10:46:07 - INFO :       Use taylor pruner...
2024-04-22 10:46:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:46:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:46:08 - INFO :       Start Pruning
2024-04-22 10:46:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:46:10 - INFO :       Loss = 11.6328125
2024-04-22 10:46:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:46:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:46:16 - INFO :       vitaminc_fact_verification: Total Sparsity 1.3561988996093322e-06
2024-04-22 10:47:20 - INFO :       vitaminc_fact_verification: Total Accuracy (22, 50, 0.44)
2024-04-22 10:47:20 - INFO :       
==================Finish================

2024-04-22 10:47:20 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:47:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:47:20 - INFO :       DATASET: tasksource/bigbench what_is_the_tao
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.17s/it]
2024-04-22 10:47:47 - INFO :       Use taylor pruner...
2024-04-22 10:47:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:47:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:47:48 - INFO :       Start Pruning
2024-04-22 10:47:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:47:50 - INFO :       Loss = 13.953125
2024-04-22 10:47:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:47:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:47:55 - INFO :       what_is_the_tao: Total Sparsity 1.3593813445221782e-06
2024-04-22 10:48:14 - INFO :       what_is_the_tao: Total Accuracy (6, 16, 0.375)
2024-04-22 10:48:14 - INFO :       
==================Finish================

2024-04-22 10:48:14 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 10:48:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:48:14 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.17s/it]
2024-04-22 10:48:42 - INFO :       Use taylor pruner...
2024-04-22 10:48:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:48:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:48:43 - INFO :       Start Pruning
Token indices sequence length is longer than the specified maximum sequence length for this model (7416 > 4096). Running this sequence through the model will result in indexing errors
2024-04-22 10:48:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:48:45 - INFO :       Loss = 1.623046875
2024-04-22 10:48:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:48:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:48:50 - INFO :       which_wiki_edit: Total Sparsity 1.348720154064144e-06
2024-04-22 10:50:50 - INFO :       which_wiki_edit: Total Accuracy (24, 50, 0.48)
2024-04-22 10:50:51 - INFO :       
==================Finish================

2024-04-22 10:50:51 - INFO :       Memory Requirement: 16809.46826171875 MiB

2024-04-22 10:50:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:50:51 - INFO :       DATASET: tasksource/bigbench winowhy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.79s/it]
2024-04-22 10:51:17 - INFO :       Use taylor pruner...
2024-04-22 10:51:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:51:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:51:18 - INFO :       Start Pruning
2024-04-22 10:51:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:51:21 - INFO :       Loss = 13.7265625
2024-04-22 10:51:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:51:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:51:26 - INFO :       winowhy: Total Sparsity 1.3601769557503897e-06
2024-04-22 10:52:23 - INFO :       winowhy: Total Accuracy (25, 50, 0.5)
2024-04-22 10:52:23 - INFO :       
==================Finish================

2024-04-22 10:52:23 - INFO :       Memory Requirement: 16777.79052734375 MiB

2024-04-22 10:52:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:52:23 - INFO :       DATASET: tasksource/mmlu abstract_algebra
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.72s/it]
2024-04-22 10:52:51 - INFO :       Use taylor pruner...
2024-04-22 10:52:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:52:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:52:52 - INFO :       Start Pruning
2024-04-22 10:52:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:52:55 - INFO :       Loss = 13.359375
2024-04-22 10:52:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:52:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:53:00 - INFO :       abstract_algebra: Total Sparsity 1.3593813445221782e-06
2024-04-22 10:53:14 - INFO :       abstract_algebra: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-22 10:53:14 - INFO :       
==================Finish================

2024-04-22 10:53:14 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 10:53:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:53:14 - INFO :       DATASET: tasksource/mmlu anatomy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.14s/it]
2024-04-22 10:53:43 - INFO :       Use taylor pruner...
2024-04-22 10:53:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:53:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:53:44 - INFO :       Start Pruning
2024-04-22 10:53:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:53:45 - INFO :       Loss = 14.109375
2024-04-22 10:53:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:53:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:53:50 - INFO :       anatomy: Total Sparsity 1.3585857332939668e-06
2024-04-22 10:54:08 - INFO :       anatomy: Total Accuracy (9, 14, 0.6428571428571429)
2024-04-22 10:54:08 - INFO :       
==================Finish================

2024-04-22 10:54:08 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 10:54:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:54:08 - INFO :       DATASET: tasksource/mmlu astronomy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.04s/it]
2024-04-22 10:54:36 - INFO :       Use taylor pruner...
2024-04-22 10:54:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:54:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:54:37 - INFO :       Start Pruning
2024-04-22 10:54:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:54:39 - INFO :       Loss = 14.0234375
2024-04-22 10:54:42 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:54:42 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:54:44 - INFO :       astronomy: Total Sparsity 1.3593813445221782e-06
2024-04-22 10:55:02 - INFO :       astronomy: Total Accuracy (3, 16, 0.1875)
2024-04-22 10:55:02 - INFO :       
==================Finish================

2024-04-22 10:55:02 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 10:55:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:55:02 - INFO :       DATASET: tasksource/mmlu business_ethics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.71s/it]
2024-04-22 10:55:27 - INFO :       Use taylor pruner...
2024-04-22 10:55:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:55:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:55:28 - INFO :       Start Pruning
2024-04-22 10:55:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:55:30 - INFO :       Loss = 13.0703125
2024-04-22 10:55:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:55:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:55:35 - INFO :       business_ethics: Total Sparsity 1.3593813445221782e-06
2024-04-22 10:55:52 - INFO :       business_ethics: Total Accuracy (6, 11, 0.5454545454545454)
2024-04-22 10:55:52 - INFO :       
==================Finish================

2024-04-22 10:55:52 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 10:55:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:55:52 - INFO :       DATASET: tasksource/mmlu clinical_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:10<00:10, 10.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  6.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:14<00:00,  7.11s/it]
2024-04-22 10:56:28 - INFO :       Use taylor pruner...
2024-04-22 10:56:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:56:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:56:29 - INFO :       Start Pruning
2024-04-22 10:56:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:56:32 - INFO :       Loss = 14.375
2024-04-22 10:56:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:56:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:56:38 - INFO :       clinical_knowledge: Total Sparsity 1.3600178335047475e-06
2024-04-22 10:57:16 - INFO :       clinical_knowledge: Total Accuracy (13, 29, 0.4482758620689655)
2024-04-22 10:57:16 - INFO :       
==================Finish================

2024-04-22 10:57:16 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 10:57:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:57:16 - INFO :       DATASET: tasksource/mmlu college_biology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.32s/it]
2024-04-22 10:57:43 - INFO :       Use taylor pruner...
2024-04-22 10:57:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:57:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:57:44 - INFO :       Start Pruning
2024-04-22 10:57:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:57:47 - INFO :       Loss = 14.0859375
2024-04-22 10:57:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:57:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:57:53 - INFO :       college_biology: Total Sparsity 1.358744855539609e-06
2024-04-22 10:58:20 - INFO :       college_biology: Total Accuracy (7, 16, 0.4375)
2024-04-22 10:58:20 - INFO :       
==================Finish================

2024-04-22 10:58:20 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 10:58:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:58:20 - INFO :       DATASET: tasksource/mmlu college_chemistry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.80s/it]
2024-04-22 10:58:53 - INFO :       Use taylor pruner...
2024-04-22 10:58:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:58:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:58:54 - INFO :       Start Pruning
num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-22 10:58:55 - WARNING :       num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-22 10:58:55 - WARNING :       num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-22 10:58:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:58:57 - INFO :       Loss = 13.09375
2024-04-22 10:58:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:58:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:59:02 - INFO :       college_chemistry: Total Sparsity 1.3595404667678207e-06
2024-04-22 10:59:11 - INFO :       college_chemistry: Total Accuracy (2, 8, 0.25)
2024-04-22 10:59:11 - INFO :       
==================Finish================

2024-04-22 10:59:11 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 10:59:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:59:11 - INFO :       DATASET: tasksource/mmlu college_computer_science
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.75s/it]
2024-04-22 10:59:37 - INFO :       Use taylor pruner...
2024-04-22 10:59:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:59:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 10:59:38 - INFO :       Start Pruning
2024-04-22 10:59:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 10:59:40 - INFO :       Loss = 13.171875
2024-04-22 10:59:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 10:59:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 10:59:46 - INFO :       college_computer_science: Total Sparsity 1.358267488802682e-06
2024-04-22 10:59:58 - INFO :       college_computer_science: Total Accuracy (2, 11, 0.18181818181818182)
2024-04-22 10:59:58 - INFO :       
==================Finish================

2024-04-22 10:59:58 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 10:59:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 10:59:58 - INFO :       DATASET: tasksource/mmlu college_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.66s/it]
2024-04-22 11:00:23 - INFO :       Use taylor pruner...
2024-04-22 11:00:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:00:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:00:24 - INFO :       Start Pruning
2024-04-22 11:00:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:00:27 - INFO :       Loss = 12.84375
2024-04-22 11:00:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:00:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:00:31 - INFO :       college_mathematics: Total Sparsity 1.3566762663462592e-06
2024-04-22 11:00:44 - INFO :       college_mathematics: Total Accuracy (2, 11, 0.18181818181818182)
2024-04-22 11:00:44 - INFO :       
==================Finish================

2024-04-22 11:00:44 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:00:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:00:44 - INFO :       DATASET: tasksource/mmlu college_medicine
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.92s/it]
2024-04-22 11:01:12 - INFO :       Use taylor pruner...
2024-04-22 11:01:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:01:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:01:13 - INFO :       Start Pruning
2024-04-22 11:01:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:01:15 - INFO :       Loss = 11.9296875
2024-04-22 11:01:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:01:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:01:21 - INFO :       college_medicine: Total Sparsity 1.3549259216441938e-06
2024-04-22 11:01:47 - INFO :       college_medicine: Total Accuracy (9, 22, 0.4090909090909091)
2024-04-22 11:01:47 - INFO :       
==================Finish================

2024-04-22 11:01:47 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:01:47 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:01:47 - INFO :       DATASET: tasksource/mmlu college_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.89s/it]
2024-04-22 11:02:16 - INFO :       Use taylor pruner...
2024-04-22 11:02:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:02:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:02:17 - INFO :       Start Pruning
2024-04-22 11:02:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:02:19 - INFO :       Loss = 12.734375
2024-04-22 11:02:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:02:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:02:23 - INFO :       college_physics: Total Sparsity 1.3609725669786013e-06
2024-04-22 11:02:38 - INFO :       college_physics: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-22 11:02:38 - INFO :       
==================Finish================

2024-04-22 11:02:38 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:02:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:02:38 - INFO :       DATASET: tasksource/mmlu computer_security
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.85s/it]
2024-04-22 11:03:04 - INFO :       Use taylor pruner...
2024-04-22 11:03:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:03:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:03:05 - INFO :       Start Pruning
2024-04-22 11:03:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:03:08 - INFO :       Loss = 14.4921875
2024-04-22 11:03:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:03:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:03:13 - INFO :       computer_security: Total Sparsity 1.3558806551180476e-06
2024-04-22 11:03:27 - INFO :       computer_security: Total Accuracy (5, 11, 0.45454545454545453)
2024-04-22 11:03:27 - INFO :       
==================Finish================

2024-04-22 11:03:27 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:03:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:03:27 - INFO :       DATASET: tasksource/mmlu conceptual_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.98s/it]
2024-04-22 11:03:57 - INFO :       Use taylor pruner...
2024-04-22 11:03:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:03:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:03:58 - INFO :       Start Pruning
2024-04-22 11:04:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:04:01 - INFO :       Loss = 14.046875
2024-04-22 11:04:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:04:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:04:06 - INFO :       conceptual_physics: Total Sparsity 1.3612908114698858e-06
2024-04-22 11:04:38 - INFO :       conceptual_physics: Total Accuracy (7, 26, 0.2692307692307692)
2024-04-22 11:04:38 - INFO :       
==================Finish================

2024-04-22 11:04:38 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:04:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:04:38 - INFO :       DATASET: tasksource/mmlu econometrics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.26s/it]
2024-04-22 11:05:06 - INFO :       Use taylor pruner...
2024-04-22 11:05:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:05:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:05:08 - INFO :       Start Pruning
2024-04-22 11:05:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:05:10 - INFO :       Loss = 13.390625
2024-04-22 11:05:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:05:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:05:15 - INFO :       econometrics: Total Sparsity 1.3573127553288283e-06
2024-04-22 11:05:29 - INFO :       econometrics: Total Accuracy (1, 12, 0.08333333333333333)
2024-04-22 11:05:29 - INFO :       
==================Finish================

2024-04-22 11:05:29 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:05:29 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:05:29 - INFO :       DATASET: tasksource/mmlu electrical_engineering
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.65s/it]
2024-04-22 11:05:55 - INFO :       Use taylor pruner...
2024-04-22 11:05:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:05:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:05:57 - INFO :       Start Pruning
2024-04-22 11:05:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:06:00 - INFO :       Loss = 14.4296875
2024-04-22 11:06:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:06:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:06:05 - INFO :       electrical_engineering: Total Sparsity 1.357153633083186e-06
2024-04-22 11:06:26 - INFO :       electrical_engineering: Total Accuracy (5, 16, 0.3125)
2024-04-22 11:06:26 - INFO :       
==================Finish================

2024-04-22 11:06:26 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:06:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:06:26 - INFO :       DATASET: tasksource/mmlu elementary_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.57s/it]
2024-04-22 11:06:55 - INFO :       Use taylor pruner...
2024-04-22 11:06:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:06:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:06:56 - INFO :       Start Pruning
2024-04-22 11:06:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:06:59 - INFO :       Loss = 13.765625
2024-04-22 11:07:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:07:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:07:04 - INFO :       elementary_mathematics: Total Sparsity 1.357153633083186e-06
2024-04-22 11:07:54 - INFO :       elementary_mathematics: Total Accuracy (9, 41, 0.21951219512195122)
2024-04-22 11:07:54 - INFO :       
==================Finish================

2024-04-22 11:07:54 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:07:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:07:54 - INFO :       DATASET: tasksource/mmlu formal_logic
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.40s/it]
2024-04-22 11:08:24 - INFO :       Use taylor pruner...
2024-04-22 11:08:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:08:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:08:25 - INFO :       Start Pruning
2024-04-22 11:08:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:08:28 - INFO :       Loss = 10.890625
2024-04-22 11:08:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:08:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:08:33 - INFO :       formal_logic: Total Sparsity 1.3589039777852514e-06
2024-04-22 11:08:51 - INFO :       formal_logic: Total Accuracy (3, 14, 0.21428571428571427)
2024-04-22 11:08:51 - INFO :       
==================Finish================

2024-04-22 11:08:51 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:08:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:08:51 - INFO :       DATASET: tasksource/mmlu global_facts
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.35s/it]
2024-04-22 11:09:20 - INFO :       Use taylor pruner...
2024-04-22 11:09:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:09:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:09:20 - INFO :       Start Pruning
2024-04-22 11:09:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:09:24 - INFO :       Loss = 13.7578125
2024-04-22 11:09:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:09:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:09:28 - INFO :       global_facts: Total Sparsity 1.3598587112591052e-06
2024-04-22 11:09:41 - INFO :       global_facts: Total Accuracy (1, 10, 0.1)
2024-04-22 11:09:41 - INFO :       
==================Finish================

2024-04-22 11:09:41 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:09:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:09:41 - INFO :       DATASET: tasksource/mmlu high_school_biology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.10s/it]
2024-04-22 11:10:10 - INFO :       Use taylor pruner...
2024-04-22 11:10:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:10:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:10:12 - INFO :       Start Pruning
2024-04-22 11:10:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:10:15 - INFO :       Loss = 13.859375
2024-04-22 11:10:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:10:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:10:20 - INFO :       high_school_biology: Total Sparsity 1.3609725669786013e-06
2024-04-22 11:11:03 - INFO :       high_school_biology: Total Accuracy (13, 32, 0.40625)
2024-04-22 11:11:03 - INFO :       
==================Finish================

2024-04-22 11:11:03 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:11:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:11:03 - INFO :       DATASET: tasksource/mmlu high_school_chemistry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.19s/it]
2024-04-22 11:11:33 - INFO :       Use taylor pruner...
2024-04-22 11:11:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:11:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:11:34 - INFO :       Start Pruning
2024-04-22 11:11:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:11:37 - INFO :       Loss = 11.640625
2024-04-22 11:11:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:11:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:11:43 - INFO :       high_school_chemistry: Total Sparsity 1.3574718775744707e-06
2024-04-22 11:12:11 - INFO :       high_school_chemistry: Total Accuracy (6, 22, 0.2727272727272727)
2024-04-22 11:12:11 - INFO :       
==================Finish================

2024-04-22 11:12:11 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:12:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:12:11 - INFO :       DATASET: tasksource/mmlu high_school_computer_science
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.01s/it]
2024-04-22 11:12:44 - INFO :       Use taylor pruner...
2024-04-22 11:12:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:12:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:12:45 - INFO :       Start Pruning
num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-22 11:12:46 - WARNING :       num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-22 11:12:46 - WARNING :       num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-22 11:12:46 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:12:47 - INFO :       Loss = 11.7109375
2024-04-22 11:12:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:12:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:12:53 - INFO :       high_school_computer_science: Total Sparsity 1.359699589013463e-06
2024-04-22 11:13:06 - INFO :       high_school_computer_science: Total Accuracy (5, 9, 0.5555555555555556)
2024-04-22 11:13:06 - INFO :       
==================Finish================

2024-04-22 11:13:06 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:13:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:13:06 - INFO :       DATASET: tasksource/mmlu high_school_european_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.05s/it]
2024-04-22 11:13:37 - INFO :       Use taylor pruner...
2024-04-22 11:13:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:13:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:13:38 - INFO :       Start Pruning
2024-04-22 11:13:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:13:43 - INFO :       Loss = 4.7421875
2024-04-22 11:13:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:13:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:13:48 - INFO :       high_school_european_history: Total Sparsity 1.357153633083186e-06
2024-04-22 11:14:11 - INFO :       high_school_european_history: Total Accuracy (11, 18, 0.6111111111111112)
2024-04-22 11:14:11 - INFO :       
==================Finish================

2024-04-22 11:14:11 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:14:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:14:11 - INFO :       DATASET: tasksource/mmlu high_school_geography
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.38s/it]
2024-04-22 11:14:39 - INFO :       Use taylor pruner...
2024-04-22 11:14:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:14:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:14:40 - INFO :       Start Pruning
2024-04-22 11:14:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:14:43 - INFO :       Loss = 14.6171875
2024-04-22 11:14:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:14:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:14:49 - INFO :       high_school_geography: Total Sparsity 1.3600178335047475e-06
2024-04-22 11:15:18 - INFO :       high_school_geography: Total Accuracy (14, 22, 0.6363636363636364)
2024-04-22 11:15:18 - INFO :       
==================Finish================

2024-04-22 11:15:18 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:15:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:15:18 - INFO :       DATASET: tasksource/mmlu high_school_government_and_politics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.70s/it]
2024-04-22 11:15:45 - INFO :       Use taylor pruner...
2024-04-22 11:15:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:15:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:15:46 - INFO :       Start Pruning
2024-04-22 11:15:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:15:48 - INFO :       Loss = 13.8125
2024-04-22 11:15:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:15:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:15:53 - INFO :       high_school_government_and_politics: Total Sparsity 1.358744855539609e-06
2024-04-22 11:16:19 - INFO :       high_school_government_and_politics: Total Accuracy (8, 21, 0.38095238095238093)
2024-04-22 11:16:19 - INFO :       
==================Finish================

2024-04-22 11:16:19 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:16:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:16:19 - INFO :       DATASET: tasksource/mmlu high_school_macroeconomics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.10s/it]
2024-04-22 11:16:48 - INFO :       Use taylor pruner...
2024-04-22 11:16:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:16:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:16:49 - INFO :       Start Pruning
2024-04-22 11:16:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:16:51 - INFO :       Loss = 14.1015625
2024-04-22 11:16:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:16:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:16:56 - INFO :       high_school_macroeconomics: Total Sparsity 1.3595404667678207e-06
2024-04-22 11:17:48 - INFO :       high_school_macroeconomics: Total Accuracy (15, 43, 0.3488372093023256)
2024-04-22 11:17:48 - INFO :       
==================Finish================

2024-04-22 11:17:48 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:17:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:17:48 - INFO :       DATASET: tasksource/mmlu high_school_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.32s/it]
2024-04-22 11:18:15 - INFO :       Use taylor pruner...
2024-04-22 11:18:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:18:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:18:16 - INFO :       Start Pruning
2024-04-22 11:18:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:18:19 - INFO :       Loss = 13.2421875
2024-04-22 11:18:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:18:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:18:24 - INFO :       high_school_mathematics: Total Sparsity 1.3585857332939668e-06
2024-04-22 11:19:00 - INFO :       high_school_mathematics: Total Accuracy (6, 29, 0.20689655172413793)
2024-04-22 11:19:00 - INFO :       
==================Finish================

2024-04-22 11:19:00 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:19:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:19:00 - INFO :       DATASET: tasksource/mmlu high_school_microeconomics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.80s/it]
2024-04-22 11:19:26 - INFO :       Use taylor pruner...
2024-04-22 11:19:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:19:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:19:27 - INFO :       Start Pruning
2024-04-22 11:19:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:19:29 - INFO :       Loss = 14.0390625
2024-04-22 11:19:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:19:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:19:33 - INFO :       high_school_microeconomics: Total Sparsity 1.357153633083186e-06
2024-04-22 11:20:03 - INFO :       high_school_microeconomics: Total Accuracy (11, 26, 0.4230769230769231)
2024-04-22 11:20:03 - INFO :       
==================Finish================

2024-04-22 11:20:03 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:20:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:20:03 - INFO :       DATASET: tasksource/mmlu high_school_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.71s/it]
2024-04-22 11:20:29 - INFO :       Use taylor pruner...
2024-04-22 11:20:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:20:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:20:30 - INFO :       Start Pruning
2024-04-22 11:20:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:20:33 - INFO :       Loss = 13.4921875
2024-04-22 11:20:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:20:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:20:37 - INFO :       high_school_physics: Total Sparsity 1.3579492443113975e-06
2024-04-22 11:20:59 - INFO :       high_school_physics: Total Accuracy (5, 17, 0.29411764705882354)
2024-04-22 11:20:59 - INFO :       
==================Finish================

2024-04-22 11:20:59 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:20:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:20:59 - INFO :       DATASET: tasksource/mmlu high_school_psychology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.13s/it]
2024-04-22 11:21:27 - INFO :       Use taylor pruner...
2024-04-22 11:21:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:21:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:21:28 - INFO :       Start Pruning
2024-04-22 11:21:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:21:31 - INFO :       Loss = 13.5546875
2024-04-22 11:21:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:21:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:21:36 - INFO :       high_school_psychology: Total Sparsity 1.3593813445221782e-06
2024-04-22 11:22:36 - INFO :       high_school_psychology: Total Accuracy (33, 50, 0.66)
2024-04-22 11:22:36 - INFO :       
==================Finish================

2024-04-22 11:22:36 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:22:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:22:36 - INFO :       DATASET: tasksource/mmlu high_school_statistics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.27s/it]
2024-04-22 11:23:05 - INFO :       Use taylor pruner...
2024-04-22 11:23:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:23:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:23:06 - INFO :       Start Pruning
2024-04-22 11:23:07 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:23:08 - INFO :       Loss = 11.484375
2024-04-22 11:23:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:23:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:23:14 - INFO :       high_school_statistics: Total Sparsity 1.360336077996032e-06
2024-04-22 11:23:41 - INFO :       high_school_statistics: Total Accuracy (9, 23, 0.391304347826087)
2024-04-22 11:23:41 - INFO :       
==================Finish================

2024-04-22 11:23:41 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:23:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:23:41 - INFO :       DATASET: tasksource/mmlu high_school_us_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.27s/it]
2024-04-22 11:24:10 - INFO :       Use taylor pruner...
2024-04-22 11:24:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:24:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:24:10 - INFO :       Start Pruning
2024-04-22 11:24:11 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:24:13 - INFO :       Loss = 5.88671875
2024-04-22 11:24:15 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:24:15 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:24:17 - INFO :       high_school_us_history: Total Sparsity 1.3579492443113975e-06
2024-04-22 11:24:50 - INFO :       high_school_us_history: Total Accuracy (13, 22, 0.5909090909090909)
2024-04-22 11:24:50 - INFO :       
==================Finish================

2024-04-22 11:24:50 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:24:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:24:50 - INFO :       DATASET: tasksource/mmlu high_school_world_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.30s/it]
2024-04-22 11:25:24 - INFO :       Use taylor pruner...
2024-04-22 11:25:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:25:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:25:25 - INFO :       Start Pruning
2024-04-22 11:25:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:25:28 - INFO :       Loss = 9.03125
2024-04-22 11:25:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:25:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:25:34 - INFO :       high_school_world_history: Total Sparsity 1.3581083665570398e-06
2024-04-22 11:26:12 - INFO :       high_school_world_history: Total Accuracy (12, 26, 0.46153846153846156)
2024-04-22 11:26:14 - INFO :       
==================Finish================

2024-04-22 11:26:14 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:26:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:26:14 - INFO :       DATASET: tasksource/mmlu human_aging
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.00s/it]
2024-04-22 11:26:46 - INFO :       Use taylor pruner...
2024-04-22 11:26:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:26:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:26:47 - INFO :       Start Pruning
2024-04-22 11:26:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:26:50 - INFO :       Loss = 14.109375
2024-04-22 11:26:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:26:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:26:57 - INFO :       human_aging: Total Sparsity 1.3617681782068128e-06
2024-04-22 11:27:31 - INFO :       human_aging: Total Accuracy (10, 23, 0.43478260869565216)
2024-04-22 11:27:31 - INFO :       
==================Finish================

2024-04-22 11:27:31 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:27:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:27:31 - INFO :       DATASET: tasksource/mmlu human_sexuality
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.85s/it]
2024-04-22 11:28:03 - INFO :       Use taylor pruner...
2024-04-22 11:28:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:28:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:28:04 - INFO :       Start Pruning
2024-04-22 11:28:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:28:06 - INFO :       Loss = 12.7890625
2024-04-22 11:28:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:28:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:28:10 - INFO :       human_sexuality: Total Sparsity 1.3573127553288283e-06
2024-04-22 11:28:25 - INFO :       human_sexuality: Total Accuracy (6, 12, 0.5)
2024-04-22 11:28:25 - INFO :       
==================Finish================

2024-04-22 11:28:25 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:28:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:28:25 - INFO :       DATASET: tasksource/mmlu international_law
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.71s/it]
2024-04-22 11:28:51 - INFO :       Use taylor pruner...
2024-04-22 11:28:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:28:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:28:52 - INFO :       Start Pruning
Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-22 11:29:03 - WARNING :       Using the latest cached version of the module from /home/bhandk/.cache/huggingface/modules/datasets_modules/datasets/tasksource--mmlu/da17f13c624cfbd07e63769c1c8e13be5dec4a17238a116a13e74bca5d0b4b04 (last modified on Tue Nov 14 13:22:18 2023) since it couldn't be found locally at tasksource/mmlu, or remotely on the Hugging Face Hub.
2024-04-22 11:29:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:29:05 - INFO :       Loss = 13.0
2024-04-22 11:29:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:29:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:29:10 - INFO :       international_law: Total Sparsity 1.354448554907267e-06
2024-04-22 11:29:28 - INFO :       international_law: Total Accuracy (11, 13, 0.8461538461538461)
2024-04-22 11:29:28 - INFO :       
==================Finish================

2024-04-22 11:29:28 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:29:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:29:28 - INFO :       DATASET: tasksource/mmlu jurisprudence
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.72s/it]
2024-04-22 11:29:54 - INFO :       Use taylor pruner...
2024-04-22 11:29:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:29:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:29:55 - INFO :       Start Pruning
2024-04-22 11:29:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:30:00 - INFO :       Loss = 13.3203125
2024-04-22 11:30:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:30:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:30:05 - INFO :       jurisprudence: Total Sparsity 1.3600178335047475e-06
2024-04-22 11:30:18 - INFO :       jurisprudence: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-22 11:30:18 - INFO :       
==================Finish================

2024-04-22 11:30:18 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:30:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:30:18 - INFO :       DATASET: tasksource/mmlu logical_fallacies
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.97s/it]
2024-04-22 11:30:48 - INFO :       Use taylor pruner...
2024-04-22 11:30:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:30:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:30:49 - INFO :       Start Pruning
2024-04-22 11:30:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:30:52 - INFO :       Loss = 13.3984375
2024-04-22 11:30:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:30:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:30:59 - INFO :       logical_fallacies: Total Sparsity 1.3617681782068128e-06
2024-04-22 11:31:29 - INFO :       logical_fallacies: Total Accuracy (11, 18, 0.6111111111111112)
2024-04-22 11:31:29 - INFO :       
==================Finish================

2024-04-22 11:31:29 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:31:29 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:31:29 - INFO :       DATASET: tasksource/mmlu machine_learning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.02s/it]
2024-04-22 11:31:59 - INFO :       Use taylor pruner...
2024-04-22 11:31:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:31:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:32:00 - INFO :       Start Pruning
2024-04-22 11:32:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:32:02 - INFO :       Loss = 13.625
2024-04-22 11:32:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:32:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:32:07 - INFO :       machine_learning: Total Sparsity 1.3574718775744707e-06
2024-04-22 11:32:20 - INFO :       machine_learning: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-22 11:32:20 - INFO :       
==================Finish================

2024-04-22 11:32:20 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:32:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:32:20 - INFO :       DATASET: tasksource/mmlu management
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.93s/it]
2024-04-22 11:32:49 - INFO :       Use taylor pruner...
2024-04-22 11:32:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:32:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:32:50 - INFO :       Start Pruning
2024-04-22 11:32:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:32:52 - INFO :       Loss = 14.4140625
2024-04-22 11:32:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:32:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:32:59 - INFO :       management: Total Sparsity 1.3561988996093322e-06
2024-04-22 11:33:17 - INFO :       management: Total Accuracy (7, 11, 0.6363636363636364)
2024-04-22 11:33:17 - INFO :       
==================Finish================

2024-04-22 11:33:17 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:33:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:33:17 - INFO :       DATASET: tasksource/mmlu marketing
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.55s/it]
2024-04-22 11:33:48 - INFO :       Use taylor pruner...
2024-04-22 11:33:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:33:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:33:49 - INFO :       Start Pruning
2024-04-22 11:33:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:33:52 - INFO :       Loss = 13.8125
2024-04-22 11:33:55 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:33:55 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:33:58 - INFO :       marketing: Total Sparsity 1.3561988996093322e-06
2024-04-22 11:34:33 - INFO :       marketing: Total Accuracy (17, 25, 0.68)
2024-04-22 11:34:33 - INFO :       
==================Finish================

2024-04-22 11:34:33 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:34:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:34:33 - INFO :       DATASET: tasksource/mmlu medical_genetics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.56s/it]
2024-04-22 11:34:59 - INFO :       Use taylor pruner...
2024-04-22 11:34:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:34:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:35:00 - INFO :       Start Pruning
2024-04-22 11:35:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:35:03 - INFO :       Loss = 14.4765625
2024-04-22 11:35:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:35:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:35:08 - INFO :       medical_genetics: Total Sparsity 1.3604952002416743e-06
2024-04-22 11:35:23 - INFO :       medical_genetics: Total Accuracy (8, 11, 0.7272727272727273)
2024-04-22 11:35:23 - INFO :       
==================Finish================

2024-04-22 11:35:23 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:35:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:35:23 - INFO :       DATASET: tasksource/mmlu miscellaneous
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.11s/it]
2024-04-22 11:35:50 - INFO :       Use taylor pruner...
2024-04-22 11:35:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:35:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:35:51 - INFO :       Start Pruning
2024-04-22 11:35:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:35:53 - INFO :       Loss = 13.640625
2024-04-22 11:35:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:35:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:35:58 - INFO :       miscellaneous: Total Sparsity 1.3590631000308936e-06
2024-04-22 11:36:57 - INFO :       miscellaneous: Total Accuracy (31, 50, 0.62)
2024-04-22 11:36:57 - INFO :       
==================Finish================

2024-04-22 11:36:57 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:36:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:36:57 - INFO :       DATASET: tasksource/mmlu moral_disputes
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.81s/it]
2024-04-22 11:37:24 - INFO :       Use taylor pruner...
2024-04-22 11:37:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:37:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:37:25 - INFO :       Start Pruning
2024-04-22 11:37:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:37:28 - INFO :       Loss = 13.7421875
2024-04-22 11:37:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:37:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:37:33 - INFO :       moral_disputes: Total Sparsity 1.3590631000308936e-06
2024-04-22 11:38:17 - INFO :       moral_disputes: Total Accuracy (18, 38, 0.47368421052631576)
2024-04-22 11:38:17 - INFO :       
==================Finish================

2024-04-22 11:38:17 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:38:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:38:17 - INFO :       DATASET: tasksource/mmlu moral_scenarios
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.31s/it]
2024-04-22 11:38:45 - INFO :       Use taylor pruner...
2024-04-22 11:38:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:38:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:38:46 - INFO :       Start Pruning
2024-04-22 11:38:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:38:49 - INFO :       Loss = 12.03125
2024-04-22 11:38:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:38:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:38:53 - INFO :       moral_scenarios: Total Sparsity 1.3558806551180476e-06
2024-04-22 11:40:06 - INFO :       moral_scenarios: Total Accuracy (0, 50, 0.0)
2024-04-22 11:40:06 - INFO :       
==================Finish================

2024-04-22 11:40:06 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:40:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:40:06 - INFO :       DATASET: tasksource/mmlu nutrition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.68s/it]
2024-04-22 11:40:37 - INFO :       Use taylor pruner...
2024-04-22 11:40:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:40:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:40:38 - INFO :       Start Pruning
2024-04-22 11:40:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:40:40 - INFO :       Loss = 13.1171875
2024-04-22 11:40:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:40:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:40:46 - INFO :       nutrition: Total Sparsity 1.358744855539609e-06
2024-04-22 11:41:27 - INFO :       nutrition: Total Accuracy (19, 33, 0.5757575757575758)
2024-04-22 11:41:27 - INFO :       
==================Finish================

2024-04-22 11:41:27 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:41:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:41:27 - INFO :       DATASET: tasksource/mmlu philosophy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.22s/it]
2024-04-22 11:42:02 - INFO :       Use taylor pruner...
2024-04-22 11:42:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:42:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:42:04 - INFO :       Start Pruning
2024-04-22 11:42:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:42:06 - INFO :       Loss = 14.046875
2024-04-22 11:42:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:42:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:42:11 - INFO :       philosophy: Total Sparsity 1.359699589013463e-06
2024-04-22 11:42:55 - INFO :       philosophy: Total Accuracy (17, 34, 0.5)
2024-04-22 11:42:56 - INFO :       
==================Finish================

2024-04-22 11:42:56 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:42:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:42:56 - INFO :       DATASET: tasksource/mmlu prehistory
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.68s/it]
2024-04-22 11:43:25 - INFO :       Use taylor pruner...
2024-04-22 11:43:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:43:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:43:26 - INFO :       Start Pruning
2024-04-22 11:43:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:43:28 - INFO :       Loss = 13.7890625
2024-04-22 11:43:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:43:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:43:32 - INFO :       prehistory: Total Sparsity 1.3590631000308936e-06
2024-04-22 11:44:15 - INFO :       prehistory: Total Accuracy (17, 35, 0.4857142857142857)
2024-04-22 11:44:15 - INFO :       
==================Finish================

2024-04-22 11:44:15 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:44:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:44:15 - INFO :       DATASET: tasksource/mmlu professional_accounting
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.48s/it]
2024-04-22 11:44:43 - INFO :       Use taylor pruner...
2024-04-22 11:44:43 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:44:43 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:44:44 - INFO :       Start Pruning
2024-04-22 11:44:45 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:44:46 - INFO :       Loss = 12.296875
2024-04-22 11:44:49 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:44:49 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:44:51 - INFO :       professional_accounting: Total Sparsity 1.357630999820113e-06
2024-04-22 11:45:30 - INFO :       professional_accounting: Total Accuracy (10, 31, 0.3225806451612903)
2024-04-22 11:45:30 - INFO :       
==================Finish================

2024-04-22 11:45:30 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:45:30 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:45:30 - INFO :       DATASET: tasksource/mmlu professional_law
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.94s/it]
2024-04-22 11:45:56 - INFO :       Use taylor pruner...
2024-04-22 11:45:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:45:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:45:57 - INFO :       Start Pruning
2024-04-22 11:45:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:46:00 - INFO :       Loss = 6.83984375
2024-04-22 11:46:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:46:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:46:04 - INFO :       professional_law: Total Sparsity 1.3552441661354783e-06
2024-04-22 11:47:10 - INFO :       professional_law: Total Accuracy (13, 50, 0.26)
2024-04-22 11:47:10 - INFO :       
==================Finish================

2024-04-22 11:47:10 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:47:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:47:10 - INFO :       DATASET: tasksource/mmlu professional_medicine
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.77s/it]
2024-04-22 11:47:38 - INFO :       Use taylor pruner...
2024-04-22 11:47:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:47:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:47:39 - INFO :       Start Pruning
2024-04-22 11:47:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:47:41 - INFO :       Loss = 10.9296875
2024-04-22 11:47:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:47:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:47:46 - INFO :       professional_medicine: Total Sparsity 1.3554032883811208e-06
2024-04-22 11:48:38 - INFO :       professional_medicine: Total Accuracy (16, 31, 0.5161290322580645)
2024-04-22 11:48:38 - INFO :       
==================Finish================

2024-04-22 11:48:38 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:48:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:48:38 - INFO :       DATASET: tasksource/mmlu professional_psychology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.40s/it]
2024-04-22 11:49:10 - INFO :       Use taylor pruner...
2024-04-22 11:49:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:49:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:49:11 - INFO :       Start Pruning
2024-04-22 11:49:12 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:49:13 - INFO :       Loss = 11.6328125
2024-04-22 11:49:16 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:49:16 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:49:18 - INFO :       professional_psychology: Total Sparsity 1.356517144100617e-06
2024-04-22 11:50:25 - INFO :       professional_psychology: Total Accuracy (23, 50, 0.46)
2024-04-22 11:50:25 - INFO :       
==================Finish================

2024-04-22 11:50:25 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:50:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:50:25 - INFO :       DATASET: tasksource/mmlu public_relations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.65s/it]
2024-04-22 11:50:56 - INFO :       Use taylor pruner...
2024-04-22 11:50:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:50:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:50:57 - INFO :       Start Pruning
2024-04-22 11:50:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:51:00 - INFO :       Loss = 14.1796875
2024-04-22 11:51:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:51:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:51:06 - INFO :       public_relations: Total Sparsity 1.3566762663462592e-06
2024-04-22 11:51:25 - INFO :       public_relations: Total Accuracy (8, 12, 0.6666666666666666)
2024-04-22 11:51:25 - INFO :       
==================Finish================

2024-04-22 11:51:25 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:51:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:51:25 - INFO :       DATASET: tasksource/mmlu security_studies
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.94s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.36s/it]
2024-04-22 11:51:58 - INFO :       Use taylor pruner...
2024-04-22 11:51:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:51:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:51:59 - INFO :       Start Pruning
2024-04-22 11:52:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:52:01 - INFO :       Loss = 12.4453125
2024-04-22 11:52:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:52:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:52:06 - INFO :       security_studies: Total Sparsity 1.3579492443113975e-06
2024-04-22 11:52:45 - INFO :       security_studies: Total Accuracy (10, 27, 0.37037037037037035)
2024-04-22 11:52:46 - INFO :       
==================Finish================

2024-04-22 11:52:46 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:52:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:52:46 - INFO :       DATASET: tasksource/mmlu sociology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.92s/it]
2024-04-22 11:53:12 - INFO :       Use taylor pruner...
2024-04-22 11:53:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:53:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:53:13 - INFO :       Start Pruning
2024-04-22 11:53:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:53:16 - INFO :       Loss = 13.9296875
2024-04-22 11:53:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:53:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:53:21 - INFO :       sociology: Total Sparsity 1.3600178335047475e-06
2024-04-22 11:53:50 - INFO :       sociology: Total Accuracy (14, 22, 0.6363636363636364)
2024-04-22 11:53:50 - INFO :       
==================Finish================

2024-04-22 11:53:50 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:53:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:53:50 - INFO :       DATASET: tasksource/mmlu us_foreign_policy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.49s/it]
2024-04-22 11:54:19 - INFO :       Use taylor pruner...
2024-04-22 11:54:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:54:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:54:20 - INFO :       Start Pruning
2024-04-22 11:54:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:54:23 - INFO :       Loss = 13.8125
2024-04-22 11:54:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:54:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:54:28 - INFO :       us_foreign_policy: Total Sparsity 1.3600178335047475e-06
2024-04-22 11:54:44 - INFO :       us_foreign_policy: Total Accuracy (6, 11, 0.5454545454545454)
2024-04-22 11:54:44 - INFO :       
==================Finish================

2024-04-22 11:54:44 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:54:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:54:44 - INFO :       DATASET: tasksource/mmlu virology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.79s/it]
2024-04-22 11:55:16 - INFO :       Use taylor pruner...
2024-04-22 11:55:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:55:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:55:17 - INFO :       Start Pruning
2024-04-22 11:55:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:55:19 - INFO :       Loss = 14.0
2024-04-22 11:55:22 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:55:22 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:55:24 - INFO :       virology: Total Sparsity 1.358267488802682e-06
2024-04-22 11:55:45 - INFO :       virology: Total Accuracy (8, 18, 0.4444444444444444)
2024-04-22 11:55:45 - INFO :       
==================Finish================

2024-04-22 11:55:45 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:55:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:55:45 - INFO :       DATASET: tasksource/mmlu world_religions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.29s/it]
2024-04-22 11:56:14 - INFO :       Use taylor pruner...
2024-04-22 11:56:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:56:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:56:15 - INFO :       Start Pruning
2024-04-22 11:56:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:56:18 - INFO :       Loss = 14.4375
2024-04-22 11:56:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:56:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:56:23 - INFO :       world_religions: Total Sparsity 1.3593813445221782e-06
2024-04-22 11:56:52 - INFO :       world_religions: Total Accuracy (13, 19, 0.6842105263157895)
2024-04-22 11:56:52 - INFO :       
==================Finish================

2024-04-22 11:56:52 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:56:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:56:52 - INFO :       DATASET: math_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.60s/it]
2024-04-22 11:57:24 - INFO :       Use taylor pruner...
2024-04-22 11:57:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:57:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:57:24 - INFO :       Start Pruning
2024-04-22 11:57:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:57:27 - INFO :       Loss = 13.265625
2024-04-22 11:57:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:57:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:57:32 - INFO :       math_qa: Total Sparsity 1.360336077996032e-06
2024-04-22 11:58:31 - INFO :       math_qa: Accuracy (8, 50, 0.16)
2024-04-22 11:58:31 - INFO :       
==================Finish================

2024-04-22 11:58:31 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:58:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:58:31 - INFO :       DATASET: EleutherAI/truthful_qa_mc
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.78s/it]
2024-04-22 11:58:57 - INFO :       Use taylor pruner...
2024-04-22 11:58:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:58:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 11:58:58 - INFO :       Start Pruning
2024-04-22 11:58:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 11:59:00 - INFO :       Loss = 13.2734375
2024-04-22 11:59:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 11:59:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 11:59:06 - INFO :       truthful_qa_mc: Total Sparsity 1.3593813445221782e-06
2024-04-22 11:59:59 - INFO :       truthful_qa_mc: Accuracy (17, 50, 0.34)
2024-04-22 11:59:59 - INFO :       
==================Finish================

2024-04-22 11:59:59 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 11:59:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 11:59:59 - INFO :       DATASET: derek-thomas/ScienceQA
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.25s/it]
2024-04-22 12:00:28 - INFO :       Use taylor pruner...
2024-04-22 12:00:28 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:00:28 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:00:29 - INFO :       Start Pruning
2024-04-22 12:00:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:00:32 - INFO :       Loss = 14.25
2024-04-22 12:00:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:00:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:00:37 - INFO :       ScienceQA: Total Sparsity 1.3585857332939668e-06
2024-04-22 12:01:34 - INFO :       ScienceQA: Accuracy (23, 50, 0.46)
2024-04-22 12:01:34 - INFO :       
==================Finish================

2024-04-22 12:01:34 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 12:01:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:01:34 - INFO :       DATASET: commonsense_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.99s/it]
2024-04-22 12:02:02 - INFO :       Use taylor pruner...
2024-04-22 12:02:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:02:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:02:03 - INFO :       Start Pruning
2024-04-22 12:02:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:02:06 - INFO :       Loss = 14.390625
2024-04-22 12:02:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:02:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:02:10 - INFO :       commonsense_qa: Total Sparsity 1.359699589013463e-06
2024-04-22 12:03:05 - INFO :       commonsense_qa: Accuracy (26, 50, 0.52)
2024-04-22 12:03:05 - INFO :       
==================Finish================

2024-04-22 12:03:05 - INFO :       Memory Requirement: 16770.79052734375 MiB

End: Memory Requirement: 3979.2666015625 MiB

Begin: Memory Requirement: 3979.2666015625 MiB

2024-04-22 12:03:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:03:05 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Index 4
Sparsity 3.5000000000000004 %
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.85s/it]
2024-04-22 12:03:31 - INFO :       Use taylor pruner...
2024-04-22 12:03:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:03:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:03:32 - INFO :       Start Pruning
Token indices sequence length is longer than the specified maximum sequence length for this model (16685 > 4096). Running this sequence through the model will result in indexing errors
2024-04-22 12:03:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:03:34 - INFO :       Loss = 1.69921875
2024-04-22 12:03:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:03:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:03:39 - INFO :       which_wiki_edit: Total Sparsity 1.3503113765205672e-06
2024-04-22 12:05:42 - INFO :       which_wiki_edit: Total Accuracy (25, 50, 0.5)
2024-04-22 12:05:42 - INFO :       
==================Finish================

2024-04-22 12:05:42 - INFO :       Memory Requirement: 16849.60302734375 MiB

2024-04-22 12:05:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:05:42 - INFO :       DATASET: tasksource/bigbench abstract_narrative_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.11s/it]
2024-04-22 12:06:14 - INFO :       Use taylor pruner...
2024-04-22 12:06:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:06:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:06:15 - INFO :       Start Pruning
2024-04-22 12:06:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:06:18 - INFO :       Loss = 7.36328125
2024-04-22 12:06:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:06:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:06:24 - INFO :       abstract_narrative_understanding: Total Sparsity 1.360813444732959e-06
2024-04-22 12:07:26 - INFO :       abstract_narrative_understanding: Total Accuracy (22, 50, 0.44)
2024-04-22 12:07:26 - INFO :       
==================Finish================

2024-04-22 12:07:26 - INFO :       Memory Requirement: 16772.79052734375 MiB

2024-04-22 12:07:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:07:26 - INFO :       DATASET: tasksource/bigbench anachronisms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.94s/it]
2024-04-22 12:08:00 - INFO :       Use taylor pruner...
2024-04-22 12:08:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:08:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:08:01 - INFO :       Start Pruning
2024-04-22 12:08:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:08:04 - INFO :       Loss = 14.0625
2024-04-22 12:08:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:08:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:08:10 - INFO :       anachronisms: Total Sparsity 1.3573127553288283e-06
2024-04-22 12:09:19 - INFO :       anachronisms: Total Accuracy (31, 46, 0.6739130434782609)
2024-04-22 12:09:20 - INFO :       
==================Finish================

2024-04-22 12:09:20 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-22 12:09:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:09:20 - INFO :       DATASET: tasksource/bigbench analogical_similarity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:09<00:09,  9.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:13<00:00,  6.65s/it]
2024-04-22 12:09:57 - INFO :       Use taylor pruner...
2024-04-22 12:09:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:09:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:09:58 - INFO :       Start Pruning
2024-04-22 12:10:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:10:01 - INFO :       Loss = 1.3515625
2024-04-22 12:10:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:10:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:10:07 - INFO :       analogical_similarity: Total Sparsity 1.3557215328724054e-06
2024-04-22 12:11:28 - INFO :       analogical_similarity: Total Accuracy (3, 50, 0.06)
2024-04-22 12:11:28 - INFO :       
==================Finish================

2024-04-22 12:11:28 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-22 12:11:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:11:28 - INFO :       DATASET: tasksource/bigbench analytic_entailment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.95s/it]
2024-04-22 12:12:00 - INFO :       Use taylor pruner...
2024-04-22 12:12:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:12:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:12:01 - INFO :       Start Pruning
2024-04-22 12:12:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:12:03 - INFO :       Loss = 14.0
2024-04-22 12:12:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:12:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:12:08 - INFO :       analytic_entailment: Total Sparsity 1.357630999820113e-06
2024-04-22 12:12:29 - INFO :       analytic_entailment: Total Accuracy (8, 16, 0.5)
2024-04-22 12:12:29 - INFO :       
==================Finish================

2024-04-22 12:12:29 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-22 12:12:29 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:12:29 - INFO :       DATASET: tasksource/bigbench arithmetic
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.52s/it]
2024-04-22 12:12:54 - INFO :       Use taylor pruner...
2024-04-22 12:12:54 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:12:54 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:12:55 - INFO :       Start Pruning
2024-04-22 12:12:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:12:57 - INFO :       Loss = 11.53125
2024-04-22 12:12:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:12:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:13:02 - INFO :       arithmetic: Total Sparsity 1.3569945108375437e-06
2024-04-22 12:14:03 - INFO :       arithmetic: Total Accuracy (0, 50, 0.0)
2024-04-22 12:14:03 - INFO :       
==================Finish================

2024-04-22 12:14:03 - INFO :       Memory Requirement: 16768.79052734375 MiB

2024-04-22 12:14:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:14:03 - INFO :       DATASET: tasksource/bigbench authorship_verification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.04s/it]
2024-04-22 12:14:29 - INFO :       Use taylor pruner...
2024-04-22 12:14:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:14:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:14:30 - INFO :       Start Pruning
2024-04-22 12:14:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:14:34 - INFO :       Loss = 2.73046875
2024-04-22 12:14:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:14:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:14:38 - INFO :       authorship_verification: Total Sparsity 1.3546076771529093e-06
2024-04-22 12:17:08 - INFO :       authorship_verification: Total Accuracy (24, 50, 0.48)
2024-04-22 12:17:08 - INFO :       
==================Finish================

2024-04-22 12:17:08 - INFO :       Memory Requirement: 16794.029296875 MiB

2024-04-22 12:17:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:17:08 - INFO :       DATASET: tasksource/bigbench bbq_lite_json
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.51s/it]
2024-04-22 12:17:32 - INFO :       Use taylor pruner...
2024-04-22 12:17:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:17:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:17:32 - INFO :       Start Pruning
2024-04-22 12:17:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:17:35 - INFO :       Loss = 11.90625
2024-04-22 12:17:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:17:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:17:40 - INFO :       bbq_lite_json: Total Sparsity 1.3566762663462592e-06
2024-04-22 12:18:40 - INFO :       bbq_lite_json: Total Accuracy (4, 50, 0.08)
2024-04-22 12:18:40 - INFO :       
==================Finish================

2024-04-22 12:18:40 - INFO :       Memory Requirement: 16771.79052734375 MiB

2024-04-22 12:18:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:18:40 - INFO :       DATASET: tasksource/bigbench causal_judgment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.81s/it]
2024-04-22 12:19:05 - INFO :       Use taylor pruner...
2024-04-22 12:19:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:19:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:19:06 - INFO :       Start Pruning
2024-04-22 12:19:08 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:19:09 - INFO :       Loss = 9.453125
2024-04-22 12:19:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:19:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:19:14 - INFO :       causal_judgment: Total Sparsity 1.3568353885919015e-06
2024-04-22 12:20:03 - INFO :       causal_judgment: Total Accuracy (17, 38, 0.4473684210526316)
2024-04-22 12:20:03 - INFO :       
==================Finish================

2024-04-22 12:20:03 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:20:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:20:03 - INFO :       DATASET: tasksource/bigbench cause_and_effect
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.82s/it]
2024-04-22 12:20:29 - INFO :       Use taylor pruner...
2024-04-22 12:20:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:20:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:20:30 - INFO :       Start Pruning
2024-04-22 12:20:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:20:32 - INFO :       Loss = 13.0234375
2024-04-22 12:20:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:20:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:20:37 - INFO :       cause_and_effect: Total Sparsity 1.3569945108375437e-06
2024-04-22 12:21:12 - INFO :       cause_and_effect: Total Accuracy (22, 30, 0.7333333333333333)
2024-04-22 12:21:12 - INFO :       
==================Finish================

2024-04-22 12:21:12 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:21:12 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:21:12 - INFO :       DATASET: tasksource/bigbench checkmate_in_one
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.66s/it]
2024-04-22 12:21:37 - INFO :       Use taylor pruner...
2024-04-22 12:21:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:21:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:21:38 - INFO :       Start Pruning
2024-04-22 12:21:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:21:41 - INFO :       Loss = 1.5087890625
2024-04-22 12:21:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:21:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:21:46 - INFO :       checkmate_in_one: Total Sparsity 1.3563580218549744e-06
2024-04-22 12:23:02 - INFO :       checkmate_in_one: Total Accuracy (2, 50, 0.04)
2024-04-22 12:23:03 - INFO :       
==================Finish================

2024-04-22 12:23:03 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:23:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:23:03 - INFO :       DATASET: tasksource/bigbench cifar10_classification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.29s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.32s/it]
2024-04-22 12:23:32 - INFO :       Use taylor pruner...
2024-04-22 12:23:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:23:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:23:33 - INFO :       Start Pruning
Token indices sequence length is longer than the specified maximum sequence length for this model (6567 > 4096). Running this sequence through the model will result in indexing errors
2024-04-22 12:23:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:23:36 - INFO :       Loss = 3.76953125
2024-04-22 12:23:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:23:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:23:42 - INFO :       cifar10_classification: Total Sparsity 1.357153633083186e-06
2024-04-22 12:26:10 - INFO :       cifar10_classification: Total Accuracy (0, 50, 0.0)
2024-04-22 12:26:11 - INFO :       
==================Finish================

2024-04-22 12:26:11 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:26:11 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:26:11 - INFO :       DATASET: tasksource/bigbench code_line_description
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.96s/it]
2024-04-22 12:26:36 - INFO :       Use taylor pruner...
2024-04-22 12:26:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:26:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:26:37 - INFO :       Start Pruning
2024-04-22 12:26:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:26:39 - INFO :       Loss = 11.2109375
2024-04-22 12:26:42 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:26:42 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:26:44 - INFO :       code_line_description: Total Sparsity 1.3568353885919015e-06
2024-04-22 12:27:04 - INFO :       code_line_description: Total Accuracy (11, 16, 0.6875)
2024-04-22 12:27:04 - INFO :       
==================Finish================

2024-04-22 12:27:04 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:27:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:27:04 - INFO :       DATASET: tasksource/bigbench color
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.25s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.31s/it]
2024-04-22 12:27:30 - INFO :       Use taylor pruner...
2024-04-22 12:27:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:27:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:27:31 - INFO :       Start Pruning
2024-04-22 12:27:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:27:34 - INFO :       Loss = 10.5078125
2024-04-22 12:27:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:27:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:27:39 - INFO :       color: Total Sparsity 1.357630999820113e-06
2024-04-22 12:28:39 - INFO :       color: Total Accuracy (1, 50, 0.02)
2024-04-22 12:28:39 - INFO :       
==================Finish================

2024-04-22 12:28:39 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:28:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:28:39 - INFO :       DATASET: tasksource/bigbench common_morpheme
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.58s/it]
2024-04-22 12:29:06 - INFO :       Use taylor pruner...
2024-04-22 12:29:06 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:29:06 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:29:07 - INFO :       Start Pruning
2024-04-22 12:29:08 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:29:09 - INFO :       Loss = 13.6640625
2024-04-22 12:29:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:29:12 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:29:14 - INFO :       common_morpheme: Total Sparsity 1.360813444732959e-06
2024-04-22 12:29:34 - INFO :       common_morpheme: Total Accuracy (4, 16, 0.25)
2024-04-22 12:29:34 - INFO :       
==================Finish================

2024-04-22 12:29:34 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:29:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:29:34 - INFO :       DATASET: tasksource/bigbench conceptual_combinations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.53s/it]
2024-04-22 12:30:01 - INFO :       Use taylor pruner...
2024-04-22 12:30:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:30:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:30:02 - INFO :       Start Pruning
2024-04-22 12:30:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:30:05 - INFO :       Loss = 11.6875
2024-04-22 12:30:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:30:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:30:10 - INFO :       conceptual_combinations: Total Sparsity 1.360813444732959e-06
2024-04-22 12:30:33 - INFO :       conceptual_combinations: Total Accuracy (11, 19, 0.5789473684210527)
2024-04-22 12:30:33 - INFO :       
==================Finish================

2024-04-22 12:30:33 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:30:33 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:30:33 - INFO :       DATASET: tasksource/bigbench crash_blossom
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.98s/it]
2024-04-22 12:31:00 - INFO :       Use taylor pruner...
2024-04-22 12:31:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:31:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:31:01 - INFO :       Start Pruning
2024-04-22 12:31:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:31:03 - INFO :       Loss = 13.6953125
2024-04-22 12:31:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:31:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:31:08 - INFO :       crash_blossom: Total Sparsity 1.3569945108375437e-06
2024-04-22 12:31:27 - INFO :       crash_blossom: Total Accuracy (6, 16, 0.375)
2024-04-22 12:31:27 - INFO :       
==================Finish================

2024-04-22 12:31:27 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:31:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:31:27 - INFO :       DATASET: tasksource/bigbench crass_ai
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.61s/it]
2024-04-22 12:31:53 - INFO :       Use taylor pruner...
2024-04-22 12:31:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:31:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:31:54 - INFO :       Start Pruning
2024-04-22 12:31:56 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:31:57 - INFO :       Loss = 11.6484375
2024-04-22 12:32:00 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:32:00 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:32:03 - INFO :       crass_ai: Total Sparsity 1.3561988996093322e-06
2024-04-22 12:32:23 - INFO :       crass_ai: Total Accuracy (5, 16, 0.3125)
2024-04-22 12:32:23 - INFO :       
==================Finish================

2024-04-22 12:32:23 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:32:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:32:23 - INFO :       DATASET: tasksource/bigbench cryobiology_spanish
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.14s/it]
2024-04-22 12:32:51 - INFO :       Use taylor pruner...
2024-04-22 12:32:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:32:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:32:52 - INFO :       Start Pruning
2024-04-22 12:32:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:32:55 - INFO :       Loss = 13.90625
2024-04-22 12:32:58 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:32:58 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:33:00 - INFO :       cryobiology_spanish: Total Sparsity 1.3566762663462592e-06
2024-04-22 12:33:34 - INFO :       cryobiology_spanish: Total Accuracy (20, 29, 0.6896551724137931)
2024-04-22 12:33:35 - INFO :       
==================Finish================

2024-04-22 12:33:35 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:33:35 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:33:35 - INFO :       DATASET: tasksource/bigbench cs_algorithms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.65s/it]
2024-04-22 12:34:02 - INFO :       Use taylor pruner...
2024-04-22 12:34:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:34:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:34:04 - INFO :       Start Pruning
2024-04-22 12:34:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:34:06 - INFO :       Loss = 13.984375
2024-04-22 12:34:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:34:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:34:10 - INFO :       cs_algorithms: Total Sparsity 1.362404667189382e-06
2024-04-22 12:35:09 - INFO :       cs_algorithms: Total Accuracy (3, 50, 0.06)
2024-04-22 12:35:09 - INFO :       
==================Finish================

2024-04-22 12:35:09 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:35:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:35:09 - INFO :       DATASET: tasksource/bigbench dark_humor_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.79s/it]
2024-04-22 12:35:38 - INFO :       Use taylor pruner...
2024-04-22 12:35:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:35:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:35:39 - INFO :       Start Pruning
2024-04-22 12:35:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:35:42 - INFO :       Loss = 13.1796875
2024-04-22 12:35:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:35:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:35:47 - INFO :       dark_humor_detection: Total Sparsity 1.3563580218549744e-06
2024-04-22 12:36:05 - INFO :       dark_humor_detection: Total Accuracy (10, 16, 0.625)
2024-04-22 12:36:05 - INFO :       
==================Finish================

2024-04-22 12:36:05 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:36:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:36:05 - INFO :       DATASET: tasksource/bigbench date_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.79s/it]
2024-04-22 12:36:31 - INFO :       Use taylor pruner...
2024-04-22 12:36:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:36:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:36:32 - INFO :       Start Pruning
2024-04-22 12:36:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:36:35 - INFO :       Loss = 11.96875
2024-04-22 12:36:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:36:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:36:39 - INFO :       date_understanding: Total Sparsity 1.3546076771529093e-06
2024-04-22 12:37:44 - INFO :       date_understanding: Total Accuracy (7, 50, 0.14)
2024-04-22 12:37:44 - INFO :       
==================Finish================

2024-04-22 12:37:44 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:37:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:37:44 - INFO :       DATASET: tasksource/bigbench disambiguation_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.52s/it]
2024-04-22 12:38:12 - INFO :       Use taylor pruner...
2024-04-22 12:38:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:38:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:38:13 - INFO :       Start Pruning
2024-04-22 12:38:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:38:16 - INFO :       Loss = 12.140625
2024-04-22 12:38:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:38:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:38:21 - INFO :       disambiguation_qa: Total Sparsity 1.356517144100617e-06
2024-04-22 12:39:25 - INFO :       disambiguation_qa: Total Accuracy (22, 50, 0.44)
2024-04-22 12:39:25 - INFO :       
==================Finish================

2024-04-22 12:39:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:39:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:39:25 - INFO :       DATASET: tasksource/bigbench discourse_marker_prediction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.31s/it]
2024-04-22 12:40:00 - INFO :       Use taylor pruner...
2024-04-22 12:40:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:40:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:40:01 - INFO :       Start Pruning
2024-04-22 12:40:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:40:04 - INFO :       Loss = 1.1630859375
2024-04-22 12:40:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:40:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:40:09 - INFO :       discourse_marker_prediction: Total Sparsity 1.355085043889836e-06
2024-04-22 12:41:20 - INFO :       discourse_marker_prediction: Total Accuracy (11, 50, 0.22)
2024-04-22 12:41:20 - INFO :       
==================Finish================

2024-04-22 12:41:20 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:41:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:41:20 - INFO :       DATASET: tasksource/bigbench dyck_languages
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.28s/it]
2024-04-22 12:41:52 - INFO :       Use taylor pruner...
2024-04-22 12:41:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:41:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:41:53 - INFO :       Start Pruning
2024-04-22 12:41:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:41:56 - INFO :       Loss = 1.0087890625
2024-04-22 12:41:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:41:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:42:02 - INFO :       dyck_languages: Total Sparsity 1.3517434767313478e-06
2024-04-22 12:43:25 - INFO :       dyck_languages: Total Accuracy (1, 50, 0.02)
2024-04-22 12:43:25 - INFO :       
==================Finish================

2024-04-22 12:43:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:43:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:43:25 - INFO :       DATASET: tasksource/bigbench elementary_math_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  8.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.97s/it]
2024-04-22 12:43:55 - INFO :       Use taylor pruner...
2024-04-22 12:43:55 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:43:55 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:43:56 - INFO :       Start Pruning
2024-04-22 12:43:57 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:43:58 - INFO :       Loss = 12.625
2024-04-22 12:44:01 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:44:01 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:44:03 - INFO :       elementary_math_qa: Total Sparsity 1.356517144100617e-06
2024-04-22 12:45:01 - INFO :       elementary_math_qa: Total Accuracy (12, 50, 0.24)
2024-04-22 12:45:01 - INFO :       
==================Finish================

2024-04-22 12:45:01 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:45:01 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:45:01 - INFO :       DATASET: tasksource/bigbench emoji_movie
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.79s/it]
2024-04-22 12:45:26 - INFO :       Use taylor pruner...
2024-04-22 12:45:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:45:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:45:27 - INFO :       Start Pruning
2024-04-22 12:45:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:45:30 - INFO :       Loss = 12.7421875
2024-04-22 12:45:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:45:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:45:35 - INFO :       emoji_movie: Total Sparsity 1.3568353885919015e-06
2024-04-22 12:45:58 - INFO :       emoji_movie: Total Accuracy (12, 20, 0.6)
2024-04-22 12:45:58 - INFO :       
==================Finish================

2024-04-22 12:45:58 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:45:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:45:58 - INFO :       DATASET: tasksource/bigbench empirical_judgments
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.55s/it]
2024-04-22 12:46:26 - INFO :       Use taylor pruner...
2024-04-22 12:46:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:46:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:46:27 - INFO :       Start Pruning
2024-04-22 12:46:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:46:30 - INFO :       Loss = 12.609375
2024-04-22 12:46:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:46:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:46:35 - INFO :       empirical_judgments: Total Sparsity 1.3577901220657553e-06
2024-04-22 12:46:57 - INFO :       empirical_judgments: Total Accuracy (3, 19, 0.15789473684210525)
2024-04-22 12:46:57 - INFO :       
==================Finish================

2024-04-22 12:46:57 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:46:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:46:57 - INFO :       DATASET: tasksource/bigbench english_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.65s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.91s/it]
2024-04-22 12:47:25 - INFO :       Use taylor pruner...
2024-04-22 12:47:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:47:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:47:26 - INFO :       Start Pruning
2024-04-22 12:47:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:47:28 - INFO :       Loss = 10.6875
2024-04-22 12:47:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:47:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:47:35 - INFO :       english_proverbs: Total Sparsity 1.359699589013463e-06
2024-04-22 12:47:55 - INFO :       english_proverbs: Total Accuracy (4, 16, 0.25)
2024-04-22 12:47:55 - INFO :       
==================Finish================

2024-04-22 12:47:55 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:47:55 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:47:55 - INFO :       DATASET: tasksource/bigbench english_russian_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.95s/it]
2024-04-22 12:48:22 - INFO :       Use taylor pruner...
2024-04-22 12:48:22 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:48:22 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:48:23 - INFO :       Start Pruning
2024-04-22 12:48:25 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:48:26 - INFO :       Loss = 11.4140625
2024-04-22 12:48:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:48:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:48:31 - INFO :       english_russian_proverbs: Total Sparsity 1.3590631000308936e-06
2024-04-22 12:48:50 - INFO :       english_russian_proverbs: Total Accuracy (1, 16, 0.0625)
2024-04-22 12:48:50 - INFO :       
==================Finish================

2024-04-22 12:48:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:48:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:48:50 - INFO :       DATASET: tasksource/bigbench entailed_polarity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.22s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:11<00:00,  5.60s/it]
2024-04-22 12:49:17 - INFO :       Use taylor pruner...
2024-04-22 12:49:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:49:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:49:18 - INFO :       Start Pruning
2024-04-22 12:49:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:49:21 - INFO :       Loss = 14.4375
2024-04-22 12:49:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:49:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:49:26 - INFO :       entailed_polarity: Total Sparsity 1.3601769557503897e-06
2024-04-22 12:49:59 - INFO :       entailed_polarity: Total Accuracy (28, 29, 0.9655172413793104)
2024-04-22 12:49:59 - INFO :       
==================Finish================

2024-04-22 12:49:59 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:49:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:49:59 - INFO :       DATASET: tasksource/bigbench entailed_polarity_hindi
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.80s/it]
2024-04-22 12:50:25 - INFO :       Use taylor pruner...
2024-04-22 12:50:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:50:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:50:26 - INFO :       Start Pruning
2024-04-22 12:50:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:50:29 - INFO :       Loss = 9.8984375
2024-04-22 12:50:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:50:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:50:33 - INFO :       entailed_polarity_hindi: Total Sparsity 1.3573127553288283e-06
2024-04-22 12:51:05 - INFO :       entailed_polarity_hindi: Total Accuracy (20, 27, 0.7407407407407407)
2024-04-22 12:51:05 - INFO :       
==================Finish================

2024-04-22 12:51:05 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:51:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:51:05 - INFO :       DATASET: tasksource/bigbench epistemic_reasoning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.75s/it]
2024-04-22 12:51:31 - INFO :       Use taylor pruner...
2024-04-22 12:51:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:51:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:51:32 - INFO :       Start Pruning
2024-04-22 12:51:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:51:35 - INFO :       Loss = 12.7109375
2024-04-22 12:51:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:51:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:51:41 - INFO :       epistemic_reasoning: Total Sparsity 1.3595404667678207e-06
2024-04-22 12:52:42 - INFO :       epistemic_reasoning: Total Accuracy (29, 50, 0.58)
2024-04-22 12:52:42 - INFO :       
==================Finish================

2024-04-22 12:52:42 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:52:42 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:52:42 - INFO :       DATASET: tasksource/bigbench evaluating_information_essentiality
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.91s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.29s/it]
2024-04-22 12:53:12 - INFO :       Use taylor pruner...
2024-04-22 12:53:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:53:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:53:13 - INFO :       Start Pruning
2024-04-22 12:53:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:53:16 - INFO :       Loss = 7.48046875
2024-04-22 12:53:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:53:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:53:20 - INFO :       evaluating_information_essentiality: Total Sparsity 1.3561988996093322e-06
2024-04-22 12:53:41 - INFO :       evaluating_information_essentiality: Total Accuracy (1, 16, 0.0625)
2024-04-22 12:53:41 - INFO :       
==================Finish================

2024-04-22 12:53:41 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:53:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:53:41 - INFO :       DATASET: tasksource/bigbench fact_checker
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  7.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.05s/it]
2024-04-22 12:54:08 - INFO :       Use taylor pruner...
2024-04-22 12:54:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:54:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:54:09 - INFO :       Start Pruning
2024-04-22 12:54:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:54:11 - INFO :       Loss = 14.3984375
2024-04-22 12:54:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:54:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:54:16 - INFO :       fact_checker: Total Sparsity 1.3563580218549744e-06
2024-04-22 12:55:15 - INFO :       fact_checker: Total Accuracy (34, 50, 0.68)
2024-04-22 12:55:16 - INFO :       
==================Finish================

2024-04-22 12:55:16 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:55:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:55:16 - INFO :       DATASET: tasksource/bigbench fantasy_reasoning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.61s/it]
2024-04-22 12:55:41 - INFO :       Use taylor pruner...
2024-04-22 12:55:41 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:55:41 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:55:42 - INFO :       Start Pruning
2024-04-22 12:55:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:55:45 - INFO :       Loss = 13.5234375
2024-04-22 12:55:47 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:55:47 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:55:50 - INFO :       fantasy_reasoning: Total Sparsity 1.357153633083186e-06
2024-04-22 12:56:44 - INFO :       fantasy_reasoning: Total Accuracy (25, 40, 0.625)
2024-04-22 12:56:44 - INFO :       
==================Finish================

2024-04-22 12:56:44 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:56:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:56:44 - INFO :       DATASET: tasksource/bigbench figure_of_speech_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:08<00:08,  9.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  5.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:12<00:00,  6.26s/it]
2024-04-22 12:57:19 - INFO :       Use taylor pruner...
2024-04-22 12:57:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:57:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:57:20 - INFO :       Start Pruning
2024-04-22 12:57:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:57:23 - INFO :       Loss = 11.8515625
2024-04-22 12:57:27 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:57:27 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:57:30 - INFO :       figure_of_speech_detection: Total Sparsity 1.3568353885919015e-06
2024-04-22 12:57:48 - INFO :       figure_of_speech_detection: Total Accuracy (3, 16, 0.1875)
2024-04-22 12:57:48 - INFO :       
==================Finish================

2024-04-22 12:57:48 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:57:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:57:48 - INFO :       DATASET: tasksource/bigbench formal_fallacies_syllogisms_negation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  4.92s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:10<00:00,  5.25s/it]
2024-04-22 12:58:18 - INFO :       Use taylor pruner...
2024-04-22 12:58:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:58:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 12:58:19 - INFO :       Start Pruning
2024-04-22 12:58:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 12:58:22 - INFO :       Loss = 11.359375
2024-04-22 12:58:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 12:58:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 12:58:27 - INFO :       formal_fallacies_syllogisms_negation: Total Sparsity 1.3568353885919015e-06
2024-04-22 12:59:38 - INFO :       formal_fallacies_syllogisms_negation: Total Accuracy (23, 50, 0.46)
2024-04-22 12:59:38 - INFO :       
==================Finish================

2024-04-22 12:59:38 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 12:59:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 12:59:38 - INFO :       DATASET: tasksource/bigbench general_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.65s/it]
2024-04-22 13:00:02 - INFO :       Use taylor pruner...
2024-04-22 13:00:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:00:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:00:03 - INFO :       Start Pruning
2024-04-22 13:00:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:00:05 - INFO :       Loss = 12.0546875
2024-04-22 13:00:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:00:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:00:10 - INFO :       general_knowledge: Total Sparsity 1.354448554907267e-06
2024-04-22 13:00:28 - INFO :       general_knowledge: Total Accuracy (13, 16, 0.8125)
2024-04-22 13:00:28 - INFO :       
==================Finish================

2024-04-22 13:00:28 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:00:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:00:28 - INFO :       DATASET: tasksource/bigbench geometric_shapes
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.09s/it]
2024-04-22 13:00:50 - INFO :       Use taylor pruner...
2024-04-22 13:00:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:00:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:00:52 - INFO :       Start Pruning
2024-04-22 13:00:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:00:54 - INFO :       Loss = 8.6875
2024-04-22 13:00:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:00:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:00:59 - INFO :       geometric_shapes: Total Sparsity 1.3577901220657553e-06
2024-04-22 13:01:56 - INFO :       geometric_shapes: Total Accuracy (6, 50, 0.12)
2024-04-22 13:01:56 - INFO :       
==================Finish================

2024-04-22 13:01:56 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:01:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:01:56 - INFO :       DATASET: tasksource/bigbench goal_step_wikihow
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.22s/it]
2024-04-22 13:02:17 - INFO :       Use taylor pruner...
2024-04-22 13:02:17 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:02:17 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:02:18 - INFO :       Start Pruning
2024-04-22 13:02:19 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:02:20 - INFO :       Loss = 12.203125
2024-04-22 13:02:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:02:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:02:25 - INFO :       goal_step_wikihow: Total Sparsity 1.3561988996093322e-06
2024-04-22 13:03:19 - INFO :       goal_step_wikihow: Total Accuracy (24, 50, 0.48)
2024-04-22 13:03:19 - INFO :       
==================Finish================

2024-04-22 13:03:19 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:03:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:03:19 - INFO :       DATASET: tasksource/bigbench gre_reading_comprehension
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.39s/it]
2024-04-22 13:03:42 - INFO :       Use taylor pruner...
2024-04-22 13:03:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:03:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:03:43 - INFO :       Start Pruning
2024-04-22 13:03:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:03:46 - INFO :       Loss = 3.3671875
2024-04-22 13:03:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:03:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:03:50 - INFO :       gre_reading_comprehension: Total Sparsity 1.3573127553288283e-06
2024-04-22 13:04:10 - INFO :       gre_reading_comprehension: Total Accuracy (5, 16, 0.3125)
2024-04-22 13:04:10 - INFO :       
==================Finish================

2024-04-22 13:04:10 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:04:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:04:10 - INFO :       DATASET: tasksource/bigbench hhh_alignment
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.60s/it]
2024-04-22 13:04:34 - INFO :       Use taylor pruner...
2024-04-22 13:04:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:04:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:04:35 - INFO :       Start Pruning
2024-04-22 13:04:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:04:37 - INFO :       Loss = 8.9296875
2024-04-22 13:04:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:04:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:04:42 - INFO :       hhh_alignment: Total Sparsity 1.3589039777852514e-06
2024-04-22 13:05:31 - INFO :       hhh_alignment: Total Accuracy (29, 42, 0.6904761904761905)
2024-04-22 13:05:31 - INFO :       
==================Finish================

2024-04-22 13:05:31 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:05:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:05:31 - INFO :       DATASET: tasksource/bigbench hindu_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.89s/it]
2024-04-22 13:05:53 - INFO :       Use taylor pruner...
2024-04-22 13:05:53 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:05:53 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:05:54 - INFO :       Start Pruning
2024-04-22 13:05:55 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:05:57 - INFO :       Loss = 13.546875
2024-04-22 13:05:59 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:05:59 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:06:01 - INFO :       hindu_knowledge: Total Sparsity 1.3611316892242436e-06
2024-04-22 13:06:38 - INFO :       hindu_knowledge: Total Accuracy (23, 35, 0.6571428571428571)
2024-04-22 13:06:38 - INFO :       
==================Finish================

2024-04-22 13:06:38 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:06:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:06:38 - INFO :       DATASET: tasksource/bigbench hinglish_toxicity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.68s/it]
2024-04-22 13:07:02 - INFO :       Use taylor pruner...
2024-04-22 13:07:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:07:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:07:03 - INFO :       Start Pruning
2024-04-22 13:07:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:07:05 - INFO :       Loss = 12.703125
2024-04-22 13:07:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:07:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:07:10 - INFO :       hinglish_toxicity: Total Sparsity 1.3563580218549744e-06
2024-04-22 13:07:51 - INFO :       hinglish_toxicity: Total Accuracy (19, 40, 0.475)
2024-04-22 13:07:51 - INFO :       
==================Finish================

2024-04-22 13:07:51 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:07:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:07:51 - INFO :       DATASET: tasksource/bigbench human_organs_senses
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.06s/it]
2024-04-22 13:08:13 - INFO :       Use taylor pruner...
2024-04-22 13:08:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:08:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:08:13 - INFO :       Start Pruning
2024-04-22 13:08:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:08:16 - INFO :       Loss = 13.953125
2024-04-22 13:08:18 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:08:18 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:08:20 - INFO :       human_organs_senses: Total Sparsity 1.3563580218549744e-06
2024-04-22 13:08:37 - INFO :       human_organs_senses: Total Accuracy (9, 16, 0.5625)
2024-04-22 13:08:37 - INFO :       
==================Finish================

2024-04-22 13:08:37 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:08:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:08:37 - INFO :       DATASET: tasksource/bigbench hyperbaton
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.97s/it]
2024-04-22 13:08:58 - INFO :       Use taylor pruner...
2024-04-22 13:08:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:08:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:08:59 - INFO :       Start Pruning
2024-04-22 13:09:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:09:01 - INFO :       Loss = 15.34375
2024-04-22 13:09:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:09:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:09:05 - INFO :       hyperbaton: Total Sparsity 1.3593813445221782e-06
2024-04-22 13:09:56 - INFO :       hyperbaton: Total Accuracy (22, 50, 0.44)
2024-04-22 13:09:56 - INFO :       
==================Finish================

2024-04-22 13:09:56 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:09:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:09:56 - INFO :       DATASET: tasksource/bigbench identify_math_theorems
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.75s/it]
2024-04-22 13:10:16 - INFO :       Use taylor pruner...
2024-04-22 13:10:16 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:10:16 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:10:17 - INFO :       Start Pruning
2024-04-22 13:10:18 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:10:19 - INFO :       Loss = 1.7666015625
2024-04-22 13:10:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:10:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:10:24 - INFO :       identify_math_theorems: Total Sparsity 1.350788743257494e-06
2024-04-22 13:10:43 - INFO :       identify_math_theorems: Total Accuracy (8, 16, 0.5)
2024-04-22 13:10:44 - INFO :       
==================Finish================

2024-04-22 13:10:44 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:10:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:10:44 - INFO :       DATASET: tasksource/bigbench identify_odd_metaphor
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.89s/it]
2024-04-22 13:11:03 - INFO :       Use taylor pruner...
2024-04-22 13:11:03 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:11:03 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:11:04 - INFO :       Start Pruning
2024-04-22 13:11:05 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:11:06 - INFO :       Loss = 11.4296875
2024-04-22 13:11:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:11:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:11:11 - INFO :       identify_odd_metaphor: Total Sparsity 1.3569945108375437e-06
2024-04-22 13:11:28 - INFO :       identify_odd_metaphor: Total Accuracy (10, 16, 0.625)
2024-04-22 13:11:28 - INFO :       
==================Finish================

2024-04-22 13:11:28 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:11:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:11:28 - INFO :       DATASET: tasksource/bigbench implicatures
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  4.00s/it]
2024-04-22 13:11:51 - INFO :       Use taylor pruner...
2024-04-22 13:11:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:11:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:11:52 - INFO :       Start Pruning
2024-04-22 13:11:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:11:55 - INFO :       Loss = 14.015625
2024-04-22 13:11:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:11:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:11:59 - INFO :       implicatures: Total Sparsity 1.3598587112591052e-06
2024-04-22 13:12:53 - INFO :       implicatures: Total Accuracy (31, 50, 0.62)
2024-04-22 13:12:54 - INFO :       
==================Finish================

2024-04-22 13:12:54 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:12:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:12:54 - INFO :       DATASET: tasksource/bigbench implicit_relations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.88s/it]
2024-04-22 13:13:15 - INFO :       Use taylor pruner...
2024-04-22 13:13:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:13:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:13:15 - INFO :       Start Pruning
2024-04-22 13:13:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:13:18 - INFO :       Loss = 6.9140625
2024-04-22 13:13:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:13:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:13:22 - INFO :       implicit_relations: Total Sparsity 1.3538120659246977e-06
2024-04-22 13:13:40 - INFO :       implicit_relations: Total Accuracy (4, 17, 0.23529411764705882)
2024-04-22 13:13:40 - INFO :       
==================Finish================

2024-04-22 13:13:40 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:13:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:13:40 - INFO :       DATASET: tasksource/bigbench indic_cause_and_effect
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.82s/it]
2024-04-22 13:14:00 - INFO :       Use taylor pruner...
2024-04-22 13:14:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:14:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:14:01 - INFO :       Start Pruning
2024-04-22 13:14:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:14:03 - INFO :       Loss = 9.5234375
2024-04-22 13:14:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:14:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:14:08 - INFO :       indic_cause_and_effect: Total Sparsity 1.3590631000308936e-06
2024-04-22 13:15:03 - INFO :       indic_cause_and_effect: Total Accuracy (34, 50, 0.68)
2024-04-22 13:15:04 - INFO :       
==================Finish================

2024-04-22 13:15:04 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:15:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:15:04 - INFO :       DATASET: tasksource/bigbench intent_recognition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.92s/it]
2024-04-22 13:15:25 - INFO :       Use taylor pruner...
2024-04-22 13:15:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:15:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:15:25 - INFO :       Start Pruning
2024-04-22 13:15:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:15:28 - INFO :       Loss = 10.6015625
2024-04-22 13:15:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:15:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:15:33 - INFO :       intent_recognition: Total Sparsity 1.3584266110483244e-06
2024-04-22 13:16:26 - INFO :       intent_recognition: Total Accuracy (24, 50, 0.48)
2024-04-22 13:16:26 - INFO :       
==================Finish================

2024-04-22 13:16:26 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:16:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:16:26 - INFO :       DATASET: tasksource/bigbench international_phonetic_alphabet_nli
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.55s/it]
2024-04-22 13:16:49 - INFO :       Use taylor pruner...
2024-04-22 13:16:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:16:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:16:50 - INFO :       Start Pruning
2024-04-22 13:16:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:16:53 - INFO :       Loss = 8.9765625
2024-04-22 13:16:55 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:16:55 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:16:57 - INFO :       international_phonetic_alphabet_nli: Total Sparsity 1.3541303104159823e-06
2024-04-22 13:17:24 - INFO :       international_phonetic_alphabet_nli: Total Accuracy (9, 25, 0.36)
2024-04-22 13:17:24 - INFO :       
==================Finish================

2024-04-22 13:17:24 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:17:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:17:24 - INFO :       DATASET: tasksource/bigbench intersect_geometry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.34s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.66s/it]
2024-04-22 13:17:47 - INFO :       Use taylor pruner...
2024-04-22 13:17:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:17:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:17:48 - INFO :       Start Pruning
2024-04-22 13:17:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:17:52 - INFO :       Loss = 2.90234375
2024-04-22 13:17:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:17:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:17:56 - INFO :       intersect_geometry: Total Sparsity 1.355562410626763e-06
2024-04-22 13:18:54 - INFO :       intersect_geometry: Total Accuracy (2, 50, 0.04)
2024-04-22 13:18:54 - INFO :       
==================Finish================

2024-04-22 13:18:54 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:18:54 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:18:54 - INFO :       DATASET: tasksource/bigbench irony_identification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.85s/it]
2024-04-22 13:19:14 - INFO :       Use taylor pruner...
2024-04-22 13:19:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:19:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:19:15 - INFO :       Start Pruning
2024-04-22 13:19:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:19:18 - INFO :       Loss = 13.7734375
2024-04-22 13:19:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:19:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:19:23 - INFO :       irony_identification: Total Sparsity 1.358744855539609e-06
2024-04-22 13:19:43 - INFO :       irony_identification: Total Accuracy (11, 19, 0.5789473684210527)
2024-04-22 13:19:44 - INFO :       
==================Finish================

2024-04-22 13:19:44 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:19:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:19:44 - INFO :       DATASET: tasksource/bigbench kannada
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.75s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.01s/it]
2024-04-22 13:20:04 - INFO :       Use taylor pruner...
2024-04-22 13:20:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:20:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:20:05 - INFO :       Start Pruning
2024-04-22 13:20:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:20:07 - INFO :       Loss = 4.2578125
2024-04-22 13:20:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:20:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:20:11 - INFO :       kannada: Total Sparsity 1.3530164546964862e-06
2024-04-22 13:21:13 - INFO :       kannada: Total Accuracy (11, 50, 0.22)
2024-04-22 13:21:14 - INFO :       
==================Finish================

2024-04-22 13:21:14 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:21:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:21:14 - INFO :       DATASET: tasksource/bigbench key_value_maps
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.03s/it]
2024-04-22 13:21:35 - INFO :       Use taylor pruner...
2024-04-22 13:21:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:21:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:21:37 - INFO :       Start Pruning
2024-04-22 13:21:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:21:39 - INFO :       Loss = 7.2890625
2024-04-22 13:21:42 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:21:42 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:21:44 - INFO :       key_value_maps: Total Sparsity 1.3574718775744707e-06
2024-04-22 13:22:08 - INFO :       key_value_maps: Total Accuracy (12, 21, 0.5714285714285714)
2024-04-22 13:22:09 - INFO :       
==================Finish================

2024-04-22 13:22:09 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:22:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:22:09 - INFO :       DATASET: tasksource/bigbench known_unknowns
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  4.00s/it]
2024-04-22 13:22:31 - INFO :       Use taylor pruner...
2024-04-22 13:22:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:22:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:22:32 - INFO :       Start Pruning
2024-04-22 13:22:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:22:35 - INFO :       Loss = 14.421875
2024-04-22 13:22:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:22:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:22:40 - INFO :       known_unknowns: Total Sparsity 1.3584266110483244e-06
2024-04-22 13:22:56 - INFO :       known_unknowns: Total Accuracy (9, 16, 0.5625)
2024-04-22 13:22:56 - INFO :       
==================Finish================

2024-04-22 13:22:56 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:22:56 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:22:56 - INFO :       DATASET: tasksource/bigbench language_identification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.98s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.26s/it]
2024-04-22 13:23:18 - INFO :       Use taylor pruner...
2024-04-22 13:23:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:23:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:23:19 - INFO :       Start Pruning
2024-04-22 13:23:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:23:21 - INFO :       Loss = 9.09375
2024-04-22 13:23:23 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:23:23 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:23:25 - INFO :       language_identification: Total Sparsity 1.3557215328724054e-06
2024-04-22 13:24:20 - INFO :       language_identification: Total Accuracy (9, 50, 0.18)
2024-04-22 13:24:20 - INFO :       
==================Finish================

2024-04-22 13:24:20 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:24:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:24:20 - INFO :       DATASET: tasksource/bigbench logic_grid_puzzle
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.01s/it]
2024-04-22 13:24:42 - INFO :       Use taylor pruner...
2024-04-22 13:24:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:24:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:24:43 - INFO :       Start Pruning
2024-04-22 13:24:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:24:45 - INFO :       Loss = 4.51953125
2024-04-22 13:24:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:24:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:24:50 - INFO :       logic_grid_puzzle: Total Sparsity 1.3541303104159823e-06
2024-04-22 13:25:47 - INFO :       logic_grid_puzzle: Total Accuracy (13, 50, 0.26)
2024-04-22 13:25:48 - INFO :       
==================Finish================

2024-04-22 13:25:48 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:25:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:25:48 - INFO :       DATASET: tasksource/bigbench logical_args
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.36s/it]
2024-04-22 13:26:11 - INFO :       Use taylor pruner...
2024-04-22 13:26:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:26:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:26:12 - INFO :       Start Pruning
2024-04-22 13:26:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:26:15 - INFO :       Loss = 8.578125
2024-04-22 13:26:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:26:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:26:19 - INFO :       logical_args: Total Sparsity 1.357630999820113e-06
2024-04-22 13:26:37 - INFO :       logical_args: Total Accuracy (8, 16, 0.5)
2024-04-22 13:26:37 - INFO :       
==================Finish================

2024-04-22 13:26:37 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:26:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:26:37 - INFO :       DATASET: tasksource/bigbench logical_deduction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.76s/it]
2024-04-22 13:26:57 - INFO :       Use taylor pruner...
2024-04-22 13:26:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:26:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:26:58 - INFO :       Start Pruning
2024-04-22 13:26:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:27:01 - INFO :       Loss = 10.46875
2024-04-22 13:27:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:27:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:27:05 - INFO :       logical_deduction: Total Sparsity 1.3589039777852514e-06
2024-04-22 13:27:57 - INFO :       logical_deduction: Total Accuracy (12, 50, 0.24)
2024-04-22 13:27:57 - INFO :       
==================Finish================

2024-04-22 13:27:57 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:27:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:27:57 - INFO :       DATASET: tasksource/bigbench logical_fallacy_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.00s/it]
2024-04-22 13:28:19 - INFO :       Use taylor pruner...
2024-04-22 13:28:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:28:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:28:20 - INFO :       Start Pruning
2024-04-22 13:28:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:28:23 - INFO :       Loss = 13.96875
2024-04-22 13:28:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:28:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:28:28 - INFO :       logical_fallacy_detection: Total Sparsity 1.358267488802682e-06
2024-04-22 13:29:27 - INFO :       logical_fallacy_detection: Total Accuracy (28, 50, 0.56)
2024-04-22 13:29:27 - INFO :       
==================Finish================

2024-04-22 13:29:27 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:29:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:29:27 - INFO :       DATASET: tasksource/bigbench logical_sequence
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.40s/it]
2024-04-22 13:29:50 - INFO :       Use taylor pruner...
2024-04-22 13:29:50 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:29:50 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:29:51 - INFO :       Start Pruning
2024-04-22 13:29:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:29:54 - INFO :       Loss = 10.921875
2024-04-22 13:29:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:29:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:29:58 - INFO :       logical_sequence: Total Sparsity 1.3558806551180476e-06
2024-04-22 13:30:15 - INFO :       logical_sequence: Total Accuracy (5, 16, 0.3125)
2024-04-22 13:30:15 - INFO :       
==================Finish================

2024-04-22 13:30:15 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:30:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:30:15 - INFO :       DATASET: tasksource/bigbench mathematical_induction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.84s/it]
2024-04-22 13:30:36 - INFO :       Use taylor pruner...
2024-04-22 13:30:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:30:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:30:36 - INFO :       Start Pruning
2024-04-22 13:30:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:30:38 - INFO :       Loss = 13.203125
2024-04-22 13:30:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:30:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:30:43 - INFO :       mathematical_induction: Total Sparsity 1.358744855539609e-06
2024-04-22 13:30:59 - INFO :       mathematical_induction: Total Accuracy (10, 16, 0.625)
2024-04-22 13:30:59 - INFO :       
==================Finish================

2024-04-22 13:30:59 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:30:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:30:59 - INFO :       DATASET: tasksource/bigbench medical_questions_russian
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.25s/it]
2024-04-22 13:31:23 - INFO :       Use taylor pruner...
2024-04-22 13:31:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:31:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:31:24 - INFO :       Start Pruning
2024-04-22 13:31:25 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:31:26 - INFO :       Loss = 10.671875
2024-04-22 13:31:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:31:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:31:30 - INFO :       medical_questions_russian: Total Sparsity 1.3557215328724054e-06
2024-04-22 13:32:26 - INFO :       medical_questions_russian: Total Accuracy (8, 50, 0.16)
2024-04-22 13:32:27 - INFO :       
==================Finish================

2024-04-22 13:32:27 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:32:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:32:27 - INFO :       DATASET: tasksource/bigbench metaphor_boolean
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.84s/it]
2024-04-22 13:32:49 - INFO :       Use taylor pruner...
2024-04-22 13:32:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:32:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:32:50 - INFO :       Start Pruning
2024-04-22 13:32:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:32:52 - INFO :       Loss = 13.6171875
2024-04-22 13:32:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:32:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:32:56 - INFO :       metaphor_boolean: Total Sparsity 1.3584266110483244e-06
2024-04-22 13:33:50 - INFO :       metaphor_boolean: Total Accuracy (18, 50, 0.36)
2024-04-22 13:33:50 - INFO :       
==================Finish================

2024-04-22 13:33:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:33:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:33:50 - INFO :       DATASET: tasksource/bigbench metaphor_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.93s/it]
2024-04-22 13:34:12 - INFO :       Use taylor pruner...
2024-04-22 13:34:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:34:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:34:12 - INFO :       Start Pruning
2024-04-22 13:34:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:34:15 - INFO :       Loss = 10.2578125
2024-04-22 13:34:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:34:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:34:19 - INFO :       metaphor_understanding: Total Sparsity 1.3552441661354783e-06
2024-04-22 13:35:10 - INFO :       metaphor_understanding: Total Accuracy (37, 46, 0.8043478260869565)
2024-04-22 13:35:10 - INFO :       
==================Finish================

2024-04-22 13:35:10 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:35:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:35:10 - INFO :       DATASET: tasksource/bigbench misconceptions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.00s/it]
2024-04-22 13:35:32 - INFO :       Use taylor pruner...
2024-04-22 13:35:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:35:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:35:33 - INFO :       Start Pruning
2024-04-22 13:35:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:35:36 - INFO :       Loss = 14.3203125
2024-04-22 13:35:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:35:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:35:40 - INFO :       misconceptions: Total Sparsity 1.3577901220657553e-06
2024-04-22 13:36:25 - INFO :       misconceptions: Total Accuracy (21, 43, 0.4883720930232558)
2024-04-22 13:36:25 - INFO :       
==================Finish================

2024-04-22 13:36:25 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:36:25 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:36:25 - INFO :       DATASET: tasksource/bigbench mnist_ascii
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.44s/it]
2024-04-22 13:36:49 - INFO :       Use taylor pruner...
2024-04-22 13:36:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:36:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:36:50 - INFO :       Start Pruning
2024-04-22 13:36:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:36:52 - INFO :       Loss = 5.59765625
2024-04-22 13:36:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:36:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:36:56 - INFO :       mnist_ascii: Total Sparsity 1.3554032883811208e-06
2024-04-22 13:38:29 - INFO :       mnist_ascii: Total Accuracy (6, 50, 0.12)
2024-04-22 13:38:29 - INFO :       
==================Finish================

2024-04-22 13:38:29 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:38:29 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:38:29 - INFO :       DATASET: tasksource/bigbench moral_permissibility
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.77s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.02s/it]
2024-04-22 13:38:51 - INFO :       Use taylor pruner...
2024-04-22 13:38:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:38:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:38:52 - INFO :       Start Pruning
2024-04-22 13:38:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:38:54 - INFO :       Loss = 12.109375
2024-04-22 13:38:56 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:38:56 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:38:58 - INFO :       moral_permissibility: Total Sparsity 1.355085043889836e-06
2024-04-22 13:39:51 - INFO :       moral_permissibility: Total Accuracy (26, 50, 0.52)
2024-04-22 13:39:51 - INFO :       
==================Finish================

2024-04-22 13:39:51 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:39:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:39:51 - INFO :       DATASET: tasksource/bigbench movie_dialog_same_or_different
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.13s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.26s/it]
2024-04-22 13:40:14 - INFO :       Use taylor pruner...
2024-04-22 13:40:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:40:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:40:14 - INFO :       Start Pruning
2024-04-22 13:40:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:40:17 - INFO :       Loss = 12.859375
2024-04-22 13:40:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:40:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:40:21 - INFO :       movie_dialog_same_or_different: Total Sparsity 1.3581083665570398e-06
2024-04-22 13:41:14 - INFO :       movie_dialog_same_or_different: Total Accuracy (23, 50, 0.46)
2024-04-22 13:41:15 - INFO :       
==================Finish================

2024-04-22 13:41:15 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:41:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:41:15 - INFO :       DATASET: tasksource/bigbench movie_recommendation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.59s/it]
2024-04-22 13:41:37 - INFO :       Use taylor pruner...
2024-04-22 13:41:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:41:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:41:38 - INFO :       Start Pruning
2024-04-22 13:41:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:41:41 - INFO :       Loss = 13.15625
2024-04-22 13:41:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:41:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:41:46 - INFO :       movie_recommendation: Total Sparsity 1.359699589013463e-06
2024-04-22 13:42:38 - INFO :       movie_recommendation: Total Accuracy (24, 50, 0.48)
2024-04-22 13:42:38 - INFO :       
==================Finish================

2024-04-22 13:42:38 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:42:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:42:38 - INFO :       DATASET: tasksource/bigbench navigate
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.10s/it]
2024-04-22 13:42:59 - INFO :       Use taylor pruner...
2024-04-22 13:42:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:42:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:43:00 - INFO :       Start Pruning
2024-04-22 13:43:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:43:03 - INFO :       Loss = 14.5390625
2024-04-22 13:43:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:43:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:43:07 - INFO :       navigate: Total Sparsity 1.359222222276536e-06
2024-04-22 13:43:58 - INFO :       navigate: Total Accuracy (10, 50, 0.2)
2024-04-22 13:43:58 - INFO :       
==================Finish================

2024-04-22 13:43:58 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:43:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:43:58 - INFO :       DATASET: tasksource/bigbench nonsense_words_grammar
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.83s/it]
2024-04-22 13:44:19 - INFO :       Use taylor pruner...
2024-04-22 13:44:19 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:44:19 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:44:20 - INFO :       Start Pruning
2024-04-22 13:44:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:44:22 - INFO :       Loss = 14.2890625
2024-04-22 13:44:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:44:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:44:27 - INFO :       nonsense_words_grammar: Total Sparsity 1.3574718775744707e-06
2024-04-22 13:44:42 - INFO :       nonsense_words_grammar: Total Accuracy (5, 16, 0.3125)
2024-04-22 13:44:43 - INFO :       
==================Finish================

2024-04-22 13:44:43 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:44:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:44:43 - INFO :       DATASET: tasksource/bigbench novel_concepts
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.10s/it]
2024-04-22 13:45:05 - INFO :       Use taylor pruner...
2024-04-22 13:45:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:45:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:45:06 - INFO :       Start Pruning
2024-04-22 13:45:07 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:45:08 - INFO :       Loss = 11.2578125
2024-04-22 13:45:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:45:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:45:13 - INFO :       novel_concepts: Total Sparsity 1.356517144100617e-06
2024-04-22 13:45:29 - INFO :       novel_concepts: Total Accuracy (6, 16, 0.375)
2024-04-22 13:45:29 - INFO :       
==================Finish================

2024-04-22 13:45:29 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:45:29 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:45:29 - INFO :       DATASET: tasksource/bigbench odd_one_out
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.08s/it]
2024-04-22 13:45:51 - INFO :       Use taylor pruner...
2024-04-22 13:45:51 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:45:51 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:45:52 - INFO :       Start Pruning
2024-04-22 13:45:53 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:45:54 - INFO :       Loss = 14.015625
2024-04-22 13:45:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:45:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:45:59 - INFO :       odd_one_out: Total Sparsity 1.3579492443113975e-06
2024-04-22 13:46:17 - INFO :       odd_one_out: Total Accuracy (3, 17, 0.17647058823529413)
2024-04-22 13:46:17 - INFO :       
==================Finish================

2024-04-22 13:46:17 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:46:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:46:17 - INFO :       DATASET: tasksource/bigbench parsinlu_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.95s/it]
2024-04-22 13:46:39 - INFO :       Use taylor pruner...
2024-04-22 13:46:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:46:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:46:40 - INFO :       Start Pruning
2024-04-22 13:46:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:46:42 - INFO :       Loss = 10.1875
2024-04-22 13:46:44 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:46:44 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:46:47 - INFO :       parsinlu_qa: Total Sparsity 1.3563580218549744e-06
2024-04-22 13:47:39 - INFO :       parsinlu_qa: Total Accuracy (14, 50, 0.28)
2024-04-22 13:47:39 - INFO :       
==================Finish================

2024-04-22 13:47:39 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:47:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:47:39 - INFO :       DATASET: tasksource/bigbench penguins_in_a_table
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.85s/it]
2024-04-22 13:48:01 - INFO :       Use taylor pruner...
2024-04-22 13:48:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:48:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:48:01 - INFO :       Start Pruning
2024-04-22 13:48:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:48:04 - INFO :       Loss = 8.4140625
2024-04-22 13:48:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:48:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:48:08 - INFO :       penguins_in_a_table: Total Sparsity 1.3542894326616245e-06
2024-04-22 13:48:40 - INFO :       penguins_in_a_table: Total Accuracy (9, 29, 0.3103448275862069)
2024-04-22 13:48:40 - INFO :       
==================Finish================

2024-04-22 13:48:40 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:48:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:48:40 - INFO :       DATASET: tasksource/bigbench persian_idioms
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.75s/it]
2024-04-22 13:49:00 - INFO :       Use taylor pruner...
2024-04-22 13:49:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:49:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:49:01 - INFO :       Start Pruning
2024-04-22 13:49:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:49:04 - INFO :       Loss = 12.0859375
2024-04-22 13:49:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:49:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:49:08 - INFO :       persian_idioms: Total Sparsity 1.3577901220657553e-06
2024-04-22 13:49:24 - INFO :       persian_idioms: Total Accuracy (6, 16, 0.375)
2024-04-22 13:49:24 - INFO :       
==================Finish================

2024-04-22 13:49:24 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:49:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:49:24 - INFO :       DATASET: tasksource/bigbench phrase_relatedness
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.02s/it]
2024-04-22 13:49:46 - INFO :       Use taylor pruner...
2024-04-22 13:49:46 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:49:46 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:49:47 - INFO :       Start Pruning
2024-04-22 13:49:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:49:50 - INFO :       Loss = 13.5
2024-04-22 13:49:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:49:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:49:54 - INFO :       phrase_relatedness: Total Sparsity 1.3584266110483244e-06
2024-04-22 13:50:15 - INFO :       phrase_relatedness: Total Accuracy (12, 20, 0.6)
2024-04-22 13:50:15 - INFO :       
==================Finish================

2024-04-22 13:50:15 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:50:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:50:15 - INFO :       DATASET: tasksource/bigbench physical_intuition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.88s/it]
2024-04-22 13:50:36 - INFO :       Use taylor pruner...
2024-04-22 13:50:36 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:50:36 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:50:37 - INFO :       Start Pruning
2024-04-22 13:50:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:50:39 - INFO :       Loss = 13.796875
2024-04-22 13:50:42 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:50:42 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:50:45 - INFO :       physical_intuition: Total Sparsity 1.360336077996032e-06
2024-04-22 13:51:03 - INFO :       physical_intuition: Total Accuracy (6, 16, 0.375)
2024-04-22 13:51:03 - INFO :       
==================Finish================

2024-04-22 13:51:03 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:51:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:51:03 - INFO :       DATASET: tasksource/bigbench physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.93s/it]
2024-04-22 13:51:25 - INFO :       Use taylor pruner...
2024-04-22 13:51:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:51:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:51:26 - INFO :       Start Pruning
2024-04-22 13:51:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:51:28 - INFO :       Loss = 9.578125
2024-04-22 13:51:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:51:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:51:34 - INFO :       physics: Total Sparsity 1.3590631000308936e-06
2024-04-22 13:52:22 - INFO :       physics: Total Accuracy (42, 45, 0.9333333333333333)
2024-04-22 13:52:22 - INFO :       
==================Finish================

2024-04-22 13:52:22 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:52:22 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:52:22 - INFO :       DATASET: tasksource/bigbench play_dialog_same_or_different
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.09s/it]
2024-04-22 13:52:44 - INFO :       Use taylor pruner...
2024-04-22 13:52:44 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:52:44 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:52:45 - INFO :       Start Pruning
2024-04-22 13:52:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:52:48 - INFO :       Loss = 9.109375
2024-04-22 13:52:50 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:52:50 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:52:53 - INFO :       play_dialog_same_or_different: Total Sparsity 1.355085043889836e-06
2024-04-22 13:53:49 - INFO :       play_dialog_same_or_different: Total Accuracy (16, 50, 0.32)
2024-04-22 13:53:49 - INFO :       
==================Finish================

2024-04-22 13:53:49 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:53:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:53:49 - INFO :       DATASET: tasksource/bigbench presuppositions_as_nli
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.90s/it]
2024-04-22 13:54:10 - INFO :       Use taylor pruner...
2024-04-22 13:54:10 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:54:10 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:54:11 - INFO :       Start Pruning
2024-04-22 13:54:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:54:14 - INFO :       Loss = 10.125
2024-04-22 13:54:15 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:54:15 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:54:18 - INFO :       presuppositions_as_nli: Total Sparsity 1.358267488802682e-06
2024-04-22 13:55:10 - INFO :       presuppositions_as_nli: Total Accuracy (11, 50, 0.22)
2024-04-22 13:55:10 - INFO :       
==================Finish================

2024-04-22 13:55:10 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:55:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:55:10 - INFO :       DATASET: tasksource/bigbench question_selection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.24s/it]
2024-04-22 13:55:35 - INFO :       Use taylor pruner...
2024-04-22 13:55:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:55:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:55:35 - INFO :       Start Pruning
2024-04-22 13:55:38 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:55:39 - INFO :       Loss = 5.4375
2024-04-22 13:55:41 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:55:41 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:55:43 - INFO :       question_selection: Total Sparsity 1.354448554907267e-06
2024-04-22 13:56:40 - INFO :       question_selection: Total Accuracy (31, 50, 0.62)
2024-04-22 13:56:41 - INFO :       
==================Finish================

2024-04-22 13:56:41 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:56:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:56:41 - INFO :       DATASET: tasksource/bigbench reasoning_about_colored_objects
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.04s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.32s/it]
2024-04-22 13:57:02 - INFO :       Use taylor pruner...
2024-04-22 13:57:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:57:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:57:03 - INFO :       Start Pruning
2024-04-22 13:57:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:57:05 - INFO :       Loss = 11.9140625
2024-04-22 13:57:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:57:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:57:09 - INFO :       reasoning_about_colored_objects: Total Sparsity 1.3585857332939668e-06
2024-04-22 13:58:00 - INFO :       reasoning_about_colored_objects: Total Accuracy (16, 50, 0.32)
2024-04-22 13:58:00 - INFO :       
==================Finish================

2024-04-22 13:58:00 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:58:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:58:00 - INFO :       DATASET: tasksource/bigbench riddle_sense
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.85s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.83s/it]
2024-04-22 13:58:25 - INFO :       Use taylor pruner...
2024-04-22 13:58:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:58:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:58:25 - INFO :       Start Pruning
2024-04-22 13:58:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:58:28 - INFO :       Loss = 13.1328125
2024-04-22 13:58:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:58:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:58:33 - INFO :       riddle_sense: Total Sparsity 1.3620864226980974e-06
2024-04-22 13:58:50 - INFO :       riddle_sense: Total Accuracy (2, 16, 0.125)
2024-04-22 13:58:50 - INFO :       
==================Finish================

2024-04-22 13:58:50 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 13:58:50 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 13:58:50 - INFO :       DATASET: tasksource/bigbench ruin_names
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.47s/it]
2024-04-22 13:59:14 - INFO :       Use taylor pruner...
2024-04-22 13:59:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:59:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 13:59:14 - INFO :       Start Pruning
2024-04-22 13:59:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 13:59:17 - INFO :       Loss = 12.8125
2024-04-22 13:59:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 13:59:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 13:59:22 - INFO :       ruin_names: Total Sparsity 1.3612908114698858e-06
2024-04-22 14:00:16 - INFO :       ruin_names: Total Accuracy (6, 50, 0.12)
2024-04-22 14:00:16 - INFO :       
==================Finish================

2024-04-22 14:00:16 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:00:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:00:16 - INFO :       DATASET: tasksource/bigbench salient_translation_error_detection
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.98s/it]
2024-04-22 14:00:38 - INFO :       Use taylor pruner...
2024-04-22 14:00:38 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:00:38 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:00:39 - INFO :       Start Pruning
2024-04-22 14:00:40 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:00:41 - INFO :       Loss = 7.1640625
2024-04-22 14:00:43 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:00:43 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:00:46 - INFO :       salient_translation_error_detection: Total Sparsity 1.355085043889836e-06
2024-04-22 14:01:42 - INFO :       salient_translation_error_detection: Total Accuracy (11, 50, 0.22)
2024-04-22 14:01:43 - INFO :       
==================Finish================

2024-04-22 14:01:43 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:01:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:01:43 - INFO :       DATASET: tasksource/bigbench sentence_ambiguity
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.81s/it]
2024-04-22 14:02:04 - INFO :       Use taylor pruner...
2024-04-22 14:02:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:02:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:02:05 - INFO :       Start Pruning
2024-04-22 14:02:07 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:02:08 - INFO :       Loss = 14.2890625
2024-04-22 14:02:10 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:02:10 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:02:12 - INFO :       sentence_ambiguity: Total Sparsity 1.355562410626763e-06
2024-04-22 14:02:28 - INFO :       sentence_ambiguity: Total Accuracy (7, 16, 0.4375)
2024-04-22 14:02:28 - INFO :       
==================Finish================

2024-04-22 14:02:28 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:02:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:02:28 - INFO :       DATASET: tasksource/bigbench similarities_abstraction
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.97s/it]
2024-04-22 14:02:49 - INFO :       Use taylor pruner...
2024-04-22 14:02:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:02:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:02:50 - INFO :       Start Pruning
2024-04-22 14:02:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:02:52 - INFO :       Loss = 13.546875
2024-04-22 14:02:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:02:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:02:57 - INFO :       similarities_abstraction: Total Sparsity 1.3590631000308936e-06
2024-04-22 14:03:13 - INFO :       similarities_abstraction: Total Accuracy (9, 16, 0.5625)
2024-04-22 14:03:13 - INFO :       
==================Finish================

2024-04-22 14:03:13 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:03:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:03:13 - INFO :       DATASET: tasksource/bigbench simple_ethical_questions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.76s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.00s/it]
2024-04-22 14:03:33 - INFO :       Use taylor pruner...
2024-04-22 14:03:34 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:03:34 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:03:34 - INFO :       Start Pruning
2024-04-22 14:03:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:03:37 - INFO :       Loss = 11.3203125
2024-04-22 14:03:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:03:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:03:41 - INFO :       simple_ethical_questions: Total Sparsity 1.357153633083186e-06
2024-04-22 14:04:04 - INFO :       simple_ethical_questions: Total Accuracy (19, 23, 0.8260869565217391)
2024-04-22 14:04:04 - INFO :       
==================Finish================

2024-04-22 14:04:04 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:04:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:04:04 - INFO :       DATASET: tasksource/bigbench snarks
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.02s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.43s/it]
2024-04-22 14:04:27 - INFO :       Use taylor pruner...
2024-04-22 14:04:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:04:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:04:28 - INFO :       Start Pruning
2024-04-22 14:04:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:04:31 - INFO :       Loss = 13.6796875
2024-04-22 14:04:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:04:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:04:35 - INFO :       snarks: Total Sparsity 1.358267488802682e-06
2024-04-22 14:05:13 - INFO :       snarks: Total Accuracy (11, 36, 0.3055555555555556)
2024-04-22 14:05:13 - INFO :       
==================Finish================

2024-04-22 14:05:13 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:05:13 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:05:13 - INFO :       DATASET: tasksource/bigbench social_iqa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.50s/it]
2024-04-22 14:05:37 - INFO :       Use taylor pruner...
2024-04-22 14:05:37 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:05:37 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:05:37 - INFO :       Start Pruning
2024-04-22 14:05:39 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:05:40 - INFO :       Loss = 13.71875
2024-04-22 14:05:42 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:05:42 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:05:44 - INFO :       social_iqa: Total Sparsity 1.360336077996032e-06
2024-04-22 14:06:38 - INFO :       social_iqa: Total Accuracy (22, 50, 0.44)
2024-04-22 14:06:38 - INFO :       
==================Finish================

2024-04-22 14:06:38 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:06:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:06:38 - INFO :       DATASET: tasksource/bigbench social_support
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.01s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.33s/it]
2024-04-22 14:07:02 - INFO :       Use taylor pruner...
2024-04-22 14:07:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:07:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:07:03 - INFO :       Start Pruning
2024-04-22 14:07:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:07:05 - INFO :       Loss = 11.8828125
2024-04-22 14:07:08 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:07:08 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:07:10 - INFO :       social_support: Total Sparsity 1.3589039777852514e-06
2024-04-22 14:08:03 - INFO :       social_support: Total Accuracy (25, 50, 0.5)
2024-04-22 14:08:04 - INFO :       
==================Finish================

2024-04-22 14:08:04 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:08:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:08:04 - INFO :       DATASET: tasksource/bigbench sports_understanding
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.98s/it]
2024-04-22 14:08:26 - INFO :       Use taylor pruner...
2024-04-22 14:08:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:08:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:08:27 - INFO :       Start Pruning
2024-04-22 14:08:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:08:30 - INFO :       Loss = 14.90625
2024-04-22 14:08:32 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:08:32 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:08:34 - INFO :       sports_understanding: Total Sparsity 1.35397118817034e-06
2024-04-22 14:09:26 - INFO :       sports_understanding: Total Accuracy (29, 50, 0.58)
2024-04-22 14:09:26 - INFO :       
==================Finish================

2024-04-22 14:09:26 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:09:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:09:26 - INFO :       DATASET: tasksource/bigbench strange_stories
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.94s/it]
2024-04-22 14:09:47 - INFO :       Use taylor pruner...
2024-04-22 14:09:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:09:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:09:48 - INFO :       Start Pruning
2024-04-22 14:09:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:09:50 - INFO :       Loss = 12.5703125
2024-04-22 14:09:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:09:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:09:55 - INFO :       strange_stories: Total Sparsity 1.3573127553288283e-06
2024-04-22 14:10:31 - INFO :       strange_stories: Total Accuracy (17, 34, 0.5)
2024-04-22 14:10:31 - INFO :       
==================Finish================

2024-04-22 14:10:31 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:10:31 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:10:31 - INFO :       DATASET: tasksource/bigbench strategyqa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.84s/it]
2024-04-22 14:10:52 - INFO :       Use taylor pruner...
2024-04-22 14:10:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:10:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:10:52 - INFO :       Start Pruning
2024-04-22 14:10:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:10:55 - INFO :       Loss = 14.375
2024-04-22 14:10:57 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:10:57 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:10:59 - INFO :       strategyqa: Total Sparsity 1.354448554907267e-06
2024-04-22 14:11:52 - INFO :       strategyqa: Total Accuracy (30, 50, 0.6)
2024-04-22 14:11:52 - INFO :       
==================Finish================

2024-04-22 14:11:52 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:11:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:11:52 - INFO :       DATASET: tasksource/bigbench suicide_risk
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.96s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.88s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.19s/it]
2024-04-22 14:12:14 - INFO :       Use taylor pruner...
2024-04-22 14:12:14 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:12:14 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:12:15 - INFO :       Start Pruning
2024-04-22 14:12:16 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:12:17 - INFO :       Loss = 9.078125
2024-04-22 14:12:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:12:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:12:21 - INFO :       suicide_risk: Total Sparsity 1.354448554907267e-06
2024-04-22 14:12:38 - INFO :       suicide_risk: Total Accuracy (3, 16, 0.1875)
2024-04-22 14:12:38 - INFO :       
==================Finish================

2024-04-22 14:12:38 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:12:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:12:38 - INFO :       DATASET: tasksource/bigbench swahili_english_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.81s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.29s/it]
2024-04-22 14:12:59 - INFO :       Use taylor pruner...
2024-04-22 14:12:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:12:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:13:00 - INFO :       Start Pruning
2024-04-22 14:13:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:13:02 - INFO :       Loss = 10.5234375
2024-04-22 14:13:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:13:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:13:06 - INFO :       swahili_english_proverbs: Total Sparsity 1.3557215328724054e-06
2024-04-22 14:13:38 - INFO :       swahili_english_proverbs: Total Accuracy (16, 30, 0.5333333333333333)
2024-04-22 14:13:38 - INFO :       
==================Finish================

2024-04-22 14:13:38 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:13:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:13:38 - INFO :       DATASET: tasksource/bigbench swedish_to_german_proverbs
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.16s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.71s/it]
2024-04-22 14:13:58 - INFO :       Use taylor pruner...
2024-04-22 14:13:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:13:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:13:59 - INFO :       Start Pruning
2024-04-22 14:14:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:14:01 - INFO :       Loss = 10.96875
2024-04-22 14:14:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:14:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:14:05 - INFO :       swedish_to_german_proverbs: Total Sparsity 1.3573127553288283e-06
2024-04-22 14:14:23 - INFO :       swedish_to_german_proverbs: Total Accuracy (7, 16, 0.4375)
2024-04-22 14:14:23 - INFO :       
==================Finish================

2024-04-22 14:14:23 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:14:23 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:14:23 - INFO :       DATASET: tasksource/bigbench symbol_interpretation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.72s/it]
2024-04-22 14:14:45 - INFO :       Use taylor pruner...
2024-04-22 14:14:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:14:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:14:46 - INFO :       Start Pruning
2024-04-22 14:14:48 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:14:49 - INFO :       Loss = 4.92578125
2024-04-22 14:14:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:14:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:14:53 - INFO :       symbol_interpretation: Total Sparsity 1.3579492443113975e-06
2024-04-22 14:16:09 - INFO :       symbol_interpretation: Total Accuracy (17, 50, 0.34)
2024-04-22 14:16:10 - INFO :       
==================Finish================

2024-04-22 14:16:10 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:16:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:16:10 - INFO :       DATASET: tasksource/bigbench temporal_sequences
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.86s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.12s/it]
2024-04-22 14:16:32 - INFO :       Use taylor pruner...
2024-04-22 14:16:32 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:16:32 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:16:33 - INFO :       Start Pruning
2024-04-22 14:16:35 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:16:36 - INFO :       Loss = 8.765625
2024-04-22 14:16:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:16:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:16:41 - INFO :       temporal_sequences: Total Sparsity 1.3589039777852514e-06
2024-04-22 14:17:34 - INFO :       temporal_sequences: Total Accuracy (15, 50, 0.3)
2024-04-22 14:17:34 - INFO :       
==================Finish================

2024-04-22 14:17:34 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:17:34 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:17:34 - INFO :       DATASET: tasksource/bigbench timedial
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.61s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.24s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.60s/it]
2024-04-22 14:17:56 - INFO :       Use taylor pruner...
2024-04-22 14:17:56 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:17:56 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:17:57 - INFO :       Start Pruning
2024-04-22 14:17:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:18:00 - INFO :       Loss = 5.46875
2024-04-22 14:18:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:18:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:18:04 - INFO :       timedial: Total Sparsity 1.3557215328724054e-06
2024-04-22 14:19:02 - INFO :       timedial: Total Accuracy (13, 50, 0.26)
2024-04-22 14:19:03 - INFO :       
==================Finish================

2024-04-22 14:19:03 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:19:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:19:03 - INFO :       DATASET: tasksource/bigbench tracking_shuffled_objects
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.39s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.68s/it]
2024-04-22 14:19:27 - INFO :       Use taylor pruner...
2024-04-22 14:19:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:19:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:19:28 - INFO :       Start Pruning
2024-04-22 14:19:30 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:19:31 - INFO :       Loss = 9.265625
2024-04-22 14:19:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:19:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:19:35 - INFO :       tracking_shuffled_objects: Total Sparsity 1.3536529436790554e-06
2024-04-22 14:20:29 - INFO :       tracking_shuffled_objects: Total Accuracy (7, 50, 0.14)
2024-04-22 14:20:29 - INFO :       
==================Finish================

2024-04-22 14:20:29 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:20:29 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:20:29 - INFO :       DATASET: tasksource/bigbench understanding_fables
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.93s/it]
2024-04-22 14:20:49 - INFO :       Use taylor pruner...
2024-04-22 14:20:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:20:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:20:50 - INFO :       Start Pruning
2024-04-22 14:20:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:20:52 - INFO :       Loss = 6.91796875
2024-04-22 14:20:54 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:20:54 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:20:56 - INFO :       understanding_fables: Total Sparsity 1.357153633083186e-06
2024-04-22 14:21:38 - INFO :       understanding_fables: Total Accuracy (9, 37, 0.24324324324324326)
2024-04-22 14:21:38 - INFO :       
==================Finish================

2024-04-22 14:21:38 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:21:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:21:38 - INFO :       DATASET: tasksource/bigbench undo_permutation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.19s/it]
2024-04-22 14:22:00 - INFO :       Use taylor pruner...
2024-04-22 14:22:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:22:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:22:00 - INFO :       Start Pruning
2024-04-22 14:22:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:22:03 - INFO :       Loss = 7.421875
2024-04-22 14:22:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:22:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:22:08 - INFO :       undo_permutation: Total Sparsity 1.3542894326616245e-06
2024-04-22 14:23:05 - INFO :       undo_permutation: Total Accuracy (23, 50, 0.46)
2024-04-22 14:23:05 - INFO :       
==================Finish================

2024-04-22 14:23:05 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:23:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:23:05 - INFO :       DATASET: tasksource/bigbench unit_interpretation
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.41s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.89s/it]
2024-04-22 14:23:26 - INFO :       Use taylor pruner...
2024-04-22 14:23:26 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:23:26 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:23:27 - INFO :       Start Pruning
2024-04-22 14:23:28 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:23:29 - INFO :       Loss = 11.0234375
2024-04-22 14:23:31 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:23:31 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:23:33 - INFO :       unit_interpretation: Total Sparsity 1.3581083665570398e-06
2024-04-22 14:23:55 - INFO :       unit_interpretation: Total Accuracy (6, 20, 0.3)
2024-04-22 14:23:55 - INFO :       
==================Finish================

2024-04-22 14:23:55 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:23:55 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:23:55 - INFO :       DATASET: tasksource/bigbench vitaminc_fact_verification
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.14s/it]
2024-04-22 14:24:18 - INFO :       Use taylor pruner...
2024-04-22 14:24:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:24:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:24:19 - INFO :       Start Pruning
2024-04-22 14:24:21 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:24:22 - INFO :       Loss = 11.3359375
2024-04-22 14:24:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:24:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:24:26 - INFO :       vitaminc_fact_verification: Total Sparsity 1.3569945108375437e-06
2024-04-22 14:25:20 - INFO :       vitaminc_fact_verification: Total Accuracy (22, 50, 0.44)
2024-04-22 14:25:20 - INFO :       
==================Finish================

2024-04-22 14:25:20 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:25:20 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:25:20 - INFO :       DATASET: tasksource/bigbench what_is_the_tao
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.20s/it]
2024-04-22 14:25:42 - INFO :       Use taylor pruner...
2024-04-22 14:25:42 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:25:42 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:25:43 - INFO :       Start Pruning
2024-04-22 14:25:44 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:25:46 - INFO :       Loss = 13.125
2024-04-22 14:25:48 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:25:48 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:25:50 - INFO :       what_is_the_tao: Total Sparsity 1.3595404667678207e-06
2024-04-22 14:26:10 - INFO :       what_is_the_tao: Total Accuracy (6, 16, 0.375)
2024-04-22 14:26:10 - INFO :       
==================Finish================

2024-04-22 14:26:10 - INFO :       Memory Requirement: 16767.79052734375 MiB

2024-04-22 14:26:10 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:26:10 - INFO :       DATASET: tasksource/bigbench which_wiki_edit
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.69s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.98s/it]
2024-04-22 14:26:31 - INFO :       Use taylor pruner...
2024-04-22 14:26:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:26:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:26:32 - INFO :       Start Pruning
2024-04-22 14:26:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:26:35 - INFO :       Loss = 1.736328125
2024-04-22 14:26:37 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:26:37 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:26:39 - INFO :       which_wiki_edit: Total Sparsity 1.35190259897699e-06
2024-04-22 14:28:27 - INFO :       which_wiki_edit: Total Accuracy (26, 50, 0.52)
2024-04-22 14:28:27 - INFO :       
==================Finish================

2024-04-22 14:28:27 - INFO :       Memory Requirement: 16809.46826171875 MiB

2024-04-22 14:28:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:28:27 - INFO :       DATASET: tasksource/bigbench winowhy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.91s/it]
2024-04-22 14:28:48 - INFO :       Use taylor pruner...
2024-04-22 14:28:48 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:28:48 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:28:49 - INFO :       Start Pruning
2024-04-22 14:28:50 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:28:51 - INFO :       Loss = 13.828125
2024-04-22 14:28:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:28:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:28:56 - INFO :       winowhy: Total Sparsity 1.3593813445221782e-06
2024-04-22 14:29:48 - INFO :       winowhy: Total Accuracy (25, 50, 0.5)
2024-04-22 14:29:48 - INFO :       
==================Finish================

2024-04-22 14:29:48 - INFO :       Memory Requirement: 16777.79052734375 MiB

2024-04-22 14:29:48 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:29:48 - INFO :       DATASET: tasksource/mmlu abstract_algebra
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.89s/it]
2024-04-22 14:30:09 - INFO :       Use taylor pruner...
2024-04-22 14:30:09 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:30:09 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:30:09 - INFO :       Start Pruning
2024-04-22 14:30:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:30:12 - INFO :       Loss = 13.2421875
2024-04-22 14:30:14 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:30:14 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:30:16 - INFO :       abstract_algebra: Total Sparsity 1.3579492443113975e-06
2024-04-22 14:30:27 - INFO :       abstract_algebra: Total Accuracy (2, 11, 0.18181818181818182)
2024-04-22 14:30:27 - INFO :       
==================Finish================

2024-04-22 14:30:27 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:30:27 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:30:27 - INFO :       DATASET: tasksource/mmlu anatomy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.82s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.78s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.09s/it]
2024-04-22 14:30:49 - INFO :       Use taylor pruner...
2024-04-22 14:30:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:30:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:30:50 - INFO :       Start Pruning
2024-04-22 14:30:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:30:52 - INFO :       Loss = 14.21875
2024-04-22 14:30:55 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:30:55 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:30:57 - INFO :       anatomy: Total Sparsity 1.3557215328724054e-06
2024-04-22 14:31:12 - INFO :       anatomy: Total Accuracy (8, 14, 0.5714285714285714)
2024-04-22 14:31:12 - INFO :       
==================Finish================

2024-04-22 14:31:12 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:31:12 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:31:12 - INFO :       DATASET: tasksource/mmlu astronomy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.64s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.96s/it]
2024-04-22 14:31:33 - INFO :       Use taylor pruner...
2024-04-22 14:31:33 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:31:33 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:31:33 - INFO :       Start Pruning
2024-04-22 14:31:34 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:31:36 - INFO :       Loss = 13.25
2024-04-22 14:31:38 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:31:38 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:31:40 - INFO :       astronomy: Total Sparsity 1.3563580218549744e-06
2024-04-22 14:31:58 - INFO :       astronomy: Total Accuracy (5, 16, 0.3125)
2024-04-22 14:31:58 - INFO :       
==================Finish================

2024-04-22 14:31:58 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:31:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:31:58 - INFO :       DATASET: tasksource/mmlu business_ethics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.97s/it]
2024-04-22 14:32:18 - INFO :       Use taylor pruner...
2024-04-22 14:32:18 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:32:18 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:32:19 - INFO :       Start Pruning
2024-04-22 14:32:20 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:32:21 - INFO :       Loss = 12.71875
2024-04-22 14:32:24 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:32:24 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:32:26 - INFO :       business_ethics: Total Sparsity 1.358267488802682e-06
2024-04-22 14:32:38 - INFO :       business_ethics: Total Accuracy (6, 11, 0.5454545454545454)
2024-04-22 14:32:38 - INFO :       
==================Finish================

2024-04-22 14:32:38 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:32:38 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:32:38 - INFO :       DATASET: tasksource/mmlu clinical_knowledge
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.15s/it]
2024-04-22 14:33:01 - INFO :       Use taylor pruner...
2024-04-22 14:33:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:33:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:33:01 - INFO :       Start Pruning
2024-04-22 14:33:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:33:04 - INFO :       Loss = 13.84375
2024-04-22 14:33:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:33:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:33:08 - INFO :       clinical_knowledge: Total Sparsity 1.3601769557503897e-06
2024-04-22 14:33:40 - INFO :       clinical_knowledge: Total Accuracy (11, 29, 0.3793103448275862)
2024-04-22 14:33:40 - INFO :       
==================Finish================

2024-04-22 14:33:40 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:33:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:33:40 - INFO :       DATASET: tasksource/mmlu college_biology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.71s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.98s/it]
2024-04-22 14:34:01 - INFO :       Use taylor pruner...
2024-04-22 14:34:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:34:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:34:02 - INFO :       Start Pruning
2024-04-22 14:34:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:34:04 - INFO :       Loss = 11.4296875
2024-04-22 14:34:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:34:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:34:08 - INFO :       college_biology: Total Sparsity 1.3617681782068128e-06
2024-04-22 14:34:24 - INFO :       college_biology: Total Accuracy (7, 16, 0.4375)
2024-04-22 14:34:24 - INFO :       
==================Finish================

2024-04-22 14:34:24 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:34:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:34:24 - INFO :       DATASET: tasksource/mmlu college_chemistry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.44s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.66s/it]
2024-04-22 14:34:47 - INFO :       Use taylor pruner...
2024-04-22 14:34:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:34:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:34:48 - INFO :       Start Pruning
num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-22 14:34:49 - WARNING :       num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-22 14:34:49 - WARNING :       num_proc must be <= 8. Reducing num_proc to 8 for dataset of size 8.
2024-04-22 14:34:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:34:50 - INFO :       Loss = 12.1484375
2024-04-22 14:34:53 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:34:53 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:34:55 - INFO :       college_chemistry: Total Sparsity 1.355085043889836e-06
2024-04-22 14:35:04 - INFO :       college_chemistry: Total Accuracy (2, 8, 0.25)
2024-04-22 14:35:04 - INFO :       
==================Finish================

2024-04-22 14:35:04 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:35:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:35:04 - INFO :       DATASET: tasksource/mmlu college_computer_science
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.94s/it]
2024-04-22 14:35:25 - INFO :       Use taylor pruner...
2024-04-22 14:35:25 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:35:25 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:35:26 - INFO :       Start Pruning
2024-04-22 14:35:27 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:35:28 - INFO :       Loss = 13.734375
2024-04-22 14:35:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:35:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:35:32 - INFO :       college_computer_science: Total Sparsity 1.3554032883811208e-06
2024-04-22 14:35:45 - INFO :       college_computer_science: Total Accuracy (2, 11, 0.18181818181818182)
2024-04-22 14:35:45 - INFO :       
==================Finish================

2024-04-22 14:35:45 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:35:45 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:35:45 - INFO :       DATASET: tasksource/mmlu college_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.84s/it]
2024-04-22 14:36:07 - INFO :       Use taylor pruner...
2024-04-22 14:36:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:36:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:36:08 - INFO :       Start Pruning
2024-04-22 14:36:09 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:36:10 - INFO :       Loss = 13.34375
2024-04-22 14:36:12 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:36:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:36:15 - INFO :       college_mathematics: Total Sparsity 1.357630999820113e-06
2024-04-22 14:36:26 - INFO :       college_mathematics: Total Accuracy (2, 11, 0.18181818181818182)
2024-04-22 14:36:26 - INFO :       
==================Finish================

2024-04-22 14:36:26 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:36:26 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:36:26 - INFO :       DATASET: tasksource/mmlu college_medicine
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.82s/it]
2024-04-22 14:36:47 - INFO :       Use taylor pruner...
2024-04-22 14:36:47 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:36:47 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:36:48 - INFO :       Start Pruning
2024-04-22 14:36:49 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:36:50 - INFO :       Loss = 14.0390625
2024-04-22 14:36:52 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:36:52 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:36:54 - INFO :       college_medicine: Total Sparsity 1.3573127553288283e-06
2024-04-22 14:37:17 - INFO :       college_medicine: Total Accuracy (10, 22, 0.45454545454545453)
2024-04-22 14:37:17 - INFO :       
==================Finish================

2024-04-22 14:37:17 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:37:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:37:17 - INFO :       DATASET: tasksource/mmlu college_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.37s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.50s/it]
2024-04-22 14:37:40 - INFO :       Use taylor pruner...
2024-04-22 14:37:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:37:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:37:41 - INFO :       Start Pruning
2024-04-22 14:37:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:37:43 - INFO :       Loss = 13.0546875
2024-04-22 14:37:46 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:37:46 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:37:48 - INFO :       college_physics: Total Sparsity 1.3601769557503897e-06
2024-04-22 14:38:00 - INFO :       college_physics: Total Accuracy (5, 11, 0.45454545454545453)
2024-04-22 14:38:00 - INFO :       
==================Finish================

2024-04-22 14:38:00 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:38:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:38:00 - INFO :       DATASET: tasksource/mmlu computer_security
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.95s/it]
2024-04-22 14:38:21 - INFO :       Use taylor pruner...
2024-04-22 14:38:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:38:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:38:21 - INFO :       Start Pruning
2024-04-22 14:38:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:38:23 - INFO :       Loss = 14.1484375
2024-04-22 14:38:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:38:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:38:28 - INFO :       computer_security: Total Sparsity 1.3581083665570398e-06
2024-04-22 14:38:41 - INFO :       computer_security: Total Accuracy (5, 11, 0.45454545454545453)
2024-04-22 14:38:41 - INFO :       
==================Finish================

2024-04-22 14:38:41 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:38:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:38:41 - INFO :       DATASET: tasksource/mmlu conceptual_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.76s/it]
2024-04-22 14:39:01 - INFO :       Use taylor pruner...
2024-04-22 14:39:01 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:39:01 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:39:02 - INFO :       Start Pruning
2024-04-22 14:39:03 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:39:04 - INFO :       Loss = 14.5546875
2024-04-22 14:39:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:39:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:39:09 - INFO :       conceptual_physics: Total Sparsity 1.3577901220657553e-06
2024-04-22 14:39:37 - INFO :       conceptual_physics: Total Accuracy (7, 26, 0.2692307692307692)
2024-04-22 14:39:37 - INFO :       
==================Finish================

2024-04-22 14:39:37 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:39:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:39:37 - INFO :       DATASET: tasksource/mmlu econometrics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.12s/it]
2024-04-22 14:39:59 - INFO :       Use taylor pruner...
2024-04-22 14:39:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:39:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:39:59 - INFO :       Start Pruning
2024-04-22 14:40:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:40:01 - INFO :       Loss = 13.546875
2024-04-22 14:40:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:40:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:40:06 - INFO :       econometrics: Total Sparsity 1.3589039777852514e-06
2024-04-22 14:40:19 - INFO :       econometrics: Total Accuracy (1, 12, 0.08333333333333333)
2024-04-22 14:40:19 - INFO :       
==================Finish================

2024-04-22 14:40:19 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:40:19 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:40:19 - INFO :       DATASET: tasksource/mmlu electrical_engineering
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.83s/it]
2024-04-22 14:40:40 - INFO :       Use taylor pruner...
2024-04-22 14:40:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:40:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:40:41 - INFO :       Start Pruning
2024-04-22 14:40:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:40:43 - INFO :       Loss = 13.8671875
2024-04-22 14:40:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:40:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:40:47 - INFO :       electrical_engineering: Total Sparsity 1.3541303104159823e-06
2024-04-22 14:41:03 - INFO :       electrical_engineering: Total Accuracy (5, 16, 0.3125)
2024-04-22 14:41:03 - INFO :       
==================Finish================

2024-04-22 14:41:03 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:41:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:41:03 - INFO :       DATASET: tasksource/mmlu elementary_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.57s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.81s/it]
2024-04-22 14:41:23 - INFO :       Use taylor pruner...
2024-04-22 14:41:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:41:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:41:23 - INFO :       Start Pruning
2024-04-22 14:41:25 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:41:26 - INFO :       Loss = 14.0390625
2024-04-22 14:41:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:41:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:41:30 - INFO :       elementary_mathematics: Total Sparsity 1.3547667993985515e-06
2024-04-22 14:42:16 - INFO :       elementary_mathematics: Total Accuracy (8, 41, 0.1951219512195122)
2024-04-22 14:42:16 - INFO :       
==================Finish================

2024-04-22 14:42:16 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:42:16 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:42:16 - INFO :       DATASET: tasksource/mmlu formal_logic
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.00s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.46s/it]
2024-04-22 14:42:39 - INFO :       Use taylor pruner...
2024-04-22 14:42:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:42:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:42:40 - INFO :       Start Pruning
2024-04-22 14:42:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:42:42 - INFO :       Loss = 12.0234375
2024-04-22 14:42:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:42:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:42:47 - INFO :       formal_logic: Total Sparsity 1.3569945108375437e-06
2024-04-22 14:43:02 - INFO :       formal_logic: Total Accuracy (2, 14, 0.14285714285714285)
2024-04-22 14:43:02 - INFO :       
==================Finish================

2024-04-22 14:43:02 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:43:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:43:02 - INFO :       DATASET: tasksource/mmlu global_facts
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.78s/it]
2024-04-22 14:43:23 - INFO :       Use taylor pruner...
2024-04-22 14:43:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:43:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:43:24 - INFO :       Start Pruning
2024-04-22 14:43:25 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:43:26 - INFO :       Loss = 13.953125
2024-04-22 14:43:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:43:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:43:31 - INFO :       global_facts: Total Sparsity 1.3558806551180476e-06
2024-04-22 14:43:41 - INFO :       global_facts: Total Accuracy (1, 10, 0.1)
2024-04-22 14:43:41 - INFO :       
==================Finish================

2024-04-22 14:43:41 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:43:41 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:43:41 - INFO :       DATASET: tasksource/mmlu high_school_biology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.52s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.78s/it]
2024-04-22 14:44:02 - INFO :       Use taylor pruner...
2024-04-22 14:44:02 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:44:02 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:44:03 - INFO :       Start Pruning
2024-04-22 14:44:04 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:44:05 - INFO :       Loss = 13.078125
2024-04-22 14:44:07 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:44:07 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:44:09 - INFO :       high_school_biology: Total Sparsity 1.3590631000308936e-06
2024-04-22 14:44:44 - INFO :       high_school_biology: Total Accuracy (12, 32, 0.375)
2024-04-22 14:44:44 - INFO :       
==================Finish================

2024-04-22 14:44:44 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:44:44 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:44:44 - INFO :       DATASET: tasksource/mmlu high_school_chemistry
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.99s/it]
2024-04-22 14:45:05 - INFO :       Use taylor pruner...
2024-04-22 14:45:05 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:45:05 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:45:06 - INFO :       Start Pruning
2024-04-22 14:45:07 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:45:09 - INFO :       Loss = 13.9296875
2024-04-22 14:45:11 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:45:11 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:45:13 - INFO :       high_school_chemistry: Total Sparsity 1.3584266110483244e-06
2024-04-22 14:45:37 - INFO :       high_school_chemistry: Total Accuracy (2, 22, 0.09090909090909091)
2024-04-22 14:45:37 - INFO :       
==================Finish================

2024-04-22 14:45:37 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:45:37 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:45:37 - INFO :       DATASET: tasksource/mmlu high_school_computer_science
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.83s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.06s/it]
2024-04-22 14:45:58 - INFO :       Use taylor pruner...
2024-04-22 14:45:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:45:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:45:58 - INFO :       Start Pruning
num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-22 14:46:00 - WARNING :       num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-22 14:46:00 - WARNING :       num_proc must be <= 9. Reducing num_proc to 9 for dataset of size 9.
2024-04-22 14:46:00 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:46:01 - INFO :       Loss = 12.765625
2024-04-22 14:46:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:46:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:46:05 - INFO :       high_school_computer_science: Total Sparsity 1.3584266110483244e-06
2024-04-22 14:46:15 - INFO :       high_school_computer_science: Total Accuracy (5, 9, 0.5555555555555556)
2024-04-22 14:46:15 - INFO :       
==================Finish================

2024-04-22 14:46:15 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:46:15 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:46:15 - INFO :       DATASET: tasksource/mmlu high_school_european_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.18s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.42s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.68s/it]
2024-04-22 14:46:35 - INFO :       Use taylor pruner...
2024-04-22 14:46:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:46:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:46:36 - INFO :       Start Pruning
2024-04-22 14:46:37 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:46:38 - INFO :       Loss = 5.7109375
2024-04-22 14:46:40 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:46:40 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:46:42 - INFO :       high_school_european_history: Total Sparsity 1.3573127553288283e-06
2024-04-22 14:47:04 - INFO :       high_school_european_history: Total Accuracy (11, 18, 0.6111111111111112)
2024-04-22 14:47:04 - INFO :       
==================Finish================

2024-04-22 14:47:04 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:47:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:47:04 - INFO :       DATASET: tasksource/mmlu high_school_geography
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.03s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.43s/it]
2024-04-22 14:47:27 - INFO :       Use taylor pruner...
2024-04-22 14:47:27 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:47:27 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:47:28 - INFO :       Start Pruning
2024-04-22 14:47:29 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:47:30 - INFO :       Loss = 14.1171875
2024-04-22 14:47:33 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:47:33 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:47:35 - INFO :       high_school_geography: Total Sparsity 1.35603977736369e-06
2024-04-22 14:47:57 - INFO :       high_school_geography: Total Accuracy (14, 22, 0.6363636363636364)
2024-04-22 14:47:57 - INFO :       
==================Finish================

2024-04-22 14:47:57 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:47:57 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:47:57 - INFO :       DATASET: tasksource/mmlu high_school_government_and_politics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.90s/it]
2024-04-22 14:48:20 - INFO :       Use taylor pruner...
2024-04-22 14:48:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:48:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:48:21 - INFO :       Start Pruning
2024-04-22 14:48:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:48:23 - INFO :       Loss = 13.9375
2024-04-22 14:48:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:48:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:48:27 - INFO :       high_school_government_and_politics: Total Sparsity 1.3590631000308936e-06
2024-04-22 14:48:49 - INFO :       high_school_government_and_politics: Total Accuracy (8, 21, 0.38095238095238093)
2024-04-22 14:48:49 - INFO :       
==================Finish================

2024-04-22 14:48:49 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:48:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:48:49 - INFO :       DATASET: tasksource/mmlu high_school_macroeconomics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.21s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.53s/it]
2024-04-22 14:49:12 - INFO :       Use taylor pruner...
2024-04-22 14:49:12 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:49:12 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:49:13 - INFO :       Start Pruning
2024-04-22 14:49:14 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:49:15 - INFO :       Loss = 13.5546875
2024-04-22 14:49:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:49:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:49:19 - INFO :       high_school_macroeconomics: Total Sparsity 1.360813444732959e-06
2024-04-22 14:50:06 - INFO :       high_school_macroeconomics: Total Accuracy (16, 43, 0.37209302325581395)
2024-04-22 14:50:06 - INFO :       
==================Finish================

2024-04-22 14:50:06 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:50:06 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:50:06 - INFO :       DATASET: tasksource/mmlu high_school_mathematics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:07<00:07,  7.12s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.47s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.88s/it]
2024-04-22 14:50:31 - INFO :       Use taylor pruner...
2024-04-22 14:50:31 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:50:31 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:50:32 - INFO :       Start Pruning
2024-04-22 14:50:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:50:34 - INFO :       Loss = 13.671875
2024-04-22 14:50:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:50:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:50:38 - INFO :       high_school_mathematics: Total Sparsity 1.3593813445221782e-06
2024-04-22 14:51:08 - INFO :       high_school_mathematics: Total Accuracy (5, 29, 0.1724137931034483)
2024-04-22 14:51:08 - INFO :       
==================Finish================

2024-04-22 14:51:08 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:51:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:51:08 - INFO :       DATASET: tasksource/mmlu high_school_microeconomics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.36s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.87s/it]
2024-04-22 14:51:29 - INFO :       Use taylor pruner...
2024-04-22 14:51:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:51:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:51:30 - INFO :       Start Pruning
2024-04-22 14:51:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:51:32 - INFO :       Loss = 12.9609375
2024-04-22 14:51:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:51:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:51:37 - INFO :       high_school_microeconomics: Total Sparsity 1.3574718775744707e-06
2024-04-22 14:52:04 - INFO :       high_school_microeconomics: Total Accuracy (13, 26, 0.5)
2024-04-22 14:52:04 - INFO :       
==================Finish================

2024-04-22 14:52:04 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:52:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:52:04 - INFO :       DATASET: tasksource/mmlu high_school_physics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.54s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.96s/it]
2024-04-22 14:52:24 - INFO :       Use taylor pruner...
2024-04-22 14:52:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:52:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:52:25 - INFO :       Start Pruning
2024-04-22 14:52:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:52:27 - INFO :       Loss = 12.1484375
2024-04-22 14:52:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:52:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:52:32 - INFO :       high_school_physics: Total Sparsity 1.3568353885919015e-06
2024-04-22 14:52:51 - INFO :       high_school_physics: Total Accuracy (5, 17, 0.29411764705882354)
2024-04-22 14:52:51 - INFO :       
==================Finish================

2024-04-22 14:52:51 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:52:51 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:52:51 - INFO :       DATASET: tasksource/mmlu high_school_psychology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.97s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.09s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.37s/it]
2024-04-22 14:53:13 - INFO :       Use taylor pruner...
2024-04-22 14:53:13 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:53:13 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:53:14 - INFO :       Start Pruning
2024-04-22 14:53:15 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:53:16 - INFO :       Loss = 13.640625
2024-04-22 14:53:19 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:53:19 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:53:21 - INFO :       high_school_psychology: Total Sparsity 1.360813444732959e-06
2024-04-22 14:54:14 - INFO :       high_school_psychology: Total Accuracy (34, 50, 0.68)
2024-04-22 14:54:14 - INFO :       
==================Finish================

2024-04-22 14:54:14 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:54:14 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:54:14 - INFO :       DATASET: tasksource/mmlu high_school_statistics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.55s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.59s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.88s/it]
2024-04-22 14:54:35 - INFO :       Use taylor pruner...
2024-04-22 14:54:35 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:54:35 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:54:35 - INFO :       Start Pruning
2024-04-22 14:54:36 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:54:37 - INFO :       Loss = 11.0859375
2024-04-22 14:54:39 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:54:39 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:54:41 - INFO :       high_school_statistics: Total Sparsity 1.3574718775744707e-06
2024-04-22 14:55:05 - INFO :       high_school_statistics: Total Accuracy (8, 23, 0.34782608695652173)
2024-04-22 14:55:05 - INFO :       
==================Finish================

2024-04-22 14:55:05 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:55:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:55:05 - INFO :       DATASET: tasksource/mmlu high_school_us_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.71s/it]
2024-04-22 14:55:30 - INFO :       Use taylor pruner...
2024-04-22 14:55:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:55:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:55:30 - INFO :       Start Pruning
2024-04-22 14:55:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:55:32 - INFO :       Loss = 5.6484375
2024-04-22 14:55:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:55:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:55:37 - INFO :       high_school_us_history: Total Sparsity 1.3568353885919015e-06
2024-04-22 14:56:01 - INFO :       high_school_us_history: Total Accuracy (13, 22, 0.5909090909090909)
2024-04-22 14:56:02 - INFO :       
==================Finish================

2024-04-22 14:56:02 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:56:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:56:02 - INFO :       DATASET: tasksource/mmlu high_school_world_history
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.23s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.26s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.56s/it]
2024-04-22 14:56:24 - INFO :       Use taylor pruner...
2024-04-22 14:56:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:56:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:56:25 - INFO :       Start Pruning
2024-04-22 14:56:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:56:27 - INFO :       Loss = 4.60546875
2024-04-22 14:56:30 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:56:30 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:56:32 - INFO :       high_school_world_history: Total Sparsity 1.3568353885919015e-06
2024-04-22 14:57:02 - INFO :       high_school_world_history: Total Accuracy (13, 26, 0.5)
2024-04-22 14:57:03 - INFO :       
==================Finish================

2024-04-22 14:57:03 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:57:03 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:57:03 - INFO :       DATASET: tasksource/mmlu human_aging
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.28s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.83s/it]
2024-04-22 14:57:24 - INFO :       Use taylor pruner...
2024-04-22 14:57:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:57:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:57:25 - INFO :       Start Pruning
2024-04-22 14:57:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:57:27 - INFO :       Loss = 14.625
2024-04-22 14:57:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:57:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:57:31 - INFO :       human_aging: Total Sparsity 1.3552441661354783e-06
2024-04-22 14:57:53 - INFO :       human_aging: Total Accuracy (12, 23, 0.5217391304347826)
2024-04-22 14:57:53 - INFO :       
==================Finish================

2024-04-22 14:57:53 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:57:53 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:57:53 - INFO :       DATASET: tasksource/mmlu human_sexuality
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.38s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.04s/it]
2024-04-22 14:58:15 - INFO :       Use taylor pruner...
2024-04-22 14:58:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:58:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:58:16 - INFO :       Start Pruning
2024-04-22 14:58:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:58:18 - INFO :       Loss = 14.2890625
2024-04-22 14:58:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:58:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:58:22 - INFO :       human_sexuality: Total Sparsity 1.3595404667678207e-06
2024-04-22 14:58:35 - INFO :       human_sexuality: Total Accuracy (4, 12, 0.3333333333333333)
2024-04-22 14:58:35 - INFO :       
==================Finish================

2024-04-22 14:58:35 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:58:35 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:58:35 - INFO :       DATASET: tasksource/mmlu international_law
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.90s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.28s/it]
2024-04-22 14:58:57 - INFO :       Use taylor pruner...
2024-04-22 14:58:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:58:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:58:57 - INFO :       Start Pruning
2024-04-22 14:58:58 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:58:59 - INFO :       Loss = 12.921875
2024-04-22 14:59:02 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:59:02 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:59:04 - INFO :       international_law: Total Sparsity 1.359222222276536e-06
2024-04-22 14:59:18 - INFO :       international_law: Total Accuracy (11, 13, 0.8461538461538461)
2024-04-22 14:59:18 - INFO :       
==================Finish================

2024-04-22 14:59:18 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:59:18 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:59:18 - INFO :       DATASET: tasksource/mmlu jurisprudence
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.20s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.56s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.81s/it]
2024-04-22 14:59:39 - INFO :       Use taylor pruner...
2024-04-22 14:59:39 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:59:39 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 14:59:40 - INFO :       Start Pruning
2024-04-22 14:59:41 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 14:59:42 - INFO :       Loss = 13.5703125
2024-04-22 14:59:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 14:59:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 14:59:47 - INFO :       jurisprudence: Total Sparsity 1.3585857332939668e-06
2024-04-22 14:59:58 - INFO :       jurisprudence: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-22 14:59:58 - INFO :       
==================Finish================

2024-04-22 14:59:58 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 14:59:58 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 14:59:58 - INFO :       DATASET: tasksource/mmlu logical_fallacies
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.67s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.96s/it]
2024-04-22 15:00:20 - INFO :       Use taylor pruner...
2024-04-22 15:00:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:00:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:00:21 - INFO :       Start Pruning
2024-04-22 15:00:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:00:23 - INFO :       Loss = 13.96875
2024-04-22 15:00:25 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:00:25 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:00:27 - INFO :       logical_fallacies: Total Sparsity 1.3612908114698858e-06
2024-04-22 15:00:46 - INFO :       logical_fallacies: Total Accuracy (11, 18, 0.6111111111111112)
2024-04-22 15:00:46 - INFO :       
==================Finish================

2024-04-22 15:00:46 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:00:46 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:00:46 - INFO :       DATASET: tasksource/mmlu machine_learning
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.66s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.96s/it]
2024-04-22 15:01:08 - INFO :       Use taylor pruner...
2024-04-22 15:01:08 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:01:08 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:01:09 - INFO :       Start Pruning
2024-04-22 15:01:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:01:11 - INFO :       Loss = 12.5625
2024-04-22 15:01:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:01:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:01:15 - INFO :       machine_learning: Total Sparsity 1.3561988996093322e-06
2024-04-22 15:01:28 - INFO :       machine_learning: Total Accuracy (3, 11, 0.2727272727272727)
2024-04-22 15:01:28 - INFO :       
==================Finish================

2024-04-22 15:01:28 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:01:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:01:28 - INFO :       DATASET: tasksource/mmlu management
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.32s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.60s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.86s/it]
2024-04-22 15:01:49 - INFO :       Use taylor pruner...
2024-04-22 15:01:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:01:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:01:50 - INFO :       Start Pruning
2024-04-22 15:01:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:01:52 - INFO :       Loss = 14.515625
2024-04-22 15:01:55 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:01:55 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:01:57 - INFO :       management: Total Sparsity 1.358267488802682e-06
2024-04-22 15:02:08 - INFO :       management: Total Accuracy (6, 11, 0.5454545454545454)
2024-04-22 15:02:08 - INFO :       
==================Finish================

2024-04-22 15:02:08 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:02:08 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:02:08 - INFO :       DATASET: tasksource/mmlu marketing
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.84s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.11s/it]
2024-04-22 15:02:29 - INFO :       Use taylor pruner...
2024-04-22 15:02:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:02:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:02:30 - INFO :       Start Pruning
2024-04-22 15:02:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:02:32 - INFO :       Loss = 14.34375
2024-04-22 15:02:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:02:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:02:37 - INFO :       marketing: Total Sparsity 1.3609725669786013e-06
2024-04-22 15:03:04 - INFO :       marketing: Total Accuracy (18, 25, 0.72)
2024-04-22 15:03:04 - INFO :       
==================Finish================

2024-04-22 15:03:04 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:03:04 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:03:04 - INFO :       DATASET: tasksource/mmlu medical_genetics
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.53s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.81s/it]
2024-04-22 15:03:24 - INFO :       Use taylor pruner...
2024-04-22 15:03:24 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:03:24 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:03:25 - INFO :       Start Pruning
2024-04-22 15:03:26 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:03:27 - INFO :       Loss = 13.8359375
2024-04-22 15:03:29 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:03:29 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:03:31 - INFO :       medical_genetics: Total Sparsity 1.360813444732959e-06
2024-04-22 15:03:43 - INFO :       medical_genetics: Total Accuracy (8, 11, 0.7272727272727273)
2024-04-22 15:03:43 - INFO :       
==================Finish================

2024-04-22 15:03:43 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:03:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:03:43 - INFO :       DATASET: tasksource/mmlu miscellaneous
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.15s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.14s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.44s/it]
2024-04-22 15:04:04 - INFO :       Use taylor pruner...
2024-04-22 15:04:04 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:04:04 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:04:05 - INFO :       Start Pruning
2024-04-22 15:04:06 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:04:07 - INFO :       Loss = 14.15625
2024-04-22 15:04:09 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:04:09 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:04:11 - INFO :       miscellaneous: Total Sparsity 1.3600178335047475e-06
2024-04-22 15:05:05 - INFO :       miscellaneous: Total Accuracy (28, 50, 0.56)
2024-04-22 15:05:05 - INFO :       
==================Finish================

2024-04-22 15:05:05 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:05:05 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:05:05 - INFO :       DATASET: tasksource/mmlu moral_disputes
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.06s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.32s/it]
2024-04-22 15:05:29 - INFO :       Use taylor pruner...
2024-04-22 15:05:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:05:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:05:30 - INFO :       Start Pruning
2024-04-22 15:05:31 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:05:32 - INFO :       Loss = 13.984375
2024-04-22 15:05:34 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:05:34 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:05:36 - INFO :       moral_disputes: Total Sparsity 1.3609725669786013e-06
2024-04-22 15:06:17 - INFO :       moral_disputes: Total Accuracy (17, 38, 0.4473684210526316)
2024-04-22 15:06:17 - INFO :       
==================Finish================

2024-04-22 15:06:17 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:06:17 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:06:17 - INFO :       DATASET: tasksource/mmlu moral_scenarios
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.80s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.05s/it]
2024-04-22 15:06:40 - INFO :       Use taylor pruner...
2024-04-22 15:06:40 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:06:40 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:06:41 - INFO :       Start Pruning
2024-04-22 15:06:42 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:06:43 - INFO :       Loss = 12.171875
2024-04-22 15:06:45 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:06:45 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:06:48 - INFO :       moral_scenarios: Total Sparsity 1.3573127553288283e-06
2024-04-22 15:07:40 - INFO :       moral_scenarios: Total Accuracy (0, 50, 0.0)
2024-04-22 15:07:40 - INFO :       
==================Finish================

2024-04-22 15:07:40 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:07:40 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:07:40 - INFO :       DATASET: tasksource/mmlu nutrition
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.43s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.89s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.12s/it]
2024-04-22 15:08:00 - INFO :       Use taylor pruner...
2024-04-22 15:08:00 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:08:00 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:08:01 - INFO :       Start Pruning
2024-04-22 15:08:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:08:03 - INFO :       Loss = 13.1171875
2024-04-22 15:08:05 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:08:05 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:08:07 - INFO :       nutrition: Total Sparsity 1.3600178335047475e-06
2024-04-22 15:08:43 - INFO :       nutrition: Total Accuracy (19, 33, 0.5757575757575758)
2024-04-22 15:08:43 - INFO :       
==================Finish================

2024-04-22 15:08:43 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:08:43 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:08:43 - INFO :       DATASET: tasksource/mmlu philosophy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.49s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.30s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.62s/it]
2024-04-22 15:09:07 - INFO :       Use taylor pruner...
2024-04-22 15:09:07 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:09:07 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:09:08 - INFO :       Start Pruning
2024-04-22 15:09:10 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:09:11 - INFO :       Loss = 14.0
2024-04-22 15:09:13 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:09:13 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:09:15 - INFO :       philosophy: Total Sparsity 1.3616090559611704e-06
2024-04-22 15:09:52 - INFO :       philosophy: Total Accuracy (16, 34, 0.47058823529411764)
2024-04-22 15:09:52 - INFO :       
==================Finish================

2024-04-22 15:09:52 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:09:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:09:52 - INFO :       DATASET: tasksource/mmlu prehistory
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.95s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.05s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.33s/it]
2024-04-22 15:10:15 - INFO :       Use taylor pruner...
2024-04-22 15:10:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:10:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:10:16 - INFO :       Start Pruning
2024-04-22 15:10:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:10:18 - INFO :       Loss = 13.515625
2024-04-22 15:10:20 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:10:20 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:10:23 - INFO :       prehistory: Total Sparsity 1.3581083665570398e-06
2024-04-22 15:11:00 - INFO :       prehistory: Total Accuracy (17, 35, 0.4857142857142857)
2024-04-22 15:11:00 - INFO :       
==================Finish================

2024-04-22 15:11:00 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:11:00 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:11:00 - INFO :       DATASET: tasksource/mmlu professional_accounting
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.62s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.87s/it]
2024-04-22 15:11:21 - INFO :       Use taylor pruner...
2024-04-22 15:11:21 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:11:21 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:11:22 - INFO :       Start Pruning
2024-04-22 15:11:23 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:11:24 - INFO :       Loss = 12.5703125
2024-04-22 15:11:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:11:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:11:28 - INFO :       professional_accounting: Total Sparsity 1.3581083665570398e-06
2024-04-22 15:12:02 - INFO :       professional_accounting: Total Accuracy (10, 31, 0.3225806451612903)
2024-04-22 15:12:02 - INFO :       
==================Finish================

2024-04-22 15:12:02 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:12:02 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:12:02 - INFO :       DATASET: tasksource/mmlu professional_law
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.10s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.51s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.75s/it]
2024-04-22 15:12:23 - INFO :       Use taylor pruner...
2024-04-22 15:12:23 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:12:23 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:12:24 - INFO :       Start Pruning
2024-04-22 15:12:25 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:12:26 - INFO :       Loss = 9.3671875
2024-04-22 15:12:28 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:12:28 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:12:31 - INFO :       professional_law: Total Sparsity 1.3573127553288283e-06
2024-04-22 15:13:24 - INFO :       professional_law: Total Accuracy (13, 50, 0.26)
2024-04-22 15:13:24 - INFO :       
==================Finish================

2024-04-22 15:13:24 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:13:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:13:24 - INFO :       DATASET: tasksource/mmlu professional_medicine
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.19s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.35s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:09<00:00,  4.63s/it]
2024-04-22 15:13:49 - INFO :       Use taylor pruner...
2024-04-22 15:13:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:13:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:13:50 - INFO :       Start Pruning
2024-04-22 15:13:51 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:13:52 - INFO :       Loss = 10.78125
2024-04-22 15:13:55 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:13:55 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:13:57 - INFO :       professional_medicine: Total Sparsity 1.3589039777852514e-06
2024-04-22 15:14:31 - INFO :       professional_medicine: Total Accuracy (15, 31, 0.4838709677419355)
2024-04-22 15:14:32 - INFO :       
==================Finish================

2024-04-22 15:14:32 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:14:32 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:14:32 - INFO :       DATASET: tasksource/mmlu professional_psychology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.31s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.48s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.76s/it]
2024-04-22 15:14:52 - INFO :       Use taylor pruner...
2024-04-22 15:14:52 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:14:52 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:14:53 - INFO :       Start Pruning
2024-04-22 15:14:54 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:14:55 - INFO :       Loss = 12.5390625
2024-04-22 15:14:58 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:14:58 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:15:00 - INFO :       professional_psychology: Total Sparsity 1.3577901220657553e-06
2024-04-22 15:15:52 - INFO :       professional_psychology: Total Accuracy (23, 50, 0.46)
2024-04-22 15:15:52 - INFO :       
==================Finish================

2024-04-22 15:15:52 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:15:52 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:15:52 - INFO :       DATASET: tasksource/mmlu public_relations
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.74s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.72s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.02s/it]
2024-04-22 15:16:15 - INFO :       Use taylor pruner...
2024-04-22 15:16:15 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:16:15 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:16:16 - INFO :       Start Pruning
2024-04-22 15:16:17 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:16:18 - INFO :       Loss = 14.34375
2024-04-22 15:16:21 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:16:21 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:16:23 - INFO :       public_relations: Total Sparsity 1.360813444732959e-06
2024-04-22 15:16:36 - INFO :       public_relations: Total Accuracy (7, 12, 0.5833333333333334)
2024-04-22 15:16:36 - INFO :       
==================Finish================

2024-04-22 15:16:36 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:16:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:16:36 - INFO :       DATASET: tasksource/mmlu security_studies
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.68s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.08s/it]
2024-04-22 15:16:57 - INFO :       Use taylor pruner...
2024-04-22 15:16:57 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:16:57 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:16:58 - INFO :       Start Pruning
2024-04-22 15:16:59 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:17:01 - INFO :       Loss = 11.796875
2024-04-22 15:17:03 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:17:03 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:17:05 - INFO :       security_studies: Total Sparsity 1.3581083665570398e-06
2024-04-22 15:17:35 - INFO :       security_studies: Total Accuracy (10, 27, 0.37037037037037035)
2024-04-22 15:17:36 - INFO :       
==================Finish================

2024-04-22 15:17:36 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:17:36 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:17:36 - INFO :       DATASET: tasksource/mmlu sociology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.45s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.99s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.21s/it]
2024-04-22 15:17:58 - INFO :       Use taylor pruner...
2024-04-22 15:17:58 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:17:58 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:17:59 - INFO :       Start Pruning
2024-04-22 15:18:01 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:18:02 - INFO :       Loss = 13.7109375
2024-04-22 15:18:04 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:18:04 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:18:06 - INFO :       sociology: Total Sparsity 1.3528573324508439e-06
2024-04-22 15:18:28 - INFO :       sociology: Total Accuracy (13, 22, 0.5909090909090909)
2024-04-22 15:18:28 - INFO :       
==================Finish================

2024-04-22 15:18:28 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:18:28 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:18:28 - INFO :       DATASET: tasksource/mmlu us_foreign_policy
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.17s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.50s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.75s/it]
2024-04-22 15:18:49 - INFO :       Use taylor pruner...
2024-04-22 15:18:49 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:18:49 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:18:50 - INFO :       Start Pruning
2024-04-22 15:18:52 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:18:53 - INFO :       Loss = 14.1015625
2024-04-22 15:18:55 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:18:55 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:18:57 - INFO :       us_foreign_policy: Total Sparsity 1.3598587112591052e-06
2024-04-22 15:19:09 - INFO :       us_foreign_policy: Total Accuracy (6, 11, 0.5454545454545454)
2024-04-22 15:19:09 - INFO :       
==================Finish================

2024-04-22 15:19:09 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:19:09 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:19:09 - INFO :       DATASET: tasksource/mmlu virology
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.63s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.70s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.99s/it]
2024-04-22 15:19:30 - INFO :       Use taylor pruner...
2024-04-22 15:19:30 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:19:30 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:19:31 - INFO :       Start Pruning
2024-04-22 15:19:33 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:19:34 - INFO :       Loss = 13.8828125
2024-04-22 15:19:36 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:19:36 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:19:38 - INFO :       virology: Total Sparsity 1.3600178335047475e-06
2024-04-22 15:19:58 - INFO :       virology: Total Accuracy (8, 18, 0.4444444444444444)
2024-04-22 15:19:59 - INFO :       
==================Finish================

2024-04-22 15:19:59 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:19:59 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:19:59 - INFO :       DATASET: tasksource/mmlu world_religions
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.27s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.73s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.96s/it]
2024-04-22 15:20:20 - INFO :       Use taylor pruner...
2024-04-22 15:20:20 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:20:20 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:20:21 - INFO :       Start Pruning
2024-04-22 15:20:22 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:20:24 - INFO :       Loss = 14.328125
2024-04-22 15:20:26 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:20:26 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:20:28 - INFO :       world_religions: Total Sparsity 1.3590631000308936e-06
2024-04-22 15:20:49 - INFO :       world_religions: Total Accuracy (14, 19, 0.7368421052631579)
2024-04-22 15:20:49 - INFO :       
==================Finish================

2024-04-22 15:20:49 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:20:49 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:20:49 - INFO :       DATASET: math_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:06<00:06,  6.46s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.07s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.43s/it]
2024-04-22 15:21:11 - INFO :       Use taylor pruner...
2024-04-22 15:21:11 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:21:11 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:21:12 - INFO :       Start Pruning
2024-04-22 15:21:13 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:21:14 - INFO :       Loss = 13.9921875
2024-04-22 15:21:17 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:21:17 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:21:19 - INFO :       math_qa: Total Sparsity 1.3563580218549744e-06
2024-04-22 15:22:07 - INFO :       math_qa: Accuracy (12, 50, 0.24)
2024-04-22 15:22:07 - INFO :       
==================Finish================

2024-04-22 15:22:07 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:22:07 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:22:07 - INFO :       DATASET: EleutherAI/truthful_qa_mc
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.87s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  3.79s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:08<00:00,  4.10s/it]
2024-04-22 15:22:29 - INFO :       Use taylor pruner...
2024-04-22 15:22:29 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:22:29 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:22:30 - INFO :       Start Pruning
2024-04-22 15:22:32 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:22:33 - INFO :       Loss = 13.4453125
2024-04-22 15:22:35 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:22:35 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:22:37 - INFO :       truthful_qa_mc: Total Sparsity 1.3609725669786013e-06
2024-04-22 15:23:24 - INFO :       truthful_qa_mc: Accuracy (17, 50, 0.34)
2024-04-22 15:23:24 - INFO :       
==================Finish================

2024-04-22 15:23:24 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:23:24 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:23:24 - INFO :       DATASET: derek-thomas/ScienceQA
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:05<00:05,  5.33s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.58s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.84s/it]
2024-04-22 15:23:45 - INFO :       Use taylor pruner...
2024-04-22 15:23:45 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:23:45 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:23:46 - INFO :       Start Pruning
2024-04-22 15:23:47 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:23:48 - INFO :       Loss = 14.1484375
2024-04-22 15:23:51 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:23:51 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:23:52 - INFO :       ScienceQA: Total Sparsity 1.360336077996032e-06
2024-04-22 15:24:39 - INFO :       ScienceQA: Accuracy (20, 50, 0.4)
2024-04-22 15:24:39 - INFO :       
==================Finish================

2024-04-22 15:24:39 - INFO :       Memory Requirement: 16770.79052734375 MiB

2024-04-22 15:24:39 - INFO :       
********************************************************************************************************************************************************************************************************

2024-04-22 15:24:39 - INFO :       DATASET: commonsense_qa
******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]Loading checkpoint shards:  50%|█████     | 1/2 [00:04<00:04,  4.93s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.40s/it]Loading checkpoint shards: 100%|██████████| 2/2 [00:07<00:00,  3.63s/it]
2024-04-22 15:24:59 - INFO :       Use taylor pruner...
2024-04-22 15:24:59 - INFO :       Pruning Attention Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:24:59 - INFO :       Pruning MLP Layer = [3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30]
2024-04-22 15:25:00 - INFO :       Start Pruning
2024-04-22 15:25:02 - INFO :       Start Backwarding in iterative steps = 0...
2024-04-22 15:25:03 - INFO :       Loss = 14.2109375
2024-04-22 15:25:06 - INFO :       After Iter 1/1, #parameters: 6546886656
2024-04-22 15:25:06 - INFO :       #Param before: 6738415616, #Param after: 6546886656, Ratio = 97.1577%
2024-04-22 15:25:08 - INFO :       commonsense_qa: Total Sparsity 1.3598587112591052e-06
2024-04-22 15:25:55 - INFO :       commonsense_qa: Accuracy (24, 50, 0.48)
2024-04-22 15:25:55 - INFO :       
==================Finish================

2024-04-22 15:25:55 - INFO :       Memory Requirement: 16770.79052734375 MiB

End: Memory Requirement: 3979.2666015625 MiB

******************************
Loading Dataset
******************************
Generating Samples
******************************
Prepare Validation Dataset
