{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random\n",
    "import argparse\n",
    "import pandas as pd\n",
    "\n",
    "import csv \n",
    "import json\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn \n",
    "\n",
    "from argparse import Namespace\n",
    "from utils.dataset import getData\n",
    "from utils.evaluation import evaluate\n",
    "from transformers import AutoTokenizer, LlamaForCausalLM\n",
    "import torch.nn.init as init\n",
    "from utils.bag_of_words.projection_community import *\n",
    "\n",
    "def set_random_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def l_0_norm(vector):\n",
    "    count = 0\n",
    "    total = 0\n",
    "    for element in vector:\n",
    "        for sub_element in element:\n",
    "            if sub_element != 0:\n",
    "                count += 1\n",
    "    return count\n",
    "def take_average(dict):\n",
    "    data = dict[\"0\"]\n",
    "    iterations_block = list([\"0\",\"1\",\"2\",\"3\",\"4\"])\n",
    "    iterations_channel = list([\"0\",\"1\",\"2\",\"3\",\"4\"])\n",
    "    #for style , iterations in zip ([\"block\",\"channel\",\"block_random\",\"channel_random\"],[iterations_block,iterations_channel,iterations_block,iterations_channel]):\n",
    "    for style , iterations in zip ([\"block\",\"channel\"],[iterations_block,iterations_channel,iterations_block,iterations_channel]):\n",
    "        for iter in iterations:\n",
    "            if iter == \"0\":\n",
    "                continue\n",
    "            for ratio in dict[iter][style]:\n",
    "                for dataset in dict[iter][style][ratio]:\n",
    "                    for norm in dict[iter][style][ratio][dataset]:\n",
    "                        value = np.array(dict[iter][style][ratio][dataset][norm])\n",
    "                        if len( value.shape) != 1:\n",
    "                            shape_model = value.shape\n",
    "                        data[style][ratio][dataset][norm]= (np.array(data[style][ratio][dataset][norm])+value)\n",
    "                        if iter == iterations[-1]:\n",
    "                            data[style][ratio][dataset][norm] = data[style][ratio][dataset][norm]/len(iterations)\n",
    "    return data, shape_model\n",
    "def strip(name):\n",
    "    name = name.split(\"/\")[-1]\n",
    "    name = name.split(\"_\")[0]\n",
    "    return name \n",
    "\n",
    "def loop_over(dict):\n",
    "    if isinstance(dict, list):\n",
    "        print(\"end\")\n",
    "    else: \n",
    "        print(dict.keys())\n",
    "        for keys in dict:\n",
    "            loop_over(dict[keys])\n",
    "        \n",
    "def get_dataset_list(dataset_list):\n",
    "    dataname = []\n",
    "    for data in dataset_list:\n",
    "        if \"subset\" not in dataset_list[data].keys():\n",
    "            dataname.append(data)\n",
    "        else:\n",
    "            for subset in dataset_list[data][\"subset\"]:\n",
    "                dataname.append(subset)\n",
    "    return dataname\n",
    "\n",
    "def find_layers(module, layers=[nn.Linear], name=''):\n",
    "    \"\"\"\n",
    "    Recursively find the layers of a certain type in a module.\n",
    "\n",
    "    Args:\n",
    "        module (nn.Module): PyTorch module.\n",
    "        layers (list): List of layer types to find.\n",
    "        name (str): Name of the module.\n",
    "\n",
    "    Returns:\n",
    "        dict: Dictionary of layers of the given type(s) within the module.\n",
    "    \"\"\"\n",
    "    if type(module) in layers:\n",
    "        return {name: module}\n",
    "    res = {}\n",
    "    for name1, child in module.named_children():\n",
    "        res.update(find_layers(\n",
    "            child, layers=layers, name=name + '.' + name1 if name != '' else name1\n",
    "        ))\n",
    "    return res\n",
    "\n",
    "def create_distribution_llm_pruner(model):\n",
    "    layers = model.model.layers\n",
    "    distribution_2 = []\n",
    "    count = 0 \n",
    "    total_params = 0\n",
    "    for i in range(len(layers)):\n",
    "        layer = layers[i]\n",
    "        subset = find_layers(layer)\n",
    "        layer_values_2 = []\n",
    "        for name in subset:\n",
    "            W = subset[name].weight.data\n",
    "            count += (W==0).sum().item()\n",
    "            total_params += W.numel()\n",
    "            layer_values_2.append(torch.linalg.matrix_norm(W, ord=float(\"Inf\")).item()) #|W|_inf norm\n",
    "        distribution_2.append(layer_values_2)\n",
    "    return  np.array(distribution_2)\n",
    "\n",
    "\n",
    "def get_model(model_name):\n",
    "    if model_name == \"llama\":\n",
    "        base_model = \"meta-llama/Llama-2-7b-hf\"\n",
    "    elif model_name == \"llama_chat\":\n",
    "        base_model = \"meta-llama/Llama-2-7b-chat-hf\"\n",
    "    elif model_name == \"vicuna\":\n",
    "        base_model = \"lmsys/vicuna-7b-v1.5\"\n",
    "    torch.cuda.empty_cache()\n",
    "    tokenizer = AutoTokenizer.from_pretrained(base_model)\n",
    "    model = LlamaForCausalLM.from_pretrained(\n",
    "        base_model,\n",
    "        low_cpu_mem_usage=True #if args.torch_version >=1.9 else False,\n",
    "    )\n",
    "    return model, tokenizer\n",
    "def create_distribution_llm_pruner(model):\n",
    "    layers = model.model.layers\n",
    "    distribution_2 = []\n",
    "    count = 0 \n",
    "    total_params = 0\n",
    "    for i in range(len(layers)):\n",
    "        layer = layers[i]\n",
    "        subset = find_layers(layer)\n",
    "        layer_values_2 = []\n",
    "        for name in subset:\n",
    "            W = subset[name].weight.data\n",
    "            count += (W==0).sum().item()\n",
    "            total_params += W.numel()\n",
    "            layer_values_2.append(torch.linalg.matrix_norm(W, ord=float(\"Inf\")).item()) #|W|_inf norm\n",
    "        distribution_2.append(layer_values_2)\n",
    "    return  np.array(distribution_2)\n",
    "\n",
    "def randomize_model(model, modules_list, alpha_scale=0.01):\n",
    "    modules_to_reinit = [(int(m.split(\"_\")[0]),m.split(\"_\")[1]) for m in modules_list]\n",
    "    layers = model.model.layers\n",
    "    for idx_layer, module in modules_to_reinit:\n",
    "        layer = layers[idx_layer]\n",
    "        #print(idx_layer, module)\n",
    "        for name1, child1 in layer.named_children():\n",
    "            #print(\"Name1\",name1)\n",
    "            for name2, child2 in child1.named_children():\n",
    "                #print(\"Name2\",name2)\n",
    "                if f\"{name1}.{name2}\" == f\"{module}_proj\" or f\"{name1}.{name2}\" == f\"self_{module}_proj\" :\n",
    "                    # Loop over all parameters in the module and apply custom random initialization\n",
    "                    for param in child2.parameters():\n",
    "                        if param.requires_grad:  # Ensure the parameter is trainable\n",
    "                            #std = param.std().item()\n",
    "                            #print(std, end=\", \")\n",
    "                            noise = torch.randn_like(param) * alpha_scale # Small noise\n",
    "                            param.data += noise\n",
    "                            '''if param.dim() > 1:  # Initialize weights\n",
    "                                init.kaiming_uniform_(param, a=0.01)\n",
    "                            else:  # Initialize biases\n",
    "                                init.constant_(param, 0)'''\n",
    "    return model\n",
    "\n",
    "def flatten_comprehension(matrix):\n",
    "     return [item for row in matrix for item in row]\n",
    "\n",
    "\n",
    "def get_all_dataset_list(dataset_info_list, dataset_list):\n",
    "    dataname = []\n",
    "    for d in dataset_list:\n",
    "        for data in dataset_info_list:\n",
    "            if \"subset\" not in dataset_info_list[data].keys():\n",
    "                if  data == d:\n",
    "                    dataname.append(data)\n",
    "                    continue\n",
    "            else:\n",
    "                if d in dataset_info_list[data][\"subset\"]:\n",
    "                    dataname.append([data,d])\n",
    "                    continue\n",
    "    return dataname\n",
    "\n",
    "def get_high_low_datasets(community, top_skill= 50): \n",
    "    return community[\"dataset\"][\"all\"][:top_skill], community[\"dataset\"][\"all\"][-top_skill:]\n",
    "\n",
    "def pick_largest_community(community_data_lists): \n",
    "    size = -1\n",
    "    community_idx = None\n",
    "    for comm_name, community in community_data_lists.items():\n",
    "        if len(community[\"dataset\"]) > size:\n",
    "            size = len(community[\"dataset\"])\n",
    "            community_idx = comm_name\n",
    "    non_idx_community = [idx for idx in community_data_lists if idx !=  community_idx]\n",
    "    return (community_idx, size),community_data_lists[community_idx][\"dataset\"], flatten_comprehension([community_data_lists[non_idx][\"dataset\"] for non_idx in non_idx_community])\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def get_modulesCommunityDataset(sparsity_ratio):\n",
    "    with open(\"./dataset_info.json\", 'r') as openfile:\n",
    "        # Reading from json file\n",
    "        dataset_info_list = json.load(openfile)\n",
    "    dataset_list = get_dataset_list(dataset_info_list)\n",
    "    #Original Distribution\n",
    "    with open(\"result/original_distribution_vicuna_7b.json\", 'r') as openfile:\n",
    "        vicuna_original = json.load(openfile)\n",
    "    with open(\"result/original_distribution_llama_7b.json\", 'r') as openfile:\n",
    "        # Reading from json file\n",
    "        llama_original = json.load(openfile)\n",
    "    with open(\"result/original_distribution_llama_7b-chat.json\", 'r') as openfile:\n",
    "        # Reading from json file\n",
    "        llama_chat_original = json.load(openfile)\n",
    "    #Pruned Distribution\n",
    "    with open(\"result/distribution_llama_7b.json\", 'r') as openfile:\n",
    "        # Reading from json file\n",
    "        llama_distribution = json.load(openfile)\n",
    "    with open(\"result/distribution_vicuna_7b.json\", 'r') as openfile:\n",
    "        # Reading from json file\n",
    "        vicuna_distribution = json.load(openfile)\n",
    "    with open(\"result/distribution_llama_7b-chat.json\", 'r') as openfile:\n",
    "        # Reading from json file\n",
    "        llama_chat_distribution= json.load(openfile)\n",
    "    with open(\"result/dataMultidisciplinaryCognitiveSkillsFrameworkRestrict.json\", 'r') as openfile:\n",
    "        dataCategory = json.load(openfile)\n",
    "\n",
    "    llama_distribution, _ = take_average(llama_distribution)\n",
    "    vicuna_distribution, _ = take_average(vicuna_distribution)\n",
    "    llama_chat_distribution, _ = take_average(llama_chat_distribution)\n",
    "    \n",
    "    distribution_dist = [llama_distribution,llama_chat_distribution,vicuna_distribution]\n",
    "    original_dist = [llama_original,llama_chat_original,vicuna_original]    \n",
    "\n",
    "    modules_community_dataset = create_projection_network(dataCategory,dataset_list, distribution_dist, original_dist, sparsity_ratio = sparsity_ratio, random_seed=True)\n",
    "    \n",
    "    return modules_community_dataset,dataset_info_list, dataset_list\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_original_model(model_name):\n",
    "    if model_name == \"llama\":\n",
    "        with open(\"result/original_distribution_llama_7b.json\", 'r') as openfile:\n",
    "            org = json.load(openfile)\n",
    "    elif model_name == \"llama_chat\":\n",
    "        with open(\"result/original_distribution_llama_7b-chat.json\", 'r') as openfile:\n",
    "            # Reading from json file\n",
    "            org = json.load(openfile)\n",
    "    elif model_name == \"vicuna\":\n",
    "        with open(\"result/original_distribution_vicuna_7b.json\", 'r') as openfile:\n",
    "            org = json.load(openfile)\n",
    "    return org"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "saved_file = pd.read_csv(f\"./result/randomize_accuracy/randomize_data_new_{str(i)}.csv\", index_col=0)\n",
    "set_random_seed(int(i))\n",
    "sparsity_ratio = \"20\"\n",
    "data = {\"iteration\":[],\"model\":[],\"pruning_style\":[],\"community\":[],\"pruning_ratio\":[],\"dataset\":[],\"accuracy\":[],\"rank\":[],\"modules\":[],\"alpha_scale\":[]}\n",
    "modules_community_dataset,dataset_info_list, dataset_list = get_modulesCommunityDataset(sparsity_ratio)\n",
    "#\"pruner_style\",\"model\",\"sparsity_ratio\",\"community\"\n",
    "iteration = 0 \n",
    "for idx, model_name in enumerate(modules_community_dataset[\"model\"]):\n",
    "    for alpha_scale in [0.1,0.075,0.05,0.025,0.01]:\n",
    "        print(idx, model_name,alpha_scale, modules_community_dataset[\"pruner_style\"][idx])\n",
    "        community_data_lists = modules_community_dataset[\"community\"][idx]\n",
    "        community_data_lists[\"-1\"] = None\n",
    "        module_dataset = random.sample(dataset_list, 50)\n",
    "        module_dataset_info_format = get_all_dataset_list(dataset_info_list, module_dataset)\n",
    "        print(\"Random Dataset\",module_dataset, flush=True)\n",
    "        for comm_name, community in community_data_lists.items():\n",
    "            print(\"Community Name:\",comm_name)\n",
    "            if comm_name == \"-1\":\n",
    "                module_list = []\n",
    "                print(\"Community Rank: Original Model\", flush=True)\n",
    "            else:\n",
    "                #if not KL then no need for \"all\"\n",
    "                print(\"Community Rank\",modules_community_dataset[\"community\"][idx][comm_name][\"dataset\"], flush=True)\n",
    "                module_list =  community[\"modules\"]\n",
    "            #tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n",
    "            module_accuracy = []\n",
    "            for dataset_name_label,dataset_name in zip(module_dataset, module_dataset_info_format):\n",
    "                if comm_name == \"-1\":\n",
    "                    rank = None\n",
    "                else:\n",
    "                    #if not KL then no need for \"all\"\n",
    "                    rank = modules_community_dataset[\"community\"][idx][comm_name][\"dataset\"].index(dataset_name_label)\n",
    "                row_from_saved_file = saved_file[(saved_file[\"pruning_style\"]==modules_community_dataset[\"pruner_style\"][idx]) & (saved_file[\"model\"]==model_name) & (saved_file[\"community\"]==comm_name)& (saved_file[\"dataset\"]==dataset_name_label)& (saved_file[\"alpha_scale\"]==alpha_scale)][\"accuracy\"].tolist()\n",
    "                if len(row_from_saved_file) == 1 and comm_name != \"-1\":\n",
    "                    data[\"accuracy\"].append(row_from_saved_file[0])\n",
    "                else:\n",
    "                    break\n",
    "                data[\"iteration\"].append(int(i))\n",
    "                data[\"model\"].append(model_name)\n",
    "                data[\"pruning_style\"].append(modules_community_dataset[\"pruner_style\"][idx])\n",
    "                data[\"community\"].append(comm_name)\n",
    "                data[\"pruning_ratio\"].append(sparsity_ratio)\n",
    "                data[\"dataset\"].append(dataset_name_label)\n",
    "                data[\"rank\"].append(rank)\n",
    "                data[\"modules\"].append(module_list)\n",
    "                data[\"alpha_scale\"].append(alpha_scale)\n",
    "                \n",
    "                #print(data[\"accuracy\"])\n",
    "                iteration += 1\n",
    "            print(module_list)\n",
    "            print(\"Module Accuracy\",comm_name,rank,module_accuracy, flush=True)\n",
    "        print(\"++\"*100)\n",
    "        df = pd.DataFrame(data)\n",
    "        print(df.head())\n",
    "        print(\"++\"*100)\n",
    "        #df.to_csv(f'./result/randomize_accuracy/randomize_data_new_{i}.csv') \n",
    "#df = pd.DataFrame(data)\n",
    "#df.to_csv(f'./result/randomize_accuracy/randomize_data_new_{i}.csv') \n",
    "print(iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(5):\n",
    "     set_random_seed(int(i))\n",
    "     sparsity_ratio = \"20\"\n",
    "     saved_file = pd.read_csv(f\"./result/randomize_accuracy/randomize_data_new_{str(i)}.csv\", index_col=0)\n",
    "     #key_list =['iteration', 'model', 'pruning_style', 'community', 'pruning_ratio', 'dataset', 'accuracy', 'rank', 'modules', 'alpha_scale']\n",
    "     key_list =['iteration', 'model', 'pruning_style', 'community', 'pruning_ratio', 'dataset', 'accuracy', 'rank_kl',\"rank_network\", 'modules']\n",
    "     key_list_wo_rank =['iteration', 'model', 'pruning_style', 'community', 'pruning_ratio', 'dataset', 'accuracy', 'modules']\n",
    "     data = {key:[] for key in key_list}\n",
    "     modules_community_dataset,dataset_info_list, dataset_list = get_modulesCommunityDataset(sparsity_ratio)\n",
    "     for index, row in saved_file.iterrows():\n",
    "          for key in  key_list_wo_rank:\n",
    "               data[key].append(row[key])\n",
    "\n",
    "          dataset_name_label = row[\"dataset\"]\n",
    "          comm_name = row[\"community\"]\n",
    "          if row[\"model\"] == \"llama\" and row[\"pruning_style\"] == \"block\":\n",
    "               idx, model_name = 0, \"llama\"\n",
    "          elif row[\"model\"] == \"llama_chat\" and row[\"pruning_style\"] == \"block\":\n",
    "               idx, model_name = 1, \"llama_chat\" \n",
    "          elif row[\"model\"] == \"vicuna\" and row[\"pruning_style\"] == \"block\":\n",
    "               idx, model_name = 2, \"vicuna\"\n",
    "          elif row[\"model\"] == \"llama\" and row[\"pruning_style\"] == \"channel\":\n",
    "               idx, model_name = 3, \"llama\"\n",
    "          elif row[\"model\"] == \"llama_chat\" and row[\"pruning_style\"] == \"channel\":\n",
    "               idx, model_name = 4, \"llama_chat\" \n",
    "          elif row[\"model\"] == \"vicuna\" and row[\"pruning_style\"] == \"channel\":\n",
    "               idx, model_name = 5, \"vicuna\"\n",
    "\n",
    "          if comm_name == -1:\n",
    "               data[\"rank_kl\"].append(None)\n",
    "               data[\"rank_network\"].append(None)\n",
    "          else:\n",
    "               data[\"rank_network\"].append(row[\"rank\"])\n",
    "               data[\"rank_kl\"].append(modules_community_dataset[\"community\"][\"kl\"][idx][comm_name][\"dataset\"][\"all\"].index(dataset_name_label))\n",
    "               #data[\"rank_network\"].append(modules_community_dataset[\"community\"][\"network\"][idx][comm_name][\"dataset\"].index(dataset_name_label))\n",
    "     df = pd.DataFrame(data)\n",
    "     print(df.head())\n",
    "     df.to_csv(f'./result/randomize_accuracy/randomize_data_new_{str(i)}.csv') \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "all = pd.read_csv(f\"/home/bhandk/MLNeuron/result/randomize_accuracy/randomize_data_new_kl_0.csv\", index_col=0)\n",
    "rand = pd.read_csv(f\"/home/bhandk/MLNeuron/result/randomize_accuracy/randomize_data_new_kl_random_0.csv\", index_col=0)\n",
    "all[\"finetune\"] = all[\"finetune\"].fillna(\"None\")\n",
    "rand[\"finetune\"] = rand[\"finetune\"].fillna(\"None\")\n",
    "new_rand = pd.concat([all, rand], axis=0)\n",
    "new_rand = new_rand.sort_values([\"model\",\"pruning_style\",\"community\",\"rank\"])\n",
    "\n",
    "new_rand.to_csv(f'./result/randomize_accuracy/randomize_data_new_kl_0.csv',index=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 2\n",
    "set_random_seed(int(i))\n",
    "sparsity_ratio = \"20\"\n",
    "#key_list =['iteration', 'model', 'pruning_style', 'community', 'pruning_ratio', 'dataset', 'accuracy', 'rank', 'modules', 'alpha_scale']\n",
    "key_list =['iteration', 'model', 'pruning_style', 'community', 'pruning_ratio', 'dataset', 'accuracy', 'rank_kl',\"rank_network\", 'modules']\n",
    "key_list_wo_rank =['iteration', 'model', 'pruning_style', 'community', 'pruning_ratio', 'dataset', 'accuracy', 'modules']\n",
    "data = {key:[] for key in key_list}\n",
    "modules_community_dataset,dataset_info_list, dataset_list = get_modulesCommunityDataset(sparsity_ratio)\n",
    "print(modules_community_dataset)\n",
    "for comm in modules_community_dataset[\"community\"][\"kl\"][0]:\n",
    "    print(comm,\":\")\n",
    "    print(\"\\t\",modules_community_dataset[\"community\"][\"kl\"][0][comm][\"modules\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLNeuron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
