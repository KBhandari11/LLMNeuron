{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from ast import literal_eval\n",
    "from scipy.stats import ttest_ind, pearsonr, spearmanr\n",
    "df = pd.read_csv('result/randomize_accuracy/randomize_data_new_kl_2.csv')\n",
    "df[\"loss\"] = df[\"loss\"].apply(lambda x: [float(xx) for xx in literal_eval(x)])\n",
    "df[\"final_loss\"] = df[\"loss\"].apply(lambda x: x[-1])\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby(['iteration', 'model', 'pruning_style', 'pruning_ratio'])\n",
    "for group_name, grouped_df in grouped:\n",
    "    print(group_name)\n",
    "    all_df = grouped_df[grouped_df['finetune'] == 'All']  # Replace 'modules' with actual label if different\n",
    "    actual_df = grouped_df[grouped_df['finetune'] == 'Community']  # Replace 'modules' with actual label if different\n",
    "    random_df = grouped_df[grouped_df['finetune'] == 'Random']  # Replace 'modules' with random label if different\n",
    "\n",
    "    \n",
    "    '''# Compare model L2 norm distributions\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.kdeplot(data = grouped_df, x='model_l2', hue=\"finetune\", palette=[\"C0\", \"C1\", \"C2\"]) \n",
    "    plt.title(f'Model L2 Norm Distribution | {group_name}')\n",
    "    plt.xlabel('L2 Norm')\n",
    "    plt.ylabel('Density')\n",
    "    plt.show()'''\n",
    "\n",
    "    # Correlation between L2 norm and final loss per epoch\n",
    "    all_l2_loss_corr, _ = pearsonr(all_df['model_l2'].tolist(), all_df['final_loss'].tolist())\n",
    "    actual_l2_loss_corr, _ = pearsonr(actual_df['model_l2'].tolist(), actual_df['final_loss'].tolist())\n",
    "    random_l2_loss_corr, _ = pearsonr(random_df['model_l2'].tolist(), random_df['final_loss'].tolist())\n",
    "    print(f'Correlation between L2 norm and final loss(All): {all_l2_loss_corr}')\n",
    "    print(f'Correlation between L2 norm and final loss(Actual): {actual_l2_loss_corr}')\n",
    "    print(f'Correlation between L2 norm and final loss(Random): {random_l2_loss_corr}')\n",
    "\n",
    "    # T-test on accuracy between actual and Randoms\n",
    "    t_stat, p_val = ttest_ind(actual_df['accuracy'], random_df['accuracy'])\n",
    "    print(f'T-test for accuracy difference between actual and Randoms: t-stat={t_stat}, p-value={p_val}')\n",
    "\n",
    "\n",
    "\n",
    "    # Loss and accuracy correlation\n",
    "    all_loss_accuracy_corr, _ = spearmanr(all_df['final_loss'], all_df['accuracy'])\n",
    "    actual_loss_accuracy_corr, _ = spearmanr(actual_df['final_loss'], actual_df['accuracy'])\n",
    "    random_loss_accuracy_corr, _ = spearmanr(random_df['final_loss'], random_df['accuracy'])\n",
    "    print(f'Spearman correlation between loss and accuracy (All): {all_loss_accuracy_corr}')\n",
    "    print(f'Spearman correlation between loss and accuracy (Actual): {actual_loss_accuracy_corr}')\n",
    "    print(f'Spearman correlation between loss and accuracy (Random): {random_loss_accuracy_corr}')\n",
    "    \n",
    "    fig, [axx,ax0,ax1,axll] = plt.subplots(figsize=(24, 6),ncols=4)\n",
    "\n",
    "    # Scatter plot with hue for different modules\n",
    "    #sns.scatterplot(data=grouped_df, x='model_l2', y='accuracy', hue='finetune')\n",
    "    sns.kdeplot(data = grouped_df, x='model_l2', hue=\"finetune\", palette=[\"C0\", \"C1\", \"C2\"],ax=axx) \n",
    "    sns.boxplot(data=grouped_df, x='finetune', y='accuracy', palette=[\"C0\", \"C1\", \"C2\"],ax=axll)\n",
    "\n",
    "    sns.scatterplot(data=grouped_df[grouped_df[\"finetune\"]!=\"All\"], x='model_l2', y='accuracy', hue='finetune', palette=[\"C1\", \"C2\"],ax=ax0)\n",
    "    sns.scatterplot(data=grouped_df[grouped_df[\"finetune\"]!=\"All\"], x='model_l2', y='final_loss', hue='finetune', palette=[\"C1\", \"C2\"],ax=ax1)\n",
    "\n",
    "    # Fit and plot a line of best fit for each module subset\n",
    "    #for finetune, subset in [(\"All\",all_df,\"C0\"),(\"Community\",actual_df,\"C1\" ),(\"Random\", random_df,\"C2\")]:\n",
    "    for finetune, subset, color in [(\"Community\",actual_df,\"C1\" ),(\"Random\", random_df,\"C2\")]:\n",
    "        slope, intercept = np.polyfit(subset['model_l2'], subset['accuracy'], 1)\n",
    "        ax0.plot(subset['model_l2'], slope * subset[\"model_l2\"] + intercept, color=color)\n",
    "        slope, intercept = np.polyfit(subset['model_l2'], subset['final_loss'], 1)\n",
    "        ax1.plot(subset['model_l2'], slope * subset[\"model_l2\"] + intercept, color=color)\n",
    "        ax1.set_ylim(ymin=0)\n",
    "    # Add labels and title\n",
    "    ax0.set_xlabel('Model L2 Norm')\n",
    "    ax0.set_ylabel('Accuracy')\n",
    "    ax1.set_ylabel('Final Loss')\n",
    "    fig.suptitle(f'{group_name}\\nMagnitude of Weight (L2) w.r.t Accuracy and Loss')\n",
    "    plt.show()\n",
    "\n",
    "    print(\"+\"*500)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MLNeuron",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
